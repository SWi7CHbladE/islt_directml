2023-11-28 13:20:14,367 Hello! This is Joey-NMT.
2023-11-28 13:20:14,369 Total params: 24931848
2023-11-28 13:20:14,369 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2023-11-28 13:20:15,001 cfg.name                           : sign_experiment
2023-11-28 13:20:15,001 cfg.data.data_path                 : ./data/
2023-11-28 13:20:15,001 cfg.data.version                   : phoenix_2014_trans
2023-11-28 13:20:15,001 cfg.data.sgn                       : sign
2023-11-28 13:20:15,001 cfg.data.txt                       : text
2023-11-28 13:20:15,001 cfg.data.gls                       : gloss
2023-11-28 13:20:15,001 cfg.data.train                     : excel_data.train
2023-11-28 13:20:15,001 cfg.data.dev                       : excel_data.dev
2023-11-28 13:20:15,001 cfg.data.test                      : excel_data.test
2023-11-28 13:20:15,001 cfg.data.feature_size              : 2560
2023-11-28 13:20:15,001 cfg.data.level                     : word
2023-11-28 13:20:15,001 cfg.data.txt_lowercase             : True
2023-11-28 13:20:15,001 cfg.data.max_sent_length           : 400
2023-11-28 13:20:15,001 cfg.data.random_train_subset       : -1
2023-11-28 13:20:15,001 cfg.data.random_dev_subset         : -1
2023-11-28 13:20:15,001 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2023-11-28 13:20:15,002 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2023-11-28 13:20:15,002 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2023-11-28 13:20:15,002 cfg.training.reset_best_ckpt       : False
2023-11-28 13:20:15,002 cfg.training.reset_scheduler       : False
2023-11-28 13:20:15,002 cfg.training.reset_optimizer       : False
2023-11-28 13:20:15,002 cfg.training.random_seed           : 42
2023-11-28 13:20:15,002 cfg.training.model_dir             : ./sign_sample_model
2023-11-28 13:20:15,002 cfg.training.recognition_loss_weight : 1.0
2023-11-28 13:20:15,002 cfg.training.translation_loss_weight : 1.0
2023-11-28 13:20:15,002 cfg.training.eval_metric           : bleu
2023-11-28 13:20:15,002 cfg.training.optimizer             : adam
2023-11-28 13:20:15,002 cfg.training.learning_rate         : 0.001
2023-11-28 13:20:15,002 cfg.training.batch_size            : 256
2023-11-28 13:20:15,002 cfg.training.num_valid_log         : 5
2023-11-28 13:20:15,002 cfg.training.epochs                : 50000
2023-11-28 13:20:15,002 cfg.training.early_stopping_metric : eval_metric
2023-11-28 13:20:15,002 cfg.training.batch_type            : sentence
2023-11-28 13:20:15,002 cfg.training.translation_normalization : batch
2023-11-28 13:20:15,002 cfg.training.eval_recognition_beam_size : 1
2023-11-28 13:20:15,002 cfg.training.eval_translation_beam_size : 1
2023-11-28 13:20:15,003 cfg.training.eval_translation_beam_alpha : -1
2023-11-28 13:20:15,003 cfg.training.overwrite             : True
2023-11-28 13:20:15,003 cfg.training.shuffle               : True
2023-11-28 13:20:15,003 cfg.training.use_cuda              : True
2023-11-28 13:20:15,003 cfg.training.translation_max_output_length : 30
2023-11-28 13:20:15,003 cfg.training.keep_last_ckpts       : 1
2023-11-28 13:20:15,003 cfg.training.batch_multiplier      : 1
2023-11-28 13:20:15,003 cfg.training.logging_freq          : 100
2023-11-28 13:20:15,003 cfg.training.validation_freq       : 100
2023-11-28 13:20:15,003 cfg.training.betas                 : [0.9, 0.998]
2023-11-28 13:20:15,003 cfg.training.scheduling            : plateau
2023-11-28 13:20:15,003 cfg.training.learning_rate_min     : 1e-07
2023-11-28 13:20:15,003 cfg.training.weight_decay          : 0.001
2023-11-28 13:20:15,003 cfg.training.patience              : 8
2023-11-28 13:20:15,003 cfg.training.decrease_factor       : 0.7
2023-11-28 13:20:15,004 cfg.training.label_smoothing       : 0.0
2023-11-28 13:20:15,004 cfg.model.initializer              : xavier
2023-11-28 13:20:15,004 cfg.model.bias_initializer         : zeros
2023-11-28 13:20:15,004 cfg.model.init_gain                : 1.0
2023-11-28 13:20:15,004 cfg.model.embed_initializer        : xavier
2023-11-28 13:20:15,004 cfg.model.embed_init_gain          : 1.0
2023-11-28 13:20:15,004 cfg.model.tied_softmax             : False
2023-11-28 13:20:15,004 cfg.model.encoder.type             : transformer
2023-11-28 13:20:15,004 cfg.model.encoder.num_layers       : 3
2023-11-28 13:20:15,004 cfg.model.encoder.num_heads        : 8
2023-11-28 13:20:15,004 cfg.model.encoder.embeddings.embedding_dim : 512
2023-11-28 13:20:15,004 cfg.model.encoder.embeddings.scale : False
2023-11-28 13:20:15,004 cfg.model.encoder.embeddings.dropout : 0.1
2023-11-28 13:20:15,004 cfg.model.encoder.embeddings.norm_type : batch
2023-11-28 13:20:15,004 cfg.model.encoder.embeddings.activation_type : softsign
2023-11-28 13:20:15,004 cfg.model.encoder.hidden_size      : 512
2023-11-28 13:20:15,004 cfg.model.encoder.ff_size          : 2048
2023-11-28 13:20:15,004 cfg.model.encoder.dropout          : 0.2
2023-11-28 13:20:15,004 cfg.model.decoder.type             : transformer
2023-11-28 13:20:15,005 cfg.model.decoder.num_layers       : 3
2023-11-28 13:20:15,005 cfg.model.decoder.num_heads        : 8
2023-11-28 13:20:15,005 cfg.model.decoder.embeddings.embedding_dim : 512
2023-11-28 13:20:15,005 cfg.model.decoder.embeddings.scale : False
2023-11-28 13:20:15,005 cfg.model.decoder.embeddings.dropout : 0.1
2023-11-28 13:20:15,005 cfg.model.decoder.embeddings.norm_type : batch
2023-11-28 13:20:15,005 cfg.model.decoder.embeddings.activation_type : softsign
2023-11-28 13:20:15,005 cfg.model.decoder.hidden_size      : 512
2023-11-28 13:20:15,005 cfg.model.decoder.ff_size          : 2048
2023-11-28 13:20:15,005 cfg.model.decoder.dropout          : 0.2
2023-11-28 13:20:15,005 Data set sizes: 
	train 407,
	valid 134,
	test 134
2023-11-28 13:20:15,005 First training example:
	[GLS] A B C D E
	[TXT] on 1st february 2022 finance minister nirmala sitharaman at the parliament
2023-11-28 13:20:15,005 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) A (4) B (5) C (6) D (7) E
2023-11-28 13:20:15,005 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) to (6) and (7) of (8) in (9) a
2023-11-28 13:20:15,005 Number of unique glosses (types): 8
2023-11-28 13:20:15,005 Number of unique words (types): 1507
2023-11-28 13:20:15,005 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=8),
	decoder=TransformerDecoder(num_layers=3, num_heads=8),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=2560),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=1507))
2023-11-28 13:20:15,006 EPOCH 1
2023-11-28 13:20:16,745 Epoch   1: Total Training Recognition Loss 35.22  Total Training Translation Loss 220.85 
2023-11-28 13:20:16,745 EPOCH 2
2023-11-28 13:20:17,813 Epoch   2: Total Training Recognition Loss 28.17  Total Training Translation Loss 204.01 
2023-11-28 13:20:17,813 EPOCH 3
2023-11-28 13:20:19,013 Epoch   3: Total Training Recognition Loss 16.95  Total Training Translation Loss 192.06 
2023-11-28 13:20:19,013 EPOCH 4
2023-11-28 13:20:20,076 Epoch   4: Total Training Recognition Loss 20.16  Total Training Translation Loss 184.01 
2023-11-28 13:20:20,076 EPOCH 5
2023-11-28 13:20:21,142 Epoch   5: Total Training Recognition Loss 13.60  Total Training Translation Loss 180.25 
2023-11-28 13:20:21,142 EPOCH 6
2023-11-28 13:20:22,265 Epoch   6: Total Training Recognition Loss 14.74  Total Training Translation Loss 176.19 
2023-11-28 13:20:22,265 EPOCH 7
2023-11-28 13:20:23,332 Epoch   7: Total Training Recognition Loss 14.34  Total Training Translation Loss 174.91 
2023-11-28 13:20:23,332 EPOCH 8
2023-11-28 13:20:24,397 Epoch   8: Total Training Recognition Loss 12.80  Total Training Translation Loss 176.03 
2023-11-28 13:20:24,398 EPOCH 9
2023-11-28 13:20:25,484 Epoch   9: Total Training Recognition Loss 11.75  Total Training Translation Loss 174.79 
2023-11-28 13:20:25,484 EPOCH 10
2023-11-28 13:20:26,573 Epoch  10: Total Training Recognition Loss 11.50  Total Training Translation Loss 174.41 
2023-11-28 13:20:26,573 EPOCH 11
2023-11-28 13:20:27,663 Epoch  11: Total Training Recognition Loss 11.82  Total Training Translation Loss 174.56 
2023-11-28 13:20:27,664 EPOCH 12
2023-11-28 13:20:28,730 Epoch  12: Total Training Recognition Loss 11.25  Total Training Translation Loss 174.27 
2023-11-28 13:20:28,730 EPOCH 13
2023-11-28 13:20:29,794 Epoch  13: Total Training Recognition Loss 10.65  Total Training Translation Loss 174.03 
2023-11-28 13:20:29,795 EPOCH 14
2023-11-28 13:20:30,868 Epoch  14: Total Training Recognition Loss 9.85  Total Training Translation Loss 173.76 
2023-11-28 13:20:30,868 EPOCH 15
2023-11-28 13:20:31,940 Epoch  15: Total Training Recognition Loss 9.05  Total Training Translation Loss 173.66 
2023-11-28 13:20:31,941 EPOCH 16
2023-11-28 13:20:33,024 Epoch  16: Total Training Recognition Loss 8.50  Total Training Translation Loss 173.60 
2023-11-28 13:20:33,024 EPOCH 17
2023-11-28 13:20:34,092 Epoch  17: Total Training Recognition Loss 7.92  Total Training Translation Loss 173.57 
2023-11-28 13:20:34,093 EPOCH 18
2023-11-28 13:20:35,170 Epoch  18: Total Training Recognition Loss 7.53  Total Training Translation Loss 173.45 
2023-11-28 13:20:35,170 EPOCH 19
2023-11-28 13:20:36,286 Epoch  19: Total Training Recognition Loss 7.26  Total Training Translation Loss 173.27 
2023-11-28 13:20:36,287 EPOCH 20
