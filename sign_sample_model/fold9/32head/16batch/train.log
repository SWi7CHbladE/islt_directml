2024-02-04 04:04:44,420 Hello! This is Joey-NMT.
2024-02-04 04:04:44,428 Total params: 25639944
2024-02-04 04:04:44,428 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2024-02-04 04:04:45,402 cfg.name                           : sign_experiment
2024-02-04 04:04:45,402 cfg.data.data_path                 : ./data/Sports_dataset/9/
2024-02-04 04:04:45,402 cfg.data.version                   : phoenix_2014_trans
2024-02-04 04:04:45,402 cfg.data.sgn                       : sign
2024-02-04 04:04:45,402 cfg.data.txt                       : text
2024-02-04 04:04:45,403 cfg.data.gls                       : gloss
2024-02-04 04:04:45,403 cfg.data.train                     : excel_data.train
2024-02-04 04:04:45,403 cfg.data.dev                       : excel_data.dev
2024-02-04 04:04:45,403 cfg.data.test                      : excel_data.test
2024-02-04 04:04:45,403 cfg.data.feature_size              : 2560
2024-02-04 04:04:45,403 cfg.data.level                     : word
2024-02-04 04:04:45,403 cfg.data.txt_lowercase             : True
2024-02-04 04:04:45,403 cfg.data.max_sent_length           : 500
2024-02-04 04:04:45,403 cfg.data.random_train_subset       : -1
2024-02-04 04:04:45,404 cfg.data.random_dev_subset         : -1
2024-02-04 04:04:45,404 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-02-04 04:04:45,404 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-02-04 04:04:45,404 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2024-02-04 04:04:45,404 cfg.training.reset_best_ckpt       : False
2024-02-04 04:04:45,404 cfg.training.reset_scheduler       : False
2024-02-04 04:04:45,404 cfg.training.reset_optimizer       : False
2024-02-04 04:04:45,404 cfg.training.random_seed           : 42
2024-02-04 04:04:45,405 cfg.training.model_dir             : ./sign_sample_model/fold9/32head/16batch
2024-02-04 04:04:45,405 cfg.training.recognition_loss_weight : 1.0
2024-02-04 04:04:45,405 cfg.training.translation_loss_weight : 1.0
2024-02-04 04:04:45,405 cfg.training.eval_metric           : bleu
2024-02-04 04:04:45,405 cfg.training.optimizer             : adam
2024-02-04 04:04:45,405 cfg.training.learning_rate         : 0.0001
2024-02-04 04:04:45,405 cfg.training.batch_size            : 16
2024-02-04 04:04:45,405 cfg.training.num_valid_log         : 5
2024-02-04 04:04:45,405 cfg.training.epochs                : 50000
2024-02-04 04:04:45,406 cfg.training.early_stopping_metric : eval_metric
2024-02-04 04:04:45,406 cfg.training.batch_type            : sentence
2024-02-04 04:04:45,406 cfg.training.translation_normalization : batch
2024-02-04 04:04:45,406 cfg.training.eval_recognition_beam_size : 1
2024-02-04 04:04:45,406 cfg.training.eval_translation_beam_size : 1
2024-02-04 04:04:45,406 cfg.training.eval_translation_beam_alpha : -1
2024-02-04 04:04:45,406 cfg.training.overwrite             : True
2024-02-04 04:04:45,406 cfg.training.shuffle               : True
2024-02-04 04:04:45,407 cfg.training.use_cuda              : True
2024-02-04 04:04:45,407 cfg.training.translation_max_output_length : 40
2024-02-04 04:04:45,407 cfg.training.keep_last_ckpts       : 1
2024-02-04 04:04:45,407 cfg.training.batch_multiplier      : 1
2024-02-04 04:04:45,407 cfg.training.logging_freq          : 100
2024-02-04 04:04:45,407 cfg.training.validation_freq       : 2000
2024-02-04 04:04:45,407 cfg.training.betas                 : [0.9, 0.998]
2024-02-04 04:04:45,407 cfg.training.scheduling            : plateau
2024-02-04 04:04:45,407 cfg.training.learning_rate_min     : 1e-08
2024-02-04 04:04:45,408 cfg.training.weight_decay          : 0.0001
2024-02-04 04:04:45,408 cfg.training.patience              : 12
2024-02-04 04:04:45,408 cfg.training.decrease_factor       : 0.5
2024-02-04 04:04:45,408 cfg.training.label_smoothing       : 0.0
2024-02-04 04:04:45,408 cfg.model.initializer              : xavier
2024-02-04 04:04:45,408 cfg.model.bias_initializer         : zeros
2024-02-04 04:04:45,408 cfg.model.init_gain                : 1.0
2024-02-04 04:04:45,409 cfg.model.embed_initializer        : xavier
2024-02-04 04:04:45,409 cfg.model.embed_init_gain          : 1.0
2024-02-04 04:04:45,409 cfg.model.tied_softmax             : True
2024-02-04 04:04:45,409 cfg.model.encoder.type             : transformer
2024-02-04 04:04:45,409 cfg.model.encoder.num_layers       : 3
2024-02-04 04:04:45,409 cfg.model.encoder.num_heads        : 32
2024-02-04 04:04:45,409 cfg.model.encoder.embeddings.embedding_dim : 512
2024-02-04 04:04:45,409 cfg.model.encoder.embeddings.scale : False
2024-02-04 04:04:45,409 cfg.model.encoder.embeddings.dropout : 0.1
2024-02-04 04:04:45,410 cfg.model.encoder.embeddings.norm_type : batch
2024-02-04 04:04:45,410 cfg.model.encoder.embeddings.activation_type : softsign
2024-02-04 04:04:45,410 cfg.model.encoder.hidden_size      : 512
2024-02-04 04:04:45,410 cfg.model.encoder.ff_size          : 2048
2024-02-04 04:04:45,410 cfg.model.encoder.dropout          : 0.1
2024-02-04 04:04:45,410 cfg.model.decoder.type             : transformer
2024-02-04 04:04:45,410 cfg.model.decoder.num_layers       : 3
2024-02-04 04:04:45,410 cfg.model.decoder.num_heads        : 32
2024-02-04 04:04:45,410 cfg.model.decoder.embeddings.embedding_dim : 512
2024-02-04 04:04:45,411 cfg.model.decoder.embeddings.scale : False
2024-02-04 04:04:45,411 cfg.model.decoder.embeddings.dropout : 0.1
2024-02-04 04:04:45,411 cfg.model.decoder.embeddings.norm_type : batch
2024-02-04 04:04:45,411 cfg.model.decoder.embeddings.activation_type : softsign
2024-02-04 04:04:45,411 cfg.model.decoder.hidden_size      : 512
2024-02-04 04:04:45,411 cfg.model.decoder.ff_size          : 2048
2024-02-04 04:04:45,411 cfg.model.decoder.dropout          : 0.1
2024-02-04 04:04:45,411 Data set sizes: 
	train 2126,
	valid 708,
	test 706
2024-02-04 04:04:45,412 First training example:
	[GLS] A B C D E
	[TXT] although new zealand was disappointed to faltered at the finals against australia they did well throughout the tournament
2024-02-04 04:04:45,412 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) A (4) B (5) C (6) D (7) E
2024-02-04 04:04:45,412 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) and (6) to (7) a (8) in (9) of
2024-02-04 04:04:45,412 Number of unique glosses (types): 8
2024-02-04 04:04:45,412 Number of unique words (types): 4397
2024-02-04 04:04:45,412 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=32),
	decoder=TransformerDecoder(num_layers=3, num_heads=32),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=2560),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=4397))
2024-02-04 04:04:45,416 EPOCH 1
2024-02-04 04:04:51,448 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   0.192999 => Gls Tokens per Sec:     1326 || Batch Translation Loss:  82.114212 => Txt Tokens per Sec:     3683 || Lr: 0.000100
2024-02-04 04:04:53,322 Epoch   1: Total Training Recognition Loss 235.40  Total Training Translation Loss 12520.80 
2024-02-04 04:04:53,322 EPOCH 2
2024-02-04 04:04:57,064 [Epoch: 002 Step: 00000200] Batch Recognition Loss:   0.019866 => Gls Tokens per Sec:     1433 || Batch Translation Loss:  87.004219 => Txt Tokens per Sec:     3975 || Lr: 0.000100
2024-02-04 04:05:00,759 Epoch   2: Total Training Recognition Loss 3.24  Total Training Translation Loss 11647.28 
2024-02-04 04:05:00,760 EPOCH 3
2024-02-04 04:05:02,648 [Epoch: 003 Step: 00000300] Batch Recognition Loss:   0.008750 => Gls Tokens per Sec:     1441 || Batch Translation Loss:  64.699432 => Txt Tokens per Sec:     3949 || Lr: 0.000100
2024-02-04 04:05:08,333 Epoch   3: Total Training Recognition Loss 1.27  Total Training Translation Loss 11144.21 
2024-02-04 04:05:08,333 EPOCH 4
2024-02-04 04:05:08,393 [Epoch: 004 Step: 00000400] Batch Recognition Loss:   0.007556 => Gls Tokens per Sec:     1356 || Batch Translation Loss: 101.413605 => Txt Tokens per Sec:     4627 || Lr: 0.000100
2024-02-04 04:05:14,065 [Epoch: 004 Step: 00000500] Batch Recognition Loss:   0.004226 => Gls Tokens per Sec:     1410 || Batch Translation Loss:  60.471687 => Txt Tokens per Sec:     3921 || Lr: 0.000100
2024-02-04 04:05:15,836 Epoch   4: Total Training Recognition Loss 1.00  Total Training Translation Loss 10578.59 
2024-02-04 04:05:15,837 EPOCH 5
2024-02-04 04:05:19,386 [Epoch: 005 Step: 00000600] Batch Recognition Loss:   0.002064 => Gls Tokens per Sec:     1533 || Batch Translation Loss:  74.643112 => Txt Tokens per Sec:     4316 || Lr: 0.000100
2024-02-04 04:05:23,211 Epoch   5: Total Training Recognition Loss 0.86  Total Training Translation Loss 10048.67 
2024-02-04 04:05:23,211 EPOCH 6
2024-02-04 04:05:25,198 [Epoch: 006 Step: 00000700] Batch Recognition Loss:   0.004732 => Gls Tokens per Sec:     1411 || Batch Translation Loss:  60.886265 => Txt Tokens per Sec:     3859 || Lr: 0.000100
2024-02-04 04:05:30,947 Epoch   6: Total Training Recognition Loss 0.91  Total Training Translation Loss 9565.82 
2024-02-04 04:05:30,948 EPOCH 7
2024-02-04 04:05:31,060 [Epoch: 007 Step: 00000800] Batch Recognition Loss:   0.006415 => Gls Tokens per Sec:     1441 || Batch Translation Loss:  42.378590 => Txt Tokens per Sec:     3892 || Lr: 0.000100
2024-02-04 04:05:36,592 [Epoch: 007 Step: 00000900] Batch Recognition Loss:   0.005632 => Gls Tokens per Sec:     1447 || Batch Translation Loss:  69.968918 => Txt Tokens per Sec:     4031 || Lr: 0.000100
2024-02-04 04:05:38,447 Epoch   7: Total Training Recognition Loss 0.76  Total Training Translation Loss 9090.69 
2024-02-04 04:05:38,448 EPOCH 8
2024-02-04 04:05:41,867 [Epoch: 008 Step: 00001000] Batch Recognition Loss:   0.008466 => Gls Tokens per Sec:     1615 || Batch Translation Loss:  51.759972 => Txt Tokens per Sec:     4316 || Lr: 0.000100
2024-02-04 04:05:45,843 Epoch   8: Total Training Recognition Loss 0.83  Total Training Translation Loss 8644.00 
2024-02-04 04:05:45,843 EPOCH 9
2024-02-04 04:05:47,941 [Epoch: 009 Step: 00001100] Batch Recognition Loss:   0.007297 => Gls Tokens per Sec:     1374 || Batch Translation Loss:  59.367970 => Txt Tokens per Sec:     3936 || Lr: 0.000100
2024-02-04 04:05:53,811 Epoch   9: Total Training Recognition Loss 1.00  Total Training Translation Loss 8211.51 
2024-02-04 04:05:53,812 EPOCH 10
2024-02-04 04:05:53,978 [Epoch: 010 Step: 00001200] Batch Recognition Loss:   0.007425 => Gls Tokens per Sec:     1449 || Batch Translation Loss:  35.645149 => Txt Tokens per Sec:     4082 || Lr: 0.000100
2024-02-04 04:05:59,443 [Epoch: 010 Step: 00001300] Batch Recognition Loss:   0.004361 => Gls Tokens per Sec:     1464 || Batch Translation Loss:  61.554497 => Txt Tokens per Sec:     4050 || Lr: 0.000100
2024-02-04 04:06:01,213 Epoch  10: Total Training Recognition Loss 1.08  Total Training Translation Loss 7777.60 
2024-02-04 04:06:01,214 EPOCH 11
2024-02-04 04:06:04,669 [Epoch: 011 Step: 00001400] Batch Recognition Loss:   0.013077 => Gls Tokens per Sec:     1621 || Batch Translation Loss:  54.998573 => Txt Tokens per Sec:     4421 || Lr: 0.000100
2024-02-04 04:06:08,592 Epoch  11: Total Training Recognition Loss 1.15  Total Training Translation Loss 7357.88 
2024-02-04 04:06:08,593 EPOCH 12
2024-02-04 04:06:10,667 [Epoch: 012 Step: 00001500] Batch Recognition Loss:   0.011193 => Gls Tokens per Sec:     1428 || Batch Translation Loss:  47.149269 => Txt Tokens per Sec:     3972 || Lr: 0.000100
2024-02-04 04:06:16,273 Epoch  12: Total Training Recognition Loss 1.26  Total Training Translation Loss 6945.04 
2024-02-04 04:06:16,274 EPOCH 13
2024-02-04 04:06:16,487 [Epoch: 013 Step: 00001600] Batch Recognition Loss:   0.009076 => Gls Tokens per Sec:     1509 || Batch Translation Loss:  53.201324 => Txt Tokens per Sec:     4273 || Lr: 0.000100
2024-02-04 04:06:21,900 [Epoch: 013 Step: 00001700] Batch Recognition Loss:   0.040085 => Gls Tokens per Sec:     1478 || Batch Translation Loss:  48.112804 => Txt Tokens per Sec:     4138 || Lr: 0.000100
2024-02-04 04:06:23,435 Epoch  13: Total Training Recognition Loss 1.44  Total Training Translation Loss 6546.47 
2024-02-04 04:06:23,435 EPOCH 14
2024-02-04 04:06:27,179 [Epoch: 014 Step: 00001800] Batch Recognition Loss:   0.008311 => Gls Tokens per Sec:     1518 || Batch Translation Loss:  33.844940 => Txt Tokens per Sec:     4212 || Lr: 0.000100
2024-02-04 04:06:30,981 Epoch  14: Total Training Recognition Loss 1.53  Total Training Translation Loss 6153.62 
2024-02-04 04:06:30,981 EPOCH 15
2024-02-04 04:06:33,293 [Epoch: 015 Step: 00001900] Batch Recognition Loss:   0.006562 => Gls Tokens per Sec:     1316 || Batch Translation Loss:  38.527763 => Txt Tokens per Sec:     3711 || Lr: 0.000100
2024-02-04 04:06:38,687 Epoch  15: Total Training Recognition Loss 1.67  Total Training Translation Loss 5765.17 
2024-02-04 04:06:38,688 EPOCH 16
2024-02-04 04:06:38,945 [Epoch: 016 Step: 00002000] Batch Recognition Loss:   0.026922 => Gls Tokens per Sec:     1556 || Batch Translation Loss:  27.959824 => Txt Tokens per Sec:     4346 || Lr: 0.000100
2024-02-04 04:06:50,336 Hooray! New best validation result [eval_metric]!
2024-02-04 04:06:50,337 Saving new checkpoint.
2024-02-04 04:06:50,605 Validation result at epoch  16, step     2000: duration: 11.6584s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.22679	Translation Loss: 58417.03906	PPL: 345.77774
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.88	(BLEU-1: 13.69,	BLEU-2: 4.63,	BLEU-3: 1.92,	BLEU-4: 0.88)
	CHRF 16.20	ROUGE 11.61
2024-02-04 04:06:50,606 Logging Recognition and Translation Outputs
2024-02-04 04:06:50,606 ========================================================================================================================
2024-02-04 04:06:50,606 Logging Sequence: 182_115.00
2024-02-04 04:06:50,606 	Gloss Reference :	A B+C+D+E
2024-02-04 04:06:50,606 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:06:50,607 	Gloss Alignment :	         
2024-02-04 04:06:50,607 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:06:50,608 	Text Reference  :	fans are unclear whether yuvraj will be returning to play  test match odi or     in     t20     leagues from  february 2022 
2024-02-04 04:06:50,608 	Text Hypothesis :	**** *** ******* ******* ****** **** ** ********* ** after the  match he  played played against the     match between  teams
2024-02-04 04:06:50,608 	Text Alignment  :	D    D   D       D       D      D    D  D         D  S     S          S   S      S      S       S       S     S        S    
2024-02-04 04:06:50,608 ========================================================================================================================
2024-02-04 04:06:50,609 Logging Sequence: 140_120.00
2024-02-04 04:06:50,609 	Gloss Reference :	A B+C+D+E
2024-02-04 04:06:50,609 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:06:50,609 	Gloss Alignment :	         
2024-02-04 04:06:50,609 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:06:50,610 	Text Reference  :	but why so it is because pant is a talented player and it will help encouraging the youth of uttarakhand toward sports
2024-02-04 04:06:50,610 	Text Hypothesis :	*** *** ** ** ** ******* he   is a ******** ****** *** ** **** **** *********** *** lot   of *********** camel  flu   
2024-02-04 04:06:50,611 	Text Alignment  :	D   D   D  D  D  D       S         D        D      D   D  D    D    D           D   S        D           S      S     
2024-02-04 04:06:50,611 ========================================================================================================================
2024-02-04 04:06:50,611 Logging Sequence: 85_36.00
2024-02-04 04:06:50,611 	Gloss Reference :	A B+C+D+E
2024-02-04 04:06:50,611 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:06:50,611 	Gloss Alignment :	         
2024-02-04 04:06:50,611 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:06:50,613 	Text Reference  :	**** symonds has scored 2    centuries in 26  tests that    he    played for his country
2024-02-04 04:06:50,613 	Text Hypothesis :	when he      was a      gold medal     in the match between india had    won the match  
2024-02-04 04:06:50,613 	Text Alignment  :	I    S       S   S      S    S            S   S     S       S     S      S   S   S      
2024-02-04 04:06:50,613 ========================================================================================================================
2024-02-04 04:06:50,613 Logging Sequence: 164_100.00
2024-02-04 04:06:50,613 	Gloss Reference :	A B+C+D+E
2024-02-04 04:06:50,613 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:06:50,614 	Gloss Alignment :	         
2024-02-04 04:06:50,614 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:06:50,616 	Text Reference  :	the tv rights for broadcasting ipl  matches in india  for the next 5 years went   to star india  for rs ****** *** 23575 crore 
2024-02-04 04:06:50,616 	Text Hypothesis :	*** ** you    are aware        that rights  of rights for the **** * ***** rights of the  rights for rs rights for the   rights
2024-02-04 04:06:50,616 	Text Alignment  :	D   D  S      S   S            S    S       S  S              D    D D     S      S  S    S             I      I   S     S     
2024-02-04 04:06:50,616 ========================================================================================================================
2024-02-04 04:06:50,616 Logging Sequence: 76_79.00
2024-02-04 04:06:50,617 	Gloss Reference :	A B+C+D+E
2024-02-04 04:06:50,617 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:06:50,617 	Gloss Alignment :	         
2024-02-04 04:06:50,617 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:06:50,617 	Text Reference  :	speaking to  ani csk  ceo kasi viswanathan said  
2024-02-04 04:06:50,618 	Text Hypothesis :	******** the ipl will be  held in          mumbai
2024-02-04 04:06:50,618 	Text Alignment  :	D        S   S   S    S   S    S           S     
2024-02-04 04:06:50,618 ========================================================================================================================
2024-02-04 04:06:56,200 [Epoch: 016 Step: 00002100] Batch Recognition Loss:   0.018101 => Gls Tokens per Sec:     1430 || Batch Translation Loss:  39.840290 => Txt Tokens per Sec:     3983 || Lr: 0.000100
2024-02-04 04:06:57,646 Epoch  16: Total Training Recognition Loss 1.74  Total Training Translation Loss 5377.30 
2024-02-04 04:06:57,646 EPOCH 17
2024-02-04 04:07:01,712 [Epoch: 017 Step: 00002200] Batch Recognition Loss:   0.020662 => Gls Tokens per Sec:     1417 || Batch Translation Loss:  29.285595 => Txt Tokens per Sec:     3922 || Lr: 0.000100
2024-02-04 04:07:05,235 Epoch  17: Total Training Recognition Loss 1.75  Total Training Translation Loss 5005.56 
2024-02-04 04:07:05,236 EPOCH 18
2024-02-04 04:07:07,605 [Epoch: 018 Step: 00002300] Batch Recognition Loss:   0.016340 => Gls Tokens per Sec:     1317 || Batch Translation Loss:  25.410231 => Txt Tokens per Sec:     3680 || Lr: 0.000100
2024-02-04 04:07:13,073 Epoch  18: Total Training Recognition Loss 1.63  Total Training Translation Loss 4686.61 
2024-02-04 04:07:13,074 EPOCH 19
2024-02-04 04:07:13,413 [Epoch: 019 Step: 00002400] Batch Recognition Loss:   0.019268 => Gls Tokens per Sec:     1423 || Batch Translation Loss:  41.089462 => Txt Tokens per Sec:     3895 || Lr: 0.000100
2024-02-04 04:07:19,324 [Epoch: 019 Step: 00002500] Batch Recognition Loss:   0.010679 => Gls Tokens per Sec:     1354 || Batch Translation Loss:  37.300442 => Txt Tokens per Sec:     3777 || Lr: 0.000100
2024-02-04 04:07:20,791 Epoch  19: Total Training Recognition Loss 1.81  Total Training Translation Loss 4287.25 
2024-02-04 04:07:20,791 EPOCH 20
2024-02-04 04:07:24,492 [Epoch: 020 Step: 00002600] Batch Recognition Loss:   0.019993 => Gls Tokens per Sec:     1579 || Batch Translation Loss:  38.952587 => Txt Tokens per Sec:     4330 || Lr: 0.000100
2024-02-04 04:07:27,985 Epoch  20: Total Training Recognition Loss 1.65  Total Training Translation Loss 3911.10 
2024-02-04 04:07:27,986 EPOCH 21
2024-02-04 04:07:30,350 [Epoch: 021 Step: 00002700] Batch Recognition Loss:   0.013433 => Gls Tokens per Sec:     1355 || Batch Translation Loss:  23.667072 => Txt Tokens per Sec:     3875 || Lr: 0.000100
2024-02-04 04:07:35,793 Epoch  21: Total Training Recognition Loss 1.54  Total Training Translation Loss 3611.11 
2024-02-04 04:07:35,793 EPOCH 22
2024-02-04 04:07:36,158 [Epoch: 022 Step: 00002800] Batch Recognition Loss:   0.009266 => Gls Tokens per Sec:     1542 || Batch Translation Loss:  18.254725 => Txt Tokens per Sec:     4349 || Lr: 0.000100
2024-02-04 04:07:41,724 [Epoch: 022 Step: 00002900] Batch Recognition Loss:   0.011683 => Gls Tokens per Sec:     1435 || Batch Translation Loss:  16.110605 => Txt Tokens per Sec:     4000 || Lr: 0.000100
2024-02-04 04:07:43,184 Epoch  22: Total Training Recognition Loss 1.73  Total Training Translation Loss 3283.64 
2024-02-04 04:07:43,184 EPOCH 23
2024-02-04 04:07:47,262 [Epoch: 023 Step: 00003000] Batch Recognition Loss:   0.010863 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   7.411166 => Txt Tokens per Sec:     4041 || Lr: 0.000100
2024-02-04 04:07:50,466 Epoch  23: Total Training Recognition Loss 1.48  Total Training Translation Loss 2992.20 
2024-02-04 04:07:50,466 EPOCH 24
2024-02-04 04:07:52,983 [Epoch: 024 Step: 00003100] Batch Recognition Loss:   0.010661 => Gls Tokens per Sec:     1303 || Batch Translation Loss:  14.486421 => Txt Tokens per Sec:     3641 || Lr: 0.000100
2024-02-04 04:07:58,494 Epoch  24: Total Training Recognition Loss 1.46  Total Training Translation Loss 2676.85 
2024-02-04 04:07:58,495 EPOCH 25
2024-02-04 04:07:58,956 [Epoch: 025 Step: 00003200] Batch Recognition Loss:   0.007599 => Gls Tokens per Sec:     1391 || Batch Translation Loss:  15.542123 => Txt Tokens per Sec:     4070 || Lr: 0.000100
2024-02-04 04:08:04,416 [Epoch: 025 Step: 00003300] Batch Recognition Loss:   0.004999 => Gls Tokens per Sec:     1463 || Batch Translation Loss:  14.972177 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-04 04:08:05,730 Epoch  25: Total Training Recognition Loss 1.33  Total Training Translation Loss 2437.08 
2024-02-04 04:08:05,731 EPOCH 26
2024-02-04 04:08:09,678 [Epoch: 026 Step: 00003400] Batch Recognition Loss:   0.010525 => Gls Tokens per Sec:     1520 || Batch Translation Loss:   5.880079 => Txt Tokens per Sec:     4172 || Lr: 0.000100
2024-02-04 04:08:13,206 Epoch  26: Total Training Recognition Loss 1.26  Total Training Translation Loss 2153.92 
2024-02-04 04:08:13,206 EPOCH 27
2024-02-04 04:08:15,337 [Epoch: 027 Step: 00003500] Batch Recognition Loss:   0.012698 => Gls Tokens per Sec:     1578 || Batch Translation Loss:  11.774353 => Txt Tokens per Sec:     4129 || Lr: 0.000100
2024-02-04 04:08:20,683 Epoch  27: Total Training Recognition Loss 1.16  Total Training Translation Loss 1917.75 
2024-02-04 04:08:20,684 EPOCH 28
2024-02-04 04:08:21,155 [Epoch: 028 Step: 00003600] Batch Recognition Loss:   0.011523 => Gls Tokens per Sec:     1531 || Batch Translation Loss:  14.076869 => Txt Tokens per Sec:     4401 || Lr: 0.000100
2024-02-04 04:08:26,668 [Epoch: 028 Step: 00003700] Batch Recognition Loss:   0.004974 => Gls Tokens per Sec:     1451 || Batch Translation Loss:  10.619044 => Txt Tokens per Sec:     4042 || Lr: 0.000100
2024-02-04 04:08:28,157 Epoch  28: Total Training Recognition Loss 1.05  Total Training Translation Loss 1685.23 
2024-02-04 04:08:28,158 EPOCH 29
2024-02-04 04:08:32,268 [Epoch: 029 Step: 00003800] Batch Recognition Loss:   0.007744 => Gls Tokens per Sec:     1480 || Batch Translation Loss:  15.045277 => Txt Tokens per Sec:     4140 || Lr: 0.000100
2024-02-04 04:08:35,508 Epoch  29: Total Training Recognition Loss 1.04  Total Training Translation Loss 1484.36 
2024-02-04 04:08:35,509 EPOCH 30
2024-02-04 04:08:38,446 [Epoch: 030 Step: 00003900] Batch Recognition Loss:   0.003448 => Gls Tokens per Sec:     1172 || Batch Translation Loss:  11.687709 => Txt Tokens per Sec:     3425 || Lr: 0.000100
2024-02-04 04:08:43,410 Epoch  30: Total Training Recognition Loss 0.92  Total Training Translation Loss 1296.51 
2024-02-04 04:08:43,411 EPOCH 31
2024-02-04 04:08:43,860 [Epoch: 031 Step: 00004000] Batch Recognition Loss:   0.007346 => Gls Tokens per Sec:     1786 || Batch Translation Loss:   3.546916 => Txt Tokens per Sec:     4600 || Lr: 0.000100
2024-02-04 04:08:54,203 Validation result at epoch  31, step     4000: duration: 10.3420s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.07010	Translation Loss: 67255.35938	PPL: 837.35406
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.59	(BLEU-1: 11.13,	BLEU-2: 3.51,	BLEU-3: 1.28,	BLEU-4: 0.59)
	CHRF 15.92	ROUGE 9.97
2024-02-04 04:08:54,204 Logging Recognition and Translation Outputs
2024-02-04 04:08:54,204 ========================================================================================================================
2024-02-04 04:08:54,204 Logging Sequence: 133_173.00
2024-02-04 04:08:54,205 	Gloss Reference :	A B+C+D+E
2024-02-04 04:08:54,205 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:08:54,205 	Gloss Alignment :	         
2024-02-04 04:08:54,205 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:08:54,207 	Text Reference  :	according to sources the leaders of the two countries are   set to   join  the  commentary panel as  well     
2024-02-04 04:08:54,207 	Text Hypothesis :	********* pm modi    is  one     of the *** most      loved and they would have a          huge  fan following
2024-02-04 04:08:54,207 	Text Alignment  :	D         S  S       S   S              D   S         S     S   S    S     S    S          S     S   S        
2024-02-04 04:08:54,207 ========================================================================================================================
2024-02-04 04:08:54,207 Logging Sequence: 83_33.00
2024-02-04 04:08:54,208 	Gloss Reference :	A B+C+D+E
2024-02-04 04:08:54,208 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:08:54,208 	Gloss Alignment :	         
2024-02-04 04:08:54,208 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:08:54,209 	Text Reference  :	*** a       football match lasts       for two equal   halves of  45  minutes
2024-02-04 04:08:54,209 	Text Hypothesis :	the denmark team     was   responsible for the denmark team   for any matches
2024-02-04 04:08:54,209 	Text Alignment  :	I   S       S        S     S               S   S       S      S   S   S      
2024-02-04 04:08:54,209 ========================================================================================================================
2024-02-04 04:08:54,209 Logging Sequence: 68_147.00
2024-02-04 04:08:54,209 	Gloss Reference :	A B+C+D+E
2024-02-04 04:08:54,210 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:08:54,210 	Gloss Alignment :	         
2024-02-04 04:08:54,210 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:08:54,211 	Text Reference  :	***** ****** *** **** remember the 2007  t20 world cup amid  a lot of sledging by english players
2024-02-04 04:08:54,211 	Text Hypothesis :	while bumrah was seen smashing the match as  he    was given a lot of ******** ** 7       runs   
2024-02-04 04:08:54,212 	Text Alignment  :	I     I      I   I    S            S     S   S     S   S              D        D  S       S      
2024-02-04 04:08:54,212 ========================================================================================================================
2024-02-04 04:08:54,212 Logging Sequence: 165_8.00
2024-02-04 04:08:54,212 	Gloss Reference :	A B+C+D+E
2024-02-04 04:08:54,212 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:08:54,212 	Gloss Alignment :	         
2024-02-04 04:08:54,212 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:08:54,213 	Text Reference  :	however many don't believe in   it      it      varies among people 
2024-02-04 04:08:54,213 	Text Hypothesis :	******* **** but   they    have already already booked their victory
2024-02-04 04:08:54,213 	Text Alignment  :	D       D    S     S       S    S       S       S      S     S      
2024-02-04 04:08:54,214 ========================================================================================================================
2024-02-04 04:08:54,214 Logging Sequence: 119_71.00
2024-02-04 04:08:54,214 	Gloss Reference :	A B+C+D+E
2024-02-04 04:08:54,214 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:08:54,214 	Gloss Alignment :	         
2024-02-04 04:08:54,214 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:08:54,216 	Text Reference  :	the special gold devices have each player' names and jersey numbers next to the     camera
2024-02-04 04:08:54,216 	Text Hypothesis :	*** and     told the     gift that he      is    one of     the     gift to idesign gold  
2024-02-04 04:08:54,216 	Text Alignment  :	D   S       S    S       S    S    S       S     S   S      S       S       S       S     
2024-02-04 04:08:54,216 ========================================================================================================================
2024-02-04 04:09:00,093 [Epoch: 031 Step: 00004100] Batch Recognition Loss:   0.004809 => Gls Tokens per Sec:     1358 || Batch Translation Loss:  11.137196 => Txt Tokens per Sec:     3781 || Lr: 0.000100
2024-02-04 04:09:01,357 Epoch  31: Total Training Recognition Loss 0.88  Total Training Translation Loss 1127.94 
2024-02-04 04:09:01,357 EPOCH 32
2024-02-04 04:09:05,621 [Epoch: 032 Step: 00004200] Batch Recognition Loss:   0.005993 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   9.119851 => Txt Tokens per Sec:     3958 || Lr: 0.000100
2024-02-04 04:09:08,753 Epoch  32: Total Training Recognition Loss 0.80  Total Training Translation Loss 994.39 
2024-02-04 04:09:08,753 EPOCH 33
2024-02-04 04:09:11,170 [Epoch: 033 Step: 00004300] Batch Recognition Loss:   0.004231 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   9.392918 => Txt Tokens per Sec:     4233 || Lr: 0.000100
2024-02-04 04:09:16,165 Epoch  33: Total Training Recognition Loss 0.81  Total Training Translation Loss 884.07 
2024-02-04 04:09:16,166 EPOCH 34
2024-02-04 04:09:16,706 [Epoch: 034 Step: 00004400] Batch Recognition Loss:   0.002764 => Gls Tokens per Sec:     1633 || Batch Translation Loss:   7.719358 => Txt Tokens per Sec:     4417 || Lr: 0.000100
2024-02-04 04:09:22,331 [Epoch: 034 Step: 00004500] Batch Recognition Loss:   0.004836 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   6.004529 => Txt Tokens per Sec:     3909 || Lr: 0.000100
2024-02-04 04:09:23,581 Epoch  34: Total Training Recognition Loss 0.70  Total Training Translation Loss 781.66 
2024-02-04 04:09:23,581 EPOCH 35
2024-02-04 04:09:27,564 [Epoch: 035 Step: 00004600] Batch Recognition Loss:   0.003746 => Gls Tokens per Sec:     1567 || Batch Translation Loss:   6.245111 => Txt Tokens per Sec:     4374 || Lr: 0.000100
2024-02-04 04:09:30,907 Epoch  35: Total Training Recognition Loss 0.63  Total Training Translation Loss 691.55 
2024-02-04 04:09:30,908 EPOCH 36
2024-02-04 04:09:33,391 [Epoch: 036 Step: 00004700] Batch Recognition Loss:   0.003931 => Gls Tokens per Sec:     1450 || Batch Translation Loss:   4.086421 => Txt Tokens per Sec:     3925 || Lr: 0.000100
2024-02-04 04:09:38,815 Epoch  36: Total Training Recognition Loss 0.56  Total Training Translation Loss 579.98 
2024-02-04 04:09:38,815 EPOCH 37
2024-02-04 04:09:39,494 [Epoch: 037 Step: 00004800] Batch Recognition Loss:   0.002551 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   3.668629 => Txt Tokens per Sec:     4107 || Lr: 0.000100
2024-02-04 04:09:45,074 [Epoch: 037 Step: 00004900] Batch Recognition Loss:   0.003842 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   4.420977 => Txt Tokens per Sec:     3975 || Lr: 0.000100
2024-02-04 04:09:46,186 Epoch  37: Total Training Recognition Loss 0.54  Total Training Translation Loss 519.40 
2024-02-04 04:09:46,187 EPOCH 38
2024-02-04 04:09:50,539 [Epoch: 038 Step: 00005000] Batch Recognition Loss:   0.002538 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   4.607191 => Txt Tokens per Sec:     4069 || Lr: 0.000100
2024-02-04 04:09:53,606 Epoch  38: Total Training Recognition Loss 0.46  Total Training Translation Loss 476.87 
2024-02-04 04:09:53,606 EPOCH 39
2024-02-04 04:09:56,188 [Epoch: 039 Step: 00005100] Batch Recognition Loss:   0.001703 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   2.546542 => Txt Tokens per Sec:     3918 || Lr: 0.000100
2024-02-04 04:10:01,178 Epoch  39: Total Training Recognition Loss 0.47  Total Training Translation Loss 435.44 
2024-02-04 04:10:01,178 EPOCH 40
2024-02-04 04:10:01,999 [Epoch: 040 Step: 00005200] Batch Recognition Loss:   0.001699 => Gls Tokens per Sec:     1269 || Batch Translation Loss:   2.539528 => Txt Tokens per Sec:     3683 || Lr: 0.000100
2024-02-04 04:10:07,655 [Epoch: 040 Step: 00005300] Batch Recognition Loss:   0.004389 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   3.434193 => Txt Tokens per Sec:     3856 || Lr: 0.000100
2024-02-04 04:10:08,851 Epoch  40: Total Training Recognition Loss 0.38  Total Training Translation Loss 395.81 
2024-02-04 04:10:08,851 EPOCH 41
2024-02-04 04:10:12,574 [Epoch: 041 Step: 00005400] Batch Recognition Loss:   0.002400 => Gls Tokens per Sec:     1720 || Batch Translation Loss:   3.748390 => Txt Tokens per Sec:     4706 || Lr: 0.000100
2024-02-04 04:10:15,782 Epoch  41: Total Training Recognition Loss 0.41  Total Training Translation Loss 351.52 
2024-02-04 04:10:15,783 EPOCH 42
2024-02-04 04:10:18,554 [Epoch: 042 Step: 00005500] Batch Recognition Loss:   0.001715 => Gls Tokens per Sec:     1358 || Batch Translation Loss:   2.145131 => Txt Tokens per Sec:     3673 || Lr: 0.000100
2024-02-04 04:10:23,434 Epoch  42: Total Training Recognition Loss 0.37  Total Training Translation Loss 317.71 
2024-02-04 04:10:23,434 EPOCH 43
2024-02-04 04:10:24,168 [Epoch: 043 Step: 00005600] Batch Recognition Loss:   0.002834 => Gls Tokens per Sec:     1529 || Batch Translation Loss:   2.537222 => Txt Tokens per Sec:     4401 || Lr: 0.000100
2024-02-04 04:10:29,328 [Epoch: 043 Step: 00005700] Batch Recognition Loss:   0.003000 => Gls Tokens per Sec:     1549 || Batch Translation Loss:   2.059395 => Txt Tokens per Sec:     4258 || Lr: 0.000100
2024-02-04 04:10:30,346 Epoch  43: Total Training Recognition Loss 0.33  Total Training Translation Loss 293.32 
2024-02-04 04:10:30,346 EPOCH 44
2024-02-04 04:10:34,758 [Epoch: 044 Step: 00005800] Batch Recognition Loss:   0.002261 => Gls Tokens per Sec:     1469 || Batch Translation Loss:   1.731687 => Txt Tokens per Sec:     3995 || Lr: 0.000100
2024-02-04 04:10:37,783 Epoch  44: Total Training Recognition Loss 0.33  Total Training Translation Loss 298.07 
2024-02-04 04:10:37,784 EPOCH 45
2024-02-04 04:10:40,606 [Epoch: 045 Step: 00005900] Batch Recognition Loss:   0.003215 => Gls Tokens per Sec:     1361 || Batch Translation Loss:   1.265860 => Txt Tokens per Sec:     3770 || Lr: 0.000100
2024-02-04 04:10:45,578 Epoch  45: Total Training Recognition Loss 0.34  Total Training Translation Loss 269.31 
2024-02-04 04:10:45,578 EPOCH 46
2024-02-04 04:10:46,498 [Epoch: 046 Step: 00006000] Batch Recognition Loss:   0.002531 => Gls Tokens per Sec:     1306 || Batch Translation Loss:   1.896258 => Txt Tokens per Sec:     3698 || Lr: 0.000100
2024-02-04 04:10:57,142 Validation result at epoch  46, step     6000: duration: 10.6428s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.01719	Translation Loss: 75082.30469	PPL: 1832.59851
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.59	(BLEU-1: 11.05,	BLEU-2: 3.84,	BLEU-3: 1.42,	BLEU-4: 0.59)
	CHRF 16.31	ROUGE 9.69
2024-02-04 04:10:57,142 Logging Recognition and Translation Outputs
2024-02-04 04:10:57,142 ========================================================================================================================
2024-02-04 04:10:57,143 Logging Sequence: 89_111.00
2024-02-04 04:10:57,143 	Gloss Reference :	A B+C+D+E
2024-02-04 04:10:57,143 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:10:57,143 	Gloss Alignment :	         
2024-02-04 04:10:57,143 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:10:57,144 	Text Reference  :	** ** *** ***** ** ** however selectors never selected me for  the team  
2024-02-04 04:10:57,144 	Text Hypothesis :	it is not known if he had     any       match he       is also a   bowler
2024-02-04 04:10:57,144 	Text Alignment  :	I  I  I   I     I  I  S       S         S     S        S  S    S   S     
2024-02-04 04:10:57,145 ========================================================================================================================
2024-02-04 04:10:57,145 Logging Sequence: 137_23.00
2024-02-04 04:10:57,145 	Gloss Reference :	A B+C+D+E
2024-02-04 04:10:57,145 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:10:57,145 	Gloss Alignment :	         
2024-02-04 04:10:57,145 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:10:57,146 	Text Reference  :	fan from around the world are in qatar      for the fifa world cup 
2024-02-04 04:10:57,146 	Text Hypothesis :	*** **** ****** *** ***** i   am devastated by  the **** ***** fans
2024-02-04 04:10:57,146 	Text Alignment  :	D   D    D      D   D     S   S  S          S       D    D     S   
2024-02-04 04:10:57,146 ========================================================================================================================
2024-02-04 04:10:57,146 Logging Sequence: 128_145.00
2024-02-04 04:10:57,147 	Gloss Reference :	A B+C+D+E
2024-02-04 04:10:57,147 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:10:57,147 	Gloss Alignment :	         
2024-02-04 04:10:57,147 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:10:57,148 	Text Reference  :	**** ** icc also uploaded a    video    of the same
2024-02-04 04:10:57,148 	Text Hypothesis :	this is why the  bcci     will continue to be  nice
2024-02-04 04:10:57,148 	Text Alignment  :	I    I  S   S    S        S    S        S  S   S   
2024-02-04 04:10:57,148 ========================================================================================================================
2024-02-04 04:10:57,148 Logging Sequence: 165_192.00
2024-02-04 04:10:57,148 	Gloss Reference :	A B+C+D+E
2024-02-04 04:10:57,148 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:10:57,149 	Gloss Alignment :	         
2024-02-04 04:10:57,149 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:10:57,150 	Text Reference  :	***** ** **** 3       ravichandran ashwin  believes that   his       bag is ** ** ****** ******* ***** lucky
2024-02-04 04:10:57,150 	Text Hypothesis :	there is many batsmen and          bowlers for      sachin tendulkar who is so he always nothing about it   
2024-02-04 04:10:57,150 	Text Alignment  :	I     I  I    S       S            S       S        S      S         S      I  I  I      I       I     S    
2024-02-04 04:10:57,150 ========================================================================================================================
2024-02-04 04:10:57,150 Logging Sequence: 180_494.00
2024-02-04 04:10:57,150 	Gloss Reference :	A B+C+D+E
2024-02-04 04:10:57,151 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:10:57,151 	Gloss Alignment :	         
2024-02-04 04:10:57,151 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:10:57,152 	Text Reference  :	the women wrestlers spoke angrily against the  police and the controversy in   front of      the media
2024-02-04 04:10:57,152 	Text Hypothesis :	*** ***** ********* ***** ******* however they have   won the wrestlers   from seven matches as  well 
2024-02-04 04:10:57,152 	Text Alignment  :	D   D     D         D     D       S       S    S      S       S           S    S     S       S   S    
2024-02-04 04:10:57,152 ========================================================================================================================
2024-02-04 04:11:02,751 [Epoch: 046 Step: 00006100] Batch Recognition Loss:   0.002942 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   1.765082 => Txt Tokens per Sec:     3989 || Lr: 0.000100
2024-02-04 04:11:03,718 Epoch  46: Total Training Recognition Loss 0.29  Total Training Translation Loss 241.73 
2024-02-04 04:11:03,718 EPOCH 47
2024-02-04 04:11:08,267 [Epoch: 047 Step: 00006200] Batch Recognition Loss:   0.002003 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   1.800962 => Txt Tokens per Sec:     3976 || Lr: 0.000100
2024-02-04 04:11:11,105 Epoch  47: Total Training Recognition Loss 0.30  Total Training Translation Loss 225.30 
2024-02-04 04:11:11,105 EPOCH 48
2024-02-04 04:11:13,646 [Epoch: 048 Step: 00006300] Batch Recognition Loss:   0.001080 => Gls Tokens per Sec:     1543 || Batch Translation Loss:   2.109030 => Txt Tokens per Sec:     4333 || Lr: 0.000100
2024-02-04 04:11:18,640 Epoch  48: Total Training Recognition Loss 0.27  Total Training Translation Loss 210.32 
2024-02-04 04:11:18,640 EPOCH 49
2024-02-04 04:11:19,521 [Epoch: 049 Step: 00006400] Batch Recognition Loss:   0.004225 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   1.087851 => Txt Tokens per Sec:     4128 || Lr: 0.000100
2024-02-04 04:11:25,092 [Epoch: 049 Step: 00006500] Batch Recognition Loss:   0.001603 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   1.498742 => Txt Tokens per Sec:     3965 || Lr: 0.000100
2024-02-04 04:11:26,152 Epoch  49: Total Training Recognition Loss 0.24  Total Training Translation Loss 190.74 
2024-02-04 04:11:26,152 EPOCH 50
2024-02-04 04:11:30,836 [Epoch: 050 Step: 00006600] Batch Recognition Loss:   0.001917 => Gls Tokens per Sec:     1418 || Batch Translation Loss:   0.641006 => Txt Tokens per Sec:     3979 || Lr: 0.000100
2024-02-04 04:11:33,957 Epoch  50: Total Training Recognition Loss 0.23  Total Training Translation Loss 187.61 
2024-02-04 04:11:33,957 EPOCH 51
2024-02-04 04:11:36,987 [Epoch: 051 Step: 00006700] Batch Recognition Loss:   0.000815 => Gls Tokens per Sec:     1321 || Batch Translation Loss:   0.841932 => Txt Tokens per Sec:     3613 || Lr: 0.000100
2024-02-04 04:11:41,657 Epoch  51: Total Training Recognition Loss 0.20  Total Training Translation Loss 167.40 
2024-02-04 04:11:41,657 EPOCH 52
2024-02-04 04:11:42,506 [Epoch: 052 Step: 00006800] Batch Recognition Loss:   0.003507 => Gls Tokens per Sec:     1604 || Batch Translation Loss:   1.827690 => Txt Tokens per Sec:     4484 || Lr: 0.000100
2024-02-04 04:11:48,089 [Epoch: 052 Step: 00006900] Batch Recognition Loss:   0.001145 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   1.762726 => Txt Tokens per Sec:     3949 || Lr: 0.000100
2024-02-04 04:11:49,083 Epoch  52: Total Training Recognition Loss 0.18  Total Training Translation Loss 172.13 
2024-02-04 04:11:49,083 EPOCH 53
2024-02-04 04:11:53,736 [Epoch: 053 Step: 00007000] Batch Recognition Loss:   0.006569 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   1.303522 => Txt Tokens per Sec:     4089 || Lr: 0.000100
2024-02-04 04:11:56,456 Epoch  53: Total Training Recognition Loss 0.19  Total Training Translation Loss 160.79 
2024-02-04 04:11:56,457 EPOCH 54
2024-02-04 04:11:59,195 [Epoch: 054 Step: 00007100] Batch Recognition Loss:   0.001082 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   2.399275 => Txt Tokens per Sec:     4093 || Lr: 0.000100
2024-02-04 04:12:04,197 Epoch  54: Total Training Recognition Loss 0.21  Total Training Translation Loss 156.16 
2024-02-04 04:12:04,198 EPOCH 55
2024-02-04 04:12:05,149 [Epoch: 055 Step: 00007200] Batch Recognition Loss:   0.000790 => Gls Tokens per Sec:     1516 || Batch Translation Loss:   1.639315 => Txt Tokens per Sec:     3967 || Lr: 0.000100
2024-02-04 04:12:10,724 [Epoch: 055 Step: 00007300] Batch Recognition Loss:   0.001797 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   0.961747 => Txt Tokens per Sec:     4008 || Lr: 0.000100
2024-02-04 04:12:11,615 Epoch  55: Total Training Recognition Loss 0.21  Total Training Translation Loss 144.94 
2024-02-04 04:12:11,616 EPOCH 56
2024-02-04 04:12:16,401 [Epoch: 056 Step: 00007400] Batch Recognition Loss:   0.000720 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.957018 => Txt Tokens per Sec:     3975 || Lr: 0.000100
2024-02-04 04:12:19,044 Epoch  56: Total Training Recognition Loss 0.18  Total Training Translation Loss 145.50 
2024-02-04 04:12:19,044 EPOCH 57
2024-02-04 04:12:21,985 [Epoch: 057 Step: 00007500] Batch Recognition Loss:   0.003359 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   1.457090 => Txt Tokens per Sec:     3883 || Lr: 0.000100
2024-02-04 04:12:26,838 Epoch  57: Total Training Recognition Loss 0.22  Total Training Translation Loss 155.78 
2024-02-04 04:12:26,839 EPOCH 58
2024-02-04 04:12:28,196 [Epoch: 058 Step: 00007600] Batch Recognition Loss:   0.003622 => Gls Tokens per Sec:     1122 || Batch Translation Loss:   1.398207 => Txt Tokens per Sec:     3345 || Lr: 0.000100
2024-02-04 04:12:33,613 [Epoch: 058 Step: 00007700] Batch Recognition Loss:   0.000545 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.799510 => Txt Tokens per Sec:     4070 || Lr: 0.000100
2024-02-04 04:12:34,419 Epoch  58: Total Training Recognition Loss 0.17  Total Training Translation Loss 130.31 
2024-02-04 04:12:34,419 EPOCH 59
2024-02-04 04:12:39,283 [Epoch: 059 Step: 00007800] Batch Recognition Loss:   0.001002 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.842997 => Txt Tokens per Sec:     3919 || Lr: 0.000100
2024-02-04 04:12:41,952 Epoch  59: Total Training Recognition Loss 0.18  Total Training Translation Loss 121.15 
2024-02-04 04:12:41,953 EPOCH 60
2024-02-04 04:12:45,149 [Epoch: 060 Step: 00007900] Batch Recognition Loss:   0.019702 => Gls Tokens per Sec:     1327 || Batch Translation Loss:   0.512078 => Txt Tokens per Sec:     3894 || Lr: 0.000100
2024-02-04 04:12:49,647 Epoch  60: Total Training Recognition Loss 0.21  Total Training Translation Loss 119.65 
2024-02-04 04:12:49,648 EPOCH 61
2024-02-04 04:12:50,644 [Epoch: 061 Step: 00008000] Batch Recognition Loss:   0.001611 => Gls Tokens per Sec:     1606 || Batch Translation Loss:   0.701481 => Txt Tokens per Sec:     4297 || Lr: 0.000100
2024-02-04 04:13:01,515 Hooray! New best validation result [eval_metric]!
2024-02-04 04:13:01,516 Saving new checkpoint.
2024-02-04 04:13:01,782 Validation result at epoch  61, step     8000: duration: 11.1377s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00771	Translation Loss: 80972.08594	PPL: 3303.97144
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.98	(BLEU-1: 12.52,	BLEU-2: 4.00,	BLEU-3: 1.79,	BLEU-4: 0.98)
	CHRF 17.82	ROUGE 10.84
2024-02-04 04:13:01,783 Logging Recognition and Translation Outputs
2024-02-04 04:13:01,783 ========================================================================================================================
2024-02-04 04:13:01,783 Logging Sequence: 88_57.00
2024-02-04 04:13:01,783 	Gloss Reference :	A B+C+D+E
2024-02-04 04:13:01,783 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:13:01,783 	Gloss Alignment :	         
2024-02-04 04:13:01,784 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:13:01,785 	Text Reference  :	******* which   stated messi  we're waiting for     you  to come      here you will be  finished when you come 
2024-02-04 04:13:01,785 	Text Hypothesis :	notably rosario has    become the   most    violent city in argentina with 250 to   300 murders  in   the world
2024-02-04 04:13:01,786 	Text Alignment  :	I       S       S      S      S     S       S       S    S  S         S    S   S    S   S        S    S   S    
2024-02-04 04:13:01,786 ========================================================================================================================
2024-02-04 04:13:01,786 Logging Sequence: 171_142.00
2024-02-04 04:13:01,786 	Gloss Reference :	A B+C+D+E
2024-02-04 04:13:01,786 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:13:01,786 	Gloss Alignment :	         
2024-02-04 04:13:01,786 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:13:01,788 	Text Reference  :	****** this decision on   dhoni     made     a     significant impact as   pathirana claimed two tough wickets
2024-02-04 04:13:01,788 	Text Hypothesis :	dahiya will now      have lucknow's staudium named after       late   with a         total   of  6     medals 
2024-02-04 04:13:01,788 	Text Alignment  :	I      S    S        S    S         S        S     S           S      S    S         S       S   S     S      
2024-02-04 04:13:01,788 ========================================================================================================================
2024-02-04 04:13:01,788 Logging Sequence: 125_207.00
2024-02-04 04:13:01,788 	Gloss Reference :	A B+C+D+E
2024-02-04 04:13:01,788 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:13:01,788 	Gloss Alignment :	         
2024-02-04 04:13:01,789 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:13:01,790 	Text Reference  :	he had not practised since he   returned and he  had    also fallen sick  
2024-02-04 04:13:01,790 	Text Hypothesis :	** *** *** neeraj    was   very happy    by  the finals of   the    finals
2024-02-04 04:13:01,790 	Text Alignment  :	D  D   D   S         S     S    S        S   S   S      S    S      S     
2024-02-04 04:13:01,790 ========================================================================================================================
2024-02-04 04:13:01,790 Logging Sequence: 68_230.00
2024-02-04 04:13:01,790 	Gloss Reference :	A B+C+D+E
2024-02-04 04:13:01,790 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:13:01,791 	Gloss Alignment :	         
2024-02-04 04:13:01,791 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:13:01,792 	Text Reference  :	** ****** ** **** ** let us     know  what    you think in    the **** *** ****** comments below
2024-02-04 04:13:01,792 	Text Hypothesis :	he scored 29 runs in a   wicket while spinner did not   touch the over who bowled very     well 
2024-02-04 04:13:01,792 	Text Alignment  :	I  I      I  I    I  S   S      S     S       S   S     S         I    I   I      S        S    
2024-02-04 04:13:01,792 ========================================================================================================================
2024-02-04 04:13:01,792 Logging Sequence: 126_82.00
2024-02-04 04:13:01,792 	Gloss Reference :	A B+C+D+E
2024-02-04 04:13:01,793 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:13:01,793 	Gloss Alignment :	         
2024-02-04 04:13:01,793 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:13:01,794 	Text Reference  :	neeraj also dedicated his gold medal  to ********* **** ** former indian olympians who came close to winning *** medals
2024-02-04 04:13:01,795 	Text Hypothesis :	he     also dedicated *** the  medals to olympians like pt usha   and    others    who came close to winning the medals
2024-02-04 04:13:01,795 	Text Alignment  :	S                     D   S    S         I         I    I  S      S      S                                   I         
2024-02-04 04:13:01,795 ========================================================================================================================
2024-02-04 04:13:07,526 [Epoch: 061 Step: 00008100] Batch Recognition Loss:   0.002679 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.643906 => Txt Tokens per Sec:     3875 || Lr: 0.000100
2024-02-04 04:13:08,303 Epoch  61: Total Training Recognition Loss 0.17  Total Training Translation Loss 127.17 
2024-02-04 04:13:08,303 EPOCH 62
2024-02-04 04:13:13,072 [Epoch: 062 Step: 00008200] Batch Recognition Loss:   0.001005 => Gls Tokens per Sec:     1460 || Batch Translation Loss:   0.786585 => Txt Tokens per Sec:     4058 || Lr: 0.000100
2024-02-04 04:13:15,790 Epoch  62: Total Training Recognition Loss 0.14  Total Training Translation Loss 112.40 
2024-02-04 04:13:15,791 EPOCH 63
2024-02-04 04:13:18,765 [Epoch: 063 Step: 00008300] Batch Recognition Loss:   0.001432 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   1.168138 => Txt Tokens per Sec:     3968 || Lr: 0.000100
2024-02-04 04:13:23,391 Epoch  63: Total Training Recognition Loss 0.16  Total Training Translation Loss 99.38 
2024-02-04 04:13:23,392 EPOCH 64
2024-02-04 04:13:24,549 [Epoch: 064 Step: 00008400] Batch Recognition Loss:   0.000555 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.674747 => Txt Tokens per Sec:     3914 || Lr: 0.000100
2024-02-04 04:13:30,042 [Epoch: 064 Step: 00008500] Batch Recognition Loss:   0.000708 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.919876 => Txt Tokens per Sec:     4058 || Lr: 0.000100
2024-02-04 04:13:30,613 Epoch  64: Total Training Recognition Loss 0.14  Total Training Translation Loss 91.93 
2024-02-04 04:13:30,614 EPOCH 65
2024-02-04 04:13:35,304 [Epoch: 065 Step: 00008600] Batch Recognition Loss:   0.000718 => Gls Tokens per Sec:     1501 || Batch Translation Loss:   0.586015 => Txt Tokens per Sec:     4108 || Lr: 0.000100
2024-02-04 04:13:37,946 Epoch  65: Total Training Recognition Loss 0.15  Total Training Translation Loss 98.58 
2024-02-04 04:13:37,946 EPOCH 66
2024-02-04 04:13:41,165 [Epoch: 066 Step: 00008700] Batch Recognition Loss:   0.000745 => Gls Tokens per Sec:     1367 || Batch Translation Loss:   0.817943 => Txt Tokens per Sec:     3781 || Lr: 0.000100
2024-02-04 04:13:45,626 Epoch  66: Total Training Recognition Loss 0.14  Total Training Translation Loss 109.40 
2024-02-04 04:13:45,627 EPOCH 67
2024-02-04 04:13:46,800 [Epoch: 067 Step: 00008800] Batch Recognition Loss:   0.000319 => Gls Tokens per Sec:     1501 || Batch Translation Loss:   0.792616 => Txt Tokens per Sec:     4291 || Lr: 0.000100
2024-02-04 04:13:52,450 [Epoch: 067 Step: 00008900] Batch Recognition Loss:   0.002320 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.531734 => Txt Tokens per Sec:     3876 || Lr: 0.000100
2024-02-04 04:13:53,068 Epoch  67: Total Training Recognition Loss 0.15  Total Training Translation Loss 93.39 
2024-02-04 04:13:53,069 EPOCH 68
2024-02-04 04:13:57,647 [Epoch: 068 Step: 00009000] Batch Recognition Loss:   0.000391 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   0.395112 => Txt Tokens per Sec:     4260 || Lr: 0.000100
2024-02-04 04:14:00,299 Epoch  68: Total Training Recognition Loss 0.14  Total Training Translation Loss 93.86 
2024-02-04 04:14:00,300 EPOCH 69
2024-02-04 04:14:03,337 [Epoch: 069 Step: 00009100] Batch Recognition Loss:   0.000398 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.788211 => Txt Tokens per Sec:     4039 || Lr: 0.000100
2024-02-04 04:14:07,817 Epoch  69: Total Training Recognition Loss 0.16  Total Training Translation Loss 85.98 
2024-02-04 04:14:07,817 EPOCH 70
2024-02-04 04:14:09,244 [Epoch: 070 Step: 00009200] Batch Recognition Loss:   0.000763 => Gls Tokens per Sec:     1290 || Batch Translation Loss:   0.324390 => Txt Tokens per Sec:     3645 || Lr: 0.000100
2024-02-04 04:14:14,742 [Epoch: 070 Step: 00009300] Batch Recognition Loss:   0.001597 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.794722 => Txt Tokens per Sec:     4003 || Lr: 0.000100
2024-02-04 04:14:15,284 Epoch  70: Total Training Recognition Loss 0.16  Total Training Translation Loss 92.47 
2024-02-04 04:14:15,284 EPOCH 71
2024-02-04 04:14:20,369 [Epoch: 071 Step: 00009400] Batch Recognition Loss:   0.001172 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.858537 => Txt Tokens per Sec:     3896 || Lr: 0.000100
2024-02-04 04:14:22,839 Epoch  71: Total Training Recognition Loss 0.13  Total Training Translation Loss 93.32 
2024-02-04 04:14:22,840 EPOCH 72
2024-02-04 04:14:25,883 [Epoch: 072 Step: 00009500] Batch Recognition Loss:   0.000737 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.351842 => Txt Tokens per Sec:     4098 || Lr: 0.000100
2024-02-04 04:14:30,172 Epoch  72: Total Training Recognition Loss 0.17  Total Training Translation Loss 87.21 
2024-02-04 04:14:30,172 EPOCH 73
2024-02-04 04:14:31,721 [Epoch: 073 Step: 00009600] Batch Recognition Loss:   0.000641 => Gls Tokens per Sec:     1242 || Batch Translation Loss:   0.308688 => Txt Tokens per Sec:     3478 || Lr: 0.000100
2024-02-04 04:14:37,311 [Epoch: 073 Step: 00009700] Batch Recognition Loss:   0.000415 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.789193 => Txt Tokens per Sec:     3973 || Lr: 0.000100
2024-02-04 04:14:37,751 Epoch  73: Total Training Recognition Loss 0.12  Total Training Translation Loss 85.70 
2024-02-04 04:14:37,752 EPOCH 74
2024-02-04 04:14:42,380 [Epoch: 074 Step: 00009800] Batch Recognition Loss:   0.001054 => Gls Tokens per Sec:     1573 || Batch Translation Loss:   0.765983 => Txt Tokens per Sec:     4315 || Lr: 0.000100
2024-02-04 04:14:44,934 Epoch  74: Total Training Recognition Loss 0.15  Total Training Translation Loss 78.54 
2024-02-04 04:14:44,934 EPOCH 75
2024-02-04 04:14:48,299 [Epoch: 075 Step: 00009900] Batch Recognition Loss:   0.001477 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.350024 => Txt Tokens per Sec:     3888 || Lr: 0.000100
2024-02-04 04:14:52,646 Epoch  75: Total Training Recognition Loss 0.15  Total Training Translation Loss 85.77 
2024-02-04 04:14:52,647 EPOCH 76
2024-02-04 04:14:54,112 [Epoch: 076 Step: 00010000] Batch Recognition Loss:   0.000365 => Gls Tokens per Sec:     1367 || Batch Translation Loss:   0.357883 => Txt Tokens per Sec:     4173 || Lr: 0.000100
2024-02-04 04:15:05,028 Validation result at epoch  76, step    10000: duration: 10.9159s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00473	Translation Loss: 86098.09375	PPL: 5518.38770
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.90	(BLEU-1: 11.49,	BLEU-2: 3.68,	BLEU-3: 1.63,	BLEU-4: 0.90)
	CHRF 17.21	ROUGE 9.55
2024-02-04 04:15:05,029 Logging Recognition and Translation Outputs
2024-02-04 04:15:05,029 ========================================================================================================================
2024-02-04 04:15:05,030 Logging Sequence: 159_139.00
2024-02-04 04:15:05,030 	Gloss Reference :	A B+C+D+E
2024-02-04 04:15:05,030 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:15:05,030 	Gloss Alignment :	         
2024-02-04 04:15:05,030 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:15:05,031 	Text Reference  :	he took time and finally was ready for the    asia cup     where he   scored the century  
2024-02-04 04:15:05,031 	Text Hypothesis :	** **** **** *** ******* *** ***** now people were shocked when  this is     not permitted
2024-02-04 04:15:05,031 	Text Alignment  :	D  D    D    D   D       D   D     S   S      S    S       S     S    S      S   S        
2024-02-04 04:15:05,031 ========================================================================================================================
2024-02-04 04:15:05,032 Logging Sequence: 159_159.00
2024-02-04 04:15:05,032 	Gloss Reference :	A B+C+D+E
2024-02-04 04:15:05,032 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:15:05,032 	Gloss Alignment :	         
2024-02-04 04:15:05,032 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:15:05,034 	Text Reference  :	he said it wasn't easy the mind has to be focussed and he    is **** glad  that he is back in form with    the       asia cup     century 
2024-02-04 04:15:05,034 	Text Hypothesis :	** **** ** ****** **** *** **** *** ** ** ******** *** kohli is very happy that ** ** **** ** **** earlier australia new  zealand pakistan
2024-02-04 04:15:05,034 	Text Alignment  :	D  D    D  D      D    D   D    D   D  D  D        D   S        I    S          D  D  D    D  D    S       S         S    S       S       
2024-02-04 04:15:05,034 ========================================================================================================================
2024-02-04 04:15:05,034 Logging Sequence: 103_8.00
2024-02-04 04:15:05,035 	Gloss Reference :	A B+C+D+E
2024-02-04 04:15:05,035 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:15:05,035 	Gloss Alignment :	         
2024-02-04 04:15:05,035 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:15:05,036 	Text Reference  :	were going on           in    birmingham england      from 28th july to  8th     august 2022 
2024-02-04 04:15:05,036 	Text Hypothesis :	**** the   commonwealth games encourage  independence from **** **** the british empire games
2024-02-04 04:15:05,036 	Text Alignment  :	D    S     S            S     S          S                 D    D    S   S       S      S    
2024-02-04 04:15:05,036 ========================================================================================================================
2024-02-04 04:15:05,036 Logging Sequence: 164_546.00
2024-02-04 04:15:05,036 	Gloss Reference :	A B+C+D+E
2024-02-04 04:15:05,037 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:15:05,037 	Gloss Alignment :	         
2024-02-04 04:15:05,037 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:15:05,037 	Text Reference  :	reliance has     turned out to   be          the ****** strongest company
2024-02-04 04:15:05,038 	Text Hypothesis :	for      another man    is  seen celebrating the common wealth    games  
2024-02-04 04:15:05,038 	Text Alignment  :	S        S       S      S   S    S               I      S         S      
2024-02-04 04:15:05,038 ========================================================================================================================
2024-02-04 04:15:05,038 Logging Sequence: 132_173.00
2024-02-04 04:15:05,038 	Gloss Reference :	A B+C+D+E
2024-02-04 04:15:05,038 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:15:05,038 	Gloss Alignment :	         
2024-02-04 04:15:05,039 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:15:05,039 	Text Reference  :	usman is **** ******* ** *** **** ****** ** **** australia' first muslim player
2024-02-04 04:15:05,039 	Text Hypothesis :	virat is very popular on the most shared by this has        not   stop   him   
2024-02-04 04:15:05,039 	Text Alignment  :	S        I    I       I  I   I    I      I  I    S          S     S      S     
2024-02-04 04:15:05,040 ========================================================================================================================
2024-02-04 04:15:10,551 [Epoch: 076 Step: 00010100] Batch Recognition Loss:   0.000886 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.464790 => Txt Tokens per Sec:     3940 || Lr: 0.000100
2024-02-04 04:15:10,953 Epoch  76: Total Training Recognition Loss 0.12  Total Training Translation Loss 70.47 
2024-02-04 04:15:10,953 EPOCH 77
2024-02-04 04:15:15,992 [Epoch: 077 Step: 00010200] Batch Recognition Loss:   0.000286 => Gls Tokens per Sec:     1461 || Batch Translation Loss:   0.312861 => Txt Tokens per Sec:     4089 || Lr: 0.000100
2024-02-04 04:15:18,277 Epoch  77: Total Training Recognition Loss 0.13  Total Training Translation Loss 71.69 
2024-02-04 04:15:18,277 EPOCH 78
2024-02-04 04:15:21,673 [Epoch: 078 Step: 00010300] Batch Recognition Loss:   0.001354 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   1.016946 => Txt Tokens per Sec:     3913 || Lr: 0.000100
2024-02-04 04:15:25,938 Epoch  78: Total Training Recognition Loss 0.10  Total Training Translation Loss 69.05 
2024-02-04 04:15:25,939 EPOCH 79
2024-02-04 04:15:27,301 [Epoch: 079 Step: 00010400] Batch Recognition Loss:   0.000349 => Gls Tokens per Sec:     1530 || Batch Translation Loss:   0.416576 => Txt Tokens per Sec:     4382 || Lr: 0.000100
2024-02-04 04:15:32,436 [Epoch: 079 Step: 00010500] Batch Recognition Loss:   0.000726 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   0.338214 => Txt Tokens per Sec:     4330 || Lr: 0.000100
2024-02-04 04:15:32,805 Epoch  79: Total Training Recognition Loss 0.13  Total Training Translation Loss 67.98 
2024-02-04 04:15:32,805 EPOCH 80
2024-02-04 04:15:38,063 [Epoch: 080 Step: 00010600] Batch Recognition Loss:   0.000728 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.602303 => Txt Tokens per Sec:     3914 || Lr: 0.000100
2024-02-04 04:15:40,184 Epoch  80: Total Training Recognition Loss 0.10  Total Training Translation Loss 62.20 
2024-02-04 04:15:40,184 EPOCH 81
2024-02-04 04:15:43,549 [Epoch: 081 Step: 00010700] Batch Recognition Loss:   0.000652 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.360950 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-04 04:15:47,946 Epoch  81: Total Training Recognition Loss 0.11  Total Training Translation Loss 71.69 
2024-02-04 04:15:47,947 EPOCH 82
2024-02-04 04:15:49,546 [Epoch: 082 Step: 00010800] Batch Recognition Loss:   0.000792 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   1.238693 => Txt Tokens per Sec:     3441 || Lr: 0.000100
2024-02-04 04:15:55,162 [Epoch: 082 Step: 00010900] Batch Recognition Loss:   0.003169 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.516825 => Txt Tokens per Sec:     4012 || Lr: 0.000100
2024-02-04 04:15:55,477 Epoch  82: Total Training Recognition Loss 0.14  Total Training Translation Loss 76.68 
2024-02-04 04:15:55,477 EPOCH 83
2024-02-04 04:16:00,670 [Epoch: 083 Step: 00011000] Batch Recognition Loss:   0.000443 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.192723 => Txt Tokens per Sec:     3996 || Lr: 0.000100
2024-02-04 04:16:02,894 Epoch  83: Total Training Recognition Loss 0.13  Total Training Translation Loss 77.49 
2024-02-04 04:16:02,894 EPOCH 84
2024-02-04 04:16:06,294 [Epoch: 084 Step: 00011100] Batch Recognition Loss:   0.001236 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.292391 => Txt Tokens per Sec:     4023 || Lr: 0.000100
2024-02-04 04:16:10,326 Epoch  84: Total Training Recognition Loss 0.10  Total Training Translation Loss 72.47 
2024-02-04 04:16:10,326 EPOCH 85
2024-02-04 04:16:11,886 [Epoch: 085 Step: 00011200] Batch Recognition Loss:   0.001403 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.558476 => Txt Tokens per Sec:     4250 || Lr: 0.000100
2024-02-04 04:16:17,561 [Epoch: 085 Step: 00011300] Batch Recognition Loss:   0.001905 => Gls Tokens per Sec:     1408 || Batch Translation Loss:   0.700404 => Txt Tokens per Sec:     3854 || Lr: 0.000100
2024-02-04 04:16:17,796 Epoch  85: Total Training Recognition Loss 0.10  Total Training Translation Loss 65.80 
2024-02-04 04:16:17,796 EPOCH 86
2024-02-04 04:16:22,677 [Epoch: 086 Step: 00011400] Batch Recognition Loss:   0.000696 => Gls Tokens per Sec:     1557 || Batch Translation Loss:   0.158669 => Txt Tokens per Sec:     4337 || Lr: 0.000100
2024-02-04 04:16:24,905 Epoch  86: Total Training Recognition Loss 0.10  Total Training Translation Loss 64.56 
2024-02-04 04:16:24,905 EPOCH 87
2024-02-04 04:16:28,539 [Epoch: 087 Step: 00011500] Batch Recognition Loss:   0.003089 => Gls Tokens per Sec:     1365 || Batch Translation Loss:   0.379168 => Txt Tokens per Sec:     3824 || Lr: 0.000100
2024-02-04 04:16:32,692 Epoch  87: Total Training Recognition Loss 0.09  Total Training Translation Loss 58.70 
2024-02-04 04:16:32,693 EPOCH 88
2024-02-04 04:16:34,346 [Epoch: 088 Step: 00011600] Batch Recognition Loss:   0.005297 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.353397 => Txt Tokens per Sec:     3816 || Lr: 0.000100
2024-02-04 04:16:39,890 [Epoch: 088 Step: 00011700] Batch Recognition Loss:   0.000304 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.359260 => Txt Tokens per Sec:     4030 || Lr: 0.000100
2024-02-04 04:16:40,097 Epoch  88: Total Training Recognition Loss 0.12  Total Training Translation Loss 59.14 
2024-02-04 04:16:40,097 EPOCH 89
2024-02-04 04:16:45,352 [Epoch: 089 Step: 00011800] Batch Recognition Loss:   0.000971 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.949806 => Txt Tokens per Sec:     4042 || Lr: 0.000100
2024-02-04 04:16:47,464 Epoch  89: Total Training Recognition Loss 0.10  Total Training Translation Loss 55.67 
2024-02-04 04:16:47,465 EPOCH 90
2024-02-04 04:16:51,180 [Epoch: 090 Step: 00011900] Batch Recognition Loss:   0.000837 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.144400 => Txt Tokens per Sec:     3778 || Lr: 0.000100
2024-02-04 04:16:55,178 Epoch  90: Total Training Recognition Loss 0.11  Total Training Translation Loss 52.82 
2024-02-04 04:16:55,178 EPOCH 91
2024-02-04 04:16:56,699 [Epoch: 091 Step: 00012000] Batch Recognition Loss:   0.000523 => Gls Tokens per Sec:     1580 || Batch Translation Loss:   0.278034 => Txt Tokens per Sec:     4343 || Lr: 0.000100
2024-02-04 04:17:07,277 Validation result at epoch  91, step    12000: duration: 10.5774s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00508	Translation Loss: 88432.92969	PPL: 6970.81396
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.72	(BLEU-1: 11.39,	BLEU-2: 3.59,	BLEU-3: 1.38,	BLEU-4: 0.72)
	CHRF 16.96	ROUGE 9.93
2024-02-04 04:17:07,278 Logging Recognition and Translation Outputs
2024-02-04 04:17:07,278 ========================================================================================================================
2024-02-04 04:17:07,278 Logging Sequence: 177_50.00
2024-02-04 04:17:07,278 	Gloss Reference :	A B+C+D+E
2024-02-04 04:17:07,278 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:17:07,279 	Gloss Alignment :	         
2024-02-04 04:17:07,279 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:17:07,280 	Text Reference  :	***** a   similar reward of       rs   50000 was announced for information against his   associate ajay kumar
2024-02-04 04:17:07,280 	Text Hypothesis :	after her son     was    arrested when she   was postponed to  the         delhi   court would     be   held 
2024-02-04 04:17:07,280 	Text Alignment  :	I     S   S       S      S        S    S         S         S   S           S       S     S         S    S    
2024-02-04 04:17:07,281 ========================================================================================================================
2024-02-04 04:17:07,281 Logging Sequence: 122_86.00
2024-02-04 04:17:07,281 	Gloss Reference :	A B+C+D+E
2024-02-04 04:17:07,281 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:17:07,281 	Gloss Alignment :	         
2024-02-04 04:17:07,281 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:17:07,282 	Text Reference  :	*** after  winning chanu spoke       to  the media and said 
2024-02-04 04:17:07,282 	Text Hypothesis :	the indian team    was   responsible for the ***** 1st match
2024-02-04 04:17:07,282 	Text Alignment  :	I   S      S       S     S           S       D     S   S    
2024-02-04 04:17:07,282 ========================================================================================================================
2024-02-04 04:17:07,282 Logging Sequence: 165_27.00
2024-02-04 04:17:07,283 	Gloss Reference :	A B+C+D+E
2024-02-04 04:17:07,283 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:17:07,283 	Gloss Alignment :	         
2024-02-04 04:17:07,283 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:17:07,284 	Text Reference  :	******** so then they change their routes some      people believe in   this while some   don't   
2024-02-04 04:17:07,284 	Text Hypothesis :	whenever he has  now  handed over  the    captaincy to     his     wife for  a     sudden decision
2024-02-04 04:17:07,284 	Text Alignment  :	I        S  S    S    S      S     S      S         S      S       S    S    S     S      S       
2024-02-04 04:17:07,284 ========================================================================================================================
2024-02-04 04:17:07,285 Logging Sequence: 70_65.00
2024-02-04 04:17:07,285 	Gloss Reference :	A B+C+D+E
2024-02-04 04:17:07,285 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:17:07,285 	Gloss Alignment :	         
2024-02-04 04:17:07,285 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:17:07,286 	Text Reference  :	during the press conference a   table was placed in  front   of        the   media   
2024-02-04 04:17:07,286 	Text Hypothesis :	****** *** ***** italy      had won   the toss   and prevent infection boost immunity
2024-02-04 04:17:07,286 	Text Alignment  :	D      D   D     S          S   S     S   S      S   S       S         S     S       
2024-02-04 04:17:07,286 ========================================================================================================================
2024-02-04 04:17:07,286 Logging Sequence: 149_65.00
2024-02-04 04:17:07,287 	Gloss Reference :	A B+C+D+E
2024-02-04 04:17:07,287 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:17:07,287 	Gloss Alignment :	         
2024-02-04 04:17:07,287 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:17:07,289 	Text Reference  :	at 6am on 6th november 2022 the   police reached sri  lankan team's    hotel in sydney australia's central business district cbd       
2024-02-04 04:17:07,289 	Text Hypothesis :	** *** in an  image    of   other indian will    play more   intensive audit in ****** *********** ******* ******** the      tournament
2024-02-04 04:17:07,289 	Text Alignment  :	D  D   S  S   S        S    S     S      S       S    S      S         S        D      D           D       D        S        S         
2024-02-04 04:17:07,289 ========================================================================================================================
2024-02-04 04:17:13,130 [Epoch: 091 Step: 00012100] Batch Recognition Loss:   0.000265 => Gls Tokens per Sec:     1365 || Batch Translation Loss:   0.694741 => Txt Tokens per Sec:     3810 || Lr: 0.000100
2024-02-04 04:17:13,337 Epoch  91: Total Training Recognition Loss 0.12  Total Training Translation Loss 58.51 
2024-02-04 04:17:13,338 EPOCH 92
2024-02-04 04:17:18,679 [Epoch: 092 Step: 00012200] Batch Recognition Loss:   0.001253 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.189429 => Txt Tokens per Sec:     4017 || Lr: 0.000100
2024-02-04 04:17:20,593 Epoch  92: Total Training Recognition Loss 0.12  Total Training Translation Loss 61.71 
2024-02-04 04:17:20,594 EPOCH 93
2024-02-04 04:17:23,745 [Epoch: 093 Step: 00012300] Batch Recognition Loss:   0.000381 => Gls Tokens per Sec:     1625 || Batch Translation Loss:   0.518939 => Txt Tokens per Sec:     4460 || Lr: 0.000100
2024-02-04 04:17:27,993 Epoch  93: Total Training Recognition Loss 0.12  Total Training Translation Loss 57.66 
2024-02-04 04:17:27,994 EPOCH 94
2024-02-04 04:17:29,881 [Epoch: 094 Step: 00012400] Batch Recognition Loss:   0.002510 => Gls Tokens per Sec:     1314 || Batch Translation Loss:   0.291858 => Txt Tokens per Sec:     3701 || Lr: 0.000100
2024-02-04 04:17:35,056 [Epoch: 094 Step: 00012500] Batch Recognition Loss:   0.001723 => Gls Tokens per Sec:     1544 || Batch Translation Loss:   0.266014 => Txt Tokens per Sec:     4252 || Lr: 0.000100
2024-02-04 04:17:35,168 Epoch  94: Total Training Recognition Loss 0.10  Total Training Translation Loss 46.85 
2024-02-04 04:17:35,168 EPOCH 95
2024-02-04 04:17:40,502 [Epoch: 095 Step: 00012600] Batch Recognition Loss:   0.000706 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.491457 => Txt Tokens per Sec:     4092 || Lr: 0.000100
2024-02-04 04:17:42,377 Epoch  95: Total Training Recognition Loss 0.09  Total Training Translation Loss 47.19 
2024-02-04 04:17:42,377 EPOCH 96
2024-02-04 04:17:45,967 [Epoch: 096 Step: 00012700] Batch Recognition Loss:   0.000358 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.166190 => Txt Tokens per Sec:     4064 || Lr: 0.000100
2024-02-04 04:17:49,881 Epoch  96: Total Training Recognition Loss 0.11  Total Training Translation Loss 49.51 
2024-02-04 04:17:49,881 EPOCH 97
2024-02-04 04:17:51,761 [Epoch: 097 Step: 00012800] Batch Recognition Loss:   0.000596 => Gls Tokens per Sec:     1362 || Batch Translation Loss:   0.571062 => Txt Tokens per Sec:     3856 || Lr: 0.000100
2024-02-04 04:17:57,562 [Epoch: 097 Step: 00012900] Batch Recognition Loss:   0.000270 => Gls Tokens per Sec:     1377 || Batch Translation Loss:   0.186529 => Txt Tokens per Sec:     3794 || Lr: 0.000100
2024-02-04 04:17:57,613 Epoch  97: Total Training Recognition Loss 0.08  Total Training Translation Loss 51.15 
2024-02-04 04:17:57,613 EPOCH 98
2024-02-04 04:18:03,015 [Epoch: 098 Step: 00013000] Batch Recognition Loss:   0.000491 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   0.090312 => Txt Tokens per Sec:     4057 || Lr: 0.000100
2024-02-04 04:18:04,855 Epoch  98: Total Training Recognition Loss 0.12  Total Training Translation Loss 58.27 
2024-02-04 04:18:04,855 EPOCH 99
2024-02-04 04:18:08,122 [Epoch: 099 Step: 00013100] Batch Recognition Loss:   0.000478 => Gls Tokens per Sec:     1617 || Batch Translation Loss:   0.186629 => Txt Tokens per Sec:     4318 || Lr: 0.000100
2024-02-04 04:18:12,322 Epoch  99: Total Training Recognition Loss 0.09  Total Training Translation Loss 54.59 
2024-02-04 04:18:12,322 EPOCH 100
2024-02-04 04:18:14,254 [Epoch: 100 Step: 00013200] Batch Recognition Loss:   0.000419 => Gls Tokens per Sec:     1368 || Batch Translation Loss:   0.119571 => Txt Tokens per Sec:     3993 || Lr: 0.000100
2024-02-04 04:18:19,779 [Epoch: 100 Step: 00013300] Batch Recognition Loss:   0.001088 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.870389 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-04 04:18:19,779 Epoch 100: Total Training Recognition Loss 0.13  Total Training Translation Loss 50.68 
2024-02-04 04:18:19,779 EPOCH 101
2024-02-04 04:18:25,403 [Epoch: 101 Step: 00013400] Batch Recognition Loss:   0.000294 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.276845 => Txt Tokens per Sec:     3966 || Lr: 0.000100
2024-02-04 04:18:27,146 Epoch 101: Total Training Recognition Loss 0.11  Total Training Translation Loss 53.56 
2024-02-04 04:18:27,147 EPOCH 102
2024-02-04 04:18:30,699 [Epoch: 102 Step: 00013500] Batch Recognition Loss:   0.002495 => Gls Tokens per Sec:     1509 || Batch Translation Loss:   0.186509 => Txt Tokens per Sec:     4257 || Lr: 0.000100
2024-02-04 04:18:34,489 Epoch 102: Total Training Recognition Loss 0.14  Total Training Translation Loss 51.40 
2024-02-04 04:18:34,489 EPOCH 103
2024-02-04 04:18:36,400 [Epoch: 103 Step: 00013600] Batch Recognition Loss:   0.000167 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.240328 => Txt Tokens per Sec:     3947 || Lr: 0.000100
2024-02-04 04:18:42,001 Epoch 103: Total Training Recognition Loss 0.08  Total Training Translation Loss 52.29 
2024-02-04 04:18:42,002 EPOCH 104
2024-02-04 04:18:42,054 [Epoch: 104 Step: 00013700] Batch Recognition Loss:   0.000324 => Gls Tokens per Sec:     1569 || Batch Translation Loss:   0.194843 => Txt Tokens per Sec:     4726 || Lr: 0.000100
2024-02-04 04:18:47,351 [Epoch: 104 Step: 00013800] Batch Recognition Loss:   0.000580 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.409668 => Txt Tokens per Sec:     4186 || Lr: 0.000100
2024-02-04 04:18:49,168 Epoch 104: Total Training Recognition Loss 0.12  Total Training Translation Loss 51.93 
2024-02-04 04:18:49,168 EPOCH 105
2024-02-04 04:18:52,579 [Epoch: 105 Step: 00013900] Batch Recognition Loss:   0.000511 => Gls Tokens per Sec:     1596 || Batch Translation Loss:   0.600016 => Txt Tokens per Sec:     4330 || Lr: 0.000100
2024-02-04 04:18:56,464 Epoch 105: Total Training Recognition Loss 0.14  Total Training Translation Loss 58.87 
2024-02-04 04:18:56,464 EPOCH 106
2024-02-04 04:18:58,324 [Epoch: 106 Step: 00014000] Batch Recognition Loss:   0.000334 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.305944 => Txt Tokens per Sec:     4061 || Lr: 0.000100
2024-02-04 04:19:09,081 Hooray! New best validation result [eval_metric]!
2024-02-04 04:19:09,082 Saving new checkpoint.
2024-02-04 04:19:09,340 Validation result at epoch 106, step    14000: duration: 11.0160s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00385	Translation Loss: 89762.45312	PPL: 7962.78027
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.99	(BLEU-1: 11.00,	BLEU-2: 3.71,	BLEU-3: 1.74,	BLEU-4: 0.99)
	CHRF 17.18	ROUGE 9.42
2024-02-04 04:19:09,341 Logging Recognition and Translation Outputs
2024-02-04 04:19:09,341 ========================================================================================================================
2024-02-04 04:19:09,341 Logging Sequence: 141_40.00
2024-02-04 04:19:09,342 	Gloss Reference :	A B+C+D+E
2024-02-04 04:19:09,342 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:19:09,342 	Gloss Alignment :	         
2024-02-04 04:19:09,342 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:19:09,343 	Text Reference  :	got infected with  covid-19      he was quarantined and  could not    take    part     in  the  warmup match
2024-02-04 04:19:09,343 	Text Hypothesis :	*** ******** since participating in the 2020        2020 he    played against welcomed him back to     bat  
2024-02-04 04:19:09,344 	Text Alignment  :	D   D        S     S             S  S   S           S    S     S      S       S        S   S    S      S    
2024-02-04 04:19:09,344 ========================================================================================================================
2024-02-04 04:19:09,344 Logging Sequence: 117_37.00
2024-02-04 04:19:09,344 	Gloss Reference :	A B+C+D+E
2024-02-04 04:19:09,344 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:19:09,344 	Gloss Alignment :	         
2024-02-04 04:19:09,344 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:19:09,345 	Text Reference  :	shikhar dhawan put   up   a  wonderful performance scoring 98      runs    
2024-02-04 04:19:09,345 	Text Hypothesis :	on      23rd   march 2023 at the       1st         match   between pakistan
2024-02-04 04:19:09,345 	Text Alignment  :	S       S      S     S    S  S         S           S       S       S       
2024-02-04 04:19:09,345 ========================================================================================================================
2024-02-04 04:19:09,346 Logging Sequence: 64_13.00
2024-02-04 04:19:09,346 	Gloss Reference :	A B+C+D+E
2024-02-04 04:19:09,346 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:19:09,346 	Gloss Alignment :	         
2024-02-04 04:19:09,346 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:19:09,347 	Text Reference  :	arrangements were made to  move all     the  ipl  matches     to the wankhede stadium in        mumbai
2024-02-04 04:19:09,347 	Text Hypothesis :	************ **** **** the two  players have been quarantined at the ******** ******* ahmedabad hotel 
2024-02-04 04:19:09,347 	Text Alignment  :	D            D    D    S   S    S       S    S    S           S      D        D       S         S     
2024-02-04 04:19:09,347 ========================================================================================================================
2024-02-04 04:19:09,348 Logging Sequence: 98_121.00
2024-02-04 04:19:09,348 	Gloss Reference :	A B+C+D+E
2024-02-04 04:19:09,348 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:19:09,348 	Gloss Alignment :	         
2024-02-04 04:19:09,348 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:19:09,349 	Text Reference  :	so then england legends and   bangladesh legends were added to the  tournament
2024-02-04 04:19:09,349 	Text Hypothesis :	** **** ******* ******* mumal shared     that    they lost  to take hotel     
2024-02-04 04:19:09,349 	Text Alignment  :	D  D    D       D       S     S          S       S    S        S    S         
2024-02-04 04:19:09,349 ========================================================================================================================
2024-02-04 04:19:09,349 Logging Sequence: 179_414.00
2024-02-04 04:19:09,349 	Gloss Reference :	A B+C+D+E
2024-02-04 04:19:09,349 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:19:09,350 	Gloss Alignment :	         
2024-02-04 04:19:09,350 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:19:09,351 	Text Reference  :	we could  not travel to    delhi as  there  was a   lockdown in     our home    town haryana 
2024-02-04 04:19:09,351 	Text Hypothesis :	** before the ioa    could send  the notice wfi has asked    phogat to  collect her  passport
2024-02-04 04:19:09,351 	Text Alignment  :	D  S      S   S      S     S     S   S      S   S   S        S      S   S       S    S       
2024-02-04 04:19:09,351 ========================================================================================================================
2024-02-04 04:19:15,054 Epoch 106: Total Training Recognition Loss 0.10  Total Training Translation Loss 48.52 
2024-02-04 04:19:15,055 EPOCH 107
2024-02-04 04:19:15,159 [Epoch: 107 Step: 00014100] Batch Recognition Loss:   0.000588 => Gls Tokens per Sec:     1538 || Batch Translation Loss:   0.133532 => Txt Tokens per Sec:     4750 || Lr: 0.000100
2024-02-04 04:19:20,665 [Epoch: 107 Step: 00014200] Batch Recognition Loss:   0.000353 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.257604 => Txt Tokens per Sec:     4035 || Lr: 0.000100
2024-02-04 04:19:22,375 Epoch 107: Total Training Recognition Loss 0.09  Total Training Translation Loss 45.35 
2024-02-04 04:19:22,375 EPOCH 108
2024-02-04 04:19:26,397 [Epoch: 108 Step: 00014300] Batch Recognition Loss:   0.000599 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.143628 => Txt Tokens per Sec:     3799 || Lr: 0.000100
2024-02-04 04:19:30,041 Epoch 108: Total Training Recognition Loss 0.10  Total Training Translation Loss 44.96 
2024-02-04 04:19:30,042 EPOCH 109
2024-02-04 04:19:32,004 [Epoch: 109 Step: 00014400] Batch Recognition Loss:   0.000666 => Gls Tokens per Sec:     1468 || Batch Translation Loss:   0.637014 => Txt Tokens per Sec:     3902 || Lr: 0.000100
2024-02-04 04:19:37,885 Epoch 109: Total Training Recognition Loss 0.10  Total Training Translation Loss 45.63 
2024-02-04 04:19:37,885 EPOCH 110
2024-02-04 04:19:38,055 [Epoch: 110 Step: 00014500] Batch Recognition Loss:   0.000311 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.559375 => Txt Tokens per Sec:     3898 || Lr: 0.000100
2024-02-04 04:19:43,526 [Epoch: 110 Step: 00014600] Batch Recognition Loss:   0.000889 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.398972 => Txt Tokens per Sec:     4084 || Lr: 0.000100
2024-02-04 04:19:45,168 Epoch 110: Total Training Recognition Loss 0.09  Total Training Translation Loss 46.61 
2024-02-04 04:19:45,169 EPOCH 111
2024-02-04 04:19:49,178 [Epoch: 111 Step: 00014700] Batch Recognition Loss:   0.000170 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.201230 => Txt Tokens per Sec:     3799 || Lr: 0.000100
2024-02-04 04:19:53,056 Epoch 111: Total Training Recognition Loss 0.10  Total Training Translation Loss 42.28 
2024-02-04 04:19:53,057 EPOCH 112
2024-02-04 04:19:55,186 [Epoch: 112 Step: 00014800] Batch Recognition Loss:   0.000537 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.215121 => Txt Tokens per Sec:     3743 || Lr: 0.000100
2024-02-04 04:20:00,790 Epoch 112: Total Training Recognition Loss 0.11  Total Training Translation Loss 38.14 
2024-02-04 04:20:00,790 EPOCH 113
2024-02-04 04:20:00,995 [Epoch: 113 Step: 00014900] Batch Recognition Loss:   0.000368 => Gls Tokens per Sec:     1569 || Batch Translation Loss:   0.543614 => Txt Tokens per Sec:     4578 || Lr: 0.000100
2024-02-04 04:20:06,814 [Epoch: 113 Step: 00015000] Batch Recognition Loss:   0.000690 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.261040 => Txt Tokens per Sec:     3840 || Lr: 0.000100
2024-02-04 04:20:08,307 Epoch 113: Total Training Recognition Loss 0.10  Total Training Translation Loss 43.74 
2024-02-04 04:20:08,308 EPOCH 114
2024-02-04 04:20:12,069 [Epoch: 114 Step: 00015100] Batch Recognition Loss:   0.000566 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.649573 => Txt Tokens per Sec:     4219 || Lr: 0.000100
2024-02-04 04:20:15,660 Epoch 114: Total Training Recognition Loss 0.09  Total Training Translation Loss 47.74 
2024-02-04 04:20:15,660 EPOCH 115
2024-02-04 04:20:17,793 [Epoch: 115 Step: 00015200] Batch Recognition Loss:   0.000410 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.127724 => Txt Tokens per Sec:     3975 || Lr: 0.000100
2024-02-04 04:20:23,351 Epoch 115: Total Training Recognition Loss 0.09  Total Training Translation Loss 44.29 
2024-02-04 04:20:23,352 EPOCH 116
2024-02-04 04:20:23,688 [Epoch: 116 Step: 00015300] Batch Recognition Loss:   0.001264 => Gls Tokens per Sec:     1194 || Batch Translation Loss:   0.142671 => Txt Tokens per Sec:     3504 || Lr: 0.000100
2024-02-04 04:20:29,333 [Epoch: 116 Step: 00015400] Batch Recognition Loss:   0.000737 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   0.756527 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-04 04:20:31,031 Epoch 116: Total Training Recognition Loss 0.11  Total Training Translation Loss 43.86 
2024-02-04 04:20:31,031 EPOCH 117
2024-02-04 04:20:35,069 [Epoch: 117 Step: 00015500] Batch Recognition Loss:   0.000737 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.350166 => Txt Tokens per Sec:     4052 || Lr: 0.000100
2024-02-04 04:20:38,524 Epoch 117: Total Training Recognition Loss 0.09  Total Training Translation Loss 43.36 
2024-02-04 04:20:38,525 EPOCH 118
2024-02-04 04:20:40,902 [Epoch: 118 Step: 00015600] Batch Recognition Loss:   0.000270 => Gls Tokens per Sec:     1312 || Batch Translation Loss:   0.274649 => Txt Tokens per Sec:     3652 || Lr: 0.000100
2024-02-04 04:20:46,513 Epoch 118: Total Training Recognition Loss 0.09  Total Training Translation Loss 50.51 
2024-02-04 04:20:46,513 EPOCH 119
2024-02-04 04:20:46,891 [Epoch: 119 Step: 00015700] Batch Recognition Loss:   0.000709 => Gls Tokens per Sec:     1277 || Batch Translation Loss:   0.349386 => Txt Tokens per Sec:     3832 || Lr: 0.000100
2024-02-04 04:20:52,410 [Epoch: 119 Step: 00015800] Batch Recognition Loss:   0.000337 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.647973 => Txt Tokens per Sec:     4030 || Lr: 0.000100
2024-02-04 04:20:53,809 Epoch 119: Total Training Recognition Loss 0.10  Total Training Translation Loss 51.32 
2024-02-04 04:20:53,810 EPOCH 120
2024-02-04 04:20:57,771 [Epoch: 120 Step: 00015900] Batch Recognition Loss:   0.000420 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.346462 => Txt Tokens per Sec:     4217 || Lr: 0.000100
2024-02-04 04:21:01,271 Epoch 120: Total Training Recognition Loss 0.08  Total Training Translation Loss 42.17 
2024-02-04 04:21:01,271 EPOCH 121
2024-02-04 04:21:03,450 [Epoch: 121 Step: 00016000] Batch Recognition Loss:   0.000491 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.485075 => Txt Tokens per Sec:     4030 || Lr: 0.000100
2024-02-04 04:21:13,981 Validation result at epoch 121, step    16000: duration: 10.5310s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00524	Translation Loss: 91426.57031	PPL: 9405.60645
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.82	(BLEU-1: 11.25,	BLEU-2: 3.68,	BLEU-3: 1.51,	BLEU-4: 0.82)
	CHRF 17.17	ROUGE 9.59
2024-02-04 04:21:13,982 Logging Recognition and Translation Outputs
2024-02-04 04:21:13,982 ========================================================================================================================
2024-02-04 04:21:13,982 Logging Sequence: 147_132.00
2024-02-04 04:21:13,982 	Gloss Reference :	A B+C+D+E
2024-02-04 04:21:13,983 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:21:13,983 	Gloss Alignment :	         
2024-02-04 04:21:13,983 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:21:13,984 	Text Reference  :	i    can    not earlier i  used to     have   fun in   gymnastics
2024-02-04 04:21:13,984 	Text Hypothesis :	they wanted to  focus   on her  mental health and well being     
2024-02-04 04:21:13,984 	Text Alignment  :	S    S      S   S       S  S    S      S      S   S    S         
2024-02-04 04:21:13,984 ========================================================================================================================
2024-02-04 04:21:13,984 Logging Sequence: 116_162.00
2024-02-04 04:21:13,985 	Gloss Reference :	A B+C+D+E
2024-02-04 04:21:13,985 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:21:13,985 	Gloss Alignment :	         
2024-02-04 04:21:13,985 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:21:13,986 	Text Reference  :	turned out     the video was shared on  social media by     a       staff at the ***** ************* hotel     
2024-02-04 04:21:13,986 	Text Hypothesis :	****** towards the ***** 6th world  cup 2022   is    played against arch  of the dubai international tournament
2024-02-04 04:21:13,986 	Text Alignment  :	D      S           D     S   S      S   S      S     S      S       S     S      I     I             S         
2024-02-04 04:21:13,987 ========================================================================================================================
2024-02-04 04:21:13,987 Logging Sequence: 73_79.00
2024-02-04 04:21:13,987 	Gloss Reference :	A B+C+D+E
2024-02-04 04:21:13,987 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:21:13,987 	Gloss Alignment :	         
2024-02-04 04:21:13,987 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:21:13,989 	Text Reference  :	raina resturant has      food from the rich spices of   north india to      the aromatic curries of        south india
2024-02-04 04:21:13,989 	Text Hypothesis :	***** the       cheapest dish on   the **** ****** menu is    raita whereas the ******** ******* costliest dish  is   
2024-02-04 04:21:13,989 	Text Alignment  :	D     S         S        S    S        D    D      S    S     S     S           D        D       S         S     S    
2024-02-04 04:21:13,989 ========================================================================================================================
2024-02-04 04:21:13,989 Logging Sequence: 165_523.00
2024-02-04 04:21:13,989 	Gloss Reference :	A B+C+D+E
2024-02-04 04:21:13,989 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:21:13,989 	Gloss Alignment :	         
2024-02-04 04:21:13,990 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:21:13,990 	Text Reference  :	as he believed that his team might lose if  he  takes off   his batting pads      
2024-02-04 04:21:13,990 	Text Hypothesis :	** ** ******** **** *** **** ***** **** icc did not   agree to  the     tournament
2024-02-04 04:21:13,991 	Text Alignment  :	D  D  D        D    D   D    D     D    S   S   S     S     S   S       S         
2024-02-04 04:21:13,991 ========================================================================================================================
2024-02-04 04:21:13,991 Logging Sequence: 125_72.00
2024-02-04 04:21:13,991 	Gloss Reference :	A B+C+D+E
2024-02-04 04:21:13,991 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:21:13,991 	Gloss Alignment :	         
2024-02-04 04:21:13,991 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:21:13,992 	Text Reference  :	some said the pakistani javelineer had    milicious intentions of tampering with       the javelin out of jealousy
2024-02-04 04:21:13,992 	Text Hypothesis :	**** **** *** ********* ********** neeraj was       flooded    by these     cricketers are javelin *** ** throw   
2024-02-04 04:21:13,992 	Text Alignment  :	D    D    D   D         D          S      S         S          S  S         S          S           D   D  S       
2024-02-04 04:21:13,993 ========================================================================================================================
2024-02-04 04:21:19,790 Epoch 121: Total Training Recognition Loss 0.09  Total Training Translation Loss 31.30 
2024-02-04 04:21:19,790 EPOCH 122
2024-02-04 04:21:20,195 [Epoch: 122 Step: 00016100] Batch Recognition Loss:   0.000527 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.126942 => Txt Tokens per Sec:     3592 || Lr: 0.000100
2024-02-04 04:21:25,719 [Epoch: 122 Step: 00016200] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.318634 => Txt Tokens per Sec:     4078 || Lr: 0.000100
2024-02-04 04:21:27,189 Epoch 122: Total Training Recognition Loss 0.10  Total Training Translation Loss 33.32 
2024-02-04 04:21:27,189 EPOCH 123
2024-02-04 04:21:31,218 [Epoch: 123 Step: 00016300] Batch Recognition Loss:   0.000706 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.311153 => Txt Tokens per Sec:     4034 || Lr: 0.000100
2024-02-04 04:21:34,678 Epoch 123: Total Training Recognition Loss 0.09  Total Training Translation Loss 33.52 
2024-02-04 04:21:34,679 EPOCH 124
2024-02-04 04:21:36,794 [Epoch: 124 Step: 00016400] Batch Recognition Loss:   0.001377 => Gls Tokens per Sec:     1552 || Batch Translation Loss:   0.317982 => Txt Tokens per Sec:     4265 || Lr: 0.000100
2024-02-04 04:21:42,226 Epoch 124: Total Training Recognition Loss 0.09  Total Training Translation Loss 35.49 
2024-02-04 04:21:42,226 EPOCH 125
2024-02-04 04:21:42,825 [Epoch: 125 Step: 00016500] Batch Recognition Loss:   0.000357 => Gls Tokens per Sec:     1070 || Batch Translation Loss:   0.233674 => Txt Tokens per Sec:     3540 || Lr: 0.000100
2024-02-04 04:21:47,989 [Epoch: 125 Step: 00016600] Batch Recognition Loss:   0.000702 => Gls Tokens per Sec:     1547 || Batch Translation Loss:   0.293800 => Txt Tokens per Sec:     4229 || Lr: 0.000100
2024-02-04 04:21:49,413 Epoch 125: Total Training Recognition Loss 0.10  Total Training Translation Loss 43.90 
2024-02-04 04:21:49,414 EPOCH 126
2024-02-04 04:21:53,721 [Epoch: 126 Step: 00016700] Batch Recognition Loss:   0.000302 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.132054 => Txt Tokens per Sec:     3911 || Lr: 0.000100
2024-02-04 04:21:57,207 Epoch 126: Total Training Recognition Loss 0.09  Total Training Translation Loss 39.33 
2024-02-04 04:21:57,208 EPOCH 127
2024-02-04 04:21:59,690 [Epoch: 127 Step: 00016800] Batch Recognition Loss:   0.000502 => Gls Tokens per Sec:     1354 || Batch Translation Loss:   0.272034 => Txt Tokens per Sec:     3744 || Lr: 0.000100
2024-02-04 04:22:04,731 Epoch 127: Total Training Recognition Loss 0.08  Total Training Translation Loss 40.94 
2024-02-04 04:22:04,731 EPOCH 128
2024-02-04 04:22:05,254 [Epoch: 128 Step: 00016900] Batch Recognition Loss:   0.000333 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.131413 => Txt Tokens per Sec:     3722 || Lr: 0.000100
2024-02-04 04:22:11,096 [Epoch: 128 Step: 00017000] Batch Recognition Loss:   0.000198 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.212911 => Txt Tokens per Sec:     3830 || Lr: 0.000100
2024-02-04 04:22:12,588 Epoch 128: Total Training Recognition Loss 0.08  Total Training Translation Loss 38.73 
2024-02-04 04:22:12,589 EPOCH 129
2024-02-04 04:22:16,659 [Epoch: 129 Step: 00017100] Batch Recognition Loss:   0.000222 => Gls Tokens per Sec:     1494 || Batch Translation Loss:   0.241323 => Txt Tokens per Sec:     4058 || Lr: 0.000100
2024-02-04 04:22:19,933 Epoch 129: Total Training Recognition Loss 0.08  Total Training Translation Loss 37.53 
2024-02-04 04:22:19,934 EPOCH 130
2024-02-04 04:22:22,200 [Epoch: 130 Step: 00017200] Batch Recognition Loss:   0.001961 => Gls Tokens per Sec:     1519 || Batch Translation Loss:   0.211155 => Txt Tokens per Sec:     4325 || Lr: 0.000100
2024-02-04 04:22:27,366 Epoch 130: Total Training Recognition Loss 0.08  Total Training Translation Loss 39.47 
2024-02-04 04:22:27,366 EPOCH 131
2024-02-04 04:22:28,009 [Epoch: 131 Step: 00017300] Batch Recognition Loss:   0.003998 => Gls Tokens per Sec:     1248 || Batch Translation Loss:   0.144415 => Txt Tokens per Sec:     3808 || Lr: 0.000100
2024-02-04 04:22:33,073 [Epoch: 131 Step: 00017400] Batch Recognition Loss:   0.000891 => Gls Tokens per Sec:     1580 || Batch Translation Loss:   0.351468 => Txt Tokens per Sec:     4364 || Lr: 0.000100
2024-02-04 04:22:34,328 Epoch 131: Total Training Recognition Loss 0.10  Total Training Translation Loss 39.56 
2024-02-04 04:22:34,328 EPOCH 132
2024-02-04 04:22:38,107 [Epoch: 132 Step: 00017500] Batch Recognition Loss:   0.000766 => Gls Tokens per Sec:     1630 || Batch Translation Loss:   0.673992 => Txt Tokens per Sec:     4557 || Lr: 0.000100
2024-02-04 04:22:41,369 Epoch 132: Total Training Recognition Loss 0.09  Total Training Translation Loss 37.60 
2024-02-04 04:22:41,370 EPOCH 133
2024-02-04 04:22:43,628 [Epoch: 133 Step: 00017600] Batch Recognition Loss:   0.000245 => Gls Tokens per Sec:     1560 || Batch Translation Loss:   0.314444 => Txt Tokens per Sec:     4348 || Lr: 0.000100
2024-02-04 04:22:48,699 Epoch 133: Total Training Recognition Loss 0.09  Total Training Translation Loss 37.36 
2024-02-04 04:22:48,699 EPOCH 134
2024-02-04 04:22:49,330 [Epoch: 134 Step: 00017700] Batch Recognition Loss:   0.000359 => Gls Tokens per Sec:     1399 || Batch Translation Loss:   0.702372 => Txt Tokens per Sec:     4129 || Lr: 0.000100
2024-02-04 04:22:54,685 [Epoch: 134 Step: 00017800] Batch Recognition Loss:   0.000310 => Gls Tokens per Sec:     1494 || Batch Translation Loss:   0.192352 => Txt Tokens per Sec:     4079 || Lr: 0.000100
2024-02-04 04:22:56,128 Epoch 134: Total Training Recognition Loss 0.07  Total Training Translation Loss 36.45 
2024-02-04 04:22:56,129 EPOCH 135
2024-02-04 04:23:00,349 [Epoch: 135 Step: 00017900] Batch Recognition Loss:   0.000334 => Gls Tokens per Sec:     1479 || Batch Translation Loss:   0.578116 => Txt Tokens per Sec:     4155 || Lr: 0.000100
2024-02-04 04:23:03,497 Epoch 135: Total Training Recognition Loss 0.11  Total Training Translation Loss 40.82 
2024-02-04 04:23:03,498 EPOCH 136
2024-02-04 04:23:06,166 [Epoch: 136 Step: 00018000] Batch Recognition Loss:   0.000621 => Gls Tokens per Sec:     1350 || Batch Translation Loss:   0.223387 => Txt Tokens per Sec:     3618 || Lr: 0.000100
2024-02-04 04:23:16,697 Validation result at epoch 136, step    18000: duration: 10.5292s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00259	Translation Loss: 93005.19531	PPL: 11015.23438
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.68	(BLEU-1: 11.55,	BLEU-2: 3.51,	BLEU-3: 1.44,	BLEU-4: 0.68)
	CHRF 17.20	ROUGE 9.93
2024-02-04 04:23:16,698 Logging Recognition and Translation Outputs
2024-02-04 04:23:16,698 ========================================================================================================================
2024-02-04 04:23:16,698 Logging Sequence: 155_119.00
2024-02-04 04:23:16,698 	Gloss Reference :	A B+C+D+E
2024-02-04 04:23:16,698 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:23:16,698 	Gloss Alignment :	         
2024-02-04 04:23:16,698 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:23:16,700 	Text Reference  :	a report  said that the ***** taliban wanted icc   to replace the    afghan  flag with        its own  
2024-02-04 04:23:16,700 	Text Hypothesis :	* however they took the first time    in     qatar to ******* decide whether to   participate in  qatar
2024-02-04 04:23:16,700 	Text Alignment  :	D S       S    S        I     S       S      S        D       S      S       S    S           S   S    
2024-02-04 04:23:16,700 ========================================================================================================================
2024-02-04 04:23:16,700 Logging Sequence: 153_43.00
2024-02-04 04:23:16,701 	Gloss Reference :	A B+C+D+E
2024-02-04 04:23:16,701 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:23:16,701 	Gloss Alignment :	         
2024-02-04 04:23:16,701 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:23:16,702 	Text Reference  :	***** *** these runs were all         because of   hardik pandya and  virat  kohli
2024-02-04 04:23:16,702 	Text Hypothesis :	hence the bcci  is   not  comfortable and     went to     his    wife sakshi dhoni
2024-02-04 04:23:16,702 	Text Alignment  :	I     I   S     S    S    S           S       S    S      S      S    S      S    
2024-02-04 04:23:16,702 ========================================================================================================================
2024-02-04 04:23:16,702 Logging Sequence: 150_35.00
2024-02-04 04:23:16,702 	Gloss Reference :	A B+C+D+E
2024-02-04 04:23:16,703 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:23:16,703 	Gloss Alignment :	         
2024-02-04 04:23:16,703 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:23:16,703 	Text Reference  :	wow india football team is really strong
2024-02-04 04:23:16,703 	Text Hypothesis :	*** ***** ******** **** 1  high   fever 
2024-02-04 04:23:16,703 	Text Alignment  :	D   D     D        D    S  S      S     
2024-02-04 04:23:16,703 ========================================================================================================================
2024-02-04 04:23:16,704 Logging Sequence: 146_154.00
2024-02-04 04:23:16,704 	Gloss Reference :	A B+C+D+E
2024-02-04 04:23:16,704 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:23:16,704 	Gloss Alignment :	         
2024-02-04 04:23:16,704 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:23:16,706 	Text Reference  :	bwf said that   testing protocols have been implemented to *** ensure the     health and **** safety of     all    participants
2024-02-04 04:23:16,706 	Text Hypothesis :	*** the  couple were    infected  by   the  media       to his wife   anushka sharma and show a      number number '˜7'        
2024-02-04 04:23:16,706 	Text Alignment  :	D   S    S      S       S         S    S    S              I   S      S       S          I    S      S      S      S           
2024-02-04 04:23:16,706 ========================================================================================================================
2024-02-04 04:23:16,706 Logging Sequence: 76_79.00
2024-02-04 04:23:16,706 	Gloss Reference :	A B+C+D+E
2024-02-04 04:23:16,707 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:23:16,707 	Gloss Alignment :	         
2024-02-04 04:23:16,707 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:23:16,708 	Text Reference  :	** **** ******** **** *** *** ***** *** ** ********* ***** ** speaking to       ani  csk  ceo kasi viswanathan said   
2024-02-04 04:23:16,708 	Text Hypothesis :	on 13th february 2023 the t20 world cup is currently going on and      pakistan will have to  play against     england
2024-02-04 04:23:16,708 	Text Alignment  :	I  I    I        I    I   I   I     I   I  I         I     I  S        S        S    S    S   S    S           S      
2024-02-04 04:23:16,708 ========================================================================================================================
2024-02-04 04:23:21,990 Epoch 136: Total Training Recognition Loss 0.09  Total Training Translation Loss 33.36 
2024-02-04 04:23:21,991 EPOCH 137
2024-02-04 04:23:22,681 [Epoch: 137 Step: 00018100] Batch Recognition Loss:   0.000593 => Gls Tokens per Sec:     1394 || Batch Translation Loss:   0.265722 => Txt Tokens per Sec:     3690 || Lr: 0.000100
2024-02-04 04:23:28,177 [Epoch: 137 Step: 00018200] Batch Recognition Loss:   0.000234 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.149622 => Txt Tokens per Sec:     4056 || Lr: 0.000100
2024-02-04 04:23:29,322 Epoch 137: Total Training Recognition Loss 0.09  Total Training Translation Loss 28.90 
2024-02-04 04:23:29,323 EPOCH 138
2024-02-04 04:23:33,956 [Epoch: 138 Step: 00018300] Batch Recognition Loss:   0.000447 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.114194 => Txt Tokens per Sec:     3799 || Lr: 0.000100
2024-02-04 04:23:36,995 Epoch 138: Total Training Recognition Loss 0.07  Total Training Translation Loss 27.60 
2024-02-04 04:23:36,995 EPOCH 139
2024-02-04 04:23:39,877 [Epoch: 139 Step: 00018400] Batch Recognition Loss:   0.000387 => Gls Tokens per Sec:     1277 || Batch Translation Loss:   0.152617 => Txt Tokens per Sec:     3613 || Lr: 0.000100
2024-02-04 04:23:44,860 Epoch 139: Total Training Recognition Loss 0.06  Total Training Translation Loss 30.89 
2024-02-04 04:23:44,861 EPOCH 140
2024-02-04 04:23:45,601 [Epoch: 140 Step: 00018500] Batch Recognition Loss:   0.000403 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.061294 => Txt Tokens per Sec:     3778 || Lr: 0.000100
2024-02-04 04:23:51,432 [Epoch: 140 Step: 00018600] Batch Recognition Loss:   0.000168 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.268853 => Txt Tokens per Sec:     3839 || Lr: 0.000100
2024-02-04 04:23:52,489 Epoch 140: Total Training Recognition Loss 0.09  Total Training Translation Loss 39.07 
2024-02-04 04:23:52,489 EPOCH 141
2024-02-04 04:23:56,894 [Epoch: 141 Step: 00018700] Batch Recognition Loss:   0.000888 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.281012 => Txt Tokens per Sec:     4026 || Lr: 0.000100
2024-02-04 04:23:59,917 Epoch 141: Total Training Recognition Loss 0.10  Total Training Translation Loss 37.88 
2024-02-04 04:23:59,917 EPOCH 142
2024-02-04 04:24:02,655 [Epoch: 142 Step: 00018800] Batch Recognition Loss:   0.000237 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.212523 => Txt Tokens per Sec:     3980 || Lr: 0.000100
2024-02-04 04:24:07,479 Epoch 142: Total Training Recognition Loss 0.09  Total Training Translation Loss 47.13 
2024-02-04 04:24:07,480 EPOCH 143
2024-02-04 04:24:08,182 [Epoch: 143 Step: 00018900] Batch Recognition Loss:   0.000473 => Gls Tokens per Sec:     1595 || Batch Translation Loss:   0.197503 => Txt Tokens per Sec:     4359 || Lr: 0.000100
2024-02-04 04:24:13,681 [Epoch: 143 Step: 00019000] Batch Recognition Loss:   0.001477 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.207819 => Txt Tokens per Sec:     4069 || Lr: 0.000100
2024-02-04 04:24:14,710 Epoch 143: Total Training Recognition Loss 0.08  Total Training Translation Loss 45.69 
2024-02-04 04:24:14,711 EPOCH 144
2024-02-04 04:24:18,931 [Epoch: 144 Step: 00019100] Batch Recognition Loss:   0.000336 => Gls Tokens per Sec:     1535 || Batch Translation Loss:   0.231726 => Txt Tokens per Sec:     4293 || Lr: 0.000100
2024-02-04 04:24:21,818 Epoch 144: Total Training Recognition Loss 0.06  Total Training Translation Loss 34.63 
2024-02-04 04:24:21,819 EPOCH 145
2024-02-04 04:24:24,351 [Epoch: 145 Step: 00019200] Batch Recognition Loss:   0.000108 => Gls Tokens per Sec:     1517 || Batch Translation Loss:   0.112388 => Txt Tokens per Sec:     4088 || Lr: 0.000100
2024-02-04 04:24:29,178 Epoch 145: Total Training Recognition Loss 0.06  Total Training Translation Loss 29.00 
2024-02-04 04:24:29,178 EPOCH 146
2024-02-04 04:24:30,048 [Epoch: 146 Step: 00019300] Batch Recognition Loss:   0.000588 => Gls Tokens per Sec:     1381 || Batch Translation Loss:   0.070250 => Txt Tokens per Sec:     3715 || Lr: 0.000100
2024-02-04 04:24:35,678 [Epoch: 146 Step: 00019400] Batch Recognition Loss:   0.000164 => Gls Tokens per Sec:     1420 || Batch Translation Loss:   0.124739 => Txt Tokens per Sec:     3966 || Lr: 0.000100
2024-02-04 04:24:36,592 Epoch 146: Total Training Recognition Loss 0.07  Total Training Translation Loss 28.96 
2024-02-04 04:24:36,592 EPOCH 147
2024-02-04 04:24:41,116 [Epoch: 147 Step: 00019500] Batch Recognition Loss:   0.001824 => Gls Tokens per Sec:     1450 || Batch Translation Loss:   0.054235 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-04 04:24:44,093 Epoch 147: Total Training Recognition Loss 0.06  Total Training Translation Loss 31.55 
2024-02-04 04:24:44,093 EPOCH 148
2024-02-04 04:24:46,947 [Epoch: 148 Step: 00019600] Batch Recognition Loss:   0.000185 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.054957 => Txt Tokens per Sec:     3791 || Lr: 0.000100
2024-02-04 04:24:52,041 Epoch 148: Total Training Recognition Loss 0.06  Total Training Translation Loss 28.20 
2024-02-04 04:24:52,041 EPOCH 149
2024-02-04 04:24:52,893 [Epoch: 149 Step: 00019700] Batch Recognition Loss:   0.000185 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.055555 => Txt Tokens per Sec:     3997 || Lr: 0.000100
2024-02-04 04:24:58,518 [Epoch: 149 Step: 00019800] Batch Recognition Loss:   0.000390 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.428476 => Txt Tokens per Sec:     3982 || Lr: 0.000100
2024-02-04 04:24:59,566 Epoch 149: Total Training Recognition Loss 0.05  Total Training Translation Loss 27.06 
2024-02-04 04:24:59,567 EPOCH 150
2024-02-04 04:25:04,189 [Epoch: 150 Step: 00019900] Batch Recognition Loss:   0.001323 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.297628 => Txt Tokens per Sec:     4010 || Lr: 0.000100
2024-02-04 04:25:06,960 Epoch 150: Total Training Recognition Loss 0.07  Total Training Translation Loss 36.80 
2024-02-04 04:25:06,960 EPOCH 151
2024-02-04 04:25:09,607 [Epoch: 151 Step: 00020000] Batch Recognition Loss:   0.000528 => Gls Tokens per Sec:     1512 || Batch Translation Loss:   0.077349 => Txt Tokens per Sec:     4200 || Lr: 0.000100
2024-02-04 04:25:20,213 Validation result at epoch 151, step    20000: duration: 10.6060s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00385	Translation Loss: 94429.38281	PPL: 12702.49219
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.71	(BLEU-1: 10.58,	BLEU-2: 3.07,	BLEU-3: 1.22,	BLEU-4: 0.71)
	CHRF 16.48	ROUGE 9.24
2024-02-04 04:25:20,215 Logging Recognition and Translation Outputs
2024-02-04 04:25:20,215 ========================================================================================================================
2024-02-04 04:25:20,215 Logging Sequence: 174_121.00
2024-02-04 04:25:20,215 	Gloss Reference :	A B+C+D+E
2024-02-04 04:25:20,215 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:25:20,215 	Gloss Alignment :	         
2024-02-04 04:25:20,215 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:25:20,216 	Text Reference  :	there was a strong competition and  a    difficult auction for  the  5  franchise owners
2024-02-04 04:25:20,216 	Text Hypothesis :	***** *** * ****** *********** they have sent      its     deaf girl on social    media 
2024-02-04 04:25:20,216 	Text Alignment  :	D     D   D D      D           S    S    S         S       S    S    S  S         S     
2024-02-04 04:25:20,217 ========================================================================================================================
2024-02-04 04:25:20,217 Logging Sequence: 170_24.00
2024-02-04 04:25:20,217 	Gloss Reference :	A B+C+D+E
2024-02-04 04:25:20,217 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:25:20,217 	Gloss Alignment :	         
2024-02-04 04:25:20,217 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:25:20,218 	Text Reference  :	let me tell you about it
2024-02-04 04:25:20,218 	Text Hypothesis :	let me tell you about it
2024-02-04 04:25:20,218 	Text Alignment  :	                        
2024-02-04 04:25:20,218 ========================================================================================================================
2024-02-04 04:25:20,218 Logging Sequence: 73_79.00
2024-02-04 04:25:20,218 	Gloss Reference :	A B+C+D+E
2024-02-04 04:25:20,218 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:25:20,218 	Gloss Alignment :	         
2024-02-04 04:25:20,219 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:25:20,220 	Text Reference  :	raina resturant has      food from the rich spices of   north india to      the aromatic curries of        south india
2024-02-04 04:25:20,220 	Text Hypothesis :	***** the       cheapest dish on   the **** ****** menu is    raita whereas the ******** ******* costliest dish  is   
2024-02-04 04:25:20,220 	Text Alignment  :	D     S         S        S    S        D    D      S    S     S     S           D        D       S         S     S    
2024-02-04 04:25:20,220 ========================================================================================================================
2024-02-04 04:25:20,220 Logging Sequence: 140_2.00
2024-02-04 04:25:20,221 	Gloss Reference :	A B+C+D+E
2024-02-04 04:25:20,221 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:25:20,221 	Gloss Alignment :	         
2024-02-04 04:25:20,221 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:25:20,222 	Text Reference  :	**** indian batsman-wicket keeper    rishabh pant has outstanding skills in cricket
2024-02-04 04:25:20,222 	Text Hypothesis :	when csk    has            announced the     bag  can playing     such   as well   
2024-02-04 04:25:20,222 	Text Alignment  :	I    S      S              S         S       S    S   S           S      S  S      
2024-02-04 04:25:20,222 ========================================================================================================================
2024-02-04 04:25:20,222 Logging Sequence: 81_470.00
2024-02-04 04:25:20,222 	Gloss Reference :	A B+C+D+E
2024-02-04 04:25:20,222 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:25:20,223 	Gloss Alignment :	         
2024-02-04 04:25:20,223 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:25:20,224 	Text Reference  :	*** or  you     don't know if    you do   let us   know in   the comments
2024-02-04 04:25:20,224 	Text Hypothesis :	and the supreme court then moved to  keep the same or   into a   lot     
2024-02-04 04:25:20,224 	Text Alignment  :	I   S   S       S     S    S     S   S    S   S    S    S    S   S       
2024-02-04 04:25:20,224 ========================================================================================================================
2024-02-04 04:25:25,140 Epoch 151: Total Training Recognition Loss 0.07  Total Training Translation Loss 35.64 
2024-02-04 04:25:25,140 EPOCH 152
2024-02-04 04:25:26,055 [Epoch: 152 Step: 00020100] Batch Recognition Loss:   0.000515 => Gls Tokens per Sec:     1490 || Batch Translation Loss:   0.601018 => Txt Tokens per Sec:     3990 || Lr: 0.000100
2024-02-04 04:25:31,812 [Epoch: 152 Step: 00020200] Batch Recognition Loss:   0.000623 => Gls Tokens per Sec:     1388 || Batch Translation Loss:   0.222377 => Txt Tokens per Sec:     3877 || Lr: 0.000100
2024-02-04 04:25:32,698 Epoch 152: Total Training Recognition Loss 0.11  Total Training Translation Loss 34.03 
2024-02-04 04:25:32,698 EPOCH 153
2024-02-04 04:25:37,369 [Epoch: 153 Step: 00020300] Batch Recognition Loss:   0.001659 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.083040 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-04 04:25:40,061 Epoch 153: Total Training Recognition Loss 0.11  Total Training Translation Loss 29.72 
2024-02-04 04:25:40,061 EPOCH 154
2024-02-04 04:25:42,814 [Epoch: 154 Step: 00020400] Batch Recognition Loss:   0.000459 => Gls Tokens per Sec:     1483 || Batch Translation Loss:   0.080435 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-04 04:25:47,819 Epoch 154: Total Training Recognition Loss 0.07  Total Training Translation Loss 33.40 
2024-02-04 04:25:47,820 EPOCH 155
2024-02-04 04:25:48,926 [Epoch: 155 Step: 00020500] Batch Recognition Loss:   0.000280 => Gls Tokens per Sec:     1303 || Batch Translation Loss:   0.111717 => Txt Tokens per Sec:     3676 || Lr: 0.000100
2024-02-04 04:25:54,578 [Epoch: 155 Step: 00020600] Batch Recognition Loss:   0.000585 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.272172 => Txt Tokens per Sec:     3921 || Lr: 0.000100
2024-02-04 04:25:55,483 Epoch 155: Total Training Recognition Loss 0.07  Total Training Translation Loss 30.78 
2024-02-04 04:25:55,483 EPOCH 156
2024-02-04 04:25:59,963 [Epoch: 156 Step: 00020700] Batch Recognition Loss:   0.000233 => Gls Tokens per Sec:     1518 || Batch Translation Loss:   0.175886 => Txt Tokens per Sec:     4202 || Lr: 0.000100
2024-02-04 04:26:02,428 Epoch 156: Total Training Recognition Loss 0.07  Total Training Translation Loss 28.32 
2024-02-04 04:26:02,429 EPOCH 157
2024-02-04 04:26:05,481 [Epoch: 157 Step: 00020800] Batch Recognition Loss:   0.000260 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.495573 => Txt Tokens per Sec:     3840 || Lr: 0.000100
2024-02-04 04:26:10,191 Epoch 157: Total Training Recognition Loss 0.07  Total Training Translation Loss 28.33 
2024-02-04 04:26:10,192 EPOCH 158
2024-02-04 04:26:11,307 [Epoch: 158 Step: 00020900] Batch Recognition Loss:   0.000235 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.120218 => Txt Tokens per Sec:     3698 || Lr: 0.000100
2024-02-04 04:26:16,677 [Epoch: 158 Step: 00021000] Batch Recognition Loss:   0.000812 => Gls Tokens per Sec:     1490 || Batch Translation Loss:   0.251625 => Txt Tokens per Sec:     4194 || Lr: 0.000100
2024-02-04 04:26:17,483 Epoch 158: Total Training Recognition Loss 0.06  Total Training Translation Loss 30.03 
2024-02-04 04:26:17,484 EPOCH 159
2024-02-04 04:26:22,233 [Epoch: 159 Step: 00021100] Batch Recognition Loss:   0.000513 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.145740 => Txt Tokens per Sec:     4006 || Lr: 0.000100
2024-02-04 04:26:24,883 Epoch 159: Total Training Recognition Loss 0.08  Total Training Translation Loss 33.54 
2024-02-04 04:26:24,883 EPOCH 160
2024-02-04 04:26:27,826 [Epoch: 160 Step: 00021200] Batch Recognition Loss:   0.000284 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.122433 => Txt Tokens per Sec:     3906 || Lr: 0.000100
2024-02-04 04:26:32,433 Epoch 160: Total Training Recognition Loss 0.07  Total Training Translation Loss 27.93 
2024-02-04 04:26:32,434 EPOCH 161
2024-02-04 04:26:33,510 [Epoch: 161 Step: 00021300] Batch Recognition Loss:   0.000253 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   0.210732 => Txt Tokens per Sec:     3941 || Lr: 0.000100
2024-02-04 04:26:39,444 [Epoch: 161 Step: 00021400] Batch Recognition Loss:   0.001178 => Gls Tokens per Sec:     1347 || Batch Translation Loss:   0.274674 => Txt Tokens per Sec:     3748 || Lr: 0.000100
2024-02-04 04:26:40,175 Epoch 161: Total Training Recognition Loss 0.07  Total Training Translation Loss 25.36 
2024-02-04 04:26:40,175 EPOCH 162
2024-02-04 04:26:44,510 [Epoch: 162 Step: 00021500] Batch Recognition Loss:   0.000684 => Gls Tokens per Sec:     1607 || Batch Translation Loss:   0.121156 => Txt Tokens per Sec:     4475 || Lr: 0.000100
2024-02-04 04:26:47,302 Epoch 162: Total Training Recognition Loss 0.08  Total Training Translation Loss 23.15 
2024-02-04 04:26:47,302 EPOCH 163
2024-02-04 04:26:50,298 [Epoch: 163 Step: 00021600] Batch Recognition Loss:   0.000561 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   0.082657 => Txt Tokens per Sec:     4128 || Lr: 0.000100
2024-02-04 04:26:54,987 Epoch 163: Total Training Recognition Loss 0.07  Total Training Translation Loss 23.32 
2024-02-04 04:26:54,988 EPOCH 164
2024-02-04 04:26:56,152 [Epoch: 164 Step: 00021700] Batch Recognition Loss:   0.000187 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.243149 => Txt Tokens per Sec:     4005 || Lr: 0.000100
2024-02-04 04:27:01,548 [Epoch: 164 Step: 00021800] Batch Recognition Loss:   0.001933 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.134129 => Txt Tokens per Sec:     4066 || Lr: 0.000100
2024-02-04 04:27:02,376 Epoch 164: Total Training Recognition Loss 0.06  Total Training Translation Loss 30.64 
2024-02-04 04:27:02,377 EPOCH 165
2024-02-04 04:27:07,300 [Epoch: 165 Step: 00021900] Batch Recognition Loss:   0.001133 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.416089 => Txt Tokens per Sec:     3881 || Lr: 0.000100
2024-02-04 04:27:09,722 Epoch 165: Total Training Recognition Loss 0.07  Total Training Translation Loss 30.60 
2024-02-04 04:27:09,723 EPOCH 166
2024-02-04 04:27:12,884 [Epoch: 166 Step: 00022000] Batch Recognition Loss:   0.001109 => Gls Tokens per Sec:     1392 || Batch Translation Loss:   0.102352 => Txt Tokens per Sec:     3863 || Lr: 0.000100
2024-02-04 04:27:23,522 Validation result at epoch 166, step    22000: duration: 10.6368s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00344	Translation Loss: 96135.69531	PPL: 15067.63086
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.77	(BLEU-1: 10.45,	BLEU-2: 3.42,	BLEU-3: 1.52,	BLEU-4: 0.77)
	CHRF 16.15	ROUGE 9.31
2024-02-04 04:27:23,523 Logging Recognition and Translation Outputs
2024-02-04 04:27:23,523 ========================================================================================================================
2024-02-04 04:27:23,523 Logging Sequence: 146_56.00
2024-02-04 04:27:23,523 	Gloss Reference :	A B+C+D+E
2024-02-04 04:27:23,523 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:27:23,523 	Gloss Alignment :	         
2024-02-04 04:27:23,523 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:27:23,525 	Text Reference  :	when the players go       back to      the    hotel as   per rules all of them have to undergo rtpcr test for covid-19 everyday
2024-02-04 04:27:23,525 	Text Hypothesis :	**** he  is      stepping with anushka sharma and   only he  got   out of **** **** ** ******* ***** **** *** his      bat     
2024-02-04 04:27:23,526 	Text Alignment  :	D    S   S       S        S    S       S      S     S    S   S     S      D    D    D  D       D     D    D   S        S       
2024-02-04 04:27:23,526 ========================================================================================================================
2024-02-04 04:27:23,526 Logging Sequence: 118_338.00
2024-02-04 04:27:23,526 	Gloss Reference :	A B+C+D+E
2024-02-04 04:27:23,526 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:27:23,526 	Gloss Alignment :	         
2024-02-04 04:27:23,526 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:27:23,527 	Text Reference  :	** **** *** ***** **** *** this   is   why even messi   wore it   
2024-02-04 04:27:23,527 	Text Hypothesis :	as they are aware that the golden ball for the  winning the  match
2024-02-04 04:27:23,527 	Text Alignment  :	I  I    I   I     I    I   S      S    S   S    S       S    S    
2024-02-04 04:27:23,527 ========================================================================================================================
2024-02-04 04:27:23,527 Logging Sequence: 66_61.00
2024-02-04 04:27:23,528 	Gloss Reference :	A B+C+D+E
2024-02-04 04:27:23,528 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:27:23,528 	Gloss Alignment :	         
2024-02-04 04:27:23,528 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:27:23,529 	Text Reference  :	instead of returning back to  his homeland because  of his injury 
2024-02-04 04:27:23,529 	Text Hypothesis :	******* ** ********* **** and she was      consoled by his brother
2024-02-04 04:27:23,529 	Text Alignment  :	D       D  D         D    S   S   S        S        S      S      
2024-02-04 04:27:23,529 ========================================================================================================================
2024-02-04 04:27:23,529 Logging Sequence: 81_278.00
2024-02-04 04:27:23,529 	Gloss Reference :	A B+C+D+E
2024-02-04 04:27:23,529 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:27:23,529 	Gloss Alignment :	         
2024-02-04 04:27:23,530 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:27:23,531 	Text Reference  :	of this amrapali group paid rs 3570 crore the remaining rs 652    crore was paid by   amrapali    sapphire developers a    subsidiary of    amrapali group     
2024-02-04 04:27:23,532 	Text Hypothesis :	** **** ******** ***** **** ** **** ***** *** ********* a  person told  you can  find information on       29th       july 2023       after the      semi-final
2024-02-04 04:27:23,532 	Text Alignment  :	D  D    D        D     D    D  D    D     D   D         S  S      S     S   S    S    S           S        S          S    S          S     S        S         
2024-02-04 04:27:23,532 ========================================================================================================================
2024-02-04 04:27:23,532 Logging Sequence: 162_125.00
2024-02-04 04:27:23,532 	Gloss Reference :	A B+C+D+E
2024-02-04 04:27:23,532 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:27:23,532 	Gloss Alignment :	         
2024-02-04 04:27:23,532 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:27:23,533 	Text Reference  :	in response to this kohli received many hate comments on  social    media
2024-02-04 04:27:23,533 	Text Hypothesis :	** ******** as per  a     hard     to   have beaten   the ahmedabad team 
2024-02-04 04:27:23,533 	Text Alignment  :	D  D        S  S    S     S        S    S    S        S   S         S    
2024-02-04 04:27:23,534 ========================================================================================================================
2024-02-04 04:27:28,188 Epoch 166: Total Training Recognition Loss 0.08  Total Training Translation Loss 28.34 
2024-02-04 04:27:28,188 EPOCH 167
2024-02-04 04:27:29,443 [Epoch: 167 Step: 00022100] Batch Recognition Loss:   0.000377 => Gls Tokens per Sec:     1403 || Batch Translation Loss:   0.319130 => Txt Tokens per Sec:     3850 || Lr: 0.000100
2024-02-04 04:27:34,449 [Epoch: 167 Step: 00022200] Batch Recognition Loss:   0.000307 => Gls Tokens per Sec:     1597 || Batch Translation Loss:   0.096035 => Txt Tokens per Sec:     4429 || Lr: 0.000100
2024-02-04 04:27:35,188 Epoch 167: Total Training Recognition Loss 0.06  Total Training Translation Loss 31.07 
2024-02-04 04:27:35,189 EPOCH 168
2024-02-04 04:27:40,158 [Epoch: 168 Step: 00022300] Batch Recognition Loss:   0.000463 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   0.204972 => Txt Tokens per Sec:     3901 || Lr: 0.000100
2024-02-04 04:27:42,673 Epoch 168: Total Training Recognition Loss 0.08  Total Training Translation Loss 30.05 
2024-02-04 04:27:42,673 EPOCH 169
2024-02-04 04:27:46,052 [Epoch: 169 Step: 00022400] Batch Recognition Loss:   0.000335 => Gls Tokens per Sec:     1326 || Batch Translation Loss:   0.065460 => Txt Tokens per Sec:     3797 || Lr: 0.000100
2024-02-04 04:27:50,541 Epoch 169: Total Training Recognition Loss 0.08  Total Training Translation Loss 29.33 
2024-02-04 04:27:50,542 EPOCH 170
2024-02-04 04:27:51,943 [Epoch: 170 Step: 00022500] Batch Recognition Loss:   0.000354 => Gls Tokens per Sec:     1315 || Batch Translation Loss:   0.227936 => Txt Tokens per Sec:     3494 || Lr: 0.000100
2024-02-04 04:27:57,760 [Epoch: 170 Step: 00022600] Batch Recognition Loss:   0.000444 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.315054 => Txt Tokens per Sec:     3850 || Lr: 0.000100
2024-02-04 04:27:58,256 Epoch 170: Total Training Recognition Loss 0.06  Total Training Translation Loss 28.07 
2024-02-04 04:27:58,256 EPOCH 171
2024-02-04 04:28:03,305 [Epoch: 171 Step: 00022700] Batch Recognition Loss:   0.000581 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.324335 => Txt Tokens per Sec:     3998 || Lr: 0.000100
2024-02-04 04:28:05,875 Epoch 171: Total Training Recognition Loss 0.09  Total Training Translation Loss 40.28 
2024-02-04 04:28:05,875 EPOCH 172
2024-02-04 04:28:08,950 [Epoch: 172 Step: 00022800] Batch Recognition Loss:   0.000288 => Gls Tokens per Sec:     1483 || Batch Translation Loss:   0.053577 => Txt Tokens per Sec:     4028 || Lr: 0.000100
2024-02-04 04:28:13,554 Epoch 172: Total Training Recognition Loss 0.08  Total Training Translation Loss 36.44 
2024-02-04 04:28:13,555 EPOCH 173
2024-02-04 04:28:14,875 [Epoch: 173 Step: 00022900] Batch Recognition Loss:   0.000711 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.076344 => Txt Tokens per Sec:     4202 || Lr: 0.000100
2024-02-04 04:28:20,864 [Epoch: 173 Step: 00023000] Batch Recognition Loss:   0.001152 => Gls Tokens per Sec:     1334 || Batch Translation Loss:   0.363669 => Txt Tokens per Sec:     3648 || Lr: 0.000100
2024-02-04 04:28:21,405 Epoch 173: Total Training Recognition Loss 0.07  Total Training Translation Loss 27.94 
2024-02-04 04:28:21,405 EPOCH 174
2024-02-04 04:28:26,302 [Epoch: 174 Step: 00023100] Batch Recognition Loss:   0.001192 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.182957 => Txt Tokens per Sec:     4089 || Lr: 0.000100
2024-02-04 04:28:28,775 Epoch 174: Total Training Recognition Loss 0.07  Total Training Translation Loss 26.00 
2024-02-04 04:28:28,776 EPOCH 175
2024-02-04 04:28:32,133 [Epoch: 175 Step: 00023200] Batch Recognition Loss:   0.000425 => Gls Tokens per Sec:     1383 || Batch Translation Loss:   0.205998 => Txt Tokens per Sec:     3874 || Lr: 0.000100
2024-02-04 04:28:36,432 Epoch 175: Total Training Recognition Loss 0.07  Total Training Translation Loss 28.76 
2024-02-04 04:28:36,432 EPOCH 176
2024-02-04 04:28:37,859 [Epoch: 176 Step: 00023300] Batch Recognition Loss:   0.000219 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.166609 => Txt Tokens per Sec:     3767 || Lr: 0.000100
2024-02-04 04:28:43,807 [Epoch: 176 Step: 00023400] Batch Recognition Loss:   0.000419 => Gls Tokens per Sec:     1344 || Batch Translation Loss:   0.298078 => Txt Tokens per Sec:     3799 || Lr: 0.000100
2024-02-04 04:28:44,155 Epoch 176: Total Training Recognition Loss 0.07  Total Training Translation Loss 24.08 
2024-02-04 04:28:44,155 EPOCH 177
2024-02-04 04:28:49,288 [Epoch: 177 Step: 00023500] Batch Recognition Loss:   0.000256 => Gls Tokens per Sec:     1434 || Batch Translation Loss:   0.052215 => Txt Tokens per Sec:     3951 || Lr: 0.000100
2024-02-04 04:28:51,512 Epoch 177: Total Training Recognition Loss 0.06  Total Training Translation Loss 24.66 
2024-02-04 04:28:51,512 EPOCH 178
2024-02-04 04:28:55,013 [Epoch: 178 Step: 00023600] Batch Recognition Loss:   0.000521 => Gls Tokens per Sec:     1349 || Batch Translation Loss:   0.078253 => Txt Tokens per Sec:     3779 || Lr: 0.000100
2024-02-04 04:28:59,432 Epoch 178: Total Training Recognition Loss 0.07  Total Training Translation Loss 25.20 
2024-02-04 04:28:59,433 EPOCH 179
2024-02-04 04:29:00,679 [Epoch: 179 Step: 00023700] Batch Recognition Loss:   0.000528 => Gls Tokens per Sec:     1671 || Batch Translation Loss:   0.057896 => Txt Tokens per Sec:     4480 || Lr: 0.000100
2024-02-04 04:29:06,514 [Epoch: 179 Step: 00023800] Batch Recognition Loss:   0.000329 => Gls Tokens per Sec:     1369 || Batch Translation Loss:   0.053842 => Txt Tokens per Sec:     3820 || Lr: 0.000100
2024-02-04 04:29:06,912 Epoch 179: Total Training Recognition Loss 0.09  Total Training Translation Loss 25.72 
2024-02-04 04:29:06,912 EPOCH 180
2024-02-04 04:29:12,132 [Epoch: 180 Step: 00023900] Batch Recognition Loss:   0.000192 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.176387 => Txt Tokens per Sec:     3962 || Lr: 0.000100
2024-02-04 04:29:14,436 Epoch 180: Total Training Recognition Loss 0.08  Total Training Translation Loss 29.82 
2024-02-04 04:29:14,437 EPOCH 181
2024-02-04 04:29:17,832 [Epoch: 181 Step: 00024000] Batch Recognition Loss:   0.000361 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.336315 => Txt Tokens per Sec:     3940 || Lr: 0.000100
2024-02-04 04:29:28,900 Validation result at epoch 181, step    24000: duration: 11.0663s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00327	Translation Loss: 95082.90625	PPL: 13560.96582
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.70	(BLEU-1: 10.89,	BLEU-2: 3.37,	BLEU-3: 1.33,	BLEU-4: 0.70)
	CHRF 16.74	ROUGE 9.60
2024-02-04 04:29:28,901 Logging Recognition and Translation Outputs
2024-02-04 04:29:28,901 ========================================================================================================================
2024-02-04 04:29:28,902 Logging Sequence: 169_165.00
2024-02-04 04:29:28,902 	Gloss Reference :	A B+C+D+E
2024-02-04 04:29:28,902 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:29:28,902 	Gloss Alignment :	         
2024-02-04 04:29:28,903 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:29:28,905 	Text Reference  :	**** the      indian government was  outraged by     the **** incident and these     changes were    undone   by   wikipedia
2024-02-04 04:29:28,905 	Text Hypothesis :	they diverted this   money      they have     booked the same time     and australia new     zealand directly full minutes  
2024-02-04 04:29:28,905 	Text Alignment  :	I    S        S      S          S    S        S          I    S            S         S       S       S        S    S        
2024-02-04 04:29:28,905 ========================================================================================================================
2024-02-04 04:29:28,906 Logging Sequence: 175_60.00
2024-02-04 04:29:28,906 	Gloss Reference :	A B+C+D+E
2024-02-04 04:29:28,906 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:29:28,906 	Gloss Alignment :	         
2024-02-04 04:29:28,907 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:29:28,907 	Text Reference  :	that is how india bagged 9    medals in      the  youth tournament
2024-02-04 04:29:28,908 	Text Hypothesis :	**** ** *** ***** ****** this upset  gambhir have been  made      
2024-02-04 04:29:28,908 	Text Alignment  :	D    D  D   D     D      S    S      S       S    S     S         
2024-02-04 04:29:28,908 ========================================================================================================================
2024-02-04 04:29:28,908 Logging Sequence: 61_255.00
2024-02-04 04:29:28,908 	Gloss Reference :	A B+C+D+E
2024-02-04 04:29:28,909 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:29:28,909 	Gloss Alignment :	         
2024-02-04 04:29:28,909 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:29:28,910 	Text Reference  :	in 2011 we  decided to     marry    and     informed our   families     
2024-02-04 04:29:28,910 	Text Hypothesis :	** it   was a       sudden decision without any      prior communication
2024-02-04 04:29:28,910 	Text Alignment  :	D  S    S   S       S      S        S       S        S     S            
2024-02-04 04:29:28,911 ========================================================================================================================
2024-02-04 04:29:28,911 Logging Sequence: 173_39.00
2024-02-04 04:29:28,911 	Gloss Reference :	A B+C+D+E
2024-02-04 04:29:28,911 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:29:28,912 	Gloss Alignment :	         
2024-02-04 04:29:28,912 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:29:28,913 	Text Reference  :	********* kohli  will step   down as     india' captain
2024-02-04 04:29:28,913 	Text Hypothesis :	rajasthan royals ben  stokes were broken his    finger 
2024-02-04 04:29:28,913 	Text Alignment  :	I         S      S    S      S    S      S      S      
2024-02-04 04:29:28,913 ========================================================================================================================
2024-02-04 04:29:28,913 Logging Sequence: 172_82.00
2024-02-04 04:29:28,914 	Gloss Reference :	A B+C+D+E
2024-02-04 04:29:28,914 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:29:28,914 	Gloss Alignment :	         
2024-02-04 04:29:28,914 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:29:28,916 	Text Reference  :	you all know that the toss was about to start at   700 pm   but it  started raining at       around 630 pm    
2024-02-04 04:29:28,917 	Text Hypothesis :	*** *** **** **** *** **** *** ***** ** she   said 'i  hope one day she     is      selected for    the finals
2024-02-04 04:29:28,917 	Text Alignment  :	D   D   D    D    D   D    D   D     D  S     S    S   S    S   S   S       S       S        S      S   S     
2024-02-04 04:29:28,917 ========================================================================================================================
2024-02-04 04:29:35,241 Epoch 181: Total Training Recognition Loss 0.07  Total Training Translation Loss 28.93 
2024-02-04 04:29:35,242 EPOCH 182
2024-02-04 04:29:36,819 [Epoch: 182 Step: 00024100] Batch Recognition Loss:   0.000731 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.799537 => Txt Tokens per Sec:     3767 || Lr: 0.000100
2024-02-04 04:29:42,550 [Epoch: 182 Step: 00024200] Batch Recognition Loss:   0.000311 => Gls Tokens per Sec:     1394 || Batch Translation Loss:   0.063784 => Txt Tokens per Sec:     3892 || Lr: 0.000100
2024-02-04 04:29:42,838 Epoch 182: Total Training Recognition Loss 0.06  Total Training Translation Loss 26.27 
2024-02-04 04:29:42,838 EPOCH 183
2024-02-04 04:29:48,077 [Epoch: 183 Step: 00024300] Batch Recognition Loss:   0.000644 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.131494 => Txt Tokens per Sec:     3958 || Lr: 0.000100
2024-02-04 04:29:50,481 Epoch 183: Total Training Recognition Loss 0.07  Total Training Translation Loss 23.24 
2024-02-04 04:29:50,482 EPOCH 184
2024-02-04 04:29:53,895 [Epoch: 184 Step: 00024400] Batch Recognition Loss:   0.000392 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.402297 => Txt Tokens per Sec:     3988 || Lr: 0.000100
2024-02-04 04:29:58,412 Epoch 184: Total Training Recognition Loss 0.07  Total Training Translation Loss 27.85 
2024-02-04 04:29:58,412 EPOCH 185
2024-02-04 04:30:00,152 [Epoch: 185 Step: 00024500] Batch Recognition Loss:   0.000539 => Gls Tokens per Sec:     1288 || Batch Translation Loss:   0.113237 => Txt Tokens per Sec:     3791 || Lr: 0.000100
2024-02-04 04:30:05,468 [Epoch: 185 Step: 00024600] Batch Recognition Loss:   0.000212 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.085233 => Txt Tokens per Sec:     4103 || Lr: 0.000100
2024-02-04 04:30:05,738 Epoch 185: Total Training Recognition Loss 0.07  Total Training Translation Loss 25.75 
2024-02-04 04:30:05,738 EPOCH 186
2024-02-04 04:30:11,044 [Epoch: 186 Step: 00024700] Batch Recognition Loss:   0.000610 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.435596 => Txt Tokens per Sec:     3952 || Lr: 0.000100
2024-02-04 04:30:13,115 Epoch 186: Total Training Recognition Loss 0.07  Total Training Translation Loss 34.84 
2024-02-04 04:30:13,115 EPOCH 187
2024-02-04 04:30:16,444 [Epoch: 187 Step: 00024800] Batch Recognition Loss:   0.000374 => Gls Tokens per Sec:     1490 || Batch Translation Loss:   0.233700 => Txt Tokens per Sec:     4130 || Lr: 0.000100
2024-02-04 04:30:20,667 Epoch 187: Total Training Recognition Loss 0.09  Total Training Translation Loss 33.03 
2024-02-04 04:30:20,667 EPOCH 188
2024-02-04 04:30:22,180 [Epoch: 188 Step: 00024900] Batch Recognition Loss:   0.000529 => Gls Tokens per Sec:     1535 || Batch Translation Loss:   0.200533 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-04 04:30:27,897 [Epoch: 188 Step: 00025000] Batch Recognition Loss:   0.000303 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.169536 => Txt Tokens per Sec:     3933 || Lr: 0.000100
2024-02-04 04:30:28,151 Epoch 188: Total Training Recognition Loss 0.07  Total Training Translation Loss 23.44 
2024-02-04 04:30:28,151 EPOCH 189
2024-02-04 04:30:33,452 [Epoch: 189 Step: 00025100] Batch Recognition Loss:   0.000202 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.085985 => Txt Tokens per Sec:     4019 || Lr: 0.000100
2024-02-04 04:30:35,477 Epoch 189: Total Training Recognition Loss 0.06  Total Training Translation Loss 21.94 
2024-02-04 04:30:35,477 EPOCH 190
2024-02-04 04:30:38,717 [Epoch: 190 Step: 00025200] Batch Recognition Loss:   0.000456 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   0.050287 => Txt Tokens per Sec:     4393 || Lr: 0.000100
2024-02-04 04:30:42,605 Epoch 190: Total Training Recognition Loss 0.06  Total Training Translation Loss 26.34 
2024-02-04 04:30:42,606 EPOCH 191
2024-02-04 04:30:44,365 [Epoch: 191 Step: 00025300] Batch Recognition Loss:   0.000338 => Gls Tokens per Sec:     1366 || Batch Translation Loss:   0.058313 => Txt Tokens per Sec:     3772 || Lr: 0.000100
2024-02-04 04:30:49,933 [Epoch: 191 Step: 00025400] Batch Recognition Loss:   0.000182 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.262954 => Txt Tokens per Sec:     3979 || Lr: 0.000100
2024-02-04 04:30:50,118 Epoch 191: Total Training Recognition Loss 0.07  Total Training Translation Loss 32.06 
2024-02-04 04:30:50,119 EPOCH 192
2024-02-04 04:30:55,511 [Epoch: 192 Step: 00025500] Batch Recognition Loss:   0.000542 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.111113 => Txt Tokens per Sec:     3968 || Lr: 0.000100
2024-02-04 04:30:57,462 Epoch 192: Total Training Recognition Loss 0.06  Total Training Translation Loss 31.05 
2024-02-04 04:30:57,462 EPOCH 193
2024-02-04 04:31:01,311 [Epoch: 193 Step: 00025600] Batch Recognition Loss:   0.000690 => Gls Tokens per Sec:     1331 || Batch Translation Loss:   0.270458 => Txt Tokens per Sec:     3699 || Lr: 0.000100
2024-02-04 04:31:05,215 Epoch 193: Total Training Recognition Loss 0.07  Total Training Translation Loss 26.03 
2024-02-04 04:31:05,215 EPOCH 194
2024-02-04 04:31:07,065 [Epoch: 194 Step: 00025700] Batch Recognition Loss:   0.000389 => Gls Tokens per Sec:     1342 || Batch Translation Loss:   0.164444 => Txt Tokens per Sec:     3862 || Lr: 0.000100
2024-02-04 04:31:12,653 [Epoch: 194 Step: 00025800] Batch Recognition Loss:   0.000592 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.507054 => Txt Tokens per Sec:     3922 || Lr: 0.000100
2024-02-04 04:31:12,754 Epoch 194: Total Training Recognition Loss 0.07  Total Training Translation Loss 26.84 
2024-02-04 04:31:12,754 EPOCH 195
2024-02-04 04:31:18,469 [Epoch: 195 Step: 00025900] Batch Recognition Loss:   0.000163 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.167008 => Txt Tokens per Sec:     3857 || Lr: 0.000100
2024-02-04 04:31:20,409 Epoch 195: Total Training Recognition Loss 0.06  Total Training Translation Loss 24.42 
2024-02-04 04:31:20,409 EPOCH 196
2024-02-04 04:31:24,235 [Epoch: 196 Step: 00026000] Batch Recognition Loss:   0.000591 => Gls Tokens per Sec:     1359 || Batch Translation Loss:   0.051818 => Txt Tokens per Sec:     3788 || Lr: 0.000100
2024-02-04 04:31:34,650 Validation result at epoch 196, step    26000: duration: 10.4143s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00222	Translation Loss: 95098.05469	PPL: 13581.54395
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.91	(BLEU-1: 10.68,	BLEU-2: 3.55,	BLEU-3: 1.63,	BLEU-4: 0.91)
	CHRF 17.22	ROUGE 9.02
2024-02-04 04:31:34,651 Logging Recognition and Translation Outputs
2024-02-04 04:31:34,651 ========================================================================================================================
2024-02-04 04:31:34,652 Logging Sequence: 130_139.00
2024-02-04 04:31:34,652 	Gloss Reference :	A B+C+D+E
2024-02-04 04:31:34,652 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:31:34,652 	Gloss Alignment :	         
2024-02-04 04:31:34,652 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:31:34,654 	Text Reference  :	he shared a picture of  a  little pouch he knit for his olympic gold medal with uk flag on one side and japanese flag on the other
2024-02-04 04:31:34,654 	Text Hypothesis :	he ****** * came    out as gay    when  he **** *** *** ******* **** ***** **** ** **** ** *** **** *** ******** **** ** was 19   
2024-02-04 04:31:34,654 	Text Alignment  :	   D      D S       S   S  S      S        D    D   D   D       D    D     D    D  D    D  D   D    D   D        D    D  S   S    
2024-02-04 04:31:34,654 ========================================================================================================================
2024-02-04 04:31:34,654 Logging Sequence: 72_194.00
2024-02-04 04:31:34,654 	Gloss Reference :	A B+C+D+E
2024-02-04 04:31:34,654 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:31:34,655 	Gloss Alignment :	         
2024-02-04 04:31:34,655 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:31:34,656 	Text Reference  :	shah told her to do what she wants and filed a    police complaint against her  
2024-02-04 04:31:34,656 	Text Hypothesis :	**** **** *** ** as per  the rules you can   have been   booked    their   hotel
2024-02-04 04:31:34,656 	Text Alignment  :	D    D    D   D  S  S    S   S     S   S     S    S      S         S       S    
2024-02-04 04:31:34,656 ========================================================================================================================
2024-02-04 04:31:34,656 Logging Sequence: 69_177.00
2024-02-04 04:31:34,656 	Gloss Reference :	A B+C+D+E
2024-02-04 04:31:34,656 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:31:34,657 	Gloss Alignment :	         
2024-02-04 04:31:34,657 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:31:34,658 	Text Reference  :	he said 'i will continue playing i know it's about time i   retire i      also have a       knee condition
2024-02-04 04:31:34,658 	Text Hypothesis :	** **** ** **** ******** ******* * **** **** ***** when csk were   elated with the  winning the  stadium  
2024-02-04 04:31:34,658 	Text Alignment  :	D  D    D  D    D        D       D D    D    D     S    S   S      S      S    S    S       S    S        
2024-02-04 04:31:34,658 ========================================================================================================================
2024-02-04 04:31:34,658 Logging Sequence: 95_118.00
2024-02-04 04:31:34,658 	Gloss Reference :	A B+C+D+E
2024-02-04 04:31:34,658 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:31:34,659 	Gloss Alignment :	         
2024-02-04 04:31:34,659 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:31:34,659 	Text Reference  :	******* the game was            stopped strangely due   to    excessive sunlight
2024-02-04 04:31:34,660 	Text Hypothesis :	however an  old  praggnanandhaa stood   comments  about their south     africa  
2024-02-04 04:31:34,660 	Text Alignment  :	I       S   S    S              S       S         S     S     S         S       
2024-02-04 04:31:34,660 ========================================================================================================================
2024-02-04 04:31:34,660 Logging Sequence: 112_8.00
2024-02-04 04:31:34,660 	Gloss Reference :	A B+C+D+E
2024-02-04 04:31:34,660 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:31:34,660 	Gloss Alignment :	         
2024-02-04 04:31:34,660 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:31:34,662 	Text Reference  :	before there were 8 teams such as mumbai indians delhi capitals punjab kings etc and now     there will   be  10      teams in  2022   
2024-02-04 04:31:34,662 	Text Hypothesis :	****** ***** **** * ***** **** ** ****** ******* ***** ******** ****** ***** *** *** however my    family was grabbed by    cvc capital
2024-02-04 04:31:34,662 	Text Alignment  :	D      D     D    D D     D    D  D      D       D     D        D      D     D   D   S       S     S      S   S       S     S   S      
2024-02-04 04:31:34,662 ========================================================================================================================
2024-02-04 04:31:38,509 Epoch 196: Total Training Recognition Loss 0.07  Total Training Translation Loss 19.61 
2024-02-04 04:31:38,509 EPOCH 197
2024-02-04 04:31:40,354 [Epoch: 197 Step: 00026100] Batch Recognition Loss:   0.000423 => Gls Tokens per Sec:     1388 || Batch Translation Loss:   0.084369 => Txt Tokens per Sec:     4132 || Lr: 0.000100
2024-02-04 04:31:45,691 [Epoch: 197 Step: 00026200] Batch Recognition Loss:   0.000527 => Gls Tokens per Sec:     1497 || Batch Translation Loss:   0.084241 => Txt Tokens per Sec:     4057 || Lr: 0.000100
2024-02-04 04:31:45,740 Epoch 197: Total Training Recognition Loss 0.05  Total Training Translation Loss 21.68 
2024-02-04 04:31:45,740 EPOCH 198
2024-02-04 04:31:51,110 [Epoch: 198 Step: 00026300] Batch Recognition Loss:   0.000182 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.680755 => Txt Tokens per Sec:     4095 || Lr: 0.000100
2024-02-04 04:31:52,917 Epoch 198: Total Training Recognition Loss 0.07  Total Training Translation Loss 24.15 
2024-02-04 04:31:52,917 EPOCH 199
2024-02-04 04:31:56,754 [Epoch: 199 Step: 00026400] Batch Recognition Loss:   0.000432 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.054078 => Txt Tokens per Sec:     3845 || Lr: 0.000100
2024-02-04 04:32:00,410 Epoch 199: Total Training Recognition Loss 0.10  Total Training Translation Loss 24.98 
2024-02-04 04:32:00,410 EPOCH 200
2024-02-04 04:32:02,322 [Epoch: 200 Step: 00026500] Batch Recognition Loss:   0.000386 => Gls Tokens per Sec:     1381 || Batch Translation Loss:   0.222515 => Txt Tokens per Sec:     3757 || Lr: 0.000100
2024-02-04 04:32:07,976 [Epoch: 200 Step: 00026600] Batch Recognition Loss:   0.000255 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.231935 => Txt Tokens per Sec:     3950 || Lr: 0.000100
2024-02-04 04:32:07,976 Epoch 200: Total Training Recognition Loss 0.06  Total Training Translation Loss 22.24 
2024-02-04 04:32:07,977 EPOCH 201
2024-02-04 04:32:13,140 [Epoch: 201 Step: 00026700] Batch Recognition Loss:   0.000626 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.157651 => Txt Tokens per Sec:     4318 || Lr: 0.000100
2024-02-04 04:32:15,038 Epoch 201: Total Training Recognition Loss 0.07  Total Training Translation Loss 32.70 
2024-02-04 04:32:15,038 EPOCH 202
2024-02-04 04:32:18,624 [Epoch: 202 Step: 00026800] Batch Recognition Loss:   0.000466 => Gls Tokens per Sec:     1495 || Batch Translation Loss:   0.155509 => Txt Tokens per Sec:     4229 || Lr: 0.000100
2024-02-04 04:32:22,501 Epoch 202: Total Training Recognition Loss 0.09  Total Training Translation Loss 27.09 
2024-02-04 04:32:22,502 EPOCH 203
2024-02-04 04:32:24,266 [Epoch: 203 Step: 00026900] Batch Recognition Loss:   0.005145 => Gls Tokens per Sec:     1544 || Batch Translation Loss:   0.061212 => Txt Tokens per Sec:     4291 || Lr: 0.000100
2024-02-04 04:32:29,889 Epoch 203: Total Training Recognition Loss 0.08  Total Training Translation Loss 27.55 
2024-02-04 04:32:29,890 EPOCH 204
2024-02-04 04:32:29,961 [Epoch: 204 Step: 00027000] Batch Recognition Loss:   0.000434 => Gls Tokens per Sec:     1143 || Batch Translation Loss:   0.079615 => Txt Tokens per Sec:     4029 || Lr: 0.000100
2024-02-04 04:32:35,662 [Epoch: 204 Step: 00027100] Batch Recognition Loss:   0.000647 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.079229 => Txt Tokens per Sec:     3909 || Lr: 0.000100
2024-02-04 04:32:37,290 Epoch 204: Total Training Recognition Loss 0.07  Total Training Translation Loss 21.64 
2024-02-04 04:32:37,290 EPOCH 205
2024-02-04 04:32:40,986 [Epoch: 205 Step: 00027200] Batch Recognition Loss:   0.000689 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.251769 => Txt Tokens per Sec:     4094 || Lr: 0.000100
2024-02-04 04:32:44,865 Epoch 205: Total Training Recognition Loss 0.07  Total Training Translation Loss 24.65 
2024-02-04 04:32:44,865 EPOCH 206
2024-02-04 04:32:46,785 [Epoch: 206 Step: 00027300] Batch Recognition Loss:   0.004834 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.152051 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-04 04:32:52,369 Epoch 206: Total Training Recognition Loss 0.05  Total Training Translation Loss 23.21 
2024-02-04 04:32:52,370 EPOCH 207
2024-02-04 04:32:52,462 [Epoch: 207 Step: 00027400] Batch Recognition Loss:   0.000389 => Gls Tokens per Sec:     1758 || Batch Translation Loss:   0.034851 => Txt Tokens per Sec:     3747 || Lr: 0.000100
2024-02-04 04:32:57,856 [Epoch: 207 Step: 00027500] Batch Recognition Loss:   0.000421 => Gls Tokens per Sec:     1483 || Batch Translation Loss:   0.240600 => Txt Tokens per Sec:     4126 || Lr: 0.000100
2024-02-04 04:32:59,672 Epoch 207: Total Training Recognition Loss 0.07  Total Training Translation Loss 20.37 
2024-02-04 04:32:59,672 EPOCH 208
2024-02-04 04:33:03,720 [Epoch: 208 Step: 00027600] Batch Recognition Loss:   0.000289 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.043623 => Txt Tokens per Sec:     3875 || Lr: 0.000100
2024-02-04 04:33:07,351 Epoch 208: Total Training Recognition Loss 0.05  Total Training Translation Loss 22.06 
2024-02-04 04:33:07,351 EPOCH 209
2024-02-04 04:33:09,283 [Epoch: 209 Step: 00027700] Batch Recognition Loss:   0.000332 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.322763 => Txt Tokens per Sec:     4109 || Lr: 0.000100
2024-02-04 04:33:14,910 Epoch 209: Total Training Recognition Loss 0.06  Total Training Translation Loss 23.91 
2024-02-04 04:33:14,911 EPOCH 210
2024-02-04 04:33:15,039 [Epoch: 210 Step: 00027800] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1890 || Batch Translation Loss:   0.142724 => Txt Tokens per Sec:     4095 || Lr: 0.000100
2024-02-04 04:33:20,311 [Epoch: 210 Step: 00027900] Batch Recognition Loss:   0.000283 => Gls Tokens per Sec:     1518 || Batch Translation Loss:   0.211149 => Txt Tokens per Sec:     4233 || Lr: 0.000100
2024-02-04 04:33:22,200 Epoch 210: Total Training Recognition Loss 0.06  Total Training Translation Loss 30.59 
2024-02-04 04:33:22,201 EPOCH 211
2024-02-04 04:33:26,298 [Epoch: 211 Step: 00028000] Batch Recognition Loss:   0.000474 => Gls Tokens per Sec:     1367 || Batch Translation Loss:   0.345066 => Txt Tokens per Sec:     3878 || Lr: 0.000100
2024-02-04 04:33:36,630 Validation result at epoch 211, step    28000: duration: 10.3310s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00262	Translation Loss: 95493.88281	PPL: 14130.31836
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.56	(BLEU-1: 9.93,	BLEU-2: 2.83,	BLEU-3: 1.10,	BLEU-4: 0.56)
	CHRF 16.13	ROUGE 8.52
2024-02-04 04:33:36,632 Logging Recognition and Translation Outputs
2024-02-04 04:33:36,632 ========================================================================================================================
2024-02-04 04:33:36,632 Logging Sequence: 67_98.00
2024-02-04 04:33:36,632 	Gloss Reference :	A B+C+D+E
2024-02-04 04:33:36,632 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:33:36,632 	Gloss Alignment :	         
2024-02-04 04:33:36,632 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:33:36,633 	Text Reference  :	it saddens me to   see people suffering   and  dying  due   to     lack of    oxygen    
2024-02-04 04:33:36,634 	Text Hypothesis :	** ******* ** when he  was    argentina's turn lionel messi scored the  brand ambassador
2024-02-04 04:33:36,634 	Text Alignment  :	D  D       D  S    S   S      S           S    S      S     S      S    S     S         
2024-02-04 04:33:36,634 ========================================================================================================================
2024-02-04 04:33:36,634 Logging Sequence: 157_83.00
2024-02-04 04:33:36,634 	Gloss Reference :	A B+C+D+E
2024-02-04 04:33:36,634 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:33:36,634 	Gloss Alignment :	         
2024-02-04 04:33:36,634 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:33:36,636 	Text Reference  :	also when you eat sandwich at  a    streetside hawker    or  stall the sandwich maker    will first apply butter with a         knife
2024-02-04 04:33:36,636 	Text Hypothesis :	**** **** *** *** the      ipl that was        postponed due to    the covid    pandemic will ***** be    held   in   september 2021 
2024-02-04 04:33:36,637 	Text Alignment  :	D    D    D   D   S        S   S    S          S         S   S         S        S             D     S     S      S    S         S    
2024-02-04 04:33:36,637 ========================================================================================================================
2024-02-04 04:33:36,637 Logging Sequence: 76_35.00
2024-02-04 04:33:36,637 	Gloss Reference :	A B+C+D+E
2024-02-04 04:33:36,637 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:33:36,637 	Gloss Alignment :	         
2024-02-04 04:33:36,637 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:33:36,638 	Text Reference  :	bcci president sourav    ganguly   along  with board   secretary jay shah
2024-02-04 04:33:36,638 	Text Hypothesis :	**** indian    cricketer yuzvendra chahal is   married to        his wife
2024-02-04 04:33:36,638 	Text Alignment  :	D    S         S         S         S      S    S       S         S   S   
2024-02-04 04:33:36,638 ========================================================================================================================
2024-02-04 04:33:36,638 Logging Sequence: 139_180.00
2024-02-04 04:33:36,639 	Gloss Reference :	A B+C+D+E
2024-02-04 04:33:36,639 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:33:36,639 	Gloss Alignment :	         
2024-02-04 04:33:36,639 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:33:36,640 	Text Reference  :	*** *** *** **** ****** ****** *** ***** *** ** netherlands also  faced similar riots
2024-02-04 04:33:36,640 	Text Hypothesis :	the 1st day then deepak chahar and chest led to a           total of    7       goals
2024-02-04 04:33:36,640 	Text Alignment  :	I   I   I   I    I      I      I   I     I   I  S           S     S     S       S    
2024-02-04 04:33:36,640 ========================================================================================================================
2024-02-04 04:33:36,640 Logging Sequence: 98_87.00
2024-02-04 04:33:36,640 	Gloss Reference :	A B+C+D+E
2024-02-04 04:33:36,640 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:33:36,640 	Gloss Alignment :	         
2024-02-04 04:33:36,641 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:33:36,642 	Text Reference  :	instead of     starting afresh in     2021 the organizers opted   to ***** ** resume with the previous edition
2024-02-04 04:33:36,642 	Text Hypothesis :	mumal   shared that     he     looked like her and        decided to start so he     got  the ******** field  
2024-02-04 04:33:36,642 	Text Alignment  :	S       S      S        S      S      S    S   S          S          I     I  S      S        D        S      
2024-02-04 04:33:36,642 ========================================================================================================================
2024-02-04 04:33:40,332 Epoch 211: Total Training Recognition Loss 0.06  Total Training Translation Loss 25.94 
2024-02-04 04:33:40,332 EPOCH 212
2024-02-04 04:33:42,486 [Epoch: 212 Step: 00028100] Batch Recognition Loss:   0.000261 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.046014 => Txt Tokens per Sec:     3937 || Lr: 0.000100
2024-02-04 04:33:47,807 Epoch 212: Total Training Recognition Loss 0.05  Total Training Translation Loss 20.46 
2024-02-04 04:33:47,807 EPOCH 213
2024-02-04 04:33:48,011 [Epoch: 213 Step: 00028200] Batch Recognition Loss:   0.000424 => Gls Tokens per Sec:     1576 || Batch Translation Loss:   0.076390 => Txt Tokens per Sec:     4571 || Lr: 0.000100
2024-02-04 04:33:53,483 [Epoch: 213 Step: 00028300] Batch Recognition Loss:   0.000348 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.192273 => Txt Tokens per Sec:     4051 || Lr: 0.000100
2024-02-04 04:33:55,151 Epoch 213: Total Training Recognition Loss 0.06  Total Training Translation Loss 17.37 
2024-02-04 04:33:55,151 EPOCH 214
2024-02-04 04:33:59,159 [Epoch: 214 Step: 00028400] Batch Recognition Loss:   0.000244 => Gls Tokens per Sec:     1418 || Batch Translation Loss:   0.090693 => Txt Tokens per Sec:     3954 || Lr: 0.000100
2024-02-04 04:34:02,627 Epoch 214: Total Training Recognition Loss 0.05  Total Training Translation Loss 19.17 
2024-02-04 04:34:02,628 EPOCH 215
2024-02-04 04:34:04,652 [Epoch: 215 Step: 00028500] Batch Recognition Loss:   0.000140 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   0.159985 => Txt Tokens per Sec:     4190 || Lr: 0.000100
2024-02-04 04:34:10,049 Epoch 215: Total Training Recognition Loss 0.06  Total Training Translation Loss 19.92 
2024-02-04 04:34:10,050 EPOCH 216
2024-02-04 04:34:10,284 [Epoch: 216 Step: 00028600] Batch Recognition Loss:   0.000423 => Gls Tokens per Sec:     1717 || Batch Translation Loss:   0.152996 => Txt Tokens per Sec:     4657 || Lr: 0.000100
2024-02-04 04:34:15,907 [Epoch: 216 Step: 00028700] Batch Recognition Loss:   0.000299 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.167172 => Txt Tokens per Sec:     3984 || Lr: 0.000100
2024-02-04 04:34:17,453 Epoch 216: Total Training Recognition Loss 0.08  Total Training Translation Loss 22.52 
2024-02-04 04:34:17,454 EPOCH 217
2024-02-04 04:34:21,360 [Epoch: 217 Step: 00028800] Batch Recognition Loss:   0.000333 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.034216 => Txt Tokens per Sec:     4155 || Lr: 0.000100
2024-02-04 04:34:24,922 Epoch 217: Total Training Recognition Loss 0.06  Total Training Translation Loss 24.25 
2024-02-04 04:34:24,923 EPOCH 218
2024-02-04 04:34:27,162 [Epoch: 218 Step: 00028900] Batch Recognition Loss:   0.000282 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.086662 => Txt Tokens per Sec:     3873 || Lr: 0.000100
2024-02-04 04:34:32,622 Epoch 218: Total Training Recognition Loss 0.07  Total Training Translation Loss 23.79 
2024-02-04 04:34:32,623 EPOCH 219
2024-02-04 04:34:32,982 [Epoch: 219 Step: 00029000] Batch Recognition Loss:   0.000202 => Gls Tokens per Sec:     1341 || Batch Translation Loss:   0.075552 => Txt Tokens per Sec:     3877 || Lr: 0.000100
2024-02-04 04:34:38,493 [Epoch: 219 Step: 00029100] Batch Recognition Loss:   0.000779 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.145071 => Txt Tokens per Sec:     4011 || Lr: 0.000100
2024-02-04 04:34:39,994 Epoch 219: Total Training Recognition Loss 0.06  Total Training Translation Loss 26.26 
2024-02-04 04:34:39,995 EPOCH 220
2024-02-04 04:34:44,069 [Epoch: 220 Step: 00029200] Batch Recognition Loss:   0.000772 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   0.126136 => Txt Tokens per Sec:     3982 || Lr: 0.000100
2024-02-04 04:34:47,507 Epoch 220: Total Training Recognition Loss 0.06  Total Training Translation Loss 22.61 
2024-02-04 04:34:47,508 EPOCH 221
2024-02-04 04:34:49,748 [Epoch: 221 Step: 00029300] Batch Recognition Loss:   0.000420 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.166104 => Txt Tokens per Sec:     3858 || Lr: 0.000100
2024-02-04 04:34:55,102 Epoch 221: Total Training Recognition Loss 0.06  Total Training Translation Loss 16.47 
2024-02-04 04:34:55,103 EPOCH 222
2024-02-04 04:34:55,465 [Epoch: 222 Step: 00029400] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1551 || Batch Translation Loss:   0.163550 => Txt Tokens per Sec:     4745 || Lr: 0.000100
2024-02-04 04:35:00,549 [Epoch: 222 Step: 00029500] Batch Recognition Loss:   0.000264 => Gls Tokens per Sec:     1573 || Batch Translation Loss:   0.054446 => Txt Tokens per Sec:     4352 || Lr: 0.000100
2024-02-04 04:35:02,029 Epoch 222: Total Training Recognition Loss 0.05  Total Training Translation Loss 21.72 
2024-02-04 04:35:02,029 EPOCH 223
2024-02-04 04:35:06,252 [Epoch: 223 Step: 00029600] Batch Recognition Loss:   0.000725 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.109200 => Txt Tokens per Sec:     3830 || Lr: 0.000100
2024-02-04 04:35:09,655 Epoch 223: Total Training Recognition Loss 0.05  Total Training Translation Loss 26.36 
2024-02-04 04:35:09,655 EPOCH 224
2024-02-04 04:35:11,840 [Epoch: 224 Step: 00029700] Batch Recognition Loss:   0.000392 => Gls Tokens per Sec:     1501 || Batch Translation Loss:   0.018495 => Txt Tokens per Sec:     4119 || Lr: 0.000100
2024-02-04 04:35:16,972 Epoch 224: Total Training Recognition Loss 0.06  Total Training Translation Loss 27.76 
2024-02-04 04:35:16,973 EPOCH 225
2024-02-04 04:35:17,409 [Epoch: 225 Step: 00029800] Batch Recognition Loss:   0.000234 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.136954 => Txt Tokens per Sec:     4103 || Lr: 0.000100
2024-02-04 04:35:23,078 [Epoch: 225 Step: 00029900] Batch Recognition Loss:   0.000200 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.208460 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-04 04:35:24,439 Epoch 225: Total Training Recognition Loss 0.06  Total Training Translation Loss 29.90 
2024-02-04 04:35:24,439 EPOCH 226
2024-02-04 04:35:28,583 [Epoch: 226 Step: 00030000] Batch Recognition Loss:   0.000352 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.048505 => Txt Tokens per Sec:     4032 || Lr: 0.000100
2024-02-04 04:35:39,181 Validation result at epoch 226, step    30000: duration: 10.5987s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00548	Translation Loss: 94195.98438	PPL: 12409.24414
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.72	(BLEU-1: 11.48,	BLEU-2: 3.57,	BLEU-3: 1.48,	BLEU-4: 0.72)
	CHRF 17.37	ROUGE 9.90
2024-02-04 04:35:39,182 Logging Recognition and Translation Outputs
2024-02-04 04:35:39,183 ========================================================================================================================
2024-02-04 04:35:39,183 Logging Sequence: 165_502.00
2024-02-04 04:35:39,183 	Gloss Reference :	A B+C+D+E
2024-02-04 04:35:39,183 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:35:39,183 	Gloss Alignment :	         
2024-02-04 04:35:39,183 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:35:39,185 	Text Reference  :	tendulkar would sit   in the **** ***** *** pavilion wearing both his  batting pads even after he got   out
2024-02-04 04:35:39,185 	Text Hypothesis :	when      the   final of the 2011 world cup 2023     will    be   held by      the  same rule  of camel flu
2024-02-04 04:35:39,185 	Text Alignment  :	S         S     S     S      I    I     I   S        S       S    S    S       S    S    S     S  S     S  
2024-02-04 04:35:39,185 ========================================================================================================================
2024-02-04 04:35:39,186 Logging Sequence: 127_57.00
2024-02-04 04:35:39,186 	Gloss Reference :	A B+C+D+E
2024-02-04 04:35:39,186 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:35:39,186 	Gloss Alignment :	         
2024-02-04 04:35:39,186 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:35:39,187 	Text Reference  :	till date india had won only 2 medals at the championships which like the    olympics is the    highest level championship
2024-02-04 04:35:39,188 	Text Hypothesis :	**** **** india had won only * ****** ** *** ************* ***** a    bronze and      a  silver medal   in    2016        
2024-02-04 04:35:39,188 	Text Alignment  :	D    D                       D D      D  D   D             D     S    S      S        S  S      S       S     S           
2024-02-04 04:35:39,188 ========================================================================================================================
2024-02-04 04:35:39,188 Logging Sequence: 169_10.00
2024-02-04 04:35:39,188 	Gloss Reference :	A B+C+D+E
2024-02-04 04:35:39,188 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:35:39,188 	Gloss Alignment :	         
2024-02-04 04:35:39,188 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:35:39,190 	Text Reference  :	the 18th over was ********** bowled by     ravi  bishnoi with khushdil shah and asif ali on the ******* crease   
2024-02-04 04:35:39,190 	Text Hypothesis :	*** when it   was australia' turn   lionel messi scored  the  first    time and gave him to the lgbtqia community
2024-02-04 04:35:39,190 	Text Alignment  :	D   S    S        I          S      S      S     S       S    S        S        S    S   S      I       S        
2024-02-04 04:35:39,191 ========================================================================================================================
2024-02-04 04:35:39,191 Logging Sequence: 64_89.00
2024-02-04 04:35:39,191 	Gloss Reference :	A B+C+D+E
2024-02-04 04:35:39,191 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:35:39,191 	Gloss Alignment :	         
2024-02-04 04:35:39,191 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:35:39,192 	Text Reference  :	but this can  not go on amidst the rising cases human lives    need to   be safeguarded
2024-02-04 04:35:39,192 	Text Hypothesis :	*** ipl  will not ** ** ****** *** ****** ***** be    possible in   june as well       
2024-02-04 04:35:39,192 	Text Alignment  :	D   S    S        D  D  D      D   D      D     S     S        S    S    S  S          
2024-02-04 04:35:39,192 ========================================================================================================================
2024-02-04 04:35:39,193 Logging Sequence: 166_261.00
2024-02-04 04:35:39,193 	Gloss Reference :	A B+C+D+E
2024-02-04 04:35:39,193 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:35:39,193 	Gloss Alignment :	         
2024-02-04 04:35:39,193 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:35:39,194 	Text Reference  :	*** ***** *** **** for all    organizational matters and the schedule
2024-02-04 04:35:39,194 	Text Hypothesis :	the world cup will be  played between        india   and 16  teams   
2024-02-04 04:35:39,194 	Text Alignment  :	I   I     I   I    S   S      S              S           S   S       
2024-02-04 04:35:39,194 ========================================================================================================================
2024-02-04 04:35:42,666 Epoch 226: Total Training Recognition Loss 0.06  Total Training Translation Loss 25.96 
2024-02-04 04:35:42,667 EPOCH 227
2024-02-04 04:35:44,932 [Epoch: 227 Step: 00030100] Batch Recognition Loss:   0.000442 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.076451 => Txt Tokens per Sec:     4050 || Lr: 0.000100
2024-02-04 04:35:50,011 Epoch 227: Total Training Recognition Loss 0.07  Total Training Translation Loss 21.88 
2024-02-04 04:35:50,011 EPOCH 228
2024-02-04 04:35:50,452 [Epoch: 228 Step: 00030200] Batch Recognition Loss:   0.000156 => Gls Tokens per Sec:     1636 || Batch Translation Loss:   0.170312 => Txt Tokens per Sec:     4493 || Lr: 0.000100
2024-02-04 04:35:55,696 [Epoch: 228 Step: 00030300] Batch Recognition Loss:   0.000345 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.082396 => Txt Tokens per Sec:     4231 || Lr: 0.000100
2024-02-04 04:35:57,029 Epoch 228: Total Training Recognition Loss 0.05  Total Training Translation Loss 20.01 
2024-02-04 04:35:57,029 EPOCH 229
2024-02-04 04:36:01,116 [Epoch: 229 Step: 00030400] Batch Recognition Loss:   0.000598 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   0.103276 => Txt Tokens per Sec:     4071 || Lr: 0.000100
2024-02-04 04:36:04,595 Epoch 229: Total Training Recognition Loss 0.06  Total Training Translation Loss 20.86 
2024-02-04 04:36:04,596 EPOCH 230
2024-02-04 04:36:06,988 [Epoch: 230 Step: 00030500] Batch Recognition Loss:   0.000147 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.156273 => Txt Tokens per Sec:     3911 || Lr: 0.000100
2024-02-04 04:36:12,267 Epoch 230: Total Training Recognition Loss 0.07  Total Training Translation Loss 18.65 
2024-02-04 04:36:12,267 EPOCH 231
2024-02-04 04:36:12,862 [Epoch: 231 Step: 00030600] Batch Recognition Loss:   0.000187 => Gls Tokens per Sec:     1349 || Batch Translation Loss:   0.030646 => Txt Tokens per Sec:     3840 || Lr: 0.000100
2024-02-04 04:36:18,386 [Epoch: 231 Step: 00030700] Batch Recognition Loss:   0.000673 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.084656 => Txt Tokens per Sec:     3982 || Lr: 0.000100
2024-02-04 04:36:19,689 Epoch 231: Total Training Recognition Loss 0.06  Total Training Translation Loss 21.71 
2024-02-04 04:36:19,689 EPOCH 232
2024-02-04 04:36:24,087 [Epoch: 232 Step: 00030800] Batch Recognition Loss:   0.000423 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.047792 => Txt Tokens per Sec:     3939 || Lr: 0.000100
2024-02-04 04:36:27,165 Epoch 232: Total Training Recognition Loss 0.07  Total Training Translation Loss 29.73 
2024-02-04 04:36:27,165 EPOCH 233
2024-02-04 04:36:29,454 [Epoch: 233 Step: 00030900] Batch Recognition Loss:   0.000160 => Gls Tokens per Sec:     1538 || Batch Translation Loss:   0.080946 => Txt Tokens per Sec:     4287 || Lr: 0.000100
2024-02-04 04:36:34,768 Epoch 233: Total Training Recognition Loss 0.05  Total Training Translation Loss 21.13 
2024-02-04 04:36:34,769 EPOCH 234
2024-02-04 04:36:35,339 [Epoch: 234 Step: 00031000] Batch Recognition Loss:   0.000195 => Gls Tokens per Sec:     1547 || Batch Translation Loss:   0.148361 => Txt Tokens per Sec:     4081 || Lr: 0.000100
2024-02-04 04:36:40,657 [Epoch: 234 Step: 00031100] Batch Recognition Loss:   0.000471 => Gls Tokens per Sec:     1505 || Batch Translation Loss:   0.034865 => Txt Tokens per Sec:     4178 || Lr: 0.000100
2024-02-04 04:36:41,935 Epoch 234: Total Training Recognition Loss 0.06  Total Training Translation Loss 16.22 
2024-02-04 04:36:41,935 EPOCH 235
2024-02-04 04:36:46,308 [Epoch: 235 Step: 00031200] Batch Recognition Loss:   0.000375 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.739877 => Txt Tokens per Sec:     4022 || Lr: 0.000100
2024-02-04 04:36:49,452 Epoch 235: Total Training Recognition Loss 0.06  Total Training Translation Loss 24.78 
2024-02-04 04:36:49,453 EPOCH 236
2024-02-04 04:36:52,008 [Epoch: 236 Step: 00031300] Batch Recognition Loss:   0.000336 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.124032 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-04 04:36:56,914 Epoch 236: Total Training Recognition Loss 0.05  Total Training Translation Loss 26.11 
2024-02-04 04:36:56,914 EPOCH 237
2024-02-04 04:36:57,579 [Epoch: 237 Step: 00031400] Batch Recognition Loss:   0.000553 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.074639 => Txt Tokens per Sec:     4235 || Lr: 0.000100
2024-02-04 04:37:03,288 [Epoch: 237 Step: 00031500] Batch Recognition Loss:   0.000389 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.680751 => Txt Tokens per Sec:     3891 || Lr: 0.000100
2024-02-04 04:37:04,478 Epoch 237: Total Training Recognition Loss 0.07  Total Training Translation Loss 27.54 
2024-02-04 04:37:04,479 EPOCH 238
2024-02-04 04:37:08,798 [Epoch: 238 Step: 00031600] Batch Recognition Loss:   0.000264 => Gls Tokens per Sec:     1464 || Batch Translation Loss:   0.254874 => Txt Tokens per Sec:     4070 || Lr: 0.000100
2024-02-04 04:37:11,888 Epoch 238: Total Training Recognition Loss 0.05  Total Training Translation Loss 17.56 
2024-02-04 04:37:11,888 EPOCH 239
2024-02-04 04:37:14,710 [Epoch: 239 Step: 00031700] Batch Recognition Loss:   0.000515 => Gls Tokens per Sec:     1305 || Batch Translation Loss:   0.052603 => Txt Tokens per Sec:     3614 || Lr: 0.000100
2024-02-04 04:37:19,719 Epoch 239: Total Training Recognition Loss 0.06  Total Training Translation Loss 19.05 
2024-02-04 04:37:19,719 EPOCH 240
2024-02-04 04:37:20,555 [Epoch: 240 Step: 00031800] Batch Recognition Loss:   0.000151 => Gls Tokens per Sec:     1246 || Batch Translation Loss:   0.123165 => Txt Tokens per Sec:     3816 || Lr: 0.000100
2024-02-04 04:37:25,948 [Epoch: 240 Step: 00031900] Batch Recognition Loss:   0.000266 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.262513 => Txt Tokens per Sec:     4063 || Lr: 0.000100
2024-02-04 04:37:27,088 Epoch 240: Total Training Recognition Loss 0.06  Total Training Translation Loss 26.46 
2024-02-04 04:37:27,089 EPOCH 241
2024-02-04 04:37:31,487 [Epoch: 241 Step: 00032000] Batch Recognition Loss:   0.001144 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.071701 => Txt Tokens per Sec:     4068 || Lr: 0.000100
2024-02-04 04:37:42,400 Validation result at epoch 241, step    32000: duration: 10.9120s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00308	Translation Loss: 94652.14062	PPL: 12988.82520
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.59	(BLEU-1: 11.36,	BLEU-2: 3.26,	BLEU-3: 1.21,	BLEU-4: 0.59)
	CHRF 17.44	ROUGE 9.67
2024-02-04 04:37:42,401 Logging Recognition and Translation Outputs
2024-02-04 04:37:42,401 ========================================================================================================================
2024-02-04 04:37:42,401 Logging Sequence: 86_11.00
2024-02-04 04:37:42,401 	Gloss Reference :	A B+C+D+E
2024-02-04 04:37:42,401 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:37:42,402 	Gloss Alignment :	         
2024-02-04 04:37:42,402 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:37:42,402 	Text Reference  :	he       was ******* ****** 66  years    old  
2024-02-04 04:37:42,402 	Text Hypothesis :	everyone was another strong and pakistan match
2024-02-04 04:37:42,402 	Text Alignment  :	S            I       I      S   S        S    
2024-02-04 04:37:42,402 ========================================================================================================================
2024-02-04 04:37:42,403 Logging Sequence: 67_16.00
2024-02-04 04:37:42,403 	Gloss Reference :	A B+C+D+E
2024-02-04 04:37:42,403 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:37:42,403 	Gloss Alignment :	         
2024-02-04 04:37:42,403 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:37:42,404 	Text Reference  :	* **** ********* *** ***** ** to help  india's fight   against the covid-19 pandemic  
2024-02-04 04:37:42,404 	Text Hypothesis :	i have dedicated the match as a  close to      compete in      the ******** tournament
2024-02-04 04:37:42,404 	Text Alignment  :	I I    I         I   I     I  S  S     S       S       S           D        S         
2024-02-04 04:37:42,404 ========================================================================================================================
2024-02-04 04:37:42,404 Logging Sequence: 69_177.00
2024-02-04 04:37:42,404 	Gloss Reference :	A B+C+D+E
2024-02-04 04:37:42,405 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:37:42,405 	Gloss Alignment :	         
2024-02-04 04:37:42,405 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:37:42,406 	Text Reference  :	he said 'i will continue playing i know it's  about time i   retire i   also    have   a   knee   condition
2024-02-04 04:37:42,406 	Text Hypothesis :	** **** ** **** ******** ******* * **** since the   4th  ipl final  and gujarat became the runner ups      
2024-02-04 04:37:42,406 	Text Alignment  :	D  D    D  D    D        D       D D    S     S     S    S   S      S   S       S      S   S      S        
2024-02-04 04:37:42,406 ========================================================================================================================
2024-02-04 04:37:42,406 Logging Sequence: 165_615.00
2024-02-04 04:37:42,407 	Gloss Reference :	A B+C+D+E
2024-02-04 04:37:42,407 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:37:42,407 	Gloss Alignment :	         
2024-02-04 04:37:42,407 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:37:42,407 	Text Reference  :	***** *** ***** **** **** **** ***** we defeated pakistan too 
2024-02-04 04:37:42,408 	Text Hypothesis :	after the match when they went viral on 5th      may      2023
2024-02-04 04:37:42,408 	Text Alignment  :	I     I   I     I    I    I    I     S  S        S        S   
2024-02-04 04:37:42,408 ========================================================================================================================
2024-02-04 04:37:42,408 Logging Sequence: 61_5.00
2024-02-04 04:37:42,408 	Gloss Reference :	A B+C+D+E
2024-02-04 04:37:42,408 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:37:42,408 	Gloss Alignment :	         
2024-02-04 04:37:42,408 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:37:42,409 	Text Reference  :	they rivalry is      seen the     most during  india pakistan cricket matches
2024-02-04 04:37:42,409 	Text Hypothesis :	**** ******* indians love cricket and  excited to    see      dhoni's message
2024-02-04 04:37:42,409 	Text Alignment  :	D    D       S       S    S       S    S       S     S        S       S      
2024-02-04 04:37:42,409 ========================================================================================================================
2024-02-04 04:37:45,765 Epoch 241: Total Training Recognition Loss 0.05  Total Training Translation Loss 23.67 
2024-02-04 04:37:45,766 EPOCH 242
2024-02-04 04:37:48,299 [Epoch: 242 Step: 00032100] Batch Recognition Loss:   0.000553 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.406887 => Txt Tokens per Sec:     4177 || Lr: 0.000100
2024-02-04 04:37:53,451 Epoch 242: Total Training Recognition Loss 0.06  Total Training Translation Loss 18.76 
2024-02-04 04:37:53,452 EPOCH 243
2024-02-04 04:37:54,147 [Epoch: 243 Step: 00032200] Batch Recognition Loss:   0.000259 => Gls Tokens per Sec:     1614 || Batch Translation Loss:   0.126384 => Txt Tokens per Sec:     4369 || Lr: 0.000100
2024-02-04 04:37:59,786 [Epoch: 243 Step: 00032300] Batch Recognition Loss:   0.000189 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.372439 => Txt Tokens per Sec:     3970 || Lr: 0.000100
2024-02-04 04:38:00,869 Epoch 243: Total Training Recognition Loss 0.06  Total Training Translation Loss 23.15 
2024-02-04 04:38:00,870 EPOCH 244
2024-02-04 04:38:05,344 [Epoch: 244 Step: 00032400] Batch Recognition Loss:   0.000552 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.183032 => Txt Tokens per Sec:     4060 || Lr: 0.000100
2024-02-04 04:38:08,449 Epoch 244: Total Training Recognition Loss 0.06  Total Training Translation Loss 22.11 
2024-02-04 04:38:08,450 EPOCH 245
2024-02-04 04:38:11,174 [Epoch: 245 Step: 00032500] Batch Recognition Loss:   0.000345 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.012374 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-04 04:38:16,094 Epoch 245: Total Training Recognition Loss 0.07  Total Training Translation Loss 18.48 
2024-02-04 04:38:16,094 EPOCH 246
2024-02-04 04:38:16,831 [Epoch: 246 Step: 00032600] Batch Recognition Loss:   0.000677 => Gls Tokens per Sec:     1630 || Batch Translation Loss:   0.285721 => Txt Tokens per Sec:     4152 || Lr: 0.000100
2024-02-04 04:38:22,348 [Epoch: 246 Step: 00032700] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1450 || Batch Translation Loss:   0.049834 => Txt Tokens per Sec:     4085 || Lr: 0.000100
2024-02-04 04:38:23,325 Epoch 246: Total Training Recognition Loss 0.05  Total Training Translation Loss 24.97 
2024-02-04 04:38:23,325 EPOCH 247
2024-02-04 04:38:27,585 [Epoch: 247 Step: 00032800] Batch Recognition Loss:   0.000259 => Gls Tokens per Sec:     1540 || Batch Translation Loss:   0.156867 => Txt Tokens per Sec:     4274 || Lr: 0.000100
2024-02-04 04:38:30,680 Epoch 247: Total Training Recognition Loss 0.06  Total Training Translation Loss 20.81 
2024-02-04 04:38:30,681 EPOCH 248
2024-02-04 04:38:33,221 [Epoch: 248 Step: 00032900] Batch Recognition Loss:   0.000597 => Gls Tokens per Sec:     1544 || Batch Translation Loss:   0.861620 => Txt Tokens per Sec:     4223 || Lr: 0.000100
2024-02-04 04:38:38,146 Epoch 248: Total Training Recognition Loss 0.06  Total Training Translation Loss 15.36 
2024-02-04 04:38:38,147 EPOCH 249
2024-02-04 04:38:39,098 [Epoch: 249 Step: 00033000] Batch Recognition Loss:   0.000437 => Gls Tokens per Sec:     1349 || Batch Translation Loss:   0.040186 => Txt Tokens per Sec:     3725 || Lr: 0.000100
2024-02-04 04:38:44,717 [Epoch: 249 Step: 00033100] Batch Recognition Loss:   0.000320 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.128006 => Txt Tokens per Sec:     3931 || Lr: 0.000100
2024-02-04 04:38:45,692 Epoch 249: Total Training Recognition Loss 0.06  Total Training Translation Loss 19.39 
2024-02-04 04:38:45,692 EPOCH 250
2024-02-04 04:38:50,227 [Epoch: 250 Step: 00033200] Batch Recognition Loss:   0.000453 => Gls Tokens per Sec:     1465 || Batch Translation Loss:   0.079909 => Txt Tokens per Sec:     4045 || Lr: 0.000100
2024-02-04 04:38:53,184 Epoch 250: Total Training Recognition Loss 0.07  Total Training Translation Loss 19.71 
2024-02-04 04:38:53,185 EPOCH 251
2024-02-04 04:38:56,099 [Epoch: 251 Step: 00033300] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.043702 => Txt Tokens per Sec:     3839 || Lr: 0.000100
2024-02-04 04:39:00,754 Epoch 251: Total Training Recognition Loss 0.06  Total Training Translation Loss 18.40 
2024-02-04 04:39:00,754 EPOCH 252
2024-02-04 04:39:01,646 [Epoch: 252 Step: 00033400] Batch Recognition Loss:   0.000308 => Gls Tokens per Sec:     1527 || Batch Translation Loss:   0.037696 => Txt Tokens per Sec:     4044 || Lr: 0.000100
2024-02-04 04:39:07,352 [Epoch: 252 Step: 00033500] Batch Recognition Loss:   0.001160 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.207018 => Txt Tokens per Sec:     3905 || Lr: 0.000100
2024-02-04 04:39:08,208 Epoch 252: Total Training Recognition Loss 0.06  Total Training Translation Loss 19.32 
2024-02-04 04:39:08,208 EPOCH 253
2024-02-04 04:39:12,661 [Epoch: 253 Step: 00033600] Batch Recognition Loss:   0.000462 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.080726 => Txt Tokens per Sec:     4141 || Lr: 0.000100
2024-02-04 04:39:15,454 Epoch 253: Total Training Recognition Loss 0.05  Total Training Translation Loss 19.32 
2024-02-04 04:39:15,454 EPOCH 254
2024-02-04 04:39:18,492 [Epoch: 254 Step: 00033700] Batch Recognition Loss:   0.000580 => Gls Tokens per Sec:     1344 || Batch Translation Loss:   0.040320 => Txt Tokens per Sec:     3727 || Lr: 0.000100
2024-02-04 04:39:23,232 Epoch 254: Total Training Recognition Loss 0.06  Total Training Translation Loss 19.60 
2024-02-04 04:39:23,232 EPOCH 255
2024-02-04 04:39:24,128 [Epoch: 255 Step: 00033800] Batch Recognition Loss:   0.000262 => Gls Tokens per Sec:     1608 || Batch Translation Loss:   0.151026 => Txt Tokens per Sec:     4036 || Lr: 0.000100
2024-02-04 04:39:29,629 [Epoch: 255 Step: 00033900] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.126679 => Txt Tokens per Sec:     4116 || Lr: 0.000100
2024-02-04 04:39:30,435 Epoch 255: Total Training Recognition Loss 0.07  Total Training Translation Loss 21.99 
2024-02-04 04:39:30,435 EPOCH 256
2024-02-04 04:39:34,842 [Epoch: 256 Step: 00034000] Batch Recognition Loss:   0.000376 => Gls Tokens per Sec:     1543 || Batch Translation Loss:   0.483632 => Txt Tokens per Sec:     4228 || Lr: 0.000100
2024-02-04 04:39:45,918 Validation result at epoch 256, step    34000: duration: 11.0763s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00334	Translation Loss: 95813.03125	PPL: 14588.87598
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.53	(BLEU-1: 10.31,	BLEU-2: 2.71,	BLEU-3: 1.04,	BLEU-4: 0.53)
	CHRF 16.34	ROUGE 9.03
2024-02-04 04:39:45,919 Logging Recognition and Translation Outputs
2024-02-04 04:39:45,919 ========================================================================================================================
2024-02-04 04:39:45,919 Logging Sequence: 92_199.00
2024-02-04 04:39:45,920 	Gloss Reference :	A B+C+D+E
2024-02-04 04:39:45,920 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:39:45,920 	Gloss Alignment :	         
2024-02-04 04:39:45,920 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:39:45,921 	Text Reference  :	**** ** *** ** people on        social media said that 
2024-02-04 04:39:45,921 	Text Hypothesis :	this is why he was    extremely fit    and   his  image
2024-02-04 04:39:45,921 	Text Alignment  :	I    I  I   I  S      S         S      S     S    S    
2024-02-04 04:39:45,921 ========================================================================================================================
2024-02-04 04:39:45,921 Logging Sequence: 109_64.00
2024-02-04 04:39:45,921 	Gloss Reference :	A B+C+D+E
2024-02-04 04:39:45,922 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:39:45,922 	Gloss Alignment :	         
2024-02-04 04:39:45,922 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:39:45,923 	Text Reference  :	the ******* 2    players as        well as   the entire kkr     team  have been  quarantined
2024-02-04 04:39:45,923 	Text Hypothesis :	the medical team is      extremely fit  when the ****** players after the  covid team       
2024-02-04 04:39:45,923 	Text Alignment  :	    I       S    S       S         S    S        D      S       S     S    S     S          
2024-02-04 04:39:45,923 ========================================================================================================================
2024-02-04 04:39:45,923 Logging Sequence: 84_108.00
2024-02-04 04:39:45,924 	Gloss Reference :	A B+C+D+E
2024-02-04 04:39:45,924 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:39:45,924 	Gloss Alignment :	         
2024-02-04 04:39:45,924 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:39:45,924 	Text Reference  :	so in order to show their protest they covered their mouth in the photos which then went viral
2024-02-04 04:39:45,925 	Text Hypothesis :	** ** ***** ** **** ***** ******* **** ******* ***** ***** ** the ****** ***** news went viral
2024-02-04 04:39:45,925 	Text Alignment  :	D  D  D     D  D    D     D       D    D       D     D     D      D      D     S              
2024-02-04 04:39:45,925 ========================================================================================================================
2024-02-04 04:39:45,925 Logging Sequence: 115_24.00
2024-02-04 04:39:45,925 	Gloss Reference :	A B+C+D+E
2024-02-04 04:39:45,925 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:39:45,925 	Gloss Alignment :	         
2024-02-04 04:39:45,925 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:39:45,926 	Text Reference  :	bumrah also did not participate in   the  5  match t20    series
2024-02-04 04:39:45,926 	Text Hypothesis :	****** this was the first       time when he was   widely shared
2024-02-04 04:39:45,926 	Text Alignment  :	D      S    S   S   S           S    S    S  S     S      S     
2024-02-04 04:39:45,927 ========================================================================================================================
2024-02-04 04:39:45,927 Logging Sequence: 96_129.00
2024-02-04 04:39:45,927 	Gloss Reference :	A B+C+D+E
2024-02-04 04:39:45,927 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:39:45,927 	Gloss Alignment :	         
2024-02-04 04:39:45,927 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:39:45,928 	Text Reference  :	** ** ******* viewers were very stressed
2024-02-04 04:39:45,928 	Text Hypothesis :	it is because dhoni   was  very excited 
2024-02-04 04:39:45,928 	Text Alignment  :	I  I  I       S       S         S       
2024-02-04 04:39:45,928 ========================================================================================================================
2024-02-04 04:39:48,868 Epoch 256: Total Training Recognition Loss 0.06  Total Training Translation Loss 22.32 
2024-02-04 04:39:48,868 EPOCH 257
2024-02-04 04:39:51,725 [Epoch: 257 Step: 00034100] Batch Recognition Loss:   0.000737 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.215935 => Txt Tokens per Sec:     3982 || Lr: 0.000100
2024-02-04 04:39:56,649 Epoch 257: Total Training Recognition Loss 0.09  Total Training Translation Loss 24.48 
2024-02-04 04:39:56,650 EPOCH 258
2024-02-04 04:39:57,796 [Epoch: 258 Step: 00034200] Batch Recognition Loss:   0.000252 => Gls Tokens per Sec:     1328 || Batch Translation Loss:   0.262374 => Txt Tokens per Sec:     3690 || Lr: 0.000100
2024-02-04 04:40:02,833 [Epoch: 258 Step: 00034300] Batch Recognition Loss:   0.000285 => Gls Tokens per Sec:     1588 || Batch Translation Loss:   0.088917 => Txt Tokens per Sec:     4410 || Lr: 0.000100
2024-02-04 04:40:03,736 Epoch 258: Total Training Recognition Loss 0.06  Total Training Translation Loss 25.62 
2024-02-04 04:40:03,736 EPOCH 259
2024-02-04 04:40:08,669 [Epoch: 259 Step: 00034400] Batch Recognition Loss:   0.000201 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.040639 => Txt Tokens per Sec:     3907 || Lr: 0.000100
2024-02-04 04:40:11,488 Epoch 259: Total Training Recognition Loss 0.07  Total Training Translation Loss 17.62 
2024-02-04 04:40:11,488 EPOCH 260
2024-02-04 04:40:14,525 [Epoch: 260 Step: 00034500] Batch Recognition Loss:   0.000182 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.068429 => Txt Tokens per Sec:     3929 || Lr: 0.000100
2024-02-04 04:40:19,111 Epoch 260: Total Training Recognition Loss 0.04  Total Training Translation Loss 16.81 
2024-02-04 04:40:19,111 EPOCH 261
2024-02-04 04:40:20,376 [Epoch: 261 Step: 00034600] Batch Recognition Loss:   0.000200 => Gls Tokens per Sec:     1266 || Batch Translation Loss:   0.046493 => Txt Tokens per Sec:     3479 || Lr: 0.000100
2024-02-04 04:40:25,790 [Epoch: 261 Step: 00034700] Batch Recognition Loss:   0.002819 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.233159 => Txt Tokens per Sec:     4082 || Lr: 0.000100
2024-02-04 04:40:26,477 Epoch 261: Total Training Recognition Loss 0.05  Total Training Translation Loss 12.61 
2024-02-04 04:40:26,477 EPOCH 262
2024-02-04 04:40:31,304 [Epoch: 262 Step: 00034800] Batch Recognition Loss:   0.000677 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   0.033776 => Txt Tokens per Sec:     4039 || Lr: 0.000100
2024-02-04 04:40:33,926 Epoch 262: Total Training Recognition Loss 0.05  Total Training Translation Loss 14.21 
2024-02-04 04:40:33,926 EPOCH 263
2024-02-04 04:40:37,001 [Epoch: 263 Step: 00034900] Batch Recognition Loss:   0.000866 => Gls Tokens per Sec:     1406 || Batch Translation Loss:   0.775460 => Txt Tokens per Sec:     4047 || Lr: 0.000100
2024-02-04 04:40:41,377 Epoch 263: Total Training Recognition Loss 0.05  Total Training Translation Loss 19.11 
2024-02-04 04:40:41,377 EPOCH 264
2024-02-04 04:40:42,438 [Epoch: 264 Step: 00035000] Batch Recognition Loss:   0.004261 => Gls Tokens per Sec:     1584 || Batch Translation Loss:   0.336905 => Txt Tokens per Sec:     4257 || Lr: 0.000100
2024-02-04 04:40:48,083 [Epoch: 264 Step: 00035100] Batch Recognition Loss:   0.000677 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   0.062484 => Txt Tokens per Sec:     3928 || Lr: 0.000100
2024-02-04 04:40:48,906 Epoch 264: Total Training Recognition Loss 0.06  Total Training Translation Loss 19.22 
2024-02-04 04:40:48,906 EPOCH 265
2024-02-04 04:40:54,152 [Epoch: 265 Step: 00035200] Batch Recognition Loss:   0.000516 => Gls Tokens per Sec:     1342 || Batch Translation Loss:   0.069105 => Txt Tokens per Sec:     3679 || Lr: 0.000100
2024-02-04 04:40:56,728 Epoch 265: Total Training Recognition Loss 0.06  Total Training Translation Loss 21.30 
2024-02-04 04:40:56,728 EPOCH 266
2024-02-04 04:40:59,648 [Epoch: 266 Step: 00035300] Batch Recognition Loss:   0.000219 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.298089 => Txt Tokens per Sec:     4104 || Lr: 0.000100
2024-02-04 04:41:03,946 Epoch 266: Total Training Recognition Loss 0.04  Total Training Translation Loss 20.86 
2024-02-04 04:41:03,947 EPOCH 267
2024-02-04 04:41:05,427 [Epoch: 267 Step: 00035400] Batch Recognition Loss:   0.000443 => Gls Tokens per Sec:     1190 || Batch Translation Loss:   0.129449 => Txt Tokens per Sec:     3235 || Lr: 0.000100
2024-02-04 04:41:10,857 [Epoch: 267 Step: 00035500] Batch Recognition Loss:   0.000490 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.103145 => Txt Tokens per Sec:     4115 || Lr: 0.000100
2024-02-04 04:41:11,419 Epoch 267: Total Training Recognition Loss 0.05  Total Training Translation Loss 22.44 
2024-02-04 04:41:11,419 EPOCH 268
2024-02-04 04:41:16,244 [Epoch: 268 Step: 00035600] Batch Recognition Loss:   0.000268 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.179284 => Txt Tokens per Sec:     4032 || Lr: 0.000100
2024-02-04 04:41:18,913 Epoch 268: Total Training Recognition Loss 0.07  Total Training Translation Loss 26.78 
2024-02-04 04:41:18,913 EPOCH 269
2024-02-04 04:41:22,008 [Epoch: 269 Step: 00035700] Batch Recognition Loss:   0.000138 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.122865 => Txt Tokens per Sec:     3974 || Lr: 0.000100
2024-02-04 04:41:26,425 Epoch 269: Total Training Recognition Loss 0.05  Total Training Translation Loss 19.24 
2024-02-04 04:41:26,425 EPOCH 270
2024-02-04 04:41:27,760 [Epoch: 270 Step: 00035800] Batch Recognition Loss:   0.000264 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.096855 => Txt Tokens per Sec:     3809 || Lr: 0.000100
2024-02-04 04:41:32,887 [Epoch: 270 Step: 00035900] Batch Recognition Loss:   0.000424 => Gls Tokens per Sec:     1558 || Batch Translation Loss:   0.023765 => Txt Tokens per Sec:     4369 || Lr: 0.000100
2024-02-04 04:41:33,340 Epoch 270: Total Training Recognition Loss 0.06  Total Training Translation Loss 19.88 
2024-02-04 04:41:33,340 EPOCH 271
2024-02-04 04:41:38,002 [Epoch: 271 Step: 00036000] Batch Recognition Loss:   0.000207 => Gls Tokens per Sec:     1545 || Batch Translation Loss:   0.301038 => Txt Tokens per Sec:     4256 || Lr: 0.000100
2024-02-04 04:41:48,659 Validation result at epoch 271, step    36000: duration: 10.6556s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00298	Translation Loss: 97409.25000	PPL: 17115.64844
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.93	(BLEU-1: 10.13,	BLEU-2: 3.42,	BLEU-3: 1.58,	BLEU-4: 0.93)
	CHRF 16.38	ROUGE 9.26
2024-02-04 04:41:48,660 Logging Recognition and Translation Outputs
2024-02-04 04:41:48,660 ========================================================================================================================
2024-02-04 04:41:48,660 Logging Sequence: 78_198.00
2024-02-04 04:41:48,660 	Gloss Reference :	A B+C+D+E
2024-02-04 04:41:48,660 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:41:48,660 	Gloss Alignment :	         
2024-02-04 04:41:48,660 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:41:48,661 	Text Reference  :	they have been  flooded    with     congratulations comments
2024-02-04 04:41:48,661 	Text Hypothesis :	**** **** queen elizabeth' grandson prince          william 
2024-02-04 04:41:48,661 	Text Alignment  :	D    D    S     S          S        S               S       
2024-02-04 04:41:48,661 ========================================================================================================================
2024-02-04 04:41:48,661 Logging Sequence: 145_216.00
2024-02-04 04:41:48,662 	Gloss Reference :	A B+C+D+E
2024-02-04 04:41:48,662 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:41:48,662 	Gloss Alignment :	         
2024-02-04 04:41:48,662 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:41:48,663 	Text Reference  :	asking him to include sameeha in the world championship as   she    was a  talented    athlete     
2024-02-04 04:41:48,663 	Text Hypothesis :	****** *** ** ******* ******* ** the ***** spinner      anil kumble has an interesting superstition
2024-02-04 04:41:48,663 	Text Alignment  :	D      D   D  D       D       D      D     S            S    S      S   S  S           S           
2024-02-04 04:41:48,663 ========================================================================================================================
2024-02-04 04:41:48,663 Logging Sequence: 70_137.00
2024-02-04 04:41:48,663 	Gloss Reference :	A B+C+D+E
2024-02-04 04:41:48,663 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:41:48,664 	Gloss Alignment :	         
2024-02-04 04:41:48,664 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:41:48,665 	Text Reference  :	the small gesture appeared to      encourage people to    drink    water instead of  aerated drinks    
2024-02-04 04:41:48,665 	Text Hypothesis :	*** ***** however a        violent brawl     in     tokyo olympics which is      the brand   ambassador
2024-02-04 04:41:48,665 	Text Alignment  :	D   D     S       S        S       S         S      S     S        S     S       S   S       S         
2024-02-04 04:41:48,665 ========================================================================================================================
2024-02-04 04:41:48,665 Logging Sequence: 119_20.00
2024-02-04 04:41:48,665 	Gloss Reference :	A B+C+D+E
2024-02-04 04:41:48,665 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:41:48,666 	Gloss Alignment :	         
2024-02-04 04:41:48,666 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:41:48,667 	Text Reference  :	messi intended to gift something to all the players and   the staff to special to celebrate the    moment      
2024-02-04 04:41:48,667 	Text Hypothesis :	***** ******** ** **** ********* as per the ******* rules the ***** ** ******* ** ********* team's achievements
2024-02-04 04:41:48,667 	Text Alignment  :	D     D        D  D    D         S  S       D       S         D     D  D       D  D         S      S           
2024-02-04 04:41:48,667 ========================================================================================================================
2024-02-04 04:41:48,667 Logging Sequence: 106_15.00
2024-02-04 04:41:48,667 	Gloss Reference :	A B+C+D+E
2024-02-04 04:41:48,667 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:41:48,667 	Gloss Alignment :	         
2024-02-04 04:41:48,668 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:41:48,668 	Text Reference  :	*** but what about     women's cricket earlier we never spoke about it   
2024-02-04 04:41:48,669 	Text Hypothesis :	and it  was  surprised that    the     times   of the   oc    be    given
2024-02-04 04:41:48,669 	Text Alignment  :	I   S   S    S         S       S       S       S  S     S     S     S    
2024-02-04 04:41:48,669 ========================================================================================================================
2024-02-04 04:41:51,340 Epoch 271: Total Training Recognition Loss 0.06  Total Training Translation Loss 20.02 
2024-02-04 04:41:51,340 EPOCH 272
2024-02-04 04:41:54,417 [Epoch: 272 Step: 00036100] Batch Recognition Loss:   0.000312 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.062098 => Txt Tokens per Sec:     3992 || Lr: 0.000100
2024-02-04 04:41:59,063 Epoch 272: Total Training Recognition Loss 0.04  Total Training Translation Loss 14.91 
2024-02-04 04:41:59,063 EPOCH 273
2024-02-04 04:42:00,469 [Epoch: 273 Step: 00036200] Batch Recognition Loss:   0.000367 => Gls Tokens per Sec:     1366 || Batch Translation Loss:   0.091415 => Txt Tokens per Sec:     3917 || Lr: 0.000100
2024-02-04 04:42:06,236 [Epoch: 273 Step: 00036300] Batch Recognition Loss:   0.000362 => Gls Tokens per Sec:     1385 || Batch Translation Loss:   0.079400 => Txt Tokens per Sec:     3833 || Lr: 0.000100
2024-02-04 04:42:06,649 Epoch 273: Total Training Recognition Loss 0.04  Total Training Translation Loss 13.12 
2024-02-04 04:42:06,649 EPOCH 274
2024-02-04 04:42:11,503 [Epoch: 274 Step: 00036400] Batch Recognition Loss:   0.000351 => Gls Tokens per Sec:     1500 || Batch Translation Loss:   0.054254 => Txt Tokens per Sec:     4179 || Lr: 0.000100
2024-02-04 04:42:13,879 Epoch 274: Total Training Recognition Loss 0.05  Total Training Translation Loss 12.49 
2024-02-04 04:42:13,879 EPOCH 275
2024-02-04 04:42:17,090 [Epoch: 275 Step: 00036500] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.047372 => Txt Tokens per Sec:     4060 || Lr: 0.000100
2024-02-04 04:42:21,325 Epoch 275: Total Training Recognition Loss 0.05  Total Training Translation Loss 10.46 
2024-02-04 04:42:21,326 EPOCH 276
2024-02-04 04:42:22,660 [Epoch: 276 Step: 00036600] Batch Recognition Loss:   0.000306 => Gls Tokens per Sec:     1500 || Batch Translation Loss:   0.062278 => Txt Tokens per Sec:     4319 || Lr: 0.000100
2024-02-04 04:42:28,210 [Epoch: 276 Step: 00036700] Batch Recognition Loss:   0.001296 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.140790 => Txt Tokens per Sec:     3983 || Lr: 0.000100
2024-02-04 04:42:28,643 Epoch 276: Total Training Recognition Loss 0.05  Total Training Translation Loss 16.29 
2024-02-04 04:42:28,644 EPOCH 277
2024-02-04 04:42:33,712 [Epoch: 277 Step: 00036800] Batch Recognition Loss:   0.000348 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.121238 => Txt Tokens per Sec:     4012 || Lr: 0.000100
2024-02-04 04:42:36,118 Epoch 277: Total Training Recognition Loss 0.06  Total Training Translation Loss 26.74 
2024-02-04 04:42:36,118 EPOCH 278
2024-02-04 04:42:39,381 [Epoch: 278 Step: 00036900] Batch Recognition Loss:   0.000595 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.113507 => Txt Tokens per Sec:     4150 || Lr: 0.000100
2024-02-04 04:42:43,263 Epoch 278: Total Training Recognition Loss 0.07  Total Training Translation Loss 30.04 
2024-02-04 04:42:43,264 EPOCH 279
2024-02-04 04:42:44,836 [Epoch: 279 Step: 00037000] Batch Recognition Loss:   0.000727 => Gls Tokens per Sec:     1325 || Batch Translation Loss:   0.194129 => Txt Tokens per Sec:     3519 || Lr: 0.000100
2024-02-04 04:42:50,290 [Epoch: 279 Step: 00037100] Batch Recognition Loss:   0.000534 => Gls Tokens per Sec:     1465 || Batch Translation Loss:   0.095739 => Txt Tokens per Sec:     4110 || Lr: 0.000100
2024-02-04 04:42:50,680 Epoch 279: Total Training Recognition Loss 0.08  Total Training Translation Loss 26.86 
2024-02-04 04:42:50,680 EPOCH 280
2024-02-04 04:42:55,903 [Epoch: 280 Step: 00037200] Batch Recognition Loss:   0.000457 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.064372 => Txt Tokens per Sec:     3956 || Lr: 0.000100
2024-02-04 04:42:58,110 Epoch 280: Total Training Recognition Loss 0.07  Total Training Translation Loss 14.76 
2024-02-04 04:42:58,110 EPOCH 281
2024-02-04 04:43:01,236 [Epoch: 281 Step: 00037300] Batch Recognition Loss:   0.000404 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   0.068110 => Txt Tokens per Sec:     4176 || Lr: 0.000100
2024-02-04 04:43:05,495 Epoch 281: Total Training Recognition Loss 0.07  Total Training Translation Loss 16.04 
2024-02-04 04:43:05,496 EPOCH 282
2024-02-04 04:43:07,138 [Epoch: 282 Step: 00037400] Batch Recognition Loss:   0.000274 => Gls Tokens per Sec:     1316 || Batch Translation Loss:   0.050363 => Txt Tokens per Sec:     3519 || Lr: 0.000100
2024-02-04 04:43:12,788 [Epoch: 282 Step: 00037500] Batch Recognition Loss:   0.000363 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.094713 => Txt Tokens per Sec:     3967 || Lr: 0.000100
2024-02-04 04:43:13,183 Epoch 282: Total Training Recognition Loss 0.05  Total Training Translation Loss 16.42 
2024-02-04 04:43:13,183 EPOCH 283
2024-02-04 04:43:18,068 [Epoch: 283 Step: 00037600] Batch Recognition Loss:   0.001120 => Gls Tokens per Sec:     1540 || Batch Translation Loss:   0.548482 => Txt Tokens per Sec:     4239 || Lr: 0.000100
2024-02-04 04:43:20,253 Epoch 283: Total Training Recognition Loss 0.05  Total Training Translation Loss 11.67 
2024-02-04 04:43:20,253 EPOCH 284
2024-02-04 04:43:23,727 [Epoch: 284 Step: 00037700] Batch Recognition Loss:   0.000436 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.189344 => Txt Tokens per Sec:     3919 || Lr: 0.000100
2024-02-04 04:43:28,086 Epoch 284: Total Training Recognition Loss 0.05  Total Training Translation Loss 16.18 
2024-02-04 04:43:28,087 EPOCH 285
2024-02-04 04:43:29,666 [Epoch: 285 Step: 00037800] Batch Recognition Loss:   0.000172 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.034899 => Txt Tokens per Sec:     3914 || Lr: 0.000100
2024-02-04 04:43:35,026 [Epoch: 285 Step: 00037900] Batch Recognition Loss:   0.000293 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.058561 => Txt Tokens per Sec:     4153 || Lr: 0.000100
2024-02-04 04:43:35,277 Epoch 285: Total Training Recognition Loss 0.05  Total Training Translation Loss 20.39 
2024-02-04 04:43:35,278 EPOCH 286
2024-02-04 04:43:40,599 [Epoch: 286 Step: 00038000] Batch Recognition Loss:   0.000326 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.076228 => Txt Tokens per Sec:     3942 || Lr: 0.000100
2024-02-04 04:43:51,089 Validation result at epoch 286, step    38000: duration: 10.4897s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00333	Translation Loss: 93850.39062	PPL: 11987.41895
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.56	(BLEU-1: 10.10,	BLEU-2: 2.86,	BLEU-3: 1.11,	BLEU-4: 0.56)
	CHRF 16.40	ROUGE 8.67
2024-02-04 04:43:51,090 Logging Recognition and Translation Outputs
2024-02-04 04:43:51,090 ========================================================================================================================
2024-02-04 04:43:51,090 Logging Sequence: 72_194.00
2024-02-04 04:43:51,090 	Gloss Reference :	A B+C+D+E
2024-02-04 04:43:51,091 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:43:51,091 	Gloss Alignment :	         
2024-02-04 04:43:51,091 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:43:51,092 	Text Reference  :	shah told her   to   do what she    wants  and filed a police complaint against her
2024-02-04 04:43:51,092 	Text Hypothesis :	**** **** babar kept me in   rented houses and ***** * ****** ********* ******* ***
2024-02-04 04:43:51,092 	Text Alignment  :	D    D    S     S    S  S    S      S          D     D D      D         D       D  
2024-02-04 04:43:51,092 ========================================================================================================================
2024-02-04 04:43:51,092 Logging Sequence: 108_59.00
2024-02-04 04:43:51,092 	Gloss Reference :	A B+C+D+E
2024-02-04 04:43:51,092 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:43:51,093 	Gloss Alignment :	         
2024-02-04 04:43:51,093 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:43:51,094 	Text Reference  :	ishan kishan remained the biggest buy of ipl as    mumbai indians paid      a   whopping rs      1525  crore   to   keep    him    
2024-02-04 04:43:51,094 	Text Hypothesis :	***** ****** ******** *** ******* *** ** a   close friend andrew  neophitou and warne'   manager james erskine kept india's victory
2024-02-04 04:43:51,094 	Text Alignment  :	D     D      D        D   D       D   D  S   S     S      S       S         S   S        S       S     S       S    S       S      
2024-02-04 04:43:51,095 ========================================================================================================================
2024-02-04 04:43:51,095 Logging Sequence: 109_10.00
2024-02-04 04:43:51,095 	Gloss Reference :	A B+C+D+E
2024-02-04 04:43:51,095 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:43:51,095 	Gloss Alignment :	         
2024-02-04 04:43:51,095 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:43:51,096 	Text Reference  :	******* *** was   scheduled to be played at   the   narendra modi stadium in   ahmedabad
2024-02-04 04:43:51,096 	Text Hypothesis :	however the match ended     in a  year   1930 which will     be   banned  from well     
2024-02-04 04:43:51,096 	Text Alignment  :	I       I   S     S         S  S  S      S    S     S        S    S       S    S        
2024-02-04 04:43:51,097 ========================================================================================================================
2024-02-04 04:43:51,097 Logging Sequence: 103_202.00
2024-02-04 04:43:51,097 	Gloss Reference :	A B+C+D+E
2024-02-04 04:43:51,097 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:43:51,097 	Gloss Alignment :	         
2024-02-04 04:43:51,097 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:43:51,099 	Text Reference  :	india in total has   won       61 medals including 22 gold    medals 16  silver medals 23  bronze       medals
2024-02-04 04:43:51,099 	Text Hypothesis :	***** ** ***** queen elizabeth ii the    queen     of england is     the patron of     the commonwealth games 
2024-02-04 04:43:51,099 	Text Alignment  :	D     D  D     S     S         S  S      S         S  S       S      S   S      S      S   S            S     
2024-02-04 04:43:51,099 ========================================================================================================================
2024-02-04 04:43:51,099 Logging Sequence: 149_77.00
2024-02-04 04:43:51,099 	Gloss Reference :	A B+C+D+E
2024-02-04 04:43:51,099 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:43:51,100 	Gloss Alignment :	         
2024-02-04 04:43:51,100 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:43:51,101 	Text Reference  :	and arrested danushka for alleged sexual assault of a *** 29   year old  woman whose  name    has not been disclosed
2024-02-04 04:43:51,101 	Text Hypothesis :	*** ******** ******** *** ******* ****** but     if a few days went into the   afghan picture of  50  of   him      
2024-02-04 04:43:51,101 	Text Alignment  :	D   D        D        D   D       D      S       S    I   S    S    S    S     S      S       S   S   S    S        
2024-02-04 04:43:51,101 ========================================================================================================================
2024-02-04 04:43:53,439 Epoch 286: Total Training Recognition Loss 0.06  Total Training Translation Loss 21.26 
2024-02-04 04:43:53,440 EPOCH 287
2024-02-04 04:43:57,021 [Epoch: 287 Step: 00038100] Batch Recognition Loss:   0.000381 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.139691 => Txt Tokens per Sec:     3867 || Lr: 0.000100
2024-02-04 04:44:01,137 Epoch 287: Total Training Recognition Loss 0.04  Total Training Translation Loss 18.41 
2024-02-04 04:44:01,138 EPOCH 288
2024-02-04 04:44:02,878 [Epoch: 288 Step: 00038200] Batch Recognition Loss:   0.000297 => Gls Tokens per Sec:     1334 || Batch Translation Loss:   0.052739 => Txt Tokens per Sec:     3812 || Lr: 0.000100
2024-02-04 04:44:08,266 [Epoch: 288 Step: 00038300] Batch Recognition Loss:   0.000117 => Gls Tokens per Sec:     1483 || Batch Translation Loss:   0.038368 => Txt Tokens per Sec:     4068 || Lr: 0.000100
2024-02-04 04:44:08,506 Epoch 288: Total Training Recognition Loss 0.05  Total Training Translation Loss 13.52 
2024-02-04 04:44:08,506 EPOCH 289
2024-02-04 04:44:13,870 [Epoch: 289 Step: 00038400] Batch Recognition Loss:   0.000428 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.093294 => Txt Tokens per Sec:     3986 || Lr: 0.000100
2024-02-04 04:44:15,829 Epoch 289: Total Training Recognition Loss 0.05  Total Training Translation Loss 18.31 
2024-02-04 04:44:15,829 EPOCH 290
2024-02-04 04:44:19,320 [Epoch: 290 Step: 00038500] Batch Recognition Loss:   0.000573 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.057333 => Txt Tokens per Sec:     4090 || Lr: 0.000100
2024-02-04 04:44:23,215 Epoch 290: Total Training Recognition Loss 0.05  Total Training Translation Loss 15.64 
2024-02-04 04:44:23,215 EPOCH 291
2024-02-04 04:44:24,849 [Epoch: 291 Step: 00038600] Batch Recognition Loss:   0.000214 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.217159 => Txt Tokens per Sec:     4305 || Lr: 0.000100
2024-02-04 04:44:30,407 [Epoch: 291 Step: 00038700] Batch Recognition Loss:   0.000454 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.041972 => Txt Tokens per Sec:     3935 || Lr: 0.000100
2024-02-04 04:44:30,554 Epoch 291: Total Training Recognition Loss 0.05  Total Training Translation Loss 20.51 
2024-02-04 04:44:30,555 EPOCH 292
2024-02-04 04:44:35,888 [Epoch: 292 Step: 00038800] Batch Recognition Loss:   0.000252 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.074976 => Txt Tokens per Sec:     4036 || Lr: 0.000100
2024-02-04 04:44:37,908 Epoch 292: Total Training Recognition Loss 0.06  Total Training Translation Loss 27.95 
2024-02-04 04:44:37,908 EPOCH 293
2024-02-04 04:44:41,280 [Epoch: 293 Step: 00038900] Batch Recognition Loss:   0.000289 => Gls Tokens per Sec:     1519 || Batch Translation Loss:   0.195062 => Txt Tokens per Sec:     4296 || Lr: 0.000100
2024-02-04 04:44:45,265 Epoch 293: Total Training Recognition Loss 0.07  Total Training Translation Loss 24.86 
2024-02-04 04:44:45,266 EPOCH 294
2024-02-04 04:44:47,059 [Epoch: 294 Step: 00039000] Batch Recognition Loss:   0.000339 => Gls Tokens per Sec:     1383 || Batch Translation Loss:   0.052594 => Txt Tokens per Sec:     3606 || Lr: 0.000100
2024-02-04 04:44:53,004 [Epoch: 294 Step: 00039100] Batch Recognition Loss:   0.000193 => Gls Tokens per Sec:     1344 || Batch Translation Loss:   0.059979 => Txt Tokens per Sec:     3792 || Lr: 0.000100
2024-02-04 04:44:53,146 Epoch 294: Total Training Recognition Loss 0.08  Total Training Translation Loss 18.14 
2024-02-04 04:44:53,146 EPOCH 295
2024-02-04 04:44:58,364 [Epoch: 295 Step: 00039200] Batch Recognition Loss:   0.000388 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.218351 => Txt Tokens per Sec:     4168 || Lr: 0.000100
2024-02-04 04:45:00,479 Epoch 295: Total Training Recognition Loss 0.06  Total Training Translation Loss 18.69 
2024-02-04 04:45:00,479 EPOCH 296
2024-02-04 04:45:04,024 [Epoch: 296 Step: 00039300] Batch Recognition Loss:   0.000304 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.075193 => Txt Tokens per Sec:     3995 || Lr: 0.000100
2024-02-04 04:45:08,155 Epoch 296: Total Training Recognition Loss 0.05  Total Training Translation Loss 15.60 
2024-02-04 04:45:08,156 EPOCH 297
2024-02-04 04:45:10,013 [Epoch: 297 Step: 00039400] Batch Recognition Loss:   0.000387 => Gls Tokens per Sec:     1380 || Batch Translation Loss:   0.716622 => Txt Tokens per Sec:     3943 || Lr: 0.000100
2024-02-04 04:45:15,496 [Epoch: 297 Step: 00039500] Batch Recognition Loss:   0.000350 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.115104 => Txt Tokens per Sec:     4009 || Lr: 0.000100
2024-02-04 04:45:15,541 Epoch 297: Total Training Recognition Loss 0.05  Total Training Translation Loss 17.18 
2024-02-04 04:45:15,542 EPOCH 298
2024-02-04 04:45:21,111 [Epoch: 298 Step: 00039600] Batch Recognition Loss:   0.000317 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.041563 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-04 04:45:22,939 Epoch 298: Total Training Recognition Loss 0.05  Total Training Translation Loss 16.83 
2024-02-04 04:45:22,939 EPOCH 299
2024-02-04 04:45:26,836 [Epoch: 299 Step: 00039700] Batch Recognition Loss:   0.000382 => Gls Tokens per Sec:     1355 || Batch Translation Loss:   0.093284 => Txt Tokens per Sec:     3891 || Lr: 0.000100
2024-02-04 04:45:30,392 Epoch 299: Total Training Recognition Loss 0.04  Total Training Translation Loss 17.76 
2024-02-04 04:45:30,393 EPOCH 300
2024-02-04 04:45:32,084 [Epoch: 300 Step: 00039800] Batch Recognition Loss:   0.000342 => Gls Tokens per Sec:     1562 || Batch Translation Loss:   0.034634 => Txt Tokens per Sec:     4373 || Lr: 0.000100
2024-02-04 04:45:37,846 [Epoch: 300 Step: 00039900] Batch Recognition Loss:   0.000321 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   1.685457 => Txt Tokens per Sec:     3839 || Lr: 0.000100
2024-02-04 04:45:37,846 Epoch 300: Total Training Recognition Loss 0.05  Total Training Translation Loss 11.23 
2024-02-04 04:45:37,846 EPOCH 301
2024-02-04 04:45:43,460 [Epoch: 301 Step: 00040000] Batch Recognition Loss:   0.000272 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.058308 => Txt Tokens per Sec:     3956 || Lr: 0.000100
2024-02-04 04:45:54,381 Validation result at epoch 301, step    40000: duration: 10.9202s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00302	Translation Loss: 94759.69531	PPL: 13129.38086
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.77	(BLEU-1: 11.08,	BLEU-2: 3.51,	BLEU-3: 1.53,	BLEU-4: 0.77)
	CHRF 17.09	ROUGE 9.21
2024-02-04 04:45:54,382 Logging Recognition and Translation Outputs
2024-02-04 04:45:54,382 ========================================================================================================================
2024-02-04 04:45:54,383 Logging Sequence: 123_104.00
2024-02-04 04:45:54,383 	Gloss Reference :	A B+C+D+E
2024-02-04 04:45:54,383 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:45:54,383 	Gloss Alignment :	         
2024-02-04 04:45:54,383 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:45:54,385 	Text Reference  :	*** the       car was presented to *** ****** *** the  former india cricketer from an    unknown person
2024-02-04 04:45:54,385 	Text Hypothesis :	now similarly on  his way       to win neeraj has been proved that  it        is   named as      well  
2024-02-04 04:45:54,385 	Text Alignment  :	I   S         S   S   S            I   I      I   S    S      S     S         S    S     S       S     
2024-02-04 04:45:54,385 ========================================================================================================================
2024-02-04 04:45:54,385 Logging Sequence: 107_23.00
2024-02-04 04:45:54,385 	Gloss Reference :	A B+C+D+E
2024-02-04 04:45:54,385 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:45:54,385 	Gloss Alignment :	         
2024-02-04 04:45:54,386 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:45:54,386 	Text Reference  :	and viktor lilov who   is *** also from   the usa  
2024-02-04 04:45:54,386 	Text Hypothesis :	*** ****** ***** which is why or   around 8   crore
2024-02-04 04:45:54,386 	Text Alignment  :	D   D      D     S        I   S    S      S   S    
2024-02-04 04:45:54,387 ========================================================================================================================
2024-02-04 04:45:54,387 Logging Sequence: 134_212.00
2024-02-04 04:45:54,387 	Gloss Reference :	A B+C+D+E
2024-02-04 04:45:54,387 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:45:54,387 	Gloss Alignment :	         
2024-02-04 04:45:54,387 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:45:54,388 	Text Reference  :	******* dhanush said that he *** ** ****** practises little yoga
2024-02-04 04:45:54,388 	Text Hypothesis :	indians love    him  that he may be played at        the    way 
2024-02-04 04:45:54,388 	Text Alignment  :	I       S       S            I   I  I      S         S      S   
2024-02-04 04:45:54,388 ========================================================================================================================
2024-02-04 04:45:54,388 Logging Sequence: 165_577.00
2024-02-04 04:45:54,389 	Gloss Reference :	A B+C+D+E
2024-02-04 04:45:54,389 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:45:54,389 	Gloss Alignment :	         
2024-02-04 04:45:54,389 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:45:54,390 	Text Reference  :	**** then after 28    years india won    the     world cup   again in  2011   
2024-02-04 04:45:54,390 	Text Hypothesis :	pant made his   lucky so    he    always carried a     video to    her victory
2024-02-04 04:45:54,390 	Text Alignment  :	I    S    S     S     S     S     S      S       S     S     S     S   S      
2024-02-04 04:45:54,390 ========================================================================================================================
2024-02-04 04:45:54,390 Logging Sequence: 88_142.00
2024-02-04 04:45:54,391 	Gloss Reference :	A B+C+D+E
2024-02-04 04:45:54,391 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:45:54,391 	Gloss Alignment :	         
2024-02-04 04:45:54,391 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:45:54,392 	Text Reference  :	******* this    is  because the police does not       do    anything
2024-02-04 04:45:54,392 	Text Hypothesis :	notably rosario has become  a   threat to   celebrate their victory 
2024-02-04 04:45:54,392 	Text Alignment  :	I       S       S   S       S   S      S    S         S     S       
2024-02-04 04:45:54,392 ========================================================================================================================
2024-02-04 04:45:56,213 Epoch 301: Total Training Recognition Loss 0.05  Total Training Translation Loss 15.76 
2024-02-04 04:45:56,213 EPOCH 302
2024-02-04 04:46:00,039 [Epoch: 302 Step: 00040100] Batch Recognition Loss:   0.000271 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.036806 => Txt Tokens per Sec:     3978 || Lr: 0.000050
2024-02-04 04:46:03,938 Epoch 302: Total Training Recognition Loss 0.04  Total Training Translation Loss 17.01 
2024-02-04 04:46:03,939 EPOCH 303
2024-02-04 04:46:05,847 [Epoch: 303 Step: 00040200] Batch Recognition Loss:   0.000184 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.048187 => Txt Tokens per Sec:     4024 || Lr: 0.000050
2024-02-04 04:46:11,430 Epoch 303: Total Training Recognition Loss 0.04  Total Training Translation Loss 6.38 
2024-02-04 04:46:11,431 EPOCH 304
2024-02-04 04:46:11,479 [Epoch: 304 Step: 00040300] Batch Recognition Loss:   0.000303 => Gls Tokens per Sec:     1702 || Batch Translation Loss:   0.030464 => Txt Tokens per Sec:     4468 || Lr: 0.000050
2024-02-04 04:46:16,844 [Epoch: 304 Step: 00040400] Batch Recognition Loss:   0.000146 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.016960 => Txt Tokens per Sec:     4146 || Lr: 0.000050
2024-02-04 04:46:18,826 Epoch 304: Total Training Recognition Loss 0.04  Total Training Translation Loss 5.02 
2024-02-04 04:46:18,826 EPOCH 305
2024-02-04 04:46:22,463 [Epoch: 305 Step: 00040500] Batch Recognition Loss:   0.000399 => Gls Tokens per Sec:     1497 || Batch Translation Loss:   0.013277 => Txt Tokens per Sec:     4126 || Lr: 0.000050
2024-02-04 04:46:26,274 Epoch 305: Total Training Recognition Loss 0.04  Total Training Translation Loss 3.56 
2024-02-04 04:46:26,275 EPOCH 306
2024-02-04 04:46:28,181 [Epoch: 306 Step: 00040600] Batch Recognition Loss:   0.000280 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.026521 => Txt Tokens per Sec:     3818 || Lr: 0.000050
2024-02-04 04:46:33,867 Epoch 306: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.08 
2024-02-04 04:46:33,868 EPOCH 307
2024-02-04 04:46:33,979 [Epoch: 307 Step: 00040700] Batch Recognition Loss:   0.000116 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.010755 => Txt Tokens per Sec:     4400 || Lr: 0.000050
2024-02-04 04:46:39,030 [Epoch: 307 Step: 00040800] Batch Recognition Loss:   0.000371 => Gls Tokens per Sec:     1584 || Batch Translation Loss:   0.174131 => Txt Tokens per Sec:     4420 || Lr: 0.000050
2024-02-04 04:46:40,923 Epoch 307: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.58 
2024-02-04 04:46:40,923 EPOCH 308
2024-02-04 04:46:44,895 [Epoch: 308 Step: 00040900] Batch Recognition Loss:   0.000204 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.025713 => Txt Tokens per Sec:     3877 || Lr: 0.000050
2024-02-04 04:46:48,735 Epoch 308: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.23 
2024-02-04 04:46:48,736 EPOCH 309
2024-02-04 04:46:50,674 [Epoch: 309 Step: 00041000] Batch Recognition Loss:   0.000422 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.008089 => Txt Tokens per Sec:     4004 || Lr: 0.000050
2024-02-04 04:46:56,245 Epoch 309: Total Training Recognition Loss 0.03  Total Training Translation Loss 2.80 
2024-02-04 04:46:56,246 EPOCH 310
2024-02-04 04:46:56,400 [Epoch: 310 Step: 00041100] Batch Recognition Loss:   0.000293 => Gls Tokens per Sec:     1569 || Batch Translation Loss:   0.008134 => Txt Tokens per Sec:     3706 || Lr: 0.000050
2024-02-04 04:47:01,954 [Epoch: 310 Step: 00041200] Batch Recognition Loss:   0.000199 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.017398 => Txt Tokens per Sec:     4013 || Lr: 0.000050
2024-02-04 04:47:03,472 Epoch 310: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.21 
2024-02-04 04:47:03,472 EPOCH 311
2024-02-04 04:47:07,577 [Epoch: 311 Step: 00041300] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1365 || Batch Translation Loss:   0.014467 => Txt Tokens per Sec:     3879 || Lr: 0.000050
2024-02-04 04:47:11,231 Epoch 311: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.67 
2024-02-04 04:47:11,231 EPOCH 312
2024-02-04 04:47:13,559 [Epoch: 312 Step: 00041400] Batch Recognition Loss:   0.000922 => Gls Tokens per Sec:     1272 || Batch Translation Loss:   0.036837 => Txt Tokens per Sec:     3627 || Lr: 0.000050
2024-02-04 04:47:18,806 Epoch 312: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.69 
2024-02-04 04:47:18,806 EPOCH 313
2024-02-04 04:47:19,012 [Epoch: 313 Step: 00041500] Batch Recognition Loss:   0.000128 => Gls Tokens per Sec:     1561 || Batch Translation Loss:   0.029584 => Txt Tokens per Sec:     4610 || Lr: 0.000050
2024-02-04 04:47:24,675 [Epoch: 313 Step: 00041600] Batch Recognition Loss:   0.000215 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.009653 => Txt Tokens per Sec:     3904 || Lr: 0.000050
2024-02-04 04:47:26,304 Epoch 313: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.42 
2024-02-04 04:47:26,304 EPOCH 314
2024-02-04 04:47:29,888 [Epoch: 314 Step: 00041700] Batch Recognition Loss:   0.000375 => Gls Tokens per Sec:     1585 || Batch Translation Loss:   0.020661 => Txt Tokens per Sec:     4331 || Lr: 0.000050
2024-02-04 04:47:33,645 Epoch 314: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.48 
2024-02-04 04:47:33,646 EPOCH 315
2024-02-04 04:47:35,730 [Epoch: 315 Step: 00041800] Batch Recognition Loss:   0.000160 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.091209 => Txt Tokens per Sec:     4033 || Lr: 0.000050
2024-02-04 04:47:41,391 Epoch 315: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.22 
2024-02-04 04:47:41,391 EPOCH 316
2024-02-04 04:47:41,704 [Epoch: 316 Step: 00041900] Batch Recognition Loss:   0.000230 => Gls Tokens per Sec:     1286 || Batch Translation Loss:   0.030527 => Txt Tokens per Sec:     3312 || Lr: 0.000050
2024-02-04 04:47:47,365 [Epoch: 316 Step: 00042000] Batch Recognition Loss:   0.000179 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.017780 => Txt Tokens per Sec:     3941 || Lr: 0.000050
2024-02-04 04:47:58,036 Validation result at epoch 316, step    42000: duration: 10.6701s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00187	Translation Loss: 95887.79688	PPL: 14698.44629
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.77	(BLEU-1: 11.37,	BLEU-2: 3.38,	BLEU-3: 1.40,	BLEU-4: 0.77)
	CHRF 17.25	ROUGE 9.41
2024-02-04 04:47:58,037 Logging Recognition and Translation Outputs
2024-02-04 04:47:58,038 ========================================================================================================================
2024-02-04 04:47:58,038 Logging Sequence: 81_8.00
2024-02-04 04:47:58,038 	Gloss Reference :	A B+C+D+E
2024-02-04 04:47:58,038 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:47:58,038 	Gloss Alignment :	         
2024-02-04 04:47:58,039 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:47:58,040 	Text Reference  :	have been   involved in a huge controversy in  connection to real estate developer amrapali group        since   last 7   years  
2024-02-04 04:47:58,041 	Text Hypothesis :	the  tagged dhoni    in * the  posts       and appealed   to **** ****** him       to       disassociate himself from the builder
2024-02-04 04:47:58,041 	Text Alignment  :	S    S      S           D S    S           S   S             D    D      S         S        S            S       S    S   S      
2024-02-04 04:47:58,041 ========================================================================================================================
2024-02-04 04:47:58,041 Logging Sequence: 148_239.00
2024-02-04 04:47:58,041 	Gloss Reference :	A B+C+D+E
2024-02-04 04:47:58,041 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:47:58,041 	Gloss Alignment :	         
2024-02-04 04:47:58,041 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:47:58,043 	Text Reference  :	the     ground staff  were very happy  and  thanked the bowler for  his     kind gesture
2024-02-04 04:47:58,043 	Text Hypothesis :	however when   sharma lost his  wicket what a       sri lanka  were shocked and  this   
2024-02-04 04:47:58,043 	Text Alignment  :	S       S      S      S    S    S      S    S       S   S      S    S       S    S      
2024-02-04 04:47:58,043 ========================================================================================================================
2024-02-04 04:47:58,043 Logging Sequence: 165_8.00
2024-02-04 04:47:58,043 	Gloss Reference :	A B+C+D+E
2024-02-04 04:47:58,043 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:47:58,043 	Gloss Alignment :	         
2024-02-04 04:47:58,044 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:47:58,045 	Text Reference  :	** ** *** ***** ** *** ****** however many        don't believe in it   it       varies among people 
2024-02-04 04:47:58,045 	Text Hypothesis :	it is not known as the middle east    respiratory and   neeraj  he will continue to     be    amazing
2024-02-04 04:47:58,045 	Text Alignment  :	I  I  I   I     I  I   I      S       S           S     S       S  S    S        S      S     S      
2024-02-04 04:47:58,045 ========================================================================================================================
2024-02-04 04:47:58,045 Logging Sequence: 93_93.00
2024-02-04 04:47:58,045 	Gloss Reference :	A B+C+D+E
2024-02-04 04:47:58,046 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:47:58,046 	Gloss Alignment :	         
2024-02-04 04:47:58,046 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:47:58,046 	Text Reference  :	**** ***** rooney was    at   the ****** club   as    well   
2024-02-04 04:47:58,046 	Text Hypothesis :	they would be     played from the points during their matches
2024-02-04 04:47:58,047 	Text Alignment  :	I    I     S      S      S        I      S      S     S      
2024-02-04 04:47:58,047 ========================================================================================================================
2024-02-04 04:47:58,047 Logging Sequence: 96_129.00
2024-02-04 04:47:58,047 	Gloss Reference :	A B+C+D+E
2024-02-04 04:47:58,047 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:47:58,047 	Gloss Alignment :	         
2024-02-04 04:47:58,047 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:47:58,048 	Text Reference  :	** ***** **** *** **** *** **** **** viewers were very stressed
2024-02-04 04:47:58,048 	Text Hypothesis :	we don't know who will win will have to      wait and  watch   
2024-02-04 04:47:58,048 	Text Alignment  :	I  I     I    I   I    I   I    I    S       S    S    S       
2024-02-04 04:47:58,048 ========================================================================================================================
2024-02-04 04:47:59,656 Epoch 316: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.09 
2024-02-04 04:47:59,657 EPOCH 317
2024-02-04 04:48:03,733 [Epoch: 317 Step: 00042100] Batch Recognition Loss:   0.000174 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.016752 => Txt Tokens per Sec:     3968 || Lr: 0.000050
2024-02-04 04:48:07,248 Epoch 317: Total Training Recognition Loss 0.04  Total Training Translation Loss 7.04 
2024-02-04 04:48:07,249 EPOCH 318
2024-02-04 04:48:09,625 [Epoch: 318 Step: 00042200] Batch Recognition Loss:   0.000190 => Gls Tokens per Sec:     1314 || Batch Translation Loss:   0.015479 => Txt Tokens per Sec:     3812 || Lr: 0.000050
2024-02-04 04:48:14,877 Epoch 318: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.17 
2024-02-04 04:48:14,877 EPOCH 319
2024-02-04 04:48:15,159 [Epoch: 319 Step: 00042300] Batch Recognition Loss:   0.000223 => Gls Tokens per Sec:     1713 || Batch Translation Loss:   0.031342 => Txt Tokens per Sec:     4764 || Lr: 0.000050
2024-02-04 04:48:20,231 [Epoch: 319 Step: 00042400] Batch Recognition Loss:   0.000162 => Gls Tokens per Sec:     1578 || Batch Translation Loss:   0.013397 => Txt Tokens per Sec:     4327 || Lr: 0.000050
2024-02-04 04:48:21,952 Epoch 319: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.52 
2024-02-04 04:48:21,953 EPOCH 320
2024-02-04 04:48:25,895 [Epoch: 320 Step: 00042500] Batch Recognition Loss:   0.000147 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.016936 => Txt Tokens per Sec:     4157 || Lr: 0.000050
2024-02-04 04:48:29,350 Epoch 320: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.15 
2024-02-04 04:48:29,351 EPOCH 321
2024-02-04 04:48:31,719 [Epoch: 321 Step: 00042600] Batch Recognition Loss:   0.000204 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   0.018546 => Txt Tokens per Sec:     3810 || Lr: 0.000050
2024-02-04 04:48:36,830 Epoch 321: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.58 
2024-02-04 04:48:36,831 EPOCH 322
2024-02-04 04:48:37,271 [Epoch: 322 Step: 00042700] Batch Recognition Loss:   0.000265 => Gls Tokens per Sec:     1276 || Batch Translation Loss:   0.034023 => Txt Tokens per Sec:     3157 || Lr: 0.000050
2024-02-04 04:48:42,774 [Epoch: 322 Step: 00042800] Batch Recognition Loss:   0.000273 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.018909 => Txt Tokens per Sec:     4071 || Lr: 0.000050
2024-02-04 04:48:44,152 Epoch 322: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.45 
2024-02-04 04:48:44,152 EPOCH 323
2024-02-04 04:48:48,466 [Epoch: 323 Step: 00042900] Batch Recognition Loss:   0.000401 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.013921 => Txt Tokens per Sec:     3845 || Lr: 0.000050
2024-02-04 04:48:51,962 Epoch 323: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.66 
2024-02-04 04:48:51,963 EPOCH 324
2024-02-04 04:48:54,103 [Epoch: 324 Step: 00043000] Batch Recognition Loss:   0.000204 => Gls Tokens per Sec:     1533 || Batch Translation Loss:   0.018603 => Txt Tokens per Sec:     4276 || Lr: 0.000050
2024-02-04 04:48:59,476 Epoch 324: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.86 
2024-02-04 04:48:59,477 EPOCH 325
2024-02-04 04:48:59,878 [Epoch: 325 Step: 00043100] Batch Recognition Loss:   0.000149 => Gls Tokens per Sec:     1600 || Batch Translation Loss:   0.024268 => Txt Tokens per Sec:     3937 || Lr: 0.000050
2024-02-04 04:49:05,194 [Epoch: 325 Step: 00043200] Batch Recognition Loss:   0.000203 => Gls Tokens per Sec:     1505 || Batch Translation Loss:   0.017591 => Txt Tokens per Sec:     4200 || Lr: 0.000050
2024-02-04 04:49:06,763 Epoch 325: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.01 
2024-02-04 04:49:06,763 EPOCH 326
2024-02-04 04:49:10,684 [Epoch: 326 Step: 00043300] Batch Recognition Loss:   0.000245 => Gls Tokens per Sec:     1531 || Batch Translation Loss:   0.018178 => Txt Tokens per Sec:     4207 || Lr: 0.000050
2024-02-04 04:49:14,319 Epoch 326: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.80 
2024-02-04 04:49:14,319 EPOCH 327
2024-02-04 04:49:16,565 [Epoch: 327 Step: 00043400] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1497 || Batch Translation Loss:   0.034853 => Txt Tokens per Sec:     4217 || Lr: 0.000050
2024-02-04 04:49:22,026 Epoch 327: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.00 
2024-02-04 04:49:22,026 EPOCH 328
2024-02-04 04:49:22,552 [Epoch: 328 Step: 00043500] Batch Recognition Loss:   0.000296 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.020671 => Txt Tokens per Sec:     3400 || Lr: 0.000050
2024-02-04 04:49:28,032 [Epoch: 328 Step: 00043600] Batch Recognition Loss:   0.000213 => Gls Tokens per Sec:     1460 || Batch Translation Loss:   0.013131 => Txt Tokens per Sec:     4046 || Lr: 0.000050
2024-02-04 04:49:29,471 Epoch 328: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.45 
2024-02-04 04:49:29,472 EPOCH 329
2024-02-04 04:49:33,794 [Epoch: 329 Step: 00043700] Batch Recognition Loss:   0.000180 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.025839 => Txt Tokens per Sec:     3877 || Lr: 0.000050
2024-02-04 04:49:37,359 Epoch 329: Total Training Recognition Loss 0.03  Total Training Translation Loss 9.04 
2024-02-04 04:49:37,360 EPOCH 330
2024-02-04 04:49:39,986 [Epoch: 330 Step: 00043800] Batch Recognition Loss:   0.000187 => Gls Tokens per Sec:     1310 || Batch Translation Loss:   0.033448 => Txt Tokens per Sec:     3730 || Lr: 0.000050
2024-02-04 04:49:45,062 Epoch 330: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.51 
2024-02-04 04:49:45,062 EPOCH 331
2024-02-04 04:49:45,566 [Epoch: 331 Step: 00043900] Batch Recognition Loss:   0.000217 => Gls Tokens per Sec:     1594 || Batch Translation Loss:   0.007636 => Txt Tokens per Sec:     4460 || Lr: 0.000050
2024-02-04 04:49:51,125 [Epoch: 331 Step: 00044000] Batch Recognition Loss:   0.000205 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.022176 => Txt Tokens per Sec:     4019 || Lr: 0.000050
2024-02-04 04:50:01,756 Validation result at epoch 331, step    44000: duration: 10.6307s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00213	Translation Loss: 95081.02344	PPL: 13558.41797
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.62	(BLEU-1: 10.64,	BLEU-2: 3.08,	BLEU-3: 1.19,	BLEU-4: 0.62)
	CHRF 16.62	ROUGE 9.22
2024-02-04 04:50:01,757 Logging Recognition and Translation Outputs
2024-02-04 04:50:01,757 ========================================================================================================================
2024-02-04 04:50:01,758 Logging Sequence: 117_29.00
2024-02-04 04:50:01,758 	Gloss Reference :	A B+C+D+E
2024-02-04 04:50:01,758 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:50:01,758 	Gloss Alignment :	         
2024-02-04 04:50:01,758 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:50:01,759 	Text Reference  :	however england was unable to  reach the target they    were all out   lost by  66     runs  
2024-02-04 04:50:01,760 	Text Hypothesis :	******* ******* *** when   csk lost  the match  because of   the first time and hardik pandya
2024-02-04 04:50:01,760 	Text Alignment  :	D       D       D   S      S   S         S      S       S    S   S     S    S   S      S     
2024-02-04 04:50:01,760 ========================================================================================================================
2024-02-04 04:50:01,760 Logging Sequence: 84_176.00
2024-02-04 04:50:01,760 	Gloss Reference :	A B+C+D+E
2024-02-04 04:50:01,760 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:50:01,760 	Gloss Alignment :	         
2024-02-04 04:50:01,761 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:50:01,762 	Text Reference  :	******** ** germany's nancy faeser who   attended the ***** **** ******* game    in   doha   against japan said
2024-02-04 04:50:01,762 	Text Hypothesis :	shocking to won       the   silver medal in       the world deaf cricket matches were unable to      tell  you 
2024-02-04 04:50:01,762 	Text Alignment  :	I        I  S         S     S      S     S            I     I    I       S       S    S      S       S     S   
2024-02-04 04:50:01,762 ========================================================================================================================
2024-02-04 04:50:01,762 Logging Sequence: 172_98.00
2024-02-04 04:50:01,762 	Gloss Reference :	A B+C+D+E
2024-02-04 04:50:01,763 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:50:01,763 	Gloss Alignment :	         
2024-02-04 04:50:01,763 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:50:01,764 	Text Reference  :	***** since 700   pm     it       kept    raining the intensity plunged around 915 pm  
2024-02-04 04:50:01,764 	Text Hypothesis :	while the   match starts anywhere between 730     and sri       lanka   were   in  time
2024-02-04 04:50:01,764 	Text Alignment  :	I     S     S     S      S        S       S       S   S         S       S      S   S   
2024-02-04 04:50:01,764 ========================================================================================================================
2024-02-04 04:50:01,764 Logging Sequence: 135_92.00
2024-02-04 04:50:01,764 	Gloss Reference :	A B+C+D+E
2024-02-04 04:50:01,765 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:50:01,765 	Gloss Alignment :	         
2024-02-04 04:50:01,765 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:50:01,766 	Text Reference  :	she   wrote     that half had   already been    raised by  the family's online fundraiser
2024-02-04 04:50:01,766 	Text Hypothesis :	these countries lost the  match in      javelin throw  was the ******** tokyo  olympics  
2024-02-04 04:50:01,766 	Text Alignment  :	S     S         S    S    S     S       S       S      S       D        S      S         
2024-02-04 04:50:01,766 ========================================================================================================================
2024-02-04 04:50:01,766 Logging Sequence: 180_332.00
2024-02-04 04:50:01,766 	Gloss Reference :	A B+C+D+E
2024-02-04 04:50:01,767 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:50:01,767 	Gloss Alignment :	         
2024-02-04 04:50:01,767 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:50:01,768 	Text Reference  :	did       i  eat     roti made   of shilajit that  i       got  energy to assault so many  girls  
2024-02-04 04:50:01,768 	Text Hypothesis :	according to rumours the  police he is       seven matches that she    be held    in seven matches
2024-02-04 04:50:01,768 	Text Alignment  :	S         S  S       S    S      S  S        S     S       S    S      S  S       S  S     S      
2024-02-04 04:50:01,769 ========================================================================================================================
2024-02-04 04:50:02,983 Epoch 331: Total Training Recognition Loss 0.04  Total Training Translation Loss 5.62 
2024-02-04 04:50:02,984 EPOCH 332
2024-02-04 04:50:07,492 [Epoch: 332 Step: 00044100] Batch Recognition Loss:   0.000137 => Gls Tokens per Sec:     1366 || Batch Translation Loss:   0.034698 => Txt Tokens per Sec:     3783 || Lr: 0.000050
2024-02-04 04:50:10,690 Epoch 332: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.43 
2024-02-04 04:50:10,690 EPOCH 333
2024-02-04 04:50:13,019 [Epoch: 333 Step: 00044200] Batch Recognition Loss:   0.000135 => Gls Tokens per Sec:     1512 || Batch Translation Loss:   0.015719 => Txt Tokens per Sec:     4335 || Lr: 0.000050
2024-02-04 04:50:18,262 Epoch 333: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.39 
2024-02-04 04:50:18,263 EPOCH 334
2024-02-04 04:50:18,766 [Epoch: 334 Step: 00044300] Batch Recognition Loss:   0.000150 => Gls Tokens per Sec:     1753 || Batch Translation Loss:   0.015553 => Txt Tokens per Sec:     4502 || Lr: 0.000050
2024-02-04 04:50:24,148 [Epoch: 334 Step: 00044400] Batch Recognition Loss:   0.000113 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.007963 => Txt Tokens per Sec:     4168 || Lr: 0.000050
2024-02-04 04:50:25,416 Epoch 334: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.46 
2024-02-04 04:50:25,416 EPOCH 335
2024-02-04 04:50:29,758 [Epoch: 335 Step: 00044500] Batch Recognition Loss:   0.000162 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.013714 => Txt Tokens per Sec:     3968 || Lr: 0.000050
2024-02-04 04:50:33,155 Epoch 335: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.34 
2024-02-04 04:50:33,155 EPOCH 336
2024-02-04 04:50:35,743 [Epoch: 336 Step: 00044600] Batch Recognition Loss:   0.000199 => Gls Tokens per Sec:     1392 || Batch Translation Loss:   0.027275 => Txt Tokens per Sec:     3933 || Lr: 0.000050
2024-02-04 04:50:40,621 Epoch 336: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.69 
2024-02-04 04:50:40,621 EPOCH 337
2024-02-04 04:50:41,254 [Epoch: 337 Step: 00044700] Batch Recognition Loss:   0.000276 => Gls Tokens per Sec:     1519 || Batch Translation Loss:   0.025802 => Txt Tokens per Sec:     4391 || Lr: 0.000050
2024-02-04 04:50:46,810 [Epoch: 337 Step: 00044800] Batch Recognition Loss:   0.000134 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.089013 => Txt Tokens per Sec:     3945 || Lr: 0.000050
2024-02-04 04:50:48,001 Epoch 337: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.67 
2024-02-04 04:50:48,001 EPOCH 338
2024-02-04 04:50:52,444 [Epoch: 338 Step: 00044900] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.024677 => Txt Tokens per Sec:     4000 || Lr: 0.000050
2024-02-04 04:50:55,416 Epoch 338: Total Training Recognition Loss 0.04  Total Training Translation Loss 5.70 
2024-02-04 04:50:55,417 EPOCH 339
2024-02-04 04:50:57,874 [Epoch: 339 Step: 00045000] Batch Recognition Loss:   0.000200 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.012817 => Txt Tokens per Sec:     4189 || Lr: 0.000050
2024-02-04 04:51:02,969 Epoch 339: Total Training Recognition Loss 0.04  Total Training Translation Loss 6.40 
2024-02-04 04:51:02,969 EPOCH 340
2024-02-04 04:51:03,676 [Epoch: 340 Step: 00045100] Batch Recognition Loss:   0.000373 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.030985 => Txt Tokens per Sec:     4434 || Lr: 0.000050
2024-02-04 04:51:09,040 [Epoch: 340 Step: 00045200] Batch Recognition Loss:   0.000227 => Gls Tokens per Sec:     1492 || Batch Translation Loss:   0.014996 => Txt Tokens per Sec:     4068 || Lr: 0.000050
2024-02-04 04:51:10,268 Epoch 340: Total Training Recognition Loss 0.05  Total Training Translation Loss 5.11 
2024-02-04 04:51:10,268 EPOCH 341
2024-02-04 04:51:14,262 [Epoch: 341 Step: 00045300] Batch Recognition Loss:   0.000222 => Gls Tokens per Sec:     1603 || Batch Translation Loss:   0.018815 => Txt Tokens per Sec:     4375 || Lr: 0.000050
2024-02-04 04:51:17,547 Epoch 341: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.48 
2024-02-04 04:51:17,548 EPOCH 342
2024-02-04 04:51:20,285 [Epoch: 342 Step: 00045400] Batch Recognition Loss:   0.000254 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.071987 => Txt Tokens per Sec:     3754 || Lr: 0.000050
2024-02-04 04:51:25,446 Epoch 342: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.73 
2024-02-04 04:51:25,447 EPOCH 343
2024-02-04 04:51:26,187 [Epoch: 343 Step: 00045500] Batch Recognition Loss:   0.000243 => Gls Tokens per Sec:     1516 || Batch Translation Loss:   0.013136 => Txt Tokens per Sec:     4119 || Lr: 0.000050
2024-02-04 04:51:31,745 [Epoch: 343 Step: 00045600] Batch Recognition Loss:   0.000150 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.021744 => Txt Tokens per Sec:     3975 || Lr: 0.000050
2024-02-04 04:51:32,930 Epoch 343: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.72 
2024-02-04 04:51:32,931 EPOCH 344
2024-02-04 04:51:37,584 [Epoch: 344 Step: 00045700] Batch Recognition Loss:   0.000147 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.013214 => Txt Tokens per Sec:     3874 || Lr: 0.000050
2024-02-04 04:51:40,661 Epoch 344: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.50 
2024-02-04 04:51:40,661 EPOCH 345
2024-02-04 04:51:43,026 [Epoch: 345 Step: 00045800] Batch Recognition Loss:   0.000171 => Gls Tokens per Sec:     1624 || Batch Translation Loss:   0.028949 => Txt Tokens per Sec:     4558 || Lr: 0.000050
2024-02-04 04:51:47,728 Epoch 345: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.08 
2024-02-04 04:51:47,729 EPOCH 346
2024-02-04 04:51:48,600 [Epoch: 346 Step: 00045900] Batch Recognition Loss:   0.000161 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.027100 => Txt Tokens per Sec:     4299 || Lr: 0.000050
2024-02-04 04:51:53,965 [Epoch: 346 Step: 00046000] Batch Recognition Loss:   0.000354 => Gls Tokens per Sec:     1489 || Batch Translation Loss:   0.014049 => Txt Tokens per Sec:     4055 || Lr: 0.000050
2024-02-04 04:52:04,992 Validation result at epoch 346, step    46000: duration: 11.0266s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00204	Translation Loss: 92997.01562	PPL: 11006.22461
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.72	(BLEU-1: 10.48,	BLEU-2: 2.91,	BLEU-3: 1.23,	BLEU-4: 0.72)
	CHRF 16.81	ROUGE 9.02
2024-02-04 04:52:04,994 Logging Recognition and Translation Outputs
2024-02-04 04:52:04,994 ========================================================================================================================
2024-02-04 04:52:04,994 Logging Sequence: 126_121.00
2024-02-04 04:52:04,994 	Gloss Reference :	A B+C+D+E
2024-02-04 04:52:04,994 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:52:04,994 	Gloss Alignment :	         
2024-02-04 04:52:04,995 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:52:04,995 	Text Reference  :	everyone was very happy by his victory
2024-02-04 04:52:04,995 	Text Hypothesis :	why      was **** ***** ** *** then   
2024-02-04 04:52:04,995 	Text Alignment  :	S            D    D     D  D   S      
2024-02-04 04:52:04,995 ========================================================================================================================
2024-02-04 04:52:04,995 Logging Sequence: 73_79.00
2024-02-04 04:52:04,996 	Gloss Reference :	A B+C+D+E
2024-02-04 04:52:04,996 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:52:04,996 	Gloss Alignment :	         
2024-02-04 04:52:04,996 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:52:04,997 	Text Reference  :	raina resturant has  food  from the rich spices of   north india to      the aromatic curries of south     india
2024-02-04 04:52:04,997 	Text Hypothesis :	the   pm        modi along with the **** ****** menu is    raita whereas the ******** ******* ** costliest dish 
2024-02-04 04:52:04,998 	Text Alignment  :	S     S         S    S     S        D    D      S    S     S     S           D        D       D  S         S    
2024-02-04 04:52:04,998 ========================================================================================================================
2024-02-04 04:52:04,998 Logging Sequence: 95_152.00
2024-02-04 04:52:04,998 	Gloss Reference :	A B+C+D+E
2024-02-04 04:52:04,998 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:52:04,998 	Gloss Alignment :	         
2024-02-04 04:52:04,998 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:52:04,999 	Text Reference  :	******* *** *** **** *** ***** how strange
2024-02-04 04:52:04,999 	Text Hypothesis :	england won the toss and chose to  bowl   
2024-02-04 04:52:04,999 	Text Alignment  :	I       I   I   I    I   I     S   S      
2024-02-04 04:52:04,999 ========================================================================================================================
2024-02-04 04:52:04,999 Logging Sequence: 135_39.00
2024-02-04 04:52:04,999 	Gloss Reference :	A B+C+D+E
2024-02-04 04:52:04,999 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:52:04,999 	Gloss Alignment :	         
2024-02-04 04:52:05,000 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:52:05,000 	Text Reference  :	who   needs   to  travel   from poland to stanford university in ******* california
2024-02-04 04:52:05,001 	Text Hypothesis :	after reading the training and  take   a  silver   medal      in javelin throw     
2024-02-04 04:52:05,001 	Text Alignment  :	S     S       S   S        S    S      S  S        S             I       S         
2024-02-04 04:52:05,001 ========================================================================================================================
2024-02-04 04:52:05,001 Logging Sequence: 87_2.00
2024-02-04 04:52:05,001 	Gloss Reference :	A B+C+D+E
2024-02-04 04:52:05,001 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:52:05,001 	Gloss Alignment :	         
2024-02-04 04:52:05,002 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:52:05,003 	Text Reference  :	cricketer gautam gambhir's jealousy against ms  dhoni   and   virat kohli   has been     increasing day by       day     
2024-02-04 04:52:05,003 	Text Hypothesis :	********* ****** ********* ******** ******* the supreme court then  ordered a   forensic audit      of  amrapali builders
2024-02-04 04:52:05,003 	Text Alignment  :	D         D      D         D        D       S   S       S     S     S       S   S        S          S   S        S       
2024-02-04 04:52:05,003 ========================================================================================================================
2024-02-04 04:52:06,011 Epoch 346: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.28 
2024-02-04 04:52:06,011 EPOCH 347
2024-02-04 04:52:10,538 [Epoch: 347 Step: 00046100] Batch Recognition Loss:   0.000133 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.055475 => Txt Tokens per Sec:     4014 || Lr: 0.000050
2024-02-04 04:52:13,656 Epoch 347: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.06 
2024-02-04 04:52:13,657 EPOCH 348
2024-02-04 04:52:16,329 [Epoch: 348 Step: 00046200] Batch Recognition Loss:   0.000189 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.022396 => Txt Tokens per Sec:     4172 || Lr: 0.000050
2024-02-04 04:52:21,217 Epoch 348: Total Training Recognition Loss 0.03  Total Training Translation Loss 2.80 
2024-02-04 04:52:21,217 EPOCH 349
2024-02-04 04:52:22,173 [Epoch: 349 Step: 00046300] Batch Recognition Loss:   0.000200 => Gls Tokens per Sec:     1340 || Batch Translation Loss:   0.015190 => Txt Tokens per Sec:     3693 || Lr: 0.000050
2024-02-04 04:52:27,672 [Epoch: 349 Step: 00046400] Batch Recognition Loss:   0.000154 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.017428 => Txt Tokens per Sec:     4030 || Lr: 0.000050
2024-02-04 04:52:28,699 Epoch 349: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.37 
2024-02-04 04:52:28,700 EPOCH 350
2024-02-04 04:52:33,136 [Epoch: 350 Step: 00046500] Batch Recognition Loss:   0.000195 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.038326 => Txt Tokens per Sec:     4102 || Lr: 0.000050
2024-02-04 04:52:36,234 Epoch 350: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.63 
2024-02-04 04:52:36,235 EPOCH 351
2024-02-04 04:52:39,313 [Epoch: 351 Step: 00046600] Batch Recognition Loss:   0.000208 => Gls Tokens per Sec:     1301 || Batch Translation Loss:   0.036411 => Txt Tokens per Sec:     3597 || Lr: 0.000050
2024-02-04 04:52:44,108 Epoch 351: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.79 
2024-02-04 04:52:44,109 EPOCH 352
2024-02-04 04:52:44,911 [Epoch: 352 Step: 00046700] Batch Recognition Loss:   0.000112 => Gls Tokens per Sec:     1701 || Batch Translation Loss:   0.020470 => Txt Tokens per Sec:     4540 || Lr: 0.000050
2024-02-04 04:52:50,573 [Epoch: 352 Step: 00046800] Batch Recognition Loss:   0.000435 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.027189 => Txt Tokens per Sec:     3958 || Lr: 0.000050
2024-02-04 04:52:51,408 Epoch 352: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.14 
2024-02-04 04:52:51,409 EPOCH 353
2024-02-04 04:52:55,860 [Epoch: 353 Step: 00046900] Batch Recognition Loss:   0.000306 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.021521 => Txt Tokens per Sec:     4240 || Lr: 0.000050
2024-02-04 04:52:58,644 Epoch 353: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.03 
2024-02-04 04:52:58,645 EPOCH 354
2024-02-04 04:53:01,467 [Epoch: 354 Step: 00047000] Batch Recognition Loss:   0.000144 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.015188 => Txt Tokens per Sec:     4101 || Lr: 0.000050
2024-02-04 04:53:06,240 Epoch 354: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.11 
2024-02-04 04:53:06,241 EPOCH 355
2024-02-04 04:53:07,199 [Epoch: 355 Step: 00047100] Batch Recognition Loss:   0.000233 => Gls Tokens per Sec:     1506 || Batch Translation Loss:   0.013725 => Txt Tokens per Sec:     4153 || Lr: 0.000050
2024-02-04 04:53:12,793 [Epoch: 355 Step: 00047200] Batch Recognition Loss:   0.000117 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.016391 => Txt Tokens per Sec:     3973 || Lr: 0.000050
2024-02-04 04:53:13,679 Epoch 355: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.29 
2024-02-04 04:53:13,679 EPOCH 356
2024-02-04 04:53:18,372 [Epoch: 356 Step: 00047300] Batch Recognition Loss:   0.000156 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.034322 => Txt Tokens per Sec:     4071 || Lr: 0.000050
2024-02-04 04:53:21,155 Epoch 356: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.41 
2024-02-04 04:53:21,155 EPOCH 357
2024-02-04 04:53:24,225 [Epoch: 357 Step: 00047400] Batch Recognition Loss:   0.000198 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.023463 => Txt Tokens per Sec:     3874 || Lr: 0.000050
2024-02-04 04:53:28,968 Epoch 357: Total Training Recognition Loss 0.04  Total Training Translation Loss 11.92 
2024-02-04 04:53:28,969 EPOCH 358
2024-02-04 04:53:30,176 [Epoch: 358 Step: 00047500] Batch Recognition Loss:   0.000364 => Gls Tokens per Sec:     1261 || Batch Translation Loss:   0.063485 => Txt Tokens per Sec:     3667 || Lr: 0.000050
2024-02-04 04:53:35,736 [Epoch: 358 Step: 00047600] Batch Recognition Loss:   0.000313 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.070934 => Txt Tokens per Sec:     3969 || Lr: 0.000050
2024-02-04 04:53:36,511 Epoch 358: Total Training Recognition Loss 0.04  Total Training Translation Loss 8.85 
2024-02-04 04:53:36,512 EPOCH 359
2024-02-04 04:53:41,403 [Epoch: 359 Step: 00047700] Batch Recognition Loss:   0.000241 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.038916 => Txt Tokens per Sec:     3839 || Lr: 0.000050
2024-02-04 04:53:44,115 Epoch 359: Total Training Recognition Loss 0.04  Total Training Translation Loss 7.86 
2024-02-04 04:53:44,116 EPOCH 360
2024-02-04 04:53:47,108 [Epoch: 360 Step: 00047800] Batch Recognition Loss:   0.000202 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   0.011647 => Txt Tokens per Sec:     3971 || Lr: 0.000050
2024-02-04 04:53:51,862 Epoch 360: Total Training Recognition Loss 0.04  Total Training Translation Loss 7.81 
2024-02-04 04:53:51,863 EPOCH 361
2024-02-04 04:53:52,929 [Epoch: 361 Step: 00047900] Batch Recognition Loss:   0.000491 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   0.074171 => Txt Tokens per Sec:     4364 || Lr: 0.000050
2024-02-04 04:53:58,522 [Epoch: 361 Step: 00048000] Batch Recognition Loss:   0.000393 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.043134 => Txt Tokens per Sec:     3927 || Lr: 0.000050
2024-02-04 04:54:09,568 Validation result at epoch 361, step    48000: duration: 11.0457s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00271	Translation Loss: 93026.85156	PPL: 11039.13770
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.86	(BLEU-1: 10.95,	BLEU-2: 3.38,	BLEU-3: 1.52,	BLEU-4: 0.86)
	CHRF 17.14	ROUGE 9.39
2024-02-04 04:54:09,569 Logging Recognition and Translation Outputs
2024-02-04 04:54:09,569 ========================================================================================================================
2024-02-04 04:54:09,570 Logging Sequence: 88_159.00
2024-02-04 04:54:09,570 	Gloss Reference :	A B+C+D+E
2024-02-04 04:54:09,570 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:54:09,570 	Gloss Alignment :	         
2024-02-04 04:54:09,570 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:54:09,571 	Text Reference  :	however he  often  comes to        the **** ***** town to  meet his relatives
2024-02-04 04:54:09,572 	Text Hypothesis :	however the police never announced the fifa world cup  for held in  qatar    
2024-02-04 04:54:09,572 	Text Alignment  :	        S   S      S     S             I    I     S    S   S    S   S        
2024-02-04 04:54:09,572 ========================================================================================================================
2024-02-04 04:54:09,572 Logging Sequence: 180_53.00
2024-02-04 04:54:09,572 	Gloss Reference :	A B+C+D+E
2024-02-04 04:54:09,572 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:54:09,572 	Gloss Alignment :	         
2024-02-04 04:54:09,572 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:54:09,573 	Text Reference  :	the      protest is  against singh   again     
2024-02-04 04:54:09,573 	Text Hypothesis :	everyone usually the supreme court's directions
2024-02-04 04:54:09,573 	Text Alignment  :	S        S       S   S       S       S         
2024-02-04 04:54:09,573 ========================================================================================================================
2024-02-04 04:54:09,573 Logging Sequence: 163_30.00
2024-02-04 04:54:09,573 	Gloss Reference :	A B+C+D+E
2024-02-04 04:54:09,574 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:54:09,574 	Gloss Alignment :	         
2024-02-04 04:54:09,574 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:54:09,574 	Text Reference  :	**** they   never permitted anyone to   reveal her  face
2024-02-04 04:54:09,574 	Text Hypothesis :	many former and   anushka   sharma have been   very cute
2024-02-04 04:54:09,575 	Text Alignment  :	I    S      S     S         S      S    S      S    S   
2024-02-04 04:54:09,575 ========================================================================================================================
2024-02-04 04:54:09,575 Logging Sequence: 51_110.00
2024-02-04 04:54:09,575 	Gloss Reference :	A B+C+D+E
2024-02-04 04:54:09,575 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:54:09,575 	Gloss Alignment :	         
2024-02-04 04:54:09,575 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:54:09,576 	Text Reference  :	**** ** * *** ***** *** **** ** the     aussies were very  happy with their victory
2024-02-04 04:54:09,576 	Text Hypothesis :	this is a t20 world cup will be captain for     the  first time  in   the   world  
2024-02-04 04:54:09,576 	Text Alignment  :	I    I  I I   I     I   I    I  S       S       S    S     S     S    S     S      
2024-02-04 04:54:09,577 ========================================================================================================================
2024-02-04 04:54:09,577 Logging Sequence: 70_249.00
2024-02-04 04:54:09,577 	Gloss Reference :	A B+C+D+E
2024-02-04 04:54:09,577 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:54:09,577 	Gloss Alignment :	         
2024-02-04 04:54:09,577 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:54:09,578 	Text Reference  :	***** ** ******* ** ***** ** ** **** ******** have a     look at *** this video 
2024-02-04 04:54:09,578 	Text Hypothesis :	there is nothing to worry he is fine 'eriksen is   awake and  at the next season
2024-02-04 04:54:09,578 	Text Alignment  :	I     I  I       I  I     I  I  I    I        S    S     S       I   S    S     
2024-02-04 04:54:09,578 ========================================================================================================================
2024-02-04 04:54:10,316 Epoch 361: Total Training Recognition Loss 0.04  Total Training Translation Loss 6.61 
2024-02-04 04:54:10,316 EPOCH 362
2024-02-04 04:54:15,070 [Epoch: 362 Step: 00048100] Batch Recognition Loss:   0.000207 => Gls Tokens per Sec:     1465 || Batch Translation Loss:   0.029595 => Txt Tokens per Sec:     4056 || Lr: 0.000050
2024-02-04 04:54:17,963 Epoch 362: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.00 
2024-02-04 04:54:17,963 EPOCH 363
2024-02-04 04:54:20,889 [Epoch: 363 Step: 00048200] Batch Recognition Loss:   0.000079 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.020405 => Txt Tokens per Sec:     4053 || Lr: 0.000050
2024-02-04 04:54:25,689 Epoch 363: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.33 
2024-02-04 04:54:25,689 EPOCH 364
2024-02-04 04:54:27,010 [Epoch: 364 Step: 00048300] Batch Recognition Loss:   0.000170 => Gls Tokens per Sec:     1273 || Batch Translation Loss:   0.027855 => Txt Tokens per Sec:     3509 || Lr: 0.000050
2024-02-04 04:54:32,696 [Epoch: 364 Step: 00048400] Batch Recognition Loss:   0.000185 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.022263 => Txt Tokens per Sec:     3874 || Lr: 0.000050
2024-02-04 04:54:33,435 Epoch 364: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.65 
2024-02-04 04:54:33,435 EPOCH 365
2024-02-04 04:54:38,264 [Epoch: 365 Step: 00048500] Batch Recognition Loss:   0.000168 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.145362 => Txt Tokens per Sec:     4079 || Lr: 0.000050
2024-02-04 04:54:40,928 Epoch 365: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.64 
2024-02-04 04:54:40,928 EPOCH 366
2024-02-04 04:54:44,005 [Epoch: 366 Step: 00048600] Batch Recognition Loss:   0.000250 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.016106 => Txt Tokens per Sec:     3834 || Lr: 0.000050
2024-02-04 04:54:48,569 Epoch 366: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.09 
2024-02-04 04:54:48,569 EPOCH 367
2024-02-04 04:54:49,833 [Epoch: 367 Step: 00048700] Batch Recognition Loss:   0.000199 => Gls Tokens per Sec:     1394 || Batch Translation Loss:   0.009800 => Txt Tokens per Sec:     4010 || Lr: 0.000050
2024-02-04 04:54:55,173 [Epoch: 367 Step: 00048800] Batch Recognition Loss:   0.000167 => Gls Tokens per Sec:     1497 || Batch Translation Loss:   0.018230 => Txt Tokens per Sec:     4110 || Lr: 0.000050
2024-02-04 04:54:55,884 Epoch 367: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.29 
2024-02-04 04:54:55,885 EPOCH 368
2024-02-04 04:55:00,680 [Epoch: 368 Step: 00048900] Batch Recognition Loss:   0.000238 => Gls Tokens per Sec:     1485 || Batch Translation Loss:   0.049312 => Txt Tokens per Sec:     4072 || Lr: 0.000050
2024-02-04 04:55:03,420 Epoch 368: Total Training Recognition Loss 0.03  Total Training Translation Loss 2.85 
2024-02-04 04:55:03,421 EPOCH 369
2024-02-04 04:55:06,579 [Epoch: 369 Step: 00049000] Batch Recognition Loss:   0.000180 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.051676 => Txt Tokens per Sec:     4005 || Lr: 0.000050
2024-02-04 04:55:10,872 Epoch 369: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.33 
2024-02-04 04:55:10,873 EPOCH 370
2024-02-04 04:55:11,938 [Epoch: 370 Step: 00049100] Batch Recognition Loss:   0.000123 => Gls Tokens per Sec:     1728 || Batch Translation Loss:   0.014660 => Txt Tokens per Sec:     4683 || Lr: 0.000050
2024-02-04 04:55:16,708 [Epoch: 370 Step: 00049200] Batch Recognition Loss:   0.000132 => Gls Tokens per Sec:     1678 || Batch Translation Loss:   0.028362 => Txt Tokens per Sec:     4683 || Lr: 0.000050
2024-02-04 04:55:17,315 Epoch 370: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.98 
2024-02-04 04:55:17,316 EPOCH 371
2024-02-04 04:55:22,336 [Epoch: 371 Step: 00049300] Batch Recognition Loss:   0.000283 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.062465 => Txt Tokens per Sec:     4002 || Lr: 0.000050
2024-02-04 04:55:24,699 Epoch 371: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.02 
2024-02-04 04:55:24,699 EPOCH 372
2024-02-04 04:55:27,999 [Epoch: 372 Step: 00049400] Batch Recognition Loss:   0.000320 => Gls Tokens per Sec:     1382 || Batch Translation Loss:   0.029164 => Txt Tokens per Sec:     3712 || Lr: 0.000050
2024-02-04 04:55:32,503 Epoch 372: Total Training Recognition Loss 0.04  Total Training Translation Loss 11.51 
2024-02-04 04:55:32,504 EPOCH 373
2024-02-04 04:55:33,986 [Epoch: 373 Step: 00049500] Batch Recognition Loss:   0.000410 => Gls Tokens per Sec:     1296 || Batch Translation Loss:   0.048643 => Txt Tokens per Sec:     3618 || Lr: 0.000050
2024-02-04 04:55:39,581 [Epoch: 373 Step: 00049600] Batch Recognition Loss:   0.000340 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.037852 => Txt Tokens per Sec:     3992 || Lr: 0.000050
2024-02-04 04:55:40,109 Epoch 373: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.16 
2024-02-04 04:55:40,109 EPOCH 374
2024-02-04 04:55:44,692 [Epoch: 374 Step: 00049700] Batch Recognition Loss:   0.000206 => Gls Tokens per Sec:     1589 || Batch Translation Loss:   0.030338 => Txt Tokens per Sec:     4412 || Lr: 0.000050
2024-02-04 04:55:47,084 Epoch 374: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.44 
2024-02-04 04:55:47,085 EPOCH 375
2024-02-04 04:55:50,331 [Epoch: 375 Step: 00049800] Batch Recognition Loss:   0.000128 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.021955 => Txt Tokens per Sec:     3934 || Lr: 0.000050
2024-02-04 04:55:54,926 Epoch 375: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.62 
2024-02-04 04:55:54,927 EPOCH 376
2024-02-04 04:55:56,370 [Epoch: 376 Step: 00049900] Batch Recognition Loss:   0.000168 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.061809 => Txt Tokens per Sec:     3786 || Lr: 0.000050
2024-02-04 04:56:01,915 [Epoch: 376 Step: 00050000] Batch Recognition Loss:   0.000152 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.021000 => Txt Tokens per Sec:     3994 || Lr: 0.000050
2024-02-04 04:56:12,930 Validation result at epoch 376, step    50000: duration: 11.0142s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00215	Translation Loss: 92036.02344	PPL: 9997.09277
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.87	(BLEU-1: 11.20,	BLEU-2: 3.39,	BLEU-3: 1.46,	BLEU-4: 0.87)
	CHRF 16.92	ROUGE 9.52
2024-02-04 04:56:12,931 Logging Recognition and Translation Outputs
2024-02-04 04:56:12,931 ========================================================================================================================
2024-02-04 04:56:12,931 Logging Sequence: 59_58.00
2024-02-04 04:56:12,931 	Gloss Reference :	A B+C+D+E
2024-02-04 04:56:12,931 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:56:12,931 	Gloss Alignment :	         
2024-02-04 04:56:12,932 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:56:12,932 	Text Reference  :	to fix   the  damage they did     not       have a     lot  of   time
2024-02-04 04:56:12,933 	Text Hypothesis :	** isn't that such   a    strange statement how  could only here you 
2024-02-04 04:56:12,933 	Text Alignment  :	D  S     S    S      S    S       S         S    S     S    S    S   
2024-02-04 04:56:12,933 ========================================================================================================================
2024-02-04 04:56:12,933 Logging Sequence: 165_2.00
2024-02-04 04:56:12,933 	Gloss Reference :	A B+C+D+E
2024-02-04 04:56:12,933 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:56:12,933 	Gloss Alignment :	         
2024-02-04 04:56:12,933 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:56:12,934 	Text Reference  :	many people believe in superstitions and think it   brings good luck   and         bad luck  
2024-02-04 04:56:12,934 	Text Hypothesis :	**** ****** ******* ** ************* he  has   also become the  indian performance in  sports
2024-02-04 04:56:12,935 	Text Alignment  :	D    D      D       D  D             S   S     S    S      S    S      S           S   S     
2024-02-04 04:56:12,935 ========================================================================================================================
2024-02-04 04:56:12,935 Logging Sequence: 58_147.00
2024-02-04 04:56:12,935 	Gloss Reference :	A B+C+D+E
2024-02-04 04:56:12,935 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:56:12,935 	Gloss Alignment :	         
2024-02-04 04:56:12,935 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:56:12,936 	Text Reference  :	the women's cricket team grabbed gold by  beating sri    lanka in the finals what a historic win  
2024-02-04 04:56:12,936 	Text Hypothesis :	*** ******* ******* **** ******* who  won the     silver medal in the ****** **** * asian    games
2024-02-04 04:56:12,936 	Text Alignment  :	D   D       D       D    D       S    S   S       S      S            D      D    D S        S    
2024-02-04 04:56:12,937 ========================================================================================================================
2024-02-04 04:56:12,937 Logging Sequence: 81_139.00
2024-02-04 04:56:12,937 	Gloss Reference :	A B+C+D+E
2024-02-04 04:56:12,937 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:56:12,937 	Gloss Alignment :	         
2024-02-04 04:56:12,937 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:56:12,938 	Text Reference  :	in 2017 the case was filed first in delhi high    court by rhiti sports   management on       behalf of     dhoni       
2024-02-04 04:56:12,939 	Text Hypothesis :	** on   the **** *** ***** ***** ** ***** supreme court ** ***** canceled the        builder' real   estate registration
2024-02-04 04:56:12,939 	Text Alignment  :	D  S        D    D   D     D     D  D     S             D  D     S        S          S        S      S      S           
2024-02-04 04:56:12,939 ========================================================================================================================
2024-02-04 04:56:12,939 Logging Sequence: 125_72.00
2024-02-04 04:56:12,939 	Gloss Reference :	A B+C+D+E
2024-02-04 04:56:12,939 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:56:12,939 	Gloss Alignment :	         
2024-02-04 04:56:12,939 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:56:12,940 	Text Reference  :	some said the pakistani javelineer had milicious intentions of  tampering with     the     javelin out of    jealousy
2024-02-04 04:56:12,940 	Text Hypothesis :	**** **** *** ********* ********** *** ********* ********** and included  talented players such    as  rahul dravid  
2024-02-04 04:56:12,940 	Text Alignment  :	D    D    D   D         D          D   D         D          S   S         S        S       S       S   S     S       
2024-02-04 04:56:12,941 ========================================================================================================================
2024-02-04 04:56:13,381 Epoch 376: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.03 
2024-02-04 04:56:13,381 EPOCH 377
2024-02-04 04:56:18,416 [Epoch: 377 Step: 00050100] Batch Recognition Loss:   0.000096 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.020221 => Txt Tokens per Sec:     4084 || Lr: 0.000050
2024-02-04 04:56:20,765 Epoch 377: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.58 
2024-02-04 04:56:20,765 EPOCH 378
2024-02-04 04:56:24,059 [Epoch: 378 Step: 00050200] Batch Recognition Loss:   0.000146 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   0.028728 => Txt Tokens per Sec:     4009 || Lr: 0.000050
2024-02-04 04:56:28,399 Epoch 378: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.61 
2024-02-04 04:56:28,400 EPOCH 379
2024-02-04 04:56:29,864 [Epoch: 379 Step: 00050300] Batch Recognition Loss:   0.000232 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.017289 => Txt Tokens per Sec:     4104 || Lr: 0.000050
2024-02-04 04:56:35,424 [Epoch: 379 Step: 00050400] Batch Recognition Loss:   0.000284 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.048274 => Txt Tokens per Sec:     3938 || Lr: 0.000050
2024-02-04 04:56:35,826 Epoch 379: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.46 
2024-02-04 04:56:35,826 EPOCH 380
2024-02-04 04:56:40,997 [Epoch: 380 Step: 00050500] Batch Recognition Loss:   0.000383 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.040967 => Txt Tokens per Sec:     3973 || Lr: 0.000050
2024-02-04 04:56:43,189 Epoch 380: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.14 
2024-02-04 04:56:43,189 EPOCH 381
2024-02-04 04:56:46,192 [Epoch: 381 Step: 00050600] Batch Recognition Loss:   0.000196 => Gls Tokens per Sec:     1599 || Batch Translation Loss:   0.005116 => Txt Tokens per Sec:     4454 || Lr: 0.000050
2024-02-04 04:56:50,415 Epoch 381: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.28 
2024-02-04 04:56:50,416 EPOCH 382
2024-02-04 04:56:51,899 [Epoch: 382 Step: 00050700] Batch Recognition Loss:   0.000275 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.025978 => Txt Tokens per Sec:     3911 || Lr: 0.000050
2024-02-04 04:56:57,544 [Epoch: 382 Step: 00050800] Batch Recognition Loss:   0.000268 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.010695 => Txt Tokens per Sec:     3985 || Lr: 0.000050
2024-02-04 04:56:57,866 Epoch 382: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.89 
2024-02-04 04:56:57,866 EPOCH 383
2024-02-04 04:57:03,071 [Epoch: 383 Step: 00050900] Batch Recognition Loss:   0.000285 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.017716 => Txt Tokens per Sec:     4027 || Lr: 0.000050
2024-02-04 04:57:05,238 Epoch 383: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.18 
2024-02-04 04:57:05,239 EPOCH 384
2024-02-04 04:57:08,509 [Epoch: 384 Step: 00051000] Batch Recognition Loss:   0.000285 => Gls Tokens per Sec:     1492 || Batch Translation Loss:   0.044694 => Txt Tokens per Sec:     4205 || Lr: 0.000050
2024-02-04 04:57:12,682 Epoch 384: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.48 
2024-02-04 04:57:12,683 EPOCH 385
2024-02-04 04:57:14,389 [Epoch: 385 Step: 00051100] Batch Recognition Loss:   0.000188 => Gls Tokens per Sec:     1313 || Batch Translation Loss:   0.032139 => Txt Tokens per Sec:     3682 || Lr: 0.000050
2024-02-04 04:57:20,014 [Epoch: 385 Step: 00051200] Batch Recognition Loss:   0.000267 => Gls Tokens per Sec:     1420 || Batch Translation Loss:   0.043352 => Txt Tokens per Sec:     3943 || Lr: 0.000050
2024-02-04 04:57:20,249 Epoch 385: Total Training Recognition Loss 0.04  Total Training Translation Loss 6.29 
2024-02-04 04:57:20,250 EPOCH 386
2024-02-04 04:57:25,507 [Epoch: 386 Step: 00051300] Batch Recognition Loss:   0.000275 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.022968 => Txt Tokens per Sec:     3970 || Lr: 0.000050
2024-02-04 04:57:27,732 Epoch 386: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.13 
2024-02-04 04:57:27,732 EPOCH 387
2024-02-04 04:57:31,425 [Epoch: 387 Step: 00051400] Batch Recognition Loss:   0.000242 => Gls Tokens per Sec:     1343 || Batch Translation Loss:   0.023756 => Txt Tokens per Sec:     3784 || Lr: 0.000050
2024-02-04 04:57:35,612 Epoch 387: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.41 
2024-02-04 04:57:35,612 EPOCH 388
2024-02-04 04:57:37,242 [Epoch: 388 Step: 00051500] Batch Recognition Loss:   0.000230 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.018032 => Txt Tokens per Sec:     4115 || Lr: 0.000050
2024-02-04 04:57:43,106 [Epoch: 388 Step: 00051600] Batch Recognition Loss:   0.000215 => Gls Tokens per Sec:     1363 || Batch Translation Loss:   0.031699 => Txt Tokens per Sec:     3739 || Lr: 0.000050
2024-02-04 04:57:43,332 Epoch 388: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.19 
2024-02-04 04:57:43,332 EPOCH 389
2024-02-04 04:57:48,650 [Epoch: 389 Step: 00051700] Batch Recognition Loss:   0.000220 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.035912 => Txt Tokens per Sec:     4020 || Lr: 0.000050
2024-02-04 04:57:50,757 Epoch 389: Total Training Recognition Loss 0.03  Total Training Translation Loss 9.61 
2024-02-04 04:57:50,758 EPOCH 390
2024-02-04 04:57:54,456 [Epoch: 390 Step: 00051800] Batch Recognition Loss:   0.000134 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.017938 => Txt Tokens per Sec:     3750 || Lr: 0.000050
2024-02-04 04:57:58,442 Epoch 390: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.88 
2024-02-04 04:57:58,442 EPOCH 391
2024-02-04 04:58:00,006 [Epoch: 391 Step: 00051900] Batch Recognition Loss:   0.000209 => Gls Tokens per Sec:     1537 || Batch Translation Loss:   0.018403 => Txt Tokens per Sec:     4093 || Lr: 0.000050
2024-02-04 04:58:05,624 [Epoch: 391 Step: 00052000] Batch Recognition Loss:   0.000538 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.038094 => Txt Tokens per Sec:     3991 || Lr: 0.000050
2024-02-04 04:58:16,011 Validation result at epoch 391, step    52000: duration: 10.3855s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00303	Translation Loss: 92271.69531	PPL: 10235.66113
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.93	(BLEU-1: 10.39,	BLEU-2: 3.57,	BLEU-3: 1.68,	BLEU-4: 0.93)
	CHRF 16.65	ROUGE 9.08
2024-02-04 04:58:16,012 Logging Recognition and Translation Outputs
2024-02-04 04:58:16,012 ========================================================================================================================
2024-02-04 04:58:16,013 Logging Sequence: 87_229.00
2024-02-04 04:58:16,013 	Gloss Reference :	A B+C+D+E
2024-02-04 04:58:16,013 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:58:16,013 	Gloss Alignment :	         
2024-02-04 04:58:16,013 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:58:16,014 	Text Reference  :	it was not  against dhoni *** or   kohli    
2024-02-04 04:58:16,014 	Text Hypothesis :	** *** then ms      dhoni has been postponed
2024-02-04 04:58:16,014 	Text Alignment  :	D  D   S    S             I   S    S        
2024-02-04 04:58:16,014 ========================================================================================================================
2024-02-04 04:58:16,014 Logging Sequence: 134_153.00
2024-02-04 04:58:16,014 	Gloss Reference :	A B+C+D+E
2024-02-04 04:58:16,014 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:58:16,014 	Gloss Alignment :	         
2024-02-04 04:58:16,015 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:58:16,017 	Text Reference  :	pm modi in his interaction said that deaf athletes must       fight for  their goals       and never give up  despite the  losses
2024-02-04 04:58:16,017 	Text Hypothesis :	pm modi ** *** told        him  that yoga and      meditation would help him   concentrate and will  help him win     more medals
2024-02-04 04:58:16,017 	Text Alignment  :	        D  D   S           S         S    S        S          S     S    S     S               S     S    S   S       S    S     
2024-02-04 04:58:16,017 ========================================================================================================================
2024-02-04 04:58:16,017 Logging Sequence: 137_155.00
2024-02-04 04:58:16,017 	Gloss Reference :	A B+C+D+E
2024-02-04 04:58:16,017 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:58:16,018 	Gloss Alignment :	         
2024-02-04 04:58:16,018 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:58:16,019 	Text Reference  :	****** ****** *** an  extremely high    tax   named as       sin       tax will be   applied
2024-02-04 04:58:16,019 	Text Hypothesis :	indian team's win the match     between india and   pakistan qualified for the  next day    
2024-02-04 04:58:16,019 	Text Alignment  :	I      I      I   S   S         S       S     S     S        S         S   S    S    S      
2024-02-04 04:58:16,019 ========================================================================================================================
2024-02-04 04:58:16,019 Logging Sequence: 59_18.00
2024-02-04 04:58:16,019 	Gloss Reference :	A B+C+D+E
2024-02-04 04:58:16,019 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:58:16,020 	Gloss Alignment :	         
2024-02-04 04:58:16,020 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:58:16,021 	Text Reference  :	**** *** ********** 27-year-old jessica fox      from australia won    a   bronze a       gold medal in  canoeing
2024-02-04 04:58:16,021 	Text Hypothesis :	well the organisers of          the     olympics in   tokyo     handed out 60000  condoms to   all   the athletes
2024-02-04 04:58:16,021 	Text Alignment  :	I    I   I          S           S       S        S    S         S      S   S      S       S    S     S   S       
2024-02-04 04:58:16,021 ========================================================================================================================
2024-02-04 04:58:16,021 Logging Sequence: 173_103.00
2024-02-04 04:58:16,022 	Gloss Reference :	A B+C+D+E
2024-02-04 04:58:16,022 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 04:58:16,022 	Gloss Alignment :	         
2024-02-04 04:58:16,022 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 04:58:16,023 	Text Reference  :	** **** ***** **** *************** **** *** **** *** **** these rumours are  absolutely *** rubbish
2024-02-04 04:58:16,023 	Text Hypothesis :	as they would have unintentionally hurt the does not want for   the     team absolutely all rounder
2024-02-04 04:58:16,023 	Text Alignment  :	I  I    I     I    I               I    I   I    I   I    S     S       S               I   S      
2024-02-04 04:58:16,023 ========================================================================================================================
2024-02-04 04:58:16,296 Epoch 391: Total Training Recognition Loss 0.04  Total Training Translation Loss 6.64 
2024-02-04 04:58:16,296 EPOCH 392
2024-02-04 04:58:21,486 [Epoch: 392 Step: 00052100] Batch Recognition Loss:   0.000184 => Gls Tokens per Sec:     1496 || Batch Translation Loss:   0.013770 => Txt Tokens per Sec:     4173 || Lr: 0.000050
2024-02-04 04:58:23,354 Epoch 392: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.93 
2024-02-04 04:58:23,354 EPOCH 393
2024-02-04 04:58:26,567 [Epoch: 393 Step: 00052200] Batch Recognition Loss:   0.000161 => Gls Tokens per Sec:     1595 || Batch Translation Loss:   0.106130 => Txt Tokens per Sec:     4383 || Lr: 0.000050
2024-02-04 04:58:30,646 Epoch 393: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.74 
2024-02-04 04:58:30,647 EPOCH 394
2024-02-04 04:58:32,317 [Epoch: 394 Step: 00052300] Batch Recognition Loss:   0.000179 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.026541 => Txt Tokens per Sec:     4073 || Lr: 0.000050
2024-02-04 04:58:38,038 [Epoch: 394 Step: 00052400] Batch Recognition Loss:   0.000116 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.145609 => Txt Tokens per Sec:     3894 || Lr: 0.000050
2024-02-04 04:58:38,161 Epoch 394: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.48 
2024-02-04 04:58:38,162 EPOCH 395
2024-02-04 04:58:43,561 [Epoch: 395 Step: 00052500] Batch Recognition Loss:   0.000122 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.036854 => Txt Tokens per Sec:     4005 || Lr: 0.000050
2024-02-04 04:58:45,560 Epoch 395: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.01 
2024-02-04 04:58:45,561 EPOCH 396
2024-02-04 04:58:48,924 [Epoch: 396 Step: 00052600] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1547 || Batch Translation Loss:   0.022626 => Txt Tokens per Sec:     4162 || Lr: 0.000050
2024-02-04 04:58:53,088 Epoch 396: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.49 
2024-02-04 04:58:53,089 EPOCH 397
2024-02-04 04:58:54,839 [Epoch: 397 Step: 00052700] Batch Recognition Loss:   0.000435 => Gls Tokens per Sec:     1464 || Batch Translation Loss:   0.020986 => Txt Tokens per Sec:     4091 || Lr: 0.000050
2024-02-04 04:59:00,643 [Epoch: 397 Step: 00052800] Batch Recognition Loss:   0.000424 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.032160 => Txt Tokens per Sec:     3819 || Lr: 0.000050
2024-02-04 04:59:00,689 Epoch 397: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.35 
2024-02-04 04:59:00,689 EPOCH 398
2024-02-04 04:59:06,067 [Epoch: 398 Step: 00052900] Batch Recognition Loss:   0.000165 => Gls Tokens per Sec:     1473 || Batch Translation Loss:   0.017541 => Txt Tokens per Sec:     4102 || Lr: 0.000050
2024-02-04 04:59:08,205 Epoch 398: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.76 
2024-02-04 04:59:08,206 EPOCH 399
2024-02-04 04:59:12,403 [Epoch: 399 Step: 00053000] Batch Recognition Loss:   0.000225 => Gls Tokens per Sec:     1258 || Batch Translation Loss:   0.022213 => Txt Tokens per Sec:     3540 || Lr: 0.000050
2024-02-04 04:59:15,998 Epoch 399: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.37 
2024-02-04 04:59:15,998 EPOCH 400
2024-02-04 04:59:17,678 [Epoch: 400 Step: 00053100] Batch Recognition Loss:   0.000246 => Gls Tokens per Sec:     1572 || Batch Translation Loss:   0.010896 => Txt Tokens per Sec:     4483 || Lr: 0.000050
2024-02-04 04:59:23,449 [Epoch: 400 Step: 00053200] Batch Recognition Loss:   0.000201 => Gls Tokens per Sec:     1385 || Batch Translation Loss:   0.018438 => Txt Tokens per Sec:     3809 || Lr: 0.000050
2024-02-04 04:59:23,450 Epoch 400: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.74 
2024-02-04 04:59:23,450 EPOCH 401
2024-02-04 04:59:28,810 [Epoch: 401 Step: 00053300] Batch Recognition Loss:   0.000209 => Gls Tokens per Sec:     1493 || Batch Translation Loss:   0.031672 => Txt Tokens per Sec:     4171 || Lr: 0.000050
2024-02-04 04:59:30,627 Epoch 401: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.70 
2024-02-04 04:59:30,627 EPOCH 402
2024-02-04 04:59:33,908 [Epoch: 402 Step: 00053400] Batch Recognition Loss:   0.000159 => Gls Tokens per Sec:     1634 || Batch Translation Loss:   0.064473 => Txt Tokens per Sec:     4437 || Lr: 0.000050
2024-02-04 04:59:37,896 Epoch 402: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.73 
2024-02-04 04:59:37,897 EPOCH 403
2024-02-04 04:59:39,722 [Epoch: 403 Step: 00053500] Batch Recognition Loss:   0.000247 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.023875 => Txt Tokens per Sec:     4112 || Lr: 0.000050
2024-02-04 04:59:45,130 Epoch 403: Total Training Recognition Loss 0.04  Total Training Translation Loss 8.26 
2024-02-04 04:59:45,131 EPOCH 404
2024-02-04 04:59:45,201 [Epoch: 404 Step: 00053600] Batch Recognition Loss:   0.000143 => Gls Tokens per Sec:     1159 || Batch Translation Loss:   0.039274 => Txt Tokens per Sec:     3435 || Lr: 0.000050
2024-02-04 04:59:50,806 [Epoch: 404 Step: 00053700] Batch Recognition Loss:   0.000334 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.022249 => Txt Tokens per Sec:     3952 || Lr: 0.000050
2024-02-04 04:59:52,574 Epoch 404: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.40 
2024-02-04 04:59:52,574 EPOCH 405
2024-02-04 04:59:56,251 [Epoch: 405 Step: 00053800] Batch Recognition Loss:   0.000159 => Gls Tokens per Sec:     1479 || Batch Translation Loss:   0.042372 => Txt Tokens per Sec:     4114 || Lr: 0.000050
2024-02-04 04:59:59,937 Epoch 405: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.35 
2024-02-04 04:59:59,937 EPOCH 406
2024-02-04 05:00:01,787 [Epoch: 406 Step: 00053900] Batch Recognition Loss:   0.000216 => Gls Tokens per Sec:     1515 || Batch Translation Loss:   0.020951 => Txt Tokens per Sec:     4121 || Lr: 0.000050
2024-02-04 05:00:07,283 Epoch 406: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.78 
2024-02-04 05:00:07,284 EPOCH 407
2024-02-04 05:00:07,381 [Epoch: 407 Step: 00054000] Batch Recognition Loss:   0.000187 => Gls Tokens per Sec:     1667 || Batch Translation Loss:   0.014887 => Txt Tokens per Sec:     3729 || Lr: 0.000050
2024-02-04 05:00:18,219 Validation result at epoch 407, step    54000: duration: 10.8370s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00246	Translation Loss: 91757.78906	PPL: 9722.57910
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.75	(BLEU-1: 10.52,	BLEU-2: 3.06,	BLEU-3: 1.29,	BLEU-4: 0.75)
	CHRF 16.68	ROUGE 9.12
2024-02-04 05:00:18,220 Logging Recognition and Translation Outputs
2024-02-04 05:00:18,220 ========================================================================================================================
2024-02-04 05:00:18,220 Logging Sequence: 130_139.00
2024-02-04 05:00:18,221 	Gloss Reference :	A B+C+D+E
2024-02-04 05:00:18,221 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:00:18,221 	Gloss Alignment :	         
2024-02-04 05:00:18,221 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:00:18,224 	Text Reference  :	he shared a picture of  a little pouch he knit for his olympic gold   medal with uk flag on  one  side   and **** japanese flag on      the     other
2024-02-04 05:00:18,224 	Text Hypothesis :	he ****** * ******* won a ****** ***** ** **** *** *** ******* bronze medal **** ** at   the 2012 london and 2016 rio      de   janeiro olympic games
2024-02-04 05:00:18,224 	Text Alignment  :	   D      D D       S     D      D     D  D    D   D   D       S            D    D  S    S   S    S          I    S        S    S       S       S    
2024-02-04 05:00:18,224 ========================================================================================================================
2024-02-04 05:00:18,224 Logging Sequence: 148_155.00
2024-02-04 05:00:18,224 	Gloss Reference :	A B+C+D+E
2024-02-04 05:00:18,225 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:00:18,225 	Gloss Alignment :	         
2024-02-04 05:00:18,225 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:00:18,226 	Text Reference  :	****** ********* ***** **** india     won           the     match with     263 balls     remaining and without losing        any     wicket    
2024-02-04 05:00:18,226 	Text Hypothesis :	indian badminton world deaf badminton championships between india pakistan is  currently at        the dubai   international cricket tournament
2024-02-04 05:00:18,226 	Text Alignment  :	I      I         I     I    S         S             S       S     S        S   S         S         S   S       S             S       S         
2024-02-04 05:00:18,226 ========================================================================================================================
2024-02-04 05:00:18,227 Logging Sequence: 126_99.00
2024-02-04 05:00:18,227 	Gloss Reference :	A B+C+D+E
2024-02-04 05:00:18,227 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:00:18,227 	Gloss Alignment :	         
2024-02-04 05:00:18,227 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:00:18,228 	Text Reference  :	** ** ** he          dedicated the   medal to sprinter milkha singh
2024-02-04 05:00:18,228 	Text Hypothesis :	it is an interesting history   about rs    1  crore    cash   prize
2024-02-04 05:00:18,228 	Text Alignment  :	I  I  I  S           S         S     S     S  S        S      S    
2024-02-04 05:00:18,228 ========================================================================================================================
2024-02-04 05:00:18,228 Logging Sequence: 149_77.00
2024-02-04 05:00:18,229 	Gloss Reference :	A B+C+D+E
2024-02-04 05:00:18,229 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:00:18,229 	Gloss Alignment :	         
2024-02-04 05:00:18,229 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:00:18,230 	Text Reference  :	and arrested danushka for alleged sexual assault of a   29  year old woman whose    name has not **** been disclosed
2024-02-04 05:00:18,231 	Text Hypothesis :	*** ******** ******** *** ******* ****** ******* ** but due to   the covid pandemic they did not miss the  match    
2024-02-04 05:00:18,231 	Text Alignment  :	D   D        D        D   D       D      D       D  S   S   S    S   S     S        S    S       I    S    S        
2024-02-04 05:00:18,231 ========================================================================================================================
2024-02-04 05:00:18,231 Logging Sequence: 168_15.00
2024-02-04 05:00:18,231 	Gloss Reference :	A B+C+D+E
2024-02-04 05:00:18,231 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:00:18,231 	Gloss Alignment :	         
2024-02-04 05:00:18,232 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:00:18,232 	Text Reference  :	when in public the ****** couple are always   approached for     photographys and  autographs
2024-02-04 05:00:18,232 	Text Hypothesis :	**** ** ****** the indian team   was jubliant with       winning the          asia cup       
2024-02-04 05:00:18,233 	Text Alignment  :	D    D  D          I      S      S   S        S          S       S            S    S         
2024-02-04 05:00:18,233 ========================================================================================================================
2024-02-04 05:00:23,744 [Epoch: 407 Step: 00054100] Batch Recognition Loss:   0.000262 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.032650 => Txt Tokens per Sec:     4028 || Lr: 0.000050
2024-02-04 05:00:25,427 Epoch 407: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.71 
2024-02-04 05:00:25,427 EPOCH 408
2024-02-04 05:00:29,072 [Epoch: 408 Step: 00054200] Batch Recognition Loss:   0.000213 => Gls Tokens per Sec:     1515 || Batch Translation Loss:   0.025799 => Txt Tokens per Sec:     4223 || Lr: 0.000050
2024-02-04 05:00:32,543 Epoch 408: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.66 
2024-02-04 05:00:32,543 EPOCH 409
2024-02-04 05:00:34,489 [Epoch: 409 Step: 00054300] Batch Recognition Loss:   0.000191 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.018932 => Txt Tokens per Sec:     4201 || Lr: 0.000050
2024-02-04 05:00:40,129 Epoch 409: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.67 
2024-02-04 05:00:40,130 EPOCH 410
2024-02-04 05:00:40,295 [Epoch: 410 Step: 00054400] Batch Recognition Loss:   0.000191 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.038702 => Txt Tokens per Sec:     4189 || Lr: 0.000050
2024-02-04 05:00:45,559 [Epoch: 410 Step: 00054500] Batch Recognition Loss:   0.000292 => Gls Tokens per Sec:     1520 || Batch Translation Loss:   0.027603 => Txt Tokens per Sec:     4242 || Lr: 0.000050
2024-02-04 05:00:47,237 Epoch 410: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.36 
2024-02-04 05:00:47,237 EPOCH 411
2024-02-04 05:00:50,912 [Epoch: 411 Step: 00054600] Batch Recognition Loss:   0.000322 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.035608 => Txt Tokens per Sec:     4224 || Lr: 0.000050
2024-02-04 05:00:54,581 Epoch 411: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.59 
2024-02-04 05:00:54,582 EPOCH 412
2024-02-04 05:00:56,561 [Epoch: 412 Step: 00054700] Batch Recognition Loss:   0.000135 => Gls Tokens per Sec:     1496 || Batch Translation Loss:   0.284450 => Txt Tokens per Sec:     3914 || Lr: 0.000050
2024-02-04 05:01:02,237 Epoch 412: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.44 
2024-02-04 05:01:02,238 EPOCH 413
2024-02-04 05:01:02,465 [Epoch: 413 Step: 00054800] Batch Recognition Loss:   0.000386 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.038554 => Txt Tokens per Sec:     3593 || Lr: 0.000050
2024-02-04 05:01:07,999 [Epoch: 413 Step: 00054900] Batch Recognition Loss:   0.000163 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.013712 => Txt Tokens per Sec:     4059 || Lr: 0.000050
2024-02-04 05:01:09,583 Epoch 413: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.43 
2024-02-04 05:01:09,584 EPOCH 414
2024-02-04 05:01:13,748 [Epoch: 414 Step: 00055000] Batch Recognition Loss:   0.000134 => Gls Tokens per Sec:     1365 || Batch Translation Loss:   0.022378 => Txt Tokens per Sec:     3791 || Lr: 0.000050
2024-02-04 05:01:17,319 Epoch 414: Total Training Recognition Loss 0.03  Total Training Translation Loss 10.34 
2024-02-04 05:01:17,320 EPOCH 415
2024-02-04 05:01:19,381 [Epoch: 415 Step: 00055100] Batch Recognition Loss:   0.000193 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.066406 => Txt Tokens per Sec:     4123 || Lr: 0.000050
2024-02-04 05:01:24,871 Epoch 415: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.78 
2024-02-04 05:01:24,871 EPOCH 416
2024-02-04 05:01:25,138 [Epoch: 416 Step: 00055200] Batch Recognition Loss:   0.000201 => Gls Tokens per Sec:     1504 || Batch Translation Loss:   0.026620 => Txt Tokens per Sec:     4579 || Lr: 0.000050
2024-02-04 05:01:30,755 [Epoch: 416 Step: 00055300] Batch Recognition Loss:   0.000168 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.030158 => Txt Tokens per Sec:     3956 || Lr: 0.000050
2024-02-04 05:01:32,260 Epoch 416: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.93 
2024-02-04 05:01:32,260 EPOCH 417
2024-02-04 05:01:35,989 [Epoch: 417 Step: 00055400] Batch Recognition Loss:   0.000174 => Gls Tokens per Sec:     1545 || Batch Translation Loss:   0.010313 => Txt Tokens per Sec:     4157 || Lr: 0.000050
2024-02-04 05:01:39,550 Epoch 417: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.50 
2024-02-04 05:01:39,550 EPOCH 418
2024-02-04 05:01:41,654 [Epoch: 418 Step: 00055500] Batch Recognition Loss:   0.000174 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.010102 => Txt Tokens per Sec:     3935 || Lr: 0.000050
2024-02-04 05:01:47,101 Epoch 418: Total Training Recognition Loss 0.02  Total Training Translation Loss 4.07 
2024-02-04 05:01:47,101 EPOCH 419
2024-02-04 05:01:47,369 [Epoch: 419 Step: 00055600] Batch Recognition Loss:   0.000440 => Gls Tokens per Sec:     1798 || Batch Translation Loss:   0.015009 => Txt Tokens per Sec:     4712 || Lr: 0.000050
2024-02-04 05:01:52,691 [Epoch: 419 Step: 00055700] Batch Recognition Loss:   0.000141 => Gls Tokens per Sec:     1501 || Batch Translation Loss:   0.039432 => Txt Tokens per Sec:     4122 || Lr: 0.000050
2024-02-04 05:01:54,293 Epoch 419: Total Training Recognition Loss 0.02  Total Training Translation Loss 4.11 
2024-02-04 05:01:54,293 EPOCH 420
2024-02-04 05:01:58,508 [Epoch: 420 Step: 00055800] Batch Recognition Loss:   0.000175 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.015659 => Txt Tokens per Sec:     3923 || Lr: 0.000050
2024-02-04 05:02:02,041 Epoch 420: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.68 
2024-02-04 05:02:02,041 EPOCH 421
2024-02-04 05:02:04,284 [Epoch: 421 Step: 00055900] Batch Recognition Loss:   0.000196 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.063473 => Txt Tokens per Sec:     4006 || Lr: 0.000050
2024-02-04 05:02:09,256 Epoch 421: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.08 
2024-02-04 05:02:09,256 EPOCH 422
2024-02-04 05:02:09,628 [Epoch: 422 Step: 00056000] Batch Recognition Loss:   0.000196 => Gls Tokens per Sec:     1509 || Batch Translation Loss:   0.019152 => Txt Tokens per Sec:     4278 || Lr: 0.000050
2024-02-04 05:02:20,320 Validation result at epoch 422, step    56000: duration: 10.6910s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00232	Translation Loss: 90740.52344	PPL: 8781.55762
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.96	(BLEU-1: 10.89,	BLEU-2: 3.64,	BLEU-3: 1.66,	BLEU-4: 0.96)
	CHRF 17.23	ROUGE 9.18
2024-02-04 05:02:20,321 Logging Recognition and Translation Outputs
2024-02-04 05:02:20,321 ========================================================================================================================
2024-02-04 05:02:20,321 Logging Sequence: 122_110.00
2024-02-04 05:02:20,321 	Gloss Reference :	A B+C+D+E
2024-02-04 05:02:20,321 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:02:20,322 	Gloss Alignment :	         
2024-02-04 05:02:20,322 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:02:20,322 	Text Reference  :	now that i     achieved my  dream and       secured a silver medal  
2024-02-04 05:02:20,322 	Text Hypothesis :	*** **** after her      win an    overjoyed with    a huge   problem
2024-02-04 05:02:20,323 	Text Alignment  :	D   D    S     S        S   S     S         S         S      S      
2024-02-04 05:02:20,323 ========================================================================================================================
2024-02-04 05:02:20,323 Logging Sequence: 161_111.00
2024-02-04 05:02:20,323 	Gloss Reference :	A B+C+D+E
2024-02-04 05:02:20,323 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:02:20,323 	Gloss Alignment :	         
2024-02-04 05:02:20,323 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:02:20,325 	Text Reference  :	*** his       last   game  as    captain was *** ******** ****** the  cape   town test  in south africa in jan 2022
2024-02-04 05:02:20,325 	Text Hypothesis :	the rajasthan royals owner whose name    was not revealed didn't slap taylor 2-4  times in anger but    it was held
2024-02-04 05:02:20,325 	Text Alignment  :	I   S         S      S     S     S           I   I        I      S    S      S    S        S     S      S  S   S   
2024-02-04 05:02:20,326 ========================================================================================================================
2024-02-04 05:02:20,326 Logging Sequence: 136_79.00
2024-02-04 05:02:20,326 	Gloss Reference :	A B+C+D+E
2024-02-04 05:02:20,326 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:02:20,326 	Gloss Alignment :	         
2024-02-04 05:02:20,326 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:02:20,327 	Text Reference  :	with this win   sindhu became the first indian woman to  win two         individual olympic medals
2024-02-04 05:02:20,327 	Text Hypothesis :	**** **** sadly sindhu lost   the ***** match  and   she was heartbroken over       the     loss  
2024-02-04 05:02:20,328 	Text Alignment  :	D    D    S            S          D     S      S     S   S   S           S          S       S     
2024-02-04 05:02:20,328 ========================================================================================================================
2024-02-04 05:02:20,328 Logging Sequence: 166_335.00
2024-02-04 05:02:20,328 	Gloss Reference :	A B+C+D+E
2024-02-04 05:02:20,328 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:02:20,328 	Gloss Alignment :	         
2024-02-04 05:02:20,328 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:02:20,330 	Text Reference  :	* ** the **** ****** **** ****** **** **** second world test championship is   scheduled from    june 2021 to    30  april 2023
2024-02-04 05:02:20,330 	Text Hypothesis :	2 of the best indian team bowled very well were   raj   bawa who          took 5         wickets and  ravi kumar who is    more
2024-02-04 05:02:20,330 	Text Alignment  :	I I      I    I      I    I      I    I    S      S     S    S            S    S         S       S    S    S     S   S     S   
2024-02-04 05:02:20,330 ========================================================================================================================
2024-02-04 05:02:20,331 Logging Sequence: 95_152.00
2024-02-04 05:02:20,331 	Gloss Reference :	A B+C+D+E
2024-02-04 05:02:20,331 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:02:20,331 	Gloss Alignment :	         
2024-02-04 05:02:20,331 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:02:20,331 	Text Reference  :	******** ************* how strange
2024-02-04 05:02:20,331 	Text Hypothesis :	everyone congratulated the couple 
2024-02-04 05:02:20,332 	Text Alignment  :	I        I             S   S      
2024-02-04 05:02:20,332 ========================================================================================================================
2024-02-04 05:02:25,864 [Epoch: 422 Step: 00056100] Batch Recognition Loss:   0.000145 => Gls Tokens per Sec:     1443 || Batch Translation Loss:   0.024345 => Txt Tokens per Sec:     4016 || Lr: 0.000050
2024-02-04 05:02:27,405 Epoch 422: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.14 
2024-02-04 05:02:27,405 EPOCH 423
2024-02-04 05:02:31,790 [Epoch: 423 Step: 00056200] Batch Recognition Loss:   0.000287 => Gls Tokens per Sec:     1350 || Batch Translation Loss:   0.023814 => Txt Tokens per Sec:     3795 || Lr: 0.000050
2024-02-04 05:02:35,011 Epoch 423: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.16 
2024-02-04 05:02:35,012 EPOCH 424
2024-02-04 05:02:36,966 [Epoch: 424 Step: 00056300] Batch Recognition Loss:   0.000223 => Gls Tokens per Sec:     1679 || Batch Translation Loss:   0.019283 => Txt Tokens per Sec:     4649 || Lr: 0.000050
2024-02-04 05:02:42,236 Epoch 424: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.29 
2024-02-04 05:02:42,237 EPOCH 425
2024-02-04 05:02:42,685 [Epoch: 425 Step: 00056400] Batch Recognition Loss:   0.000408 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.040668 => Txt Tokens per Sec:     4067 || Lr: 0.000050
2024-02-04 05:02:48,178 [Epoch: 425 Step: 00056500] Batch Recognition Loss:   0.000273 => Gls Tokens per Sec:     1456 || Batch Translation Loss:   0.183920 => Txt Tokens per Sec:     4070 || Lr: 0.000050
2024-02-04 05:02:49,581 Epoch 425: Total Training Recognition Loss 0.04  Total Training Translation Loss 10.95 
2024-02-04 05:02:49,582 EPOCH 426
2024-02-04 05:02:53,563 [Epoch: 426 Step: 00056600] Batch Recognition Loss:   0.000215 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.024077 => Txt Tokens per Sec:     4117 || Lr: 0.000050
2024-02-04 05:02:56,962 Epoch 426: Total Training Recognition Loss 0.04  Total Training Translation Loss 11.48 
2024-02-04 05:02:56,962 EPOCH 427
2024-02-04 05:02:59,318 [Epoch: 427 Step: 00056700] Batch Recognition Loss:   0.000127 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.059763 => Txt Tokens per Sec:     4070 || Lr: 0.000050
2024-02-04 05:03:04,663 Epoch 427: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.50 
2024-02-04 05:03:04,664 EPOCH 428
2024-02-04 05:03:05,195 [Epoch: 428 Step: 00056800] Batch Recognition Loss:   0.000182 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.026286 => Txt Tokens per Sec:     3903 || Lr: 0.000050
2024-02-04 05:03:10,818 [Epoch: 428 Step: 00056900] Batch Recognition Loss:   0.000238 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.039921 => Txt Tokens per Sec:     3939 || Lr: 0.000050
2024-02-04 05:03:12,307 Epoch 428: Total Training Recognition Loss 0.04  Total Training Translation Loss 5.99 
2024-02-04 05:03:12,307 EPOCH 429
2024-02-04 05:03:16,478 [Epoch: 429 Step: 00057000] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.036364 => Txt Tokens per Sec:     4067 || Lr: 0.000050
2024-02-04 05:03:19,594 Epoch 429: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.96 
2024-02-04 05:03:19,594 EPOCH 430
2024-02-04 05:03:22,236 [Epoch: 430 Step: 00057100] Batch Recognition Loss:   0.000264 => Gls Tokens per Sec:     1302 || Batch Translation Loss:   0.013582 => Txt Tokens per Sec:     3796 || Lr: 0.000050
2024-02-04 05:03:27,276 Epoch 430: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.26 
2024-02-04 05:03:27,276 EPOCH 431
2024-02-04 05:03:27,713 [Epoch: 431 Step: 00057200] Batch Recognition Loss:   0.000144 => Gls Tokens per Sec:     1839 || Batch Translation Loss:   0.013513 => Txt Tokens per Sec:     4828 || Lr: 0.000050
2024-02-04 05:03:33,362 [Epoch: 431 Step: 00057300] Batch Recognition Loss:   0.000185 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.009245 => Txt Tokens per Sec:     3957 || Lr: 0.000050
2024-02-04 05:03:34,706 Epoch 431: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.58 
2024-02-04 05:03:34,706 EPOCH 432
2024-02-04 05:03:39,117 [Epoch: 432 Step: 00057400] Batch Recognition Loss:   0.000131 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.009184 => Txt Tokens per Sec:     3889 || Lr: 0.000050
2024-02-04 05:03:42,169 Epoch 432: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.89 
2024-02-04 05:03:42,169 EPOCH 433
2024-02-04 05:03:44,439 [Epoch: 433 Step: 00057500] Batch Recognition Loss:   0.000153 => Gls Tokens per Sec:     1552 || Batch Translation Loss:   0.674213 => Txt Tokens per Sec:     4289 || Lr: 0.000050
2024-02-04 05:03:49,740 Epoch 433: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.66 
2024-02-04 05:03:49,741 EPOCH 434
2024-02-04 05:03:50,373 [Epoch: 434 Step: 00057600] Batch Recognition Loss:   0.000159 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.020691 => Txt Tokens per Sec:     4138 || Lr: 0.000050
2024-02-04 05:03:55,690 [Epoch: 434 Step: 00057700] Batch Recognition Loss:   0.000178 => Gls Tokens per Sec:     1505 || Batch Translation Loss:   0.022389 => Txt Tokens per Sec:     4113 || Lr: 0.000050
2024-02-04 05:03:56,967 Epoch 434: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.70 
2024-02-04 05:03:56,968 EPOCH 435
2024-02-04 05:04:00,991 [Epoch: 435 Step: 00057800] Batch Recognition Loss:   0.000158 => Gls Tokens per Sec:     1552 || Batch Translation Loss:   0.055873 => Txt Tokens per Sec:     4332 || Lr: 0.000050
2024-02-04 05:04:04,204 Epoch 435: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.56 
2024-02-04 05:04:04,205 EPOCH 436
2024-02-04 05:04:06,707 [Epoch: 436 Step: 00057900] Batch Recognition Loss:   0.000136 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.022253 => Txt Tokens per Sec:     3906 || Lr: 0.000050
2024-02-04 05:04:11,770 Epoch 436: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.73 
2024-02-04 05:04:11,770 EPOCH 437
2024-02-04 05:04:12,385 [Epoch: 437 Step: 00058000] Batch Recognition Loss:   0.000278 => Gls Tokens per Sec:     1564 || Batch Translation Loss:   0.023679 => Txt Tokens per Sec:     4137 || Lr: 0.000050
2024-02-04 05:04:23,336 Validation result at epoch 437, step    58000: duration: 10.9501s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00245	Translation Loss: 91475.87500	PPL: 9452.13086
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.96	(BLEU-1: 10.82,	BLEU-2: 3.56,	BLEU-3: 1.66,	BLEU-4: 0.96)
	CHRF 16.88	ROUGE 9.29
2024-02-04 05:04:23,337 Logging Recognition and Translation Outputs
2024-02-04 05:04:23,337 ========================================================================================================================
2024-02-04 05:04:23,337 Logging Sequence: 180_138.00
2024-02-04 05:04:23,337 	Gloss Reference :	A B+C+D+E
2024-02-04 05:04:23,337 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:04:23,337 	Gloss Alignment :	         
2024-02-04 05:04:23,337 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:04:23,339 	Text Reference  :	ioa president p t usha constituted a    seven-member panel which included world champions from various sports    to  inquire into   the allegations
2024-02-04 05:04:23,339 	Text Hypothesis :	*** ********* * * **** singh       also said         that  he    has      full  faith     in   the     judiciary and will    accpet the verdict    
2024-02-04 05:04:23,340 	Text Alignment  :	D   D         D D D    S           S    S            S     S     S        S     S         S    S       S         S   S       S          S          
2024-02-04 05:04:23,340 ========================================================================================================================
2024-02-04 05:04:23,340 Logging Sequence: 128_189.00
2024-02-04 05:04:23,340 	Gloss Reference :	A B+C+D+E
2024-02-04 05:04:23,340 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:04:23,340 	Gloss Alignment :	         
2024-02-04 05:04:23,340 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:04:23,341 	Text Reference  :	*** meanwhile some funny incidents happened during the ***** match
2024-02-04 05:04:23,341 	Text Hypothesis :	for the       icc  world cup       2022     at     the first time 
2024-02-04 05:04:23,341 	Text Alignment  :	I   S         S    S     S         S        S          I     S    
2024-02-04 05:04:23,341 ========================================================================================================================
2024-02-04 05:04:23,341 Logging Sequence: 165_523.00
2024-02-04 05:04:23,342 	Gloss Reference :	A B+C+D+E
2024-02-04 05:04:23,342 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:04:23,342 	Gloss Alignment :	         
2024-02-04 05:04:23,342 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:04:23,343 	Text Reference  :	as he believed that his team might lose if he  takes off    his batting pads      
2024-02-04 05:04:23,343 	Text Hypothesis :	** ** ******** **** and they will  lose ** one of    vamika in  the     tournament
2024-02-04 05:04:23,343 	Text Alignment  :	D  D  D        D    S   S    S          D  S   S     S      S   S       S         
2024-02-04 05:04:23,343 ========================================================================================================================
2024-02-04 05:04:23,343 Logging Sequence: 145_168.00
2024-02-04 05:04:23,344 	Gloss Reference :	A B+C+D+E
2024-02-04 05:04:23,344 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:04:23,344 	Gloss Alignment :	         
2024-02-04 05:04:23,344 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:04:23,344 	Text Reference  :	the decision  has devastated sameeha and     her parents
2024-02-04 05:04:23,344 	Text Hypothesis :	the committee has ********** gained  control 5   years  
2024-02-04 05:04:23,345 	Text Alignment  :	    S             D          S       S       S   S      
2024-02-04 05:04:23,345 ========================================================================================================================
2024-02-04 05:04:23,345 Logging Sequence: 92_123.00
2024-02-04 05:04:23,345 	Gloss Reference :	A B+C+D+E
2024-02-04 05:04:23,345 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:04:23,345 	Gloss Alignment :	         
2024-02-04 05:04:23,345 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:04:23,346 	Text Reference  :	a heated argument also took place between members of the family and the    two    men 
2024-02-04 05:04:23,346 	Text Hypothesis :	* and    is       also **** ***** a       report  by the ****** *** police learnt that
2024-02-04 05:04:23,346 	Text Alignment  :	D S      S             D    D     S       S       S      D      D   S      S      S   
2024-02-04 05:04:23,347 ========================================================================================================================
2024-02-04 05:04:29,055 [Epoch: 437 Step: 00058100] Batch Recognition Loss:   0.000205 => Gls Tokens per Sec:     1399 || Batch Translation Loss:   0.029109 => Txt Tokens per Sec:     3897 || Lr: 0.000050
2024-02-04 05:04:30,235 Epoch 437: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.49 
2024-02-04 05:04:30,235 EPOCH 438
2024-02-04 05:04:34,291 [Epoch: 438 Step: 00058200] Batch Recognition Loss:   0.000214 => Gls Tokens per Sec:     1559 || Batch Translation Loss:   0.021982 => Txt Tokens per Sec:     4386 || Lr: 0.000050
2024-02-04 05:04:37,098 Epoch 438: Total Training Recognition Loss 0.03  Total Training Translation Loss 13.36 
2024-02-04 05:04:37,098 EPOCH 439
2024-02-04 05:04:39,417 [Epoch: 439 Step: 00058300] Batch Recognition Loss:   0.000302 => Gls Tokens per Sec:     1588 || Batch Translation Loss:   0.033469 => Txt Tokens per Sec:     4406 || Lr: 0.000050
2024-02-04 05:04:44,204 Epoch 439: Total Training Recognition Loss 0.04  Total Training Translation Loss 7.84 
2024-02-04 05:04:44,205 EPOCH 440
2024-02-04 05:04:44,885 [Epoch: 440 Step: 00058400] Batch Recognition Loss:   0.000179 => Gls Tokens per Sec:     1531 || Batch Translation Loss:   0.024607 => Txt Tokens per Sec:     3717 || Lr: 0.000050
2024-02-04 05:04:50,376 [Epoch: 440 Step: 00058500] Batch Recognition Loss:   0.000269 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.012691 => Txt Tokens per Sec:     4105 || Lr: 0.000050
2024-02-04 05:04:51,691 Epoch 440: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.54 
2024-02-04 05:04:51,692 EPOCH 441
2024-02-04 05:04:56,120 [Epoch: 441 Step: 00058600] Batch Recognition Loss:   0.000161 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.010022 => Txt Tokens per Sec:     4073 || Lr: 0.000050
2024-02-04 05:04:59,224 Epoch 441: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.82 
2024-02-04 05:04:59,224 EPOCH 442
2024-02-04 05:05:02,025 [Epoch: 442 Step: 00058700] Batch Recognition Loss:   0.000204 => Gls Tokens per Sec:     1343 || Batch Translation Loss:   0.032036 => Txt Tokens per Sec:     3887 || Lr: 0.000050
2024-02-04 05:05:06,727 Epoch 442: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.01 
2024-02-04 05:05:06,727 EPOCH 443
2024-02-04 05:05:07,580 [Epoch: 443 Step: 00058800] Batch Recognition Loss:   0.000199 => Gls Tokens per Sec:     1316 || Batch Translation Loss:   0.028375 => Txt Tokens per Sec:     3615 || Lr: 0.000050
2024-02-04 05:05:13,286 [Epoch: 443 Step: 00058900] Batch Recognition Loss:   0.000184 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.022400 => Txt Tokens per Sec:     3877 || Lr: 0.000050
2024-02-04 05:05:14,341 Epoch 443: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.18 
2024-02-04 05:05:14,341 EPOCH 444
2024-02-04 05:05:18,875 [Epoch: 444 Step: 00059000] Batch Recognition Loss:   0.000235 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.022572 => Txt Tokens per Sec:     3929 || Lr: 0.000050
2024-02-04 05:05:21,940 Epoch 444: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.15 
2024-02-04 05:05:21,941 EPOCH 445
2024-02-04 05:05:24,682 [Epoch: 445 Step: 00059100] Batch Recognition Loss:   0.000248 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.018212 => Txt Tokens per Sec:     3926 || Lr: 0.000050
2024-02-04 05:05:29,651 Epoch 445: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.29 
2024-02-04 05:05:29,652 EPOCH 446
2024-02-04 05:05:30,465 [Epoch: 446 Step: 00059200] Batch Recognition Loss:   0.000244 => Gls Tokens per Sec:     1478 || Batch Translation Loss:   0.035621 => Txt Tokens per Sec:     3926 || Lr: 0.000050
2024-02-04 05:05:36,336 [Epoch: 446 Step: 00059300] Batch Recognition Loss:   0.000333 => Gls Tokens per Sec:     1361 || Batch Translation Loss:   0.039420 => Txt Tokens per Sec:     3781 || Lr: 0.000050
2024-02-04 05:05:37,297 Epoch 446: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.83 
2024-02-04 05:05:37,297 EPOCH 447
2024-02-04 05:05:41,464 [Epoch: 447 Step: 00059400] Batch Recognition Loss:   0.000131 => Gls Tokens per Sec:     1575 || Batch Translation Loss:   0.022233 => Txt Tokens per Sec:     4279 || Lr: 0.000050
2024-02-04 05:05:44,618 Epoch 447: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.11 
2024-02-04 05:05:44,618 EPOCH 448
2024-02-04 05:05:47,469 [Epoch: 448 Step: 00059500] Batch Recognition Loss:   0.000196 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.022724 => Txt Tokens per Sec:     3871 || Lr: 0.000050
2024-02-04 05:05:52,308 Epoch 448: Total Training Recognition Loss 0.03  Total Training Translation Loss 9.42 
2024-02-04 05:05:52,309 EPOCH 449
2024-02-04 05:05:53,332 [Epoch: 449 Step: 00059600] Batch Recognition Loss:   0.000296 => Gls Tokens per Sec:     1252 || Batch Translation Loss:   0.085614 => Txt Tokens per Sec:     3713 || Lr: 0.000050
2024-02-04 05:05:58,713 [Epoch: 449 Step: 00059700] Batch Recognition Loss:   0.000174 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.026341 => Txt Tokens per Sec:     4081 || Lr: 0.000050
2024-02-04 05:05:59,842 Epoch 449: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.85 
2024-02-04 05:05:59,843 EPOCH 450
2024-02-04 05:06:04,387 [Epoch: 450 Step: 00059800] Batch Recognition Loss:   0.000188 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.026915 => Txt Tokens per Sec:     4064 || Lr: 0.000050
2024-02-04 05:06:07,154 Epoch 450: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.78 
2024-02-04 05:06:07,154 EPOCH 451
2024-02-04 05:06:10,202 [Epoch: 451 Step: 00059900] Batch Recognition Loss:   0.000245 => Gls Tokens per Sec:     1313 || Batch Translation Loss:   0.026621 => Txt Tokens per Sec:     3679 || Lr: 0.000050
2024-02-04 05:06:14,897 Epoch 451: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.86 
2024-02-04 05:06:14,897 EPOCH 452
2024-02-04 05:06:15,770 [Epoch: 452 Step: 00060000] Batch Recognition Loss:   0.000197 => Gls Tokens per Sec:     1559 || Batch Translation Loss:   0.237538 => Txt Tokens per Sec:     4548 || Lr: 0.000050
2024-02-04 05:06:26,659 Validation result at epoch 452, step    60000: duration: 10.8882s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00288	Translation Loss: 92106.32812	PPL: 10067.67285
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.72	(BLEU-1: 10.61,	BLEU-2: 3.21,	BLEU-3: 1.38,	BLEU-4: 0.72)
	CHRF 16.56	ROUGE 9.17
2024-02-04 05:06:26,660 Logging Recognition and Translation Outputs
2024-02-04 05:06:26,661 ========================================================================================================================
2024-02-04 05:06:26,661 Logging Sequence: 179_269.00
2024-02-04 05:06:26,661 	Gloss Reference :	A B+C+D+E
2024-02-04 05:06:26,661 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:06:26,661 	Gloss Alignment :	         
2024-02-04 05:06:26,661 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:06:26,662 	Text Reference  :	the ban would mean she can't compete in any    national or  other domestic events 
2024-02-04 05:06:26,662 	Text Hypothesis :	*** *** ***** **** *** ***** ******* ** vinesh phogat   got her   schedule changed
2024-02-04 05:06:26,662 	Text Alignment  :	D   D   D     D    D   D     D       D  S      S        S   S     S        S      
2024-02-04 05:06:26,662 ========================================================================================================================
2024-02-04 05:06:26,663 Logging Sequence: 94_253.00
2024-02-04 05:06:26,663 	Gloss Reference :	A B+C+D+E
2024-02-04 05:06:26,663 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:06:26,663 	Gloss Alignment :	         
2024-02-04 05:06:26,663 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:06:26,665 	Text Reference  :	however some tickets will be    kept aside       for   physical sale      at    the stadiums a few days prior to   the match    
2024-02-04 05:06:26,665 	Text Hypothesis :	******* for  the     sri  lanka vs   afghanistan match is       currently asked him with     a *** **** ***** huge fan following
2024-02-04 05:06:26,665 	Text Alignment  :	D       S    S       S    S     S    S           S     S        S         S     S   S          D   D    D     S    S   S        
2024-02-04 05:06:26,665 ========================================================================================================================
2024-02-04 05:06:26,665 Logging Sequence: 114_201.00
2024-02-04 05:06:26,666 	Gloss Reference :	A B+C+D+E
2024-02-04 05:06:26,666 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:06:26,666 	Gloss Alignment :	         
2024-02-04 05:06:26,666 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:06:26,667 	Text Reference  :	********** **** ** *** ********* *** **** this is    his first time winning the copa
2024-02-04 05:06:26,667 	Text Hypothesis :	vengsarkar said he was extremely fit when i    asked him about his  routine he  said
2024-02-04 05:06:26,667 	Text Alignment  :	I          I    I  I   I         I   I    S    S     S   S     S    S       S   S   
2024-02-04 05:06:26,667 ========================================================================================================================
2024-02-04 05:06:26,667 Logging Sequence: 118_104.00
2024-02-04 05:06:26,667 	Gloss Reference :	A B+C+D+E
2024-02-04 05:06:26,667 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:06:26,668 	Gloss Alignment :	         
2024-02-04 05:06:26,668 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:06:26,668 	Text Reference  :	kylian mbappã strong performance in  the   match was  greatly appreciated
2024-02-04 05:06:26,669 	Text Hypothesis :	after  the    tweet  he          was given a     sigh of      relief     
2024-02-04 05:06:26,669 	Text Alignment  :	S      S      S      S           S   S     S     S    S       S          
2024-02-04 05:06:26,669 ========================================================================================================================
2024-02-04 05:06:26,669 Logging Sequence: 144_74.00
2024-02-04 05:06:26,669 	Gloss Reference :	A B+C+D+E
2024-02-04 05:06:26,669 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:06:26,669 	Gloss Alignment :	         
2024-02-04 05:06:26,669 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:06:26,670 	Text Reference  :	** ***** isn't that amazing
2024-02-04 05:06:26,670 	Text Hypothesis :	so these are   the  rules  
2024-02-04 05:06:26,670 	Text Alignment  :	I  I     S     S    S      
2024-02-04 05:06:26,670 ========================================================================================================================
2024-02-04 05:06:32,259 [Epoch: 452 Step: 00060100] Batch Recognition Loss:   0.000197 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.027463 => Txt Tokens per Sec:     3923 || Lr: 0.000050
2024-02-04 05:06:33,187 Epoch 452: Total Training Recognition Loss 0.03  Total Training Translation Loss 11.01 
2024-02-04 05:06:33,188 EPOCH 453
2024-02-04 05:06:37,842 [Epoch: 453 Step: 00060200] Batch Recognition Loss:   0.000270 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.041208 => Txt Tokens per Sec:     4069 || Lr: 0.000050
2024-02-04 05:06:40,803 Epoch 453: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.19 
2024-02-04 05:06:40,803 EPOCH 454
2024-02-04 05:06:43,768 [Epoch: 454 Step: 00060300] Batch Recognition Loss:   0.000170 => Gls Tokens per Sec:     1377 || Batch Translation Loss:   0.012264 => Txt Tokens per Sec:     3800 || Lr: 0.000050
2024-02-04 05:06:48,318 Epoch 454: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.26 
2024-02-04 05:06:48,318 EPOCH 455
2024-02-04 05:06:49,290 [Epoch: 455 Step: 00060400] Batch Recognition Loss:   0.000338 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.029037 => Txt Tokens per Sec:     4037 || Lr: 0.000050
2024-02-04 05:06:55,000 [Epoch: 455 Step: 00060500] Batch Recognition Loss:   0.000121 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.020547 => Txt Tokens per Sec:     3904 || Lr: 0.000050
2024-02-04 05:06:55,938 Epoch 455: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.97 
2024-02-04 05:06:55,938 EPOCH 456
2024-02-04 05:07:00,709 [Epoch: 456 Step: 00060600] Batch Recognition Loss:   0.000274 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.017007 => Txt Tokens per Sec:     3940 || Lr: 0.000050
2024-02-04 05:07:03,455 Epoch 456: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.09 
2024-02-04 05:07:03,455 EPOCH 457
2024-02-04 05:07:06,419 [Epoch: 457 Step: 00060700] Batch Recognition Loss:   0.000222 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.049255 => Txt Tokens per Sec:     4101 || Lr: 0.000050
2024-02-04 05:07:11,260 Epoch 457: Total Training Recognition Loss 0.03  Total Training Translation Loss 2.58 
2024-02-04 05:07:11,260 EPOCH 458
2024-02-04 05:07:12,415 [Epoch: 458 Step: 00060800] Batch Recognition Loss:   0.000141 => Gls Tokens per Sec:     1317 || Batch Translation Loss:   0.016394 => Txt Tokens per Sec:     3989 || Lr: 0.000050
2024-02-04 05:07:17,815 [Epoch: 458 Step: 00060900] Batch Recognition Loss:   0.000165 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.025538 => Txt Tokens per Sec:     4083 || Lr: 0.000050
2024-02-04 05:07:18,701 Epoch 458: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.99 
2024-02-04 05:07:18,701 EPOCH 459
2024-02-04 05:07:23,364 [Epoch: 459 Step: 00061000] Batch Recognition Loss:   0.000213 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.046653 => Txt Tokens per Sec:     4076 || Lr: 0.000050
2024-02-04 05:07:26,071 Epoch 459: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.65 
2024-02-04 05:07:26,071 EPOCH 460
2024-02-04 05:07:28,542 [Epoch: 460 Step: 00061100] Batch Recognition Loss:   0.000205 => Gls Tokens per Sec:     1716 || Batch Translation Loss:   0.023301 => Txt Tokens per Sec:     4638 || Lr: 0.000050
2024-02-04 05:07:33,277 Epoch 460: Total Training Recognition Loss 0.03  Total Training Translation Loss 10.13 
2024-02-04 05:07:33,277 EPOCH 461
2024-02-04 05:07:34,355 [Epoch: 461 Step: 00061200] Batch Recognition Loss:   0.000149 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.031572 => Txt Tokens per Sec:     3948 || Lr: 0.000050
2024-02-04 05:07:39,966 [Epoch: 461 Step: 00061300] Batch Recognition Loss:   0.000303 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.041100 => Txt Tokens per Sec:     4011 || Lr: 0.000050
2024-02-04 05:07:40,639 Epoch 461: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.06 
2024-02-04 05:07:40,639 EPOCH 462
2024-02-04 05:07:45,188 [Epoch: 462 Step: 00061400] Batch Recognition Loss:   0.000278 => Gls Tokens per Sec:     1530 || Batch Translation Loss:   0.050296 => Txt Tokens per Sec:     4311 || Lr: 0.000050
2024-02-04 05:07:47,627 Epoch 462: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.73 
2024-02-04 05:07:47,627 EPOCH 463
2024-02-04 05:07:50,901 [Epoch: 463 Step: 00061500] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1320 || Batch Translation Loss:   0.034407 => Txt Tokens per Sec:     3683 || Lr: 0.000050
2024-02-04 05:07:55,248 Epoch 463: Total Training Recognition Loss 0.04  Total Training Translation Loss 13.30 
2024-02-04 05:07:55,248 EPOCH 464
2024-02-04 05:07:56,309 [Epoch: 464 Step: 00061600] Batch Recognition Loss:   0.000447 => Gls Tokens per Sec:     1586 || Batch Translation Loss:   0.029076 => Txt Tokens per Sec:     4687 || Lr: 0.000050
2024-02-04 05:08:01,577 [Epoch: 464 Step: 00061700] Batch Recognition Loss:   0.000304 => Gls Tokens per Sec:     1517 || Batch Translation Loss:   0.041506 => Txt Tokens per Sec:     4173 || Lr: 0.000050
2024-02-04 05:08:02,191 Epoch 464: Total Training Recognition Loss 0.04  Total Training Translation Loss 6.21 
2024-02-04 05:08:02,191 EPOCH 465
2024-02-04 05:08:06,797 [Epoch: 465 Step: 00061800] Batch Recognition Loss:   0.000386 => Gls Tokens per Sec:     1529 || Batch Translation Loss:   0.022701 => Txt Tokens per Sec:     4278 || Lr: 0.000050
2024-02-04 05:08:09,385 Epoch 465: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.12 
2024-02-04 05:08:09,385 EPOCH 466
2024-02-04 05:08:12,620 [Epoch: 466 Step: 00061900] Batch Recognition Loss:   0.000151 => Gls Tokens per Sec:     1361 || Batch Translation Loss:   0.010135 => Txt Tokens per Sec:     3830 || Lr: 0.000050
2024-02-04 05:08:17,096 Epoch 466: Total Training Recognition Loss 0.04  Total Training Translation Loss 6.02 
2024-02-04 05:08:17,097 EPOCH 467
2024-02-04 05:08:18,453 [Epoch: 467 Step: 00062000] Batch Recognition Loss:   0.000265 => Gls Tokens per Sec:     1298 || Batch Translation Loss:   0.173248 => Txt Tokens per Sec:     3794 || Lr: 0.000050
2024-02-04 05:08:29,498 Validation result at epoch 467, step    62000: duration: 11.0434s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00282	Translation Loss: 90866.87500	PPL: 8893.29492
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.93	(BLEU-1: 10.81,	BLEU-2: 3.45,	BLEU-3: 1.60,	BLEU-4: 0.93)
	CHRF 17.01	ROUGE 9.21
2024-02-04 05:08:29,499 Logging Recognition and Translation Outputs
2024-02-04 05:08:29,499 ========================================================================================================================
2024-02-04 05:08:29,499 Logging Sequence: 87_52.00
2024-02-04 05:08:29,499 	Gloss Reference :	A B+C+D+E
2024-02-04 05:08:29,499 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:08:29,499 	Gloss Alignment :	         
2024-02-04 05:08:29,499 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:08:29,501 	Text Reference  :	that is     when gambhir walked into bat   and  rescued india with   his brilliant 97      runs  
2024-02-04 05:08:29,501 	Text Hypothesis :	csk  scored 37   runs    in     20   overs they won     6     medals in  the       various groups
2024-02-04 05:08:29,501 	Text Alignment  :	S    S      S    S       S      S    S     S    S       S     S      S   S         S       S     
2024-02-04 05:08:29,501 ========================================================================================================================
2024-02-04 05:08:29,501 Logging Sequence: 85_2.00
2024-02-04 05:08:29,501 	Gloss Reference :	A B+C+D+E
2024-02-04 05:08:29,502 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:08:29,502 	Gloss Alignment :	         
2024-02-04 05:08:29,502 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:08:29,503 	Text Reference  :	** *** andrew symonds is      one   of      the finest all       rounders in the history of australian cricket
2024-02-04 05:08:29,503 	Text Hypothesis :	he was also   a       violent clash betweem the afghan pakistani fans     in *** ******* ** ********** india  
2024-02-04 05:08:29,503 	Text Alignment  :	I  I   S      S       S       S     S           S      S         S           D   D       D  D          S      
2024-02-04 05:08:29,503 ========================================================================================================================
2024-02-04 05:08:29,503 Logging Sequence: 51_110.00
2024-02-04 05:08:29,504 	Gloss Reference :	A B+C+D+E
2024-02-04 05:08:29,504 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:08:29,504 	Gloss Alignment :	         
2024-02-04 05:08:29,504 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:08:29,504 	Text Reference  :	the aussies were very happy with their   victory
2024-02-04 05:08:29,504 	Text Hypothesis :	*** ******* **** they own   the  lucknow team   
2024-02-04 05:08:29,505 	Text Alignment  :	D   D       D    S    S     S    S       S      
2024-02-04 05:08:29,505 ========================================================================================================================
2024-02-04 05:08:29,505 Logging Sequence: 72_59.00
2024-02-04 05:08:29,505 	Gloss Reference :	A B+C+D+E
2024-02-04 05:08:29,505 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:08:29,505 	Gloss Alignment :	         
2024-02-04 05:08:29,505 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:08:29,507 	Text Reference  :	*** *** after that sapna and *** * **** shobit started arguing and misbehaving with    the ***** ****** *** *** ******* ** cricketer
2024-02-04 05:08:29,507 	Text Hypothesis :	you all know  that kohli and put a very few    days    back    the argument    however the exact reason was not present to see      
2024-02-04 05:08:29,507 	Text Alignment  :	I   I   S          S         I   I I    S      S       S       S   S           S           I     I      I   I   I       I  S        
2024-02-04 05:08:29,507 ========================================================================================================================
2024-02-04 05:08:29,507 Logging Sequence: 122_184.00
2024-02-04 05:08:29,508 	Gloss Reference :	A B+C+D+E
2024-02-04 05:08:29,508 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:08:29,508 	Gloss Alignment :	         
2024-02-04 05:08:29,508 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:08:29,509 	Text Reference  :	are playing exceptionally well and keeping hopes of  further olympic medals alive
2024-02-04 05:08:29,509 	Text Hypothesis :	*** the     kiwis         won  the world   cup   for held    in      uae    oman 
2024-02-04 05:08:29,509 	Text Alignment  :	D   S       S             S    S   S       S     S   S       S       S      S    
2024-02-04 05:08:29,509 ========================================================================================================================
2024-02-04 05:08:35,179 [Epoch: 467 Step: 00062100] Batch Recognition Loss:   0.000297 => Gls Tokens per Sec:     1408 || Batch Translation Loss:   0.018143 => Txt Tokens per Sec:     3836 || Lr: 0.000050
2024-02-04 05:08:35,876 Epoch 467: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.48 
2024-02-04 05:08:35,876 EPOCH 468
2024-02-04 05:08:40,616 [Epoch: 468 Step: 00062200] Batch Recognition Loss:   0.000203 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   0.088728 => Txt Tokens per Sec:     4134 || Lr: 0.000050
2024-02-04 05:08:43,318 Epoch 468: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.79 
2024-02-04 05:08:43,318 EPOCH 469
2024-02-04 05:08:46,383 [Epoch: 469 Step: 00062300] Batch Recognition Loss:   0.000289 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.023660 => Txt Tokens per Sec:     4112 || Lr: 0.000050
2024-02-04 05:08:50,726 Epoch 469: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.47 
2024-02-04 05:08:50,727 EPOCH 470
2024-02-04 05:08:52,188 [Epoch: 470 Step: 00062400] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1260 || Batch Translation Loss:   0.027903 => Txt Tokens per Sec:     3710 || Lr: 0.000050
2024-02-04 05:08:57,503 [Epoch: 470 Step: 00062500] Batch Recognition Loss:   0.000260 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.042568 => Txt Tokens per Sec:     4083 || Lr: 0.000050
2024-02-04 05:08:58,065 Epoch 470: Total Training Recognition Loss 0.03  Total Training Translation Loss 9.06 
2024-02-04 05:08:58,065 EPOCH 471
2024-02-04 05:09:03,227 [Epoch: 471 Step: 00062600] Batch Recognition Loss:   0.000161 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.039525 => Txt Tokens per Sec:     3863 || Lr: 0.000050
2024-02-04 05:09:05,494 Epoch 471: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.94 
2024-02-04 05:09:05,495 EPOCH 472
2024-02-04 05:09:08,437 [Epoch: 472 Step: 00062700] Batch Recognition Loss:   0.000359 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.097631 => Txt Tokens per Sec:     4316 || Lr: 0.000050
2024-02-04 05:09:12,181 Epoch 472: Total Training Recognition Loss 0.04  Total Training Translation Loss 5.95 
2024-02-04 05:09:12,181 EPOCH 473
2024-02-04 05:09:13,424 [Epoch: 473 Step: 00062800] Batch Recognition Loss:   0.000223 => Gls Tokens per Sec:     1546 || Batch Translation Loss:   0.024096 => Txt Tokens per Sec:     4212 || Lr: 0.000050
2024-02-04 05:09:19,245 [Epoch: 473 Step: 00062900] Batch Recognition Loss:   0.000134 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   1.279346 => Txt Tokens per Sec:     3825 || Lr: 0.000050
2024-02-04 05:09:19,781 Epoch 473: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.64 
2024-02-04 05:09:19,781 EPOCH 474
2024-02-04 05:09:24,739 [Epoch: 474 Step: 00063000] Batch Recognition Loss:   0.000202 => Gls Tokens per Sec:     1469 || Batch Translation Loss:   0.020628 => Txt Tokens per Sec:     4044 || Lr: 0.000050
2024-02-04 05:09:27,076 Epoch 474: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.00 
2024-02-04 05:09:27,076 EPOCH 475
2024-02-04 05:09:29,945 [Epoch: 475 Step: 00063100] Batch Recognition Loss:   0.000172 => Gls Tokens per Sec:     1618 || Batch Translation Loss:   0.009498 => Txt Tokens per Sec:     4457 || Lr: 0.000050
2024-02-04 05:09:34,551 Epoch 475: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.07 
2024-02-04 05:09:34,552 EPOCH 476
2024-02-04 05:09:35,954 [Epoch: 476 Step: 00063200] Batch Recognition Loss:   0.000220 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.032825 => Txt Tokens per Sec:     3814 || Lr: 0.000050
2024-02-04 05:09:41,498 [Epoch: 476 Step: 00063300] Batch Recognition Loss:   0.000266 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.030347 => Txt Tokens per Sec:     4045 || Lr: 0.000050
2024-02-04 05:09:41,947 Epoch 476: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.44 
2024-02-04 05:09:41,948 EPOCH 477
2024-02-04 05:09:46,742 [Epoch: 477 Step: 00063400] Batch Recognition Loss:   0.000138 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   0.009480 => Txt Tokens per Sec:     4259 || Lr: 0.000050
2024-02-04 05:09:49,160 Epoch 477: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.45 
2024-02-04 05:09:49,161 EPOCH 478
2024-02-04 05:09:52,355 [Epoch: 478 Step: 00063500] Batch Recognition Loss:   0.000183 => Gls Tokens per Sec:     1479 || Batch Translation Loss:   0.011081 => Txt Tokens per Sec:     4100 || Lr: 0.000050
2024-02-04 05:09:56,841 Epoch 478: Total Training Recognition Loss 0.02  Total Training Translation Loss 4.72 
2024-02-04 05:09:56,842 EPOCH 479
2024-02-04 05:09:58,213 [Epoch: 479 Step: 00063600] Batch Recognition Loss:   0.000114 => Gls Tokens per Sec:     1518 || Batch Translation Loss:   0.010889 => Txt Tokens per Sec:     3980 || Lr: 0.000050
2024-02-04 05:10:03,878 [Epoch: 479 Step: 00063700] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.037396 => Txt Tokens per Sec:     4002 || Lr: 0.000050
2024-02-04 05:10:04,254 Epoch 479: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.90 
2024-02-04 05:10:04,255 EPOCH 480
2024-02-04 05:10:09,456 [Epoch: 480 Step: 00063800] Batch Recognition Loss:   0.000180 => Gls Tokens per Sec:     1431 || Batch Translation Loss:   0.026762 => Txt Tokens per Sec:     3983 || Lr: 0.000050
2024-02-04 05:10:11,574 Epoch 480: Total Training Recognition Loss 0.03  Total Training Translation Loss 7.50 
2024-02-04 05:10:11,575 EPOCH 481
2024-02-04 05:10:15,084 [Epoch: 481 Step: 00063900] Batch Recognition Loss:   0.000374 => Gls Tokens per Sec:     1368 || Batch Translation Loss:   0.076372 => Txt Tokens per Sec:     3882 || Lr: 0.000050
2024-02-04 05:10:19,058 Epoch 481: Total Training Recognition Loss 0.04  Total Training Translation Loss 12.17 
2024-02-04 05:10:19,058 EPOCH 482
2024-02-04 05:10:20,509 [Epoch: 482 Step: 00064000] Batch Recognition Loss:   0.000199 => Gls Tokens per Sec:     1489 || Batch Translation Loss:   0.028335 => Txt Tokens per Sec:     4206 || Lr: 0.000050
2024-02-04 05:10:31,173 Validation result at epoch 482, step    64000: duration: 10.6633s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00327	Translation Loss: 92121.04688	PPL: 10082.50879
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.40	(BLEU-1: 9.91,	BLEU-2: 2.85,	BLEU-3: 0.98,	BLEU-4: 0.40)
	CHRF 16.39	ROUGE 8.73
2024-02-04 05:10:31,174 Logging Recognition and Translation Outputs
2024-02-04 05:10:31,174 ========================================================================================================================
2024-02-04 05:10:31,175 Logging Sequence: 72_2.00
2024-02-04 05:10:31,175 	Gloss Reference :	A B+C+D+E
2024-02-04 05:10:31,175 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:10:31,175 	Gloss Alignment :	         
2024-02-04 05:10:31,175 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:10:31,178 	Text Reference  :	***** star  india batter     prithvi shaw and friend ashish yadav went to   a 5 star  hotel for     dinner on 15   february early morning
2024-02-04 05:10:31,178 	Text Hypothesis :	later mirza was   witnessing bad     form in  her    career and   she  took a * break from  playing tennis in 2017 for      a     surgery
2024-02-04 05:10:31,178 	Text Alignment  :	I     S     S     S          S       S    S   S      S      S     S    S      D S     S     S       S      S  S    S        S     S      
2024-02-04 05:10:31,178 ========================================================================================================================
2024-02-04 05:10:31,178 Logging Sequence: 138_257.00
2024-02-04 05:10:31,179 	Gloss Reference :	A B+C+D+E
2024-02-04 05:10:31,179 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:10:31,179 	Gloss Alignment :	         
2024-02-04 05:10:31,179 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:10:31,180 	Text Reference  :	*** ****** ** ****** have      vehemently condemned the    racial attacks towards the *** three players
2024-02-04 05:10:31,180 	Text Hypothesis :	the finals of junior wimbledon which      is        tennis for    players below   the age of    18     
2024-02-04 05:10:31,180 	Text Alignment  :	I   I      I  I      S         S          S         S      S      S       S           I   S     S      
2024-02-04 05:10:31,180 ========================================================================================================================
2024-02-04 05:10:31,180 Logging Sequence: 170_134.00
2024-02-04 05:10:31,181 	Gloss Reference :	A B+C+D+E
2024-02-04 05:10:31,181 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:10:31,181 	Gloss Alignment :	         
2024-02-04 05:10:31,181 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:10:31,183 	Text Reference  :	taylor felt that the owner at the back of the mind was upset that he     had  paid    8    crores but  taylor failed to    score a **** run 
2024-02-04 05:10:31,183 	Text Hypothesis :	****** **** **** *** ***** ** *** **** ** *** **** *** ***** now  people were shocked with this   news and    what   about him   a good luck
2024-02-04 05:10:31,183 	Text Alignment  :	D      D    D    D   D     D  D   D    D  D   D    D   D     S    S      S    S       S    S      S    S      S      S     S       I    S   
2024-02-04 05:10:31,183 ========================================================================================================================
2024-02-04 05:10:31,183 Logging Sequence: 70_39.00
2024-02-04 05:10:31,184 	Gloss Reference :	A B+C+D+E
2024-02-04 05:10:31,184 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:10:31,184 	Gloss Alignment :	         
2024-02-04 05:10:31,184 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:10:31,185 	Text Reference  :	well the tournament called euro 2020 when it    is        being held in    2021       
2024-02-04 05:10:31,185 	Text Hypothesis :	**** *** ********** ****** **** **** **** since pathirana was   the  first tie-breaker
2024-02-04 05:10:31,185 	Text Alignment  :	D    D   D          D      D    D    D    S     S         S     S    S     S          
2024-02-04 05:10:31,185 ========================================================================================================================
2024-02-04 05:10:31,185 Logging Sequence: 124_172.00
2024-02-04 05:10:31,185 	Gloss Reference :	A B+C+D+E
2024-02-04 05:10:31,185 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:10:31,185 	Gloss Alignment :	         
2024-02-04 05:10:31,186 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:10:31,187 	Text Reference  :	**** ********* ****** ******* the ipl   matches   will be   held     only in  pune mumbai at 25  capacity
2024-02-04 05:10:31,187 	Text Hypothesis :	bcci president sourav ganguly and board secretary jay  shah welcomed the  two new  teams  to the ipl     
2024-02-04 05:10:31,187 	Text Alignment  :	I    I         I      I       S   S     S         S    S    S        S    S   S    S      S  S   S       
2024-02-04 05:10:31,187 ========================================================================================================================
2024-02-04 05:10:36,731 [Epoch: 482 Step: 00064100] Batch Recognition Loss:   0.000199 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.028210 => Txt Tokens per Sec:     3967 || Lr: 0.000050
2024-02-04 05:10:37,064 Epoch 482: Total Training Recognition Loss 0.04  Total Training Translation Loss 10.81 
2024-02-04 05:10:37,065 EPOCH 483
2024-02-04 05:10:42,447 [Epoch: 483 Step: 00064200] Batch Recognition Loss:   0.000222 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.036780 => Txt Tokens per Sec:     3898 || Lr: 0.000050
2024-02-04 05:10:44,600 Epoch 483: Total Training Recognition Loss 0.04  Total Training Translation Loss 7.74 
2024-02-04 05:10:44,600 EPOCH 484
2024-02-04 05:10:48,042 [Epoch: 484 Step: 00064300] Batch Recognition Loss:   0.000154 => Gls Tokens per Sec:     1418 || Batch Translation Loss:   0.062385 => Txt Tokens per Sec:     4004 || Lr: 0.000050
2024-02-04 05:10:52,043 Epoch 484: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.58 
2024-02-04 05:10:52,044 EPOCH 485
2024-02-04 05:10:53,390 [Epoch: 485 Step: 00064400] Batch Recognition Loss:   0.000261 => Gls Tokens per Sec:     1668 || Batch Translation Loss:   0.047972 => Txt Tokens per Sec:     4336 || Lr: 0.000050
2024-02-04 05:10:59,592 [Epoch: 485 Step: 00064500] Batch Recognition Loss:   0.000142 => Gls Tokens per Sec:     1288 || Batch Translation Loss:   0.027890 => Txt Tokens per Sec:     3646 || Lr: 0.000050
2024-02-04 05:10:59,862 Epoch 485: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.92 
2024-02-04 05:10:59,862 EPOCH 486
2024-02-04 05:11:05,115 [Epoch: 486 Step: 00064600] Batch Recognition Loss:   0.000155 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.020057 => Txt Tokens per Sec:     4033 || Lr: 0.000050
2024-02-04 05:11:07,216 Epoch 486: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.09 
2024-02-04 05:11:07,217 EPOCH 487
2024-02-04 05:11:10,410 [Epoch: 487 Step: 00064700] Batch Recognition Loss:   0.000271 => Gls Tokens per Sec:     1553 || Batch Translation Loss:   0.022128 => Txt Tokens per Sec:     4333 || Lr: 0.000050
2024-02-04 05:11:14,522 Epoch 487: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.05 
2024-02-04 05:11:14,523 EPOCH 488
2024-02-04 05:11:16,206 [Epoch: 488 Step: 00064800] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.017545 => Txt Tokens per Sec:     4087 || Lr: 0.000050
2024-02-04 05:11:22,004 [Epoch: 488 Step: 00064900] Batch Recognition Loss:   0.000203 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.020931 => Txt Tokens per Sec:     3755 || Lr: 0.000050
2024-02-04 05:11:22,217 Epoch 488: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.35 
2024-02-04 05:11:22,217 EPOCH 489
2024-02-04 05:11:27,258 [Epoch: 489 Step: 00065000] Batch Recognition Loss:   0.000207 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.403035 => Txt Tokens per Sec:     4200 || Lr: 0.000050
2024-02-04 05:11:29,409 Epoch 489: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.44 
2024-02-04 05:11:29,409 EPOCH 490
2024-02-04 05:11:32,626 [Epoch: 490 Step: 00065100] Batch Recognition Loss:   0.000152 => Gls Tokens per Sec:     1567 || Batch Translation Loss:   0.012276 => Txt Tokens per Sec:     4127 || Lr: 0.000050
2024-02-04 05:11:37,120 Epoch 490: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.99 
2024-02-04 05:11:37,120 EPOCH 491
2024-02-04 05:11:38,831 [Epoch: 491 Step: 00065200] Batch Recognition Loss:   0.000143 => Gls Tokens per Sec:     1403 || Batch Translation Loss:   0.025604 => Txt Tokens per Sec:     3776 || Lr: 0.000050
2024-02-04 05:11:44,392 [Epoch: 491 Step: 00065300] Batch Recognition Loss:   0.000206 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.031853 => Txt Tokens per Sec:     4036 || Lr: 0.000050
2024-02-04 05:11:44,548 Epoch 491: Total Training Recognition Loss 0.03  Total Training Translation Loss 8.17 
2024-02-04 05:11:44,548 EPOCH 492
2024-02-04 05:11:50,021 [Epoch: 492 Step: 00065400] Batch Recognition Loss:   0.000146 => Gls Tokens per Sec:     1418 || Batch Translation Loss:   0.014632 => Txt Tokens per Sec:     3948 || Lr: 0.000050
2024-02-04 05:11:52,113 Epoch 492: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.40 
2024-02-04 05:11:52,113 EPOCH 493
2024-02-04 05:11:55,628 [Epoch: 493 Step: 00065500] Batch Recognition Loss:   0.000319 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.020252 => Txt Tokens per Sec:     3985 || Lr: 0.000050
2024-02-04 05:11:59,866 Epoch 493: Total Training Recognition Loss 0.03  Total Training Translation Loss 4.32 
2024-02-04 05:11:59,867 EPOCH 494
2024-02-04 05:12:01,530 [Epoch: 494 Step: 00065600] Batch Recognition Loss:   0.000236 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.020686 => Txt Tokens per Sec:     4152 || Lr: 0.000050
2024-02-04 05:12:07,390 [Epoch: 494 Step: 00065700] Batch Recognition Loss:   0.000305 => Gls Tokens per Sec:     1363 || Batch Translation Loss:   0.021172 => Txt Tokens per Sec:     3779 || Lr: 0.000050
2024-02-04 05:12:07,496 Epoch 494: Total Training Recognition Loss 0.03  Total Training Translation Loss 3.48 
2024-02-04 05:12:07,496 EPOCH 495
2024-02-04 05:12:12,932 [Epoch: 495 Step: 00065800] Batch Recognition Loss:   0.000197 => Gls Tokens per Sec:     1443 || Batch Translation Loss:   0.105398 => Txt Tokens per Sec:     4008 || Lr: 0.000050
2024-02-04 05:12:14,898 Epoch 495: Total Training Recognition Loss 0.03  Total Training Translation Loss 5.15 
2024-02-04 05:12:14,899 EPOCH 496
2024-02-04 05:12:18,368 [Epoch: 496 Step: 00065900] Batch Recognition Loss:   0.000150 => Gls Tokens per Sec:     1499 || Batch Translation Loss:   0.014948 => Txt Tokens per Sec:     4126 || Lr: 0.000050
2024-02-04 05:12:22,241 Epoch 496: Total Training Recognition Loss 0.03  Total Training Translation Loss 6.49 
2024-02-04 05:12:22,242 EPOCH 497
2024-02-04 05:12:23,946 [Epoch: 497 Step: 00066000] Batch Recognition Loss:   0.000297 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.052411 => Txt Tokens per Sec:     4322 || Lr: 0.000050
2024-02-04 05:12:34,508 Validation result at epoch 497, step    66000: duration: 10.5610s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 0.00391	Translation Loss: 91384.39062	PPL: 9365.98926
	Eval Metric: BLEU
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.74	(BLEU-1: 10.09,	BLEU-2: 3.01,	BLEU-3: 1.28,	BLEU-4: 0.74)
	CHRF 16.51	ROUGE 8.72
2024-02-04 05:12:34,508 Logging Recognition and Translation Outputs
2024-02-04 05:12:34,509 ========================================================================================================================
2024-02-04 05:12:34,509 Logging Sequence: 144_42.00
2024-02-04 05:12:34,509 	Gloss Reference :	A B+C+D+E
2024-02-04 05:12:34,509 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:12:34,509 	Gloss Alignment :	         
2024-02-04 05:12:34,509 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:12:34,510 	Text Reference  :	******* *** mumal was    overjoyed with     the  response
2024-02-04 05:12:34,510 	Text Hypothesis :	despite the delay people were      watching this match   
2024-02-04 05:12:34,510 	Text Alignment  :	I       I   S     S      S         S        S    S       
2024-02-04 05:12:34,510 ========================================================================================================================
2024-02-04 05:12:34,510 Logging Sequence: 116_162.00
2024-02-04 05:12:34,510 	Gloss Reference :	A B+C+D+E
2024-02-04 05:12:34,511 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:12:34,511 	Gloss Alignment :	         
2024-02-04 05:12:34,511 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:12:34,512 	Text Reference  :	turned out  the  video was shared on    social media by a      staff at the hotel
2024-02-04 05:12:34,512 	Text Hypothesis :	****** pant said that  he  can    never forget these 2  people ever  in his life 
2024-02-04 05:12:34,512 	Text Alignment  :	D      S    S    S     S   S      S     S      S     S  S      S     S  S   S    
2024-02-04 05:12:34,512 ========================================================================================================================
2024-02-04 05:12:34,513 Logging Sequence: 168_78.00
2024-02-04 05:12:34,513 	Gloss Reference :	A B+C+D+E
2024-02-04 05:12:34,513 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:12:34,513 	Gloss Alignment :	         
2024-02-04 05:12:34,513 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:12:34,514 	Text Reference  :	once she   posted a     picture eating at   a table but you could only see the back of   vamika's head     
2024-02-04 05:12:34,514 	Text Hypothesis :	**** virat kohli  actor anushka sharma have a ***** *** *** ***** **** *** *** **** huge fan      following
2024-02-04 05:12:34,515 	Text Alignment  :	D    S     S      S     S       S      S      D     D   D   D     D    D   D   D    S    S        S        
2024-02-04 05:12:34,515 ========================================================================================================================
2024-02-04 05:12:34,515 Logging Sequence: 118_223.00
2024-02-04 05:12:34,515 	Gloss Reference :	A B+C+D+E
2024-02-04 05:12:34,515 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:12:34,515 	Gloss Alignment :	         
2024-02-04 05:12:34,515 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:12:34,516 	Text Reference  :	her outfits were designed by the ****** ****** **** luxury company louis   vuitton 
2024-02-04 05:12:34,516 	Text Hypothesis :	it  is      not  known    as the indian team's goal from   the     penalty shootout
2024-02-04 05:12:34,516 	Text Alignment  :	S   S       S    S        S      I      I      I    S      S       S       S       
2024-02-04 05:12:34,517 ========================================================================================================================
2024-02-04 05:12:34,517 Logging Sequence: 132_125.00
2024-02-04 05:12:34,517 	Gloss Reference :	A B+C+D+E
2024-02-04 05:12:34,517 	Gloss Hypothesis:	A B+C+D+E
2024-02-04 05:12:34,517 	Gloss Alignment :	         
2024-02-04 05:12:34,517 	--------------------------------------------------------------------------------------------------------------------
2024-02-04 05:12:34,518 	Text Reference  :	'œusman is muslim and does not    drink alcohol because of  his religious beliefs
2024-02-04 05:12:34,518 	Text Hypothesis :	******* ** one    day on   social media was     playing for his ********* mother 
2024-02-04 05:12:34,518 	Text Alignment  :	D       D  S      S   S    S      S     S       S       S       D         S      
2024-02-04 05:12:34,518 ========================================================================================================================
2024-02-04 05:12:34,522 Training ended since there were no improvements inthe last learning rate step: 0.000050
2024-02-04 05:12:34,522 Best validation result at step    14000:   0.99 eval_metric.
2024-02-04 05:12:59,794 ------------------------------------------------------------
2024-02-04 05:12:59,794 [DEV] partition [RECOGNITION] experiment [BW]: 1
2024-02-04 05:13:11,172 finished in 11.3787s 
2024-02-04 05:13:11,173 ************************************************************
2024-02-04 05:13:11,173 [DEV] partition [RECOGNITION] results:
	New Best CTC Decode Beam Size: 1
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
2024-02-04 05:13:11,173 ************************************************************
2024-02-04 05:13:11,173 ------------------------------------------------------------
2024-02-04 05:13:11,173 [DEV] partition [RECOGNITION] experiment [BW]: 2
2024-02-04 05:13:21,921 finished in 10.7474s 
2024-02-04 05:13:21,922 ------------------------------------------------------------
2024-02-04 05:13:21,922 [DEV] partition [RECOGNITION] experiment [BW]: 3
2024-02-04 05:13:32,605 finished in 10.6830s 
2024-02-04 05:13:32,605 ------------------------------------------------------------
2024-02-04 05:13:32,605 [DEV] partition [RECOGNITION] experiment [BW]: 4
2024-02-04 05:13:43,571 finished in 10.9658s 
2024-02-04 05:13:43,571 ------------------------------------------------------------
2024-02-04 05:13:43,572 [DEV] partition [RECOGNITION] experiment [BW]: 5
2024-02-04 05:13:54,228 finished in 10.6563s 
2024-02-04 05:13:54,229 ------------------------------------------------------------
2024-02-04 05:13:54,229 [DEV] partition [RECOGNITION] experiment [BW]: 6
2024-02-04 05:14:04,805 finished in 10.5747s 
2024-02-04 05:14:04,805 ------------------------------------------------------------
2024-02-04 05:14:04,805 [DEV] partition [RECOGNITION] experiment [BW]: 7
2024-02-04 05:14:15,729 finished in 10.9239s 
2024-02-04 05:14:15,729 ------------------------------------------------------------
2024-02-04 05:14:15,729 [DEV] partition [RECOGNITION] experiment [BW]: 8
2024-02-04 05:14:26,619 finished in 10.8890s 
2024-02-04 05:14:26,619 ------------------------------------------------------------
2024-02-04 05:14:26,620 [DEV] partition [RECOGNITION] experiment [BW]: 9
2024-02-04 05:14:37,372 finished in 10.7527s 
2024-02-04 05:14:37,373 ------------------------------------------------------------
2024-02-04 05:14:37,373 [DEV] partition [RECOGNITION] experiment [BW]: 10
2024-02-04 05:14:48,204 finished in 10.8312s 
2024-02-04 05:14:48,205 ============================================================
2024-02-04 05:14:58,876 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: -1
	BLEU-4 0.99	(BLEU-1: 11.00,	BLEU-2: 3.71,	BLEU-3: 1.74,	BLEU-4: 0.99)
	CHRF 17.18	ROUGE 9.42
2024-02-04 05:14:58,877 ------------------------------------------------------------
2024-02-04 05:21:35,430 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 5 and Alpha: 3
	BLEU-4 1.01	(BLEU-1: 10.90,	BLEU-2: 3.64,	BLEU-3: 1.70,	BLEU-4: 1.01)
	CHRF 16.93	ROUGE 9.34
2024-02-04 05:21:35,430 ------------------------------------------------------------
2024-02-04 05:31:20,328 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 10 and Alpha: 4
	BLEU-4 1.01	(BLEU-1: 10.95,	BLEU-2: 3.66,	BLEU-3: 1.70,	BLEU-4: 1.01)
	CHRF 17.09	ROUGE 9.41
2024-02-04 05:31:20,329 ------------------------------------------------------------
2024-02-04 05:31:38,608 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 10 and Alpha: 5
	BLEU-4 1.01	(BLEU-1: 10.96,	BLEU-2: 3.67,	BLEU-3: 1.71,	BLEU-4: 1.01)
	CHRF 17.10	ROUGE 9.42
2024-02-04 05:31:38,609 ------------------------------------------------------------
2024-02-04 05:31:38,609 ************************************************************
2024-02-04 05:31:38,609 [DEV] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 1
	Best Translation Beam Size: 10 and Alpha: 5
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 1.01	(BLEU-1: 10.96,	BLEU-2: 3.67,	BLEU-3: 1.71,	BLEU-4: 1.01)
	CHRF 17.10	ROUGE 9.42
2024-02-04 05:31:38,609 ************************************************************
2024-02-04 05:31:56,919 [TEST] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 1
	Best Translation Beam Size: 10 and Alpha: 5
	WER 0.00	(DEL: 0.00,	INS: 0.00,	SUB: 0.00)
	BLEU-4 0.84	(BLEU-1: 10.49,	BLEU-2: 3.42,	BLEU-3: 1.51,	BLEU-4: 0.84)
	CHRF 17.11	ROUGE 8.71
2024-02-04 05:31:56,920 ************************************************************
