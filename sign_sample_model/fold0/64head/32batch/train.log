2024-01-31 01:24:58,772 Hello! This is Joey-NMT.
2024-01-31 01:24:58,784 Total params: 25639944
2024-01-31 01:24:58,785 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2024-01-31 01:24:58,972 cfg.name                           : sign_experiment
2024-01-31 01:24:58,973 cfg.data.data_path                 : ./data/Sports_dataset/0/
2024-01-31 01:24:58,973 cfg.data.version                   : phoenix_2014_trans
2024-01-31 01:24:58,973 cfg.data.sgn                       : sign
2024-01-31 01:24:58,973 cfg.data.txt                       : text
2024-01-31 01:24:58,973 cfg.data.gls                       : gloss
2024-01-31 01:24:58,973 cfg.data.train                     : excel_data.train
2024-01-31 01:24:58,974 cfg.data.dev                       : excel_data.dev
2024-01-31 01:24:58,974 cfg.data.test                      : excel_data.test
2024-01-31 01:24:58,974 cfg.data.feature_size              : 2560
2024-01-31 01:24:58,974 cfg.data.level                     : word
2024-01-31 01:24:58,974 cfg.data.txt_lowercase             : True
2024-01-31 01:24:58,974 cfg.data.max_sent_length           : 500
2024-01-31 01:24:58,974 cfg.data.random_train_subset       : -1
2024-01-31 01:24:58,974 cfg.data.random_dev_subset         : -1
2024-01-31 01:24:58,974 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-01-31 01:24:58,975 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-01-31 01:24:58,975 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2024-01-31 01:24:58,975 cfg.training.reset_best_ckpt       : True
2024-01-31 01:24:58,975 cfg.training.reset_scheduler       : True
2024-01-31 01:24:58,975 cfg.training.reset_optimizer       : True
2024-01-31 01:24:58,975 cfg.training.random_seed           : 42
2024-01-31 01:24:58,975 cfg.training.model_dir             : ./sign_sample_model/fold0/64head/32batch
2024-01-31 01:24:58,975 cfg.training.recognition_loss_weight : 1.0
2024-01-31 01:24:58,976 cfg.training.translation_loss_weight : 1.0
2024-01-31 01:24:58,976 cfg.training.eval_metric           : bleu
2024-01-31 01:24:58,976 cfg.training.optimizer             : adam
2024-01-31 01:24:58,976 cfg.training.learning_rate         : 0.0001
2024-01-31 01:24:58,976 cfg.training.batch_size            : 32
2024-01-31 01:24:58,976 cfg.training.num_valid_log         : 5
2024-01-31 01:24:58,976 cfg.training.epochs                : 50000
2024-01-31 01:24:58,976 cfg.training.early_stopping_metric : eval_metric
2024-01-31 01:24:58,977 cfg.training.batch_type            : sentence
2024-01-31 01:24:58,977 cfg.training.translation_normalization : batch
2024-01-31 01:24:58,977 cfg.training.eval_recognition_beam_size : 1
2024-01-31 01:24:58,977 cfg.training.eval_translation_beam_size : 1
2024-01-31 01:24:58,977 cfg.training.eval_translation_beam_alpha : -1
2024-01-31 01:24:58,977 cfg.training.overwrite             : True
2024-01-31 01:24:58,977 cfg.training.shuffle               : True
2024-01-31 01:24:58,977 cfg.training.use_cuda              : True
2024-01-31 01:24:58,977 cfg.training.translation_max_output_length : 40
2024-01-31 01:24:58,978 cfg.training.keep_last_ckpts       : 1
2024-01-31 01:24:58,978 cfg.training.batch_multiplier      : 1
2024-01-31 01:24:58,978 cfg.training.logging_freq          : 100
2024-01-31 01:24:58,978 cfg.training.validation_freq       : 2000
2024-01-31 01:24:58,978 cfg.training.betas                 : [0.9, 0.998]
2024-01-31 01:24:58,978 cfg.training.scheduling            : plateau
2024-01-31 01:24:58,978 cfg.training.learning_rate_min     : 1e-08
2024-01-31 01:24:58,978 cfg.training.weight_decay          : 0.0001
2024-01-31 01:24:58,978 cfg.training.patience              : 12
2024-01-31 01:24:58,979 cfg.training.decrease_factor       : 0.5
2024-01-31 01:24:58,979 cfg.training.label_smoothing       : 0.1
2024-01-31 01:24:58,979 cfg.model.initializer              : xavier
2024-01-31 01:24:58,979 cfg.model.bias_initializer         : zeros
2024-01-31 01:24:58,979 cfg.model.init_gain                : 1.0
2024-01-31 01:24:58,979 cfg.model.embed_initializer        : xavier
2024-01-31 01:24:58,979 cfg.model.embed_init_gain          : 1.0
2024-01-31 01:24:58,979 cfg.model.tied_softmax             : True
2024-01-31 01:24:58,980 cfg.model.encoder.type             : transformer
2024-01-31 01:24:58,980 cfg.model.encoder.num_layers       : 3
2024-01-31 01:24:58,980 cfg.model.encoder.num_heads        : 64
2024-01-31 01:24:58,980 cfg.model.encoder.embeddings.embedding_dim : 512
2024-01-31 01:24:58,980 cfg.model.encoder.embeddings.scale : False
2024-01-31 01:24:58,980 cfg.model.encoder.embeddings.dropout : 0.1
2024-01-31 01:24:58,980 cfg.model.encoder.embeddings.norm_type : batch
2024-01-31 01:24:58,980 cfg.model.encoder.embeddings.activation_type : softsign
2024-01-31 01:24:58,980 cfg.model.encoder.hidden_size      : 512
2024-01-31 01:24:58,981 cfg.model.encoder.ff_size          : 2048
2024-01-31 01:24:58,981 cfg.model.encoder.dropout          : 0.1
2024-01-31 01:24:58,981 cfg.model.decoder.type             : transformer
2024-01-31 01:24:58,981 cfg.model.decoder.num_layers       : 3
2024-01-31 01:24:58,981 cfg.model.decoder.num_heads        : 64
2024-01-31 01:24:58,981 cfg.model.decoder.embeddings.embedding_dim : 512
2024-01-31 01:24:58,981 cfg.model.decoder.embeddings.scale : False
2024-01-31 01:24:58,981 cfg.model.decoder.embeddings.dropout : 0.1
2024-01-31 01:24:58,981 cfg.model.decoder.embeddings.norm_type : batch
2024-01-31 01:24:58,982 cfg.model.decoder.embeddings.activation_type : softsign
2024-01-31 01:24:58,982 cfg.model.decoder.hidden_size      : 512
2024-01-31 01:24:58,982 cfg.model.decoder.ff_size          : 2048
2024-01-31 01:24:58,982 cfg.model.decoder.dropout          : 0.1
2024-01-31 01:24:58,982 Data set sizes: 
	train 2126,
	valid 708,
	test 706
2024-01-31 01:24:58,982 First training example:
	[GLS] A B C D E
	[TXT] although new zealand was disappointed to faltered at the finals against australia they did well throughout the tournament
2024-01-31 01:24:58,982 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) A (4) B (5) C (6) D (7) E
2024-01-31 01:24:58,982 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) and (6) to (7) a (8) in (9) of
2024-01-31 01:24:58,983 Number of unique glosses (types): 8
2024-01-31 01:24:58,983 Number of unique words (types): 4397
2024-01-31 01:24:58,983 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=64),
	decoder=TransformerDecoder(num_layers=3, num_heads=64),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=2560),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=4397))
2024-01-31 01:24:58,986 EPOCH 1
2024-01-31 01:25:32,303 Epoch   1: Total Training Recognition Loss 2125.50  Total Training Translation Loss 6847.76 
2024-01-31 01:25:32,304 EPOCH 2
2024-01-31 01:25:45,458 [Epoch: 002 Step: 00000100] Batch Recognition Loss:  37.376713 => Gls Tokens per Sec:      401 || Batch Translation Loss:  97.560478 => Txt Tokens per Sec:     1144 || Lr: 0.000100
2024-01-31 01:25:57,595 Epoch   2: Total Training Recognition Loss 2129.12  Total Training Translation Loss 6848.13 
2024-01-31 01:25:57,595 EPOCH 3
2024-01-31 01:26:22,871 [Epoch: 003 Step: 00000200] Batch Recognition Loss:  27.380039 => Gls Tokens per Sec:      414 || Batch Translation Loss: 100.896667 => Txt Tokens per Sec:     1152 || Lr: 0.000100
2024-01-31 01:26:23,054 Epoch   3: Total Training Recognition Loss 2128.22  Total Training Translation Loss 6850.54 
2024-01-31 01:26:23,055 EPOCH 4
2024-01-31 01:26:48,706 Epoch   4: Total Training Recognition Loss 2128.77  Total Training Translation Loss 6847.51 
2024-01-31 01:26:48,706 EPOCH 5
2024-01-31 01:26:59,491 [Epoch: 005 Step: 00000300] Batch Recognition Loss:  40.463692 => Gls Tokens per Sec:      475 || Batch Translation Loss: 110.819847 => Txt Tokens per Sec:     1258 || Lr: 0.000100
2024-01-31 01:27:14,316 Epoch   5: Total Training Recognition Loss 2123.72  Total Training Translation Loss 6849.67 
2024-01-31 01:27:14,316 EPOCH 6
2024-01-31 01:27:39,071 [Epoch: 006 Step: 00000400] Batch Recognition Loss:  37.614113 => Gls Tokens per Sec:      417 || Batch Translation Loss:  95.545944 => Txt Tokens per Sec:     1154 || Lr: 0.000100
2024-01-31 01:27:39,999 Epoch   6: Total Training Recognition Loss 2127.17  Total Training Translation Loss 6848.70 
2024-01-31 01:27:39,999 EPOCH 7
2024-01-31 01:28:05,549 Epoch   7: Total Training Recognition Loss 2127.96  Total Training Translation Loss 6848.46 
2024-01-31 01:28:05,549 EPOCH 8
2024-01-31 01:28:17,338 [Epoch: 008 Step: 00000500] Batch Recognition Loss:  18.580078 => Gls Tokens per Sec:      421 || Batch Translation Loss:  82.787979 => Txt Tokens per Sec:     1188 || Lr: 0.000100
2024-01-31 01:28:31,149 Epoch   8: Total Training Recognition Loss 2122.78  Total Training Translation Loss 6847.17 
2024-01-31 01:28:31,149 EPOCH 9
2024-01-31 01:28:55,599 [Epoch: 009 Step: 00000600] Batch Recognition Loss:  38.841942 => Gls Tokens per Sec:      415 || Batch Translation Loss: 124.396591 => Txt Tokens per Sec:     1149 || Lr: 0.000100
2024-01-31 01:28:56,678 Epoch   9: Total Training Recognition Loss 2129.46  Total Training Translation Loss 6848.08 
2024-01-31 01:28:56,679 EPOCH 10
2024-01-31 01:29:22,223 Epoch  10: Total Training Recognition Loss 2125.68  Total Training Translation Loss 6849.14 
2024-01-31 01:29:22,223 EPOCH 11
2024-01-31 01:29:33,487 [Epoch: 011 Step: 00000700] Batch Recognition Loss:  12.654350 => Gls Tokens per Sec:      426 || Batch Translation Loss:  65.256088 => Txt Tokens per Sec:     1163 || Lr: 0.000100
2024-01-31 01:29:47,847 Epoch  11: Total Training Recognition Loss 2126.10  Total Training Translation Loss 6848.96 
2024-01-31 01:29:47,847 EPOCH 12
2024-01-31 01:30:11,948 [Epoch: 012 Step: 00000800] Batch Recognition Loss:  38.016785 => Gls Tokens per Sec:      415 || Batch Translation Loss: 126.579819 => Txt Tokens per Sec:     1151 || Lr: 0.000100
2024-01-31 01:30:13,339 Epoch  12: Total Training Recognition Loss 2127.53  Total Training Translation Loss 6848.38 
2024-01-31 01:30:13,339 EPOCH 13
2024-01-31 01:30:39,006 Epoch  13: Total Training Recognition Loss 2128.08  Total Training Translation Loss 6848.45 
2024-01-31 01:30:39,006 EPOCH 14
2024-01-31 01:30:52,240 [Epoch: 014 Step: 00000900] Batch Recognition Loss:  36.853134 => Gls Tokens per Sec:      351 || Batch Translation Loss: 118.925064 => Txt Tokens per Sec:     1031 || Lr: 0.000100
2024-01-31 01:31:04,670 Epoch  14: Total Training Recognition Loss 2126.68  Total Training Translation Loss 6849.61 
2024-01-31 01:31:04,670 EPOCH 15
2024-01-31 01:31:28,525 [Epoch: 015 Step: 00001000] Batch Recognition Loss:  27.676395 => Gls Tokens per Sec:      412 || Batch Translation Loss: 110.665588 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 01:31:30,373 Epoch  15: Total Training Recognition Loss 2126.69  Total Training Translation Loss 6848.04 
2024-01-31 01:31:30,374 EPOCH 16
2024-01-31 01:31:55,695 Epoch  16: Total Training Recognition Loss 2129.60  Total Training Translation Loss 6847.46 
2024-01-31 01:31:55,695 EPOCH 17
2024-01-31 01:32:07,477 [Epoch: 017 Step: 00001100] Batch Recognition Loss:  11.386707 => Gls Tokens per Sec:      373 || Batch Translation Loss:  63.154358 => Txt Tokens per Sec:     1042 || Lr: 0.000100
2024-01-31 01:32:21,143 Epoch  17: Total Training Recognition Loss 2127.96  Total Training Translation Loss 6848.89 
2024-01-31 01:32:21,143 EPOCH 18
2024-01-31 01:32:43,972 [Epoch: 018 Step: 00001200] Batch Recognition Loss:  30.018070 => Gls Tokens per Sec:      424 || Batch Translation Loss: 106.131042 => Txt Tokens per Sec:     1163 || Lr: 0.000100
2024-01-31 01:32:46,714 Epoch  18: Total Training Recognition Loss 2128.94  Total Training Translation Loss 6849.37 
2024-01-31 01:32:46,715 EPOCH 19
2024-01-31 01:33:12,177 Epoch  19: Total Training Recognition Loss 2129.71  Total Training Translation Loss 6848.51 
2024-01-31 01:33:12,178 EPOCH 20
2024-01-31 01:33:22,281 [Epoch: 020 Step: 00001300] Batch Recognition Loss:  27.738056 => Gls Tokens per Sec:      428 || Batch Translation Loss:  93.576248 => Txt Tokens per Sec:     1172 || Lr: 0.000100
2024-01-31 01:33:37,914 Epoch  20: Total Training Recognition Loss 2125.24  Total Training Translation Loss 6849.60 
2024-01-31 01:33:37,914 EPOCH 21
2024-01-31 01:34:00,652 [Epoch: 021 Step: 00001400] Batch Recognition Loss:  26.947018 => Gls Tokens per Sec:      418 || Batch Translation Loss:  91.594437 => Txt Tokens per Sec:     1148 || Lr: 0.000100
2024-01-31 01:34:03,524 Epoch  21: Total Training Recognition Loss 2128.45  Total Training Translation Loss 6846.58 
2024-01-31 01:34:03,525 EPOCH 22
2024-01-31 01:34:28,976 Epoch  22: Total Training Recognition Loss 2125.86  Total Training Translation Loss 6848.02 
2024-01-31 01:34:28,976 EPOCH 23
2024-01-31 01:34:38,730 [Epoch: 023 Step: 00001500] Batch Recognition Loss:  34.513943 => Gls Tokens per Sec:      427 || Batch Translation Loss:  91.179230 => Txt Tokens per Sec:     1154 || Lr: 0.000100
2024-01-31 01:34:54,467 Epoch  23: Total Training Recognition Loss 2128.17  Total Training Translation Loss 6849.71 
2024-01-31 01:34:54,467 EPOCH 24
2024-01-31 01:35:16,078 [Epoch: 024 Step: 00001600] Batch Recognition Loss:  37.809551 => Gls Tokens per Sec:      433 || Batch Translation Loss: 125.145683 => Txt Tokens per Sec:     1203 || Lr: 0.000100
2024-01-31 01:35:20,052 Epoch  24: Total Training Recognition Loss 2128.20  Total Training Translation Loss 6848.63 
2024-01-31 01:35:20,052 EPOCH 25
2024-01-31 01:35:45,711 Epoch  25: Total Training Recognition Loss 2123.99  Total Training Translation Loss 6849.24 
2024-01-31 01:35:45,711 EPOCH 26
2024-01-31 01:35:54,962 [Epoch: 026 Step: 00001700] Batch Recognition Loss:  40.806389 => Gls Tokens per Sec:      432 || Batch Translation Loss: 135.621185 => Txt Tokens per Sec:     1210 || Lr: 0.000100
2024-01-31 01:36:11,311 Epoch  26: Total Training Recognition Loss 2128.42  Total Training Translation Loss 6847.13 
2024-01-31 01:36:11,312 EPOCH 27
2024-01-31 01:36:36,836 [Epoch: 027 Step: 00001800] Batch Recognition Loss:  39.020912 => Gls Tokens per Sec:      360 || Batch Translation Loss: 127.024406 => Txt Tokens per Sec:     1001 || Lr: 0.000100
2024-01-31 01:36:40,245 Epoch  27: Total Training Recognition Loss 2126.74  Total Training Translation Loss 6848.13 
2024-01-31 01:36:40,245 EPOCH 28
2024-01-31 01:37:08,995 Epoch  28: Total Training Recognition Loss 2130.54  Total Training Translation Loss 6847.88 
2024-01-31 01:37:08,995 EPOCH 29
2024-01-31 01:37:18,254 [Epoch: 029 Step: 00001900] Batch Recognition Loss:  11.456881 => Gls Tokens per Sec:      415 || Batch Translation Loss:  63.101658 => Txt Tokens per Sec:     1176 || Lr: 0.000100
2024-01-31 01:37:34,965 Epoch  29: Total Training Recognition Loss 2126.09  Total Training Translation Loss 6847.07 
2024-01-31 01:37:34,966 EPOCH 30
2024-01-31 01:37:57,270 [Epoch: 030 Step: 00002000] Batch Recognition Loss:  15.811484 => Gls Tokens per Sec:      405 || Batch Translation Loss:  73.104050 => Txt Tokens per Sec:     1110 || Lr: 0.000100
2024-01-31 01:38:27,270 Hooray! New best validation result [eval_metric]!
2024-01-31 01:38:27,277 Saving new checkpoint.
2024-01-31 01:38:28,279 Validation result at epoch  30, step     2000: duration: 31.0075s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 684.40283	Translation Loss: 73476.65625	PPL: 1560.57971
	Eval Metric: BLEU
	WER 552.75	(DEL: 4.17,	INS: 464.55,	SUB: 84.04)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.43	ROUGE 0.01
2024-01-31 01:38:28,281 Logging Recognition and Translation Outputs
2024-01-31 01:38:28,281 ========================================================================================================================
2024-01-31 01:38:28,281 Logging Sequence: 182_115.00
2024-01-31 01:38:28,281 	Gloss Reference :	A B+C+D+E
2024-01-31 01:38:28,281 	Gloss Hypothesis:	E C+E+B+E
2024-01-31 01:38:28,282 	Gloss Alignment :	S S      
2024-01-31 01:38:28,282 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:38:28,286 	Text Reference  :	*** *** *** *** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** fans   are    unclear whether yuvraj will   be     returning to     play   test   match  odi    or     in     t20    leagues from   february 2022  
2024-01-31 01:38:28,286 	Text Hypothesis :	<s> <s> <s> <s> chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen  chosen  chosen chosen chosen chosen    chosen chosen chosen chosen chosen chosen chosen chosen chosen  chosen chosen   chosen
2024-01-31 01:38:28,286 	Text Alignment  :	I   I   I   I   I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      S      S      S       S       S      S      S      S         S      S      S      S      S      S      S      S      S       S      S        S     
2024-01-31 01:38:28,286 ========================================================================================================================
2024-01-31 01:38:28,287 Logging Sequence: 140_120.00
2024-01-31 01:38:28,287 	Gloss Reference :	A B+C+D+E
2024-01-31 01:38:28,287 	Gloss Hypothesis:	* E      
2024-01-31 01:38:28,287 	Gloss Alignment :	D S      
2024-01-31 01:38:28,287 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:38:28,292 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** but why so  it  is  because pant is  a   talented player and it  will help encouraging the youth of  uttarakhand toward sports
2024-01-31 01:38:28,292 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s>  <s> <s> <s>      <s>    <s> <s> <s>  <s>  <s>         <s> <s>   <s> <s>         <s>    <s>   
2024-01-31 01:38:28,292 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S   S   S   S   S       S    S   S   S        S      S   S   S    S    S           S   S     S   S           S      S     
2024-01-31 01:38:28,292 ========================================================================================================================
2024-01-31 01:38:28,292 Logging Sequence: 85_36.00
2024-01-31 01:38:28,293 	Gloss Reference :	***** ***** ***** A ***** * ***** ******* ***** ***** ***** * ***** *** ***** B+C+D+E
2024-01-31 01:38:28,293 	Gloss Hypothesis:	<unk> <pad> <unk> A <unk> C <unk> C+E+C+B <pad> C+E+C <unk> C <unk> C+E <unk> E      
2024-01-31 01:38:28,293 	Gloss Alignment :	I     I     I       I     I I     I       I     I     I     I I     I   I     S      
2024-01-31 01:38:28,293 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:38:28,296 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** symonds has scored 2   centuries in  26  tests that he  played for his country
2024-01-31 01:38:28,296 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s> <s>    <s> <s>       <s> <s> <s>   <s>  <s> <s>    <s> <s> <s>    
2024-01-31 01:38:28,296 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S       S   S      S   S         S   S   S     S    S   S      S   S   S      
2024-01-31 01:38:28,296 ========================================================================================================================
2024-01-31 01:38:28,296 Logging Sequence: 164_100.00
2024-01-31 01:38:28,297 	Gloss Reference :	* A     B+C+D+E                          
2024-01-31 01:38:28,297 	Gloss Hypothesis:	E <unk> E+C+E+D+E+C+E+C+E+C+E+C+E+C+E+C+E
2024-01-31 01:38:28,297 	Gloss Alignment :	I S     S                                
2024-01-31 01:38:28,297 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:38:28,302 	Text Reference  :	*** *** *** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** the    tv     rights for    broadcasting ipl    matches in     india  for    the    next   5      years  went   to     star   india  for    rs     23575  crore 
2024-01-31 01:38:28,302 	Text Hypothesis :	<s> <s> <s> boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards       boards boards  boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards
2024-01-31 01:38:28,302 	Text Alignment  :	I   I   I   I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      S      S      S      S      S            S      S       S      S      S      S      S      S      S      S      S      S      S      S      S      S      S     
2024-01-31 01:38:28,302 ========================================================================================================================
2024-01-31 01:38:28,302 Logging Sequence: 76_79.00
2024-01-31 01:38:28,303 	Gloss Reference :	***** ***** ***** * ***** * ***** * A     B+C+D+E  
2024-01-31 01:38:28,303 	Gloss Hypothesis:	<unk> E+A+E <unk> C <unk> E <unk> E <unk> E+C+E+B+E
2024-01-31 01:38:28,303 	Gloss Alignment :	I     I     I     I I     I I     I S     S        
2024-01-31 01:38:28,303 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:38:28,305 	Text Reference  :	*** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* speaking to      ani     csk     ceo     kasi    viswanathan said   
2024-01-31 01:38:28,305 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing  nothing nothing nothing nothing nothing nothing     nothing
2024-01-31 01:38:28,305 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S        S       S       S       S       S       S           S      
2024-01-31 01:38:28,305 ========================================================================================================================
2024-01-31 01:38:34,675 Epoch  30: Total Training Recognition Loss 2127.27  Total Training Translation Loss 6844.66 
2024-01-31 01:38:34,676 EPOCH 31
2024-01-31 01:39:02,414 Epoch  31: Total Training Recognition Loss 2124.31  Total Training Translation Loss 6847.91 
2024-01-31 01:39:02,415 EPOCH 32
2024-01-31 01:39:12,413 [Epoch: 032 Step: 00002100] Batch Recognition Loss:  17.231327 => Gls Tokens per Sec:      368 || Batch Translation Loss:  64.834610 => Txt Tokens per Sec:     1025 || Lr: 0.000100
2024-01-31 01:39:27,928 Epoch  32: Total Training Recognition Loss 2127.99  Total Training Translation Loss 6847.95 
2024-01-31 01:39:27,928 EPOCH 33
2024-01-31 01:39:49,412 [Epoch: 033 Step: 00002200] Batch Recognition Loss:  32.288219 => Gls Tokens per Sec:      417 || Batch Translation Loss:  98.140755 => Txt Tokens per Sec:     1176 || Lr: 0.000100
2024-01-31 01:39:53,337 Epoch  33: Total Training Recognition Loss 2129.25  Total Training Translation Loss 6849.71 
2024-01-31 01:39:53,337 EPOCH 34
2024-01-31 01:40:18,830 Epoch  34: Total Training Recognition Loss 2126.23  Total Training Translation Loss 6849.33 
2024-01-31 01:40:18,831 EPOCH 35
2024-01-31 01:40:28,252 [Epoch: 035 Step: 00002300] Batch Recognition Loss:  38.198002 => Gls Tokens per Sec:      364 || Batch Translation Loss: 116.442657 => Txt Tokens per Sec:     1004 || Lr: 0.000100
2024-01-31 01:40:44,174 Epoch  35: Total Training Recognition Loss 2122.35  Total Training Translation Loss 6847.04 
2024-01-31 01:40:44,174 EPOCH 36
2024-01-31 01:41:03,478 [Epoch: 036 Step: 00002400] Batch Recognition Loss:   7.164417 => Gls Tokens per Sec:      451 || Batch Translation Loss:  55.111149 => Txt Tokens per Sec:     1238 || Lr: 0.000100
2024-01-31 01:41:10,901 Epoch  36: Total Training Recognition Loss 2127.13  Total Training Translation Loss 6849.10 
2024-01-31 01:41:10,901 EPOCH 37
2024-01-31 01:41:36,355 Epoch  37: Total Training Recognition Loss 2129.26  Total Training Translation Loss 6847.49 
2024-01-31 01:41:36,356 EPOCH 38
2024-01-31 01:41:45,227 [Epoch: 038 Step: 00002500] Batch Recognition Loss:  22.901176 => Gls Tokens per Sec:      379 || Batch Translation Loss:  95.800148 => Txt Tokens per Sec:     1116 || Lr: 0.000100
2024-01-31 01:42:01,870 Epoch  38: Total Training Recognition Loss 2124.78  Total Training Translation Loss 6847.66 
2024-01-31 01:42:01,871 EPOCH 39
2024-01-31 01:42:23,790 [Epoch: 039 Step: 00002600] Batch Recognition Loss:  27.242645 => Gls Tokens per Sec:      390 || Batch Translation Loss:  89.472015 => Txt Tokens per Sec:     1112 || Lr: 0.000100
2024-01-31 01:42:27,347 Epoch  39: Total Training Recognition Loss 2125.81  Total Training Translation Loss 6847.94 
2024-01-31 01:42:27,347 EPOCH 40
2024-01-31 01:42:52,722 Epoch  40: Total Training Recognition Loss 2129.19  Total Training Translation Loss 6850.32 
2024-01-31 01:42:52,723 EPOCH 41
2024-01-31 01:42:58,806 [Epoch: 041 Step: 00002700] Batch Recognition Loss:  37.338676 => Gls Tokens per Sec:      526 || Batch Translation Loss: 121.623314 => Txt Tokens per Sec:     1402 || Lr: 0.000100
2024-01-31 01:43:18,202 Epoch  41: Total Training Recognition Loss 2128.74  Total Training Translation Loss 6848.57 
2024-01-31 01:43:18,202 EPOCH 42
2024-01-31 01:43:38,630 [Epoch: 042 Step: 00002800] Batch Recognition Loss:  37.690346 => Gls Tokens per Sec:      415 || Batch Translation Loss: 109.019440 => Txt Tokens per Sec:     1162 || Lr: 0.000100
2024-01-31 01:43:43,813 Epoch  42: Total Training Recognition Loss 2122.27  Total Training Translation Loss 6847.25 
2024-01-31 01:43:43,814 EPOCH 43
2024-01-31 01:44:09,553 Epoch  43: Total Training Recognition Loss 2126.91  Total Training Translation Loss 6848.75 
2024-01-31 01:44:09,554 EPOCH 44
2024-01-31 01:44:16,831 [Epoch: 044 Step: 00002900] Batch Recognition Loss:  12.477989 => Gls Tokens per Sec:      405 || Batch Translation Loss:  65.467056 => Txt Tokens per Sec:     1122 || Lr: 0.000100
2024-01-31 01:44:35,216 Epoch  44: Total Training Recognition Loss 2125.47  Total Training Translation Loss 6848.30 
2024-01-31 01:44:35,216 EPOCH 45
2024-01-31 01:44:54,173 [Epoch: 045 Step: 00003000] Batch Recognition Loss:  34.581581 => Gls Tokens per Sec:      434 || Batch Translation Loss: 112.996620 => Txt Tokens per Sec:     1175 || Lr: 0.000100
2024-01-31 01:45:00,893 Epoch  45: Total Training Recognition Loss 2124.97  Total Training Translation Loss 6848.12 
2024-01-31 01:45:00,893 EPOCH 46
2024-01-31 01:45:26,520 Epoch  46: Total Training Recognition Loss 2124.60  Total Training Translation Loss 6846.72 
2024-01-31 01:45:26,520 EPOCH 47
2024-01-31 01:45:30,976 [Epoch: 047 Step: 00003100] Batch Recognition Loss:  29.898928 => Gls Tokens per Sec:      646 || Batch Translation Loss:  92.340927 => Txt Tokens per Sec:     1581 || Lr: 0.000100
2024-01-31 01:45:52,173 Epoch  47: Total Training Recognition Loss 2123.23  Total Training Translation Loss 6848.06 
2024-01-31 01:45:52,173 EPOCH 48
2024-01-31 01:46:13,736 [Epoch: 048 Step: 00003200] Batch Recognition Loss:  33.921993 => Gls Tokens per Sec:      378 || Batch Translation Loss:  97.497696 => Txt Tokens per Sec:     1039 || Lr: 0.000100
2024-01-31 01:46:20,687 Epoch  48: Total Training Recognition Loss 2125.87  Total Training Translation Loss 6848.59 
2024-01-31 01:46:20,687 EPOCH 49
2024-01-31 01:46:46,752 Epoch  49: Total Training Recognition Loss 2122.51  Total Training Translation Loss 6848.84 
2024-01-31 01:46:46,752 EPOCH 50
2024-01-31 01:46:52,576 [Epoch: 050 Step: 00003300] Batch Recognition Loss:  38.382160 => Gls Tokens per Sec:      467 || Batch Translation Loss: 126.804153 => Txt Tokens per Sec:     1298 || Lr: 0.000100
2024-01-31 01:47:12,313 Epoch  50: Total Training Recognition Loss 2131.93  Total Training Translation Loss 6848.17 
2024-01-31 01:47:12,313 EPOCH 51
2024-01-31 01:47:31,911 [Epoch: 051 Step: 00003400] Batch Recognition Loss:  33.210442 => Gls Tokens per Sec:      404 || Batch Translation Loss: 113.225494 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 01:47:37,932 Epoch  51: Total Training Recognition Loss 2125.14  Total Training Translation Loss 6849.35 
2024-01-31 01:47:37,933 EPOCH 52
2024-01-31 01:48:03,396 Epoch  52: Total Training Recognition Loss 2127.96  Total Training Translation Loss 6848.15 
2024-01-31 01:48:03,396 EPOCH 53
2024-01-31 01:48:09,810 [Epoch: 053 Step: 00003500] Batch Recognition Loss:  31.893347 => Gls Tokens per Sec:      399 || Batch Translation Loss:  94.712326 => Txt Tokens per Sec:     1142 || Lr: 0.000100
2024-01-31 01:48:28,939 Epoch  53: Total Training Recognition Loss 2125.73  Total Training Translation Loss 6848.67 
2024-01-31 01:48:28,940 EPOCH 54
2024-01-31 01:48:47,006 [Epoch: 054 Step: 00003600] Batch Recognition Loss:  33.610977 => Gls Tokens per Sec:      434 || Batch Translation Loss: 103.628349 => Txt Tokens per Sec:     1189 || Lr: 0.000100
2024-01-31 01:48:54,427 Epoch  54: Total Training Recognition Loss 2126.16  Total Training Translation Loss 6849.80 
2024-01-31 01:48:54,427 EPOCH 55
2024-01-31 01:49:19,968 Epoch  55: Total Training Recognition Loss 2126.20  Total Training Translation Loss 6847.74 
2024-01-31 01:49:19,968 EPOCH 56
2024-01-31 01:49:28,121 [Epoch: 056 Step: 00003700] Batch Recognition Loss:  28.034803 => Gls Tokens per Sec:      283 || Batch Translation Loss:  86.154106 => Txt Tokens per Sec:      843 || Lr: 0.000100
2024-01-31 01:49:45,451 Epoch  56: Total Training Recognition Loss 2126.47  Total Training Translation Loss 6848.96 
2024-01-31 01:49:45,451 EPOCH 57
2024-01-31 01:50:04,006 [Epoch: 057 Step: 00003800] Batch Recognition Loss:  37.840412 => Gls Tokens per Sec:      414 || Batch Translation Loss: 129.454956 => Txt Tokens per Sec:     1150 || Lr: 0.000100
2024-01-31 01:50:10,979 Epoch  57: Total Training Recognition Loss 2131.40  Total Training Translation Loss 6848.88 
2024-01-31 01:50:10,979 EPOCH 58
2024-01-31 01:50:36,537 Epoch  58: Total Training Recognition Loss 2130.06  Total Training Translation Loss 6849.87 
2024-01-31 01:50:36,537 EPOCH 59
2024-01-31 01:50:41,682 [Epoch: 059 Step: 00003900] Batch Recognition Loss:  36.121567 => Gls Tokens per Sec:      436 || Batch Translation Loss: 132.983826 => Txt Tokens per Sec:     1195 || Lr: 0.000100
2024-01-31 01:51:02,013 Epoch  59: Total Training Recognition Loss 2123.75  Total Training Translation Loss 6848.07 
2024-01-31 01:51:02,013 EPOCH 60
2024-01-31 01:51:19,622 [Epoch: 060 Step: 00004000] Batch Recognition Loss:  27.613483 => Gls Tokens per Sec:      422 || Batch Translation Loss: 111.898994 => Txt Tokens per Sec:     1169 || Lr: 0.000100
2024-01-31 01:51:49,453 Validation result at epoch  60, step     4000: duration: 29.8317s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 688.70282	Translation Loss: 73449.53906	PPL: 1556.35071
	Eval Metric: BLEU
	WER 561.30	(DEL: 4.24,	INS: 472.95,	SUB: 84.11)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.47	ROUGE 0.00
2024-01-31 01:51:49,454 Logging Recognition and Translation Outputs
2024-01-31 01:51:49,454 ========================================================================================================================
2024-01-31 01:51:49,454 Logging Sequence: 133_173.00
2024-01-31 01:51:49,455 	Gloss Reference :	A B+C+D+E
2024-01-31 01:51:49,455 	Gloss Hypothesis:	* E      
2024-01-31 01:51:49,455 	Gloss Alignment :	D S      
2024-01-31 01:51:49,455 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:51:49,459 	Text Reference  :	*** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* according     to            sources       the           leaders       of            the           two           countries     are           set           to            join          the           commentary    panel         as            well         
2024-01-31 01:51:49,459 	Text Hypothesis :	<s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 01:51:49,460 	Text Alignment  :	I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 01:51:49,460 ========================================================================================================================
2024-01-31 01:51:49,460 Logging Sequence: 83_33.00
2024-01-31 01:51:49,460 	Gloss Reference :	***** * ***** * ***** ***** * ***** *** ***** * ***** *********************** ***** ***** ***** ***** * ***** ***** ***** ***************************** A     B+C+D+E
2024-01-31 01:51:49,460 	Gloss Hypothesis:	<pad> B <pad> B <unk> <pad> C <unk> D+E <pad> B <unk> C+B+E+C+E+D+C+E+C+E+B+E <pad> <unk> <pad> <unk> C <unk> <pad> <unk> E+C+B+C+B+D+C+E+C+E+C+E+C+E+C <unk> E      
2024-01-31 01:51:49,461 	Gloss Alignment :	I     I I     I I     I     I I     I   I     I I     I                       I     I     I     I     I I     I     I     I                             S     S      
2024-01-31 01:51:49,461 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:51:49,463 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** a   football match lasts for two equal halves of  45  minutes
2024-01-31 01:51:49,463 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>      <s>   <s>   <s> <s> <s>   <s>    <s> <s> <s>    
2024-01-31 01:51:49,463 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S        S     S     S   S   S     S      S   S   S      
2024-01-31 01:51:49,463 ========================================================================================================================
2024-01-31 01:51:49,464 Logging Sequence: 68_147.00
2024-01-31 01:51:49,464 	Gloss Reference :	***** * ***** * ***** ******* ***** * ***** ***************** ***** * ***** *** ***** * ***** * ***** ************* ***** *********** ***** * A     B+C+D+E
2024-01-31 01:51:49,464 	Gloss Hypothesis:	<unk> C <pad> C <pad> E+C+E+D <unk> C <unk> C+E+B+E+C+B+E+C+E <pad> D <unk> C+E <unk> C <unk> E <unk> E+C+E+C+B+E+C <pad> C+E+C+E+C+E <unk> E <unk> E      
2024-01-31 01:51:49,464 	Gloss Alignment :	I     I I     I I     I       I     I I     I                 I     I I     I   I     I I     I I     I             I     I           I     I S     S      
2024-01-31 01:51:49,464 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:51:49,468 	Text Reference  :	*** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** remember the   2007  t20   world cup   amid  a     lot   of    sledging by    english players
2024-01-31 01:51:49,468 	Text Hypothesis :	<s> <s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    sabha sabha   sabha  
2024-01-31 01:51:49,468 	Text Alignment  :	I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S        S     S     S     S     S     S     S     S     S     S        S     S       S      
2024-01-31 01:51:49,468 ========================================================================================================================
2024-01-31 01:51:49,468 Logging Sequence: 165_8.00
2024-01-31 01:51:49,468 	Gloss Reference :	***** ***************** A     B+C+D+E
2024-01-31 01:51:49,469 	Gloss Hypothesis:	<unk> E+B+E+A+E+A+E+A+E <unk> E      
2024-01-31 01:51:49,469 	Gloss Alignment :	I     I                 S     S      
2024-01-31 01:51:49,469 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:51:49,471 	Text Reference  :	*** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** however many  don't believe in    it    it    varies among people
2024-01-31 01:51:49,471 	Text Hypothesis :	<s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha   sabha sabha sabha   sabha sabha sabha sabha  sabha sabha 
2024-01-31 01:51:49,471 	Text Alignment  :	I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S       S     S     S       S     S     S     S      S     S     
2024-01-31 01:51:49,471 ========================================================================================================================
2024-01-31 01:51:49,471 Logging Sequence: 119_71.00
2024-01-31 01:51:49,472 	Gloss Reference :	***** * ***** * ***** * ***** ***** A     B+C+D+E  
2024-01-31 01:51:49,472 	Gloss Hypothesis:	<pad> B <pad> B <pad> B <pad> B+E+B <pad> B+E+B+E+B
2024-01-31 01:51:49,472 	Gloss Alignment :	I     I I     I I     I I     I     S     S        
2024-01-31 01:51:49,472 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 01:51:49,475 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** the special gold devices have each player' names and jersey numbers next to  the camera
2024-01-31 01:51:49,476 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s>  <s>     <s>  <s>  <s>     <s>   <s> <s>    <s>     <s>  <s> <s> <s>   
2024-01-31 01:51:49,476 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S       S    S       S    S    S       S     S   S      S       S    S   S   S     
2024-01-31 01:51:49,476 ========================================================================================================================
2024-01-31 01:51:57,590 Epoch  60: Total Training Recognition Loss 2125.96  Total Training Translation Loss 6848.86 
2024-01-31 01:51:57,590 EPOCH 61
2024-01-31 01:52:23,079 Epoch  61: Total Training Recognition Loss 2129.26  Total Training Translation Loss 6848.51 
2024-01-31 01:52:23,080 EPOCH 62
2024-01-31 01:52:27,969 [Epoch: 062 Step: 00004100] Batch Recognition Loss:  40.832016 => Gls Tokens per Sec:      426 || Batch Translation Loss: 118.175682 => Txt Tokens per Sec:     1163 || Lr: 0.000100
2024-01-31 01:52:48,624 Epoch  62: Total Training Recognition Loss 2127.01  Total Training Translation Loss 6848.17 
2024-01-31 01:52:48,624 EPOCH 63
2024-01-31 01:53:04,153 [Epoch: 063 Step: 00004200] Batch Recognition Loss:  23.390179 => Gls Tokens per Sec:      474 || Batch Translation Loss:  83.047440 => Txt Tokens per Sec:     1295 || Lr: 0.000100
2024-01-31 01:53:14,145 Epoch  63: Total Training Recognition Loss 2125.17  Total Training Translation Loss 6849.27 
2024-01-31 01:53:14,146 EPOCH 64
2024-01-31 01:53:39,861 Epoch  64: Total Training Recognition Loss 2128.16  Total Training Translation Loss 6848.63 
2024-01-31 01:53:39,862 EPOCH 65
2024-01-31 01:53:43,005 [Epoch: 065 Step: 00004300] Batch Recognition Loss:  16.111536 => Gls Tokens per Sec:      611 || Batch Translation Loss:  70.423576 => Txt Tokens per Sec:     1519 || Lr: 0.000100
2024-01-31 01:54:05,280 Epoch  65: Total Training Recognition Loss 2128.19  Total Training Translation Loss 6849.22 
2024-01-31 01:54:05,280 EPOCH 66
2024-01-31 01:54:24,330 [Epoch: 066 Step: 00004400] Batch Recognition Loss:  30.300640 => Gls Tokens per Sec:      373 || Batch Translation Loss: 109.254303 => Txt Tokens per Sec:     1062 || Lr: 0.000100
2024-01-31 01:54:30,866 Epoch  66: Total Training Recognition Loss 2127.70  Total Training Translation Loss 6847.90 
2024-01-31 01:54:30,866 EPOCH 67
2024-01-31 01:54:56,391 Epoch  67: Total Training Recognition Loss 2127.14  Total Training Translation Loss 6847.66 
2024-01-31 01:54:56,391 EPOCH 68
2024-01-31 01:55:00,604 [Epoch: 068 Step: 00004500] Batch Recognition Loss:  31.293743 => Gls Tokens per Sec:      396 || Batch Translation Loss:  90.978676 => Txt Tokens per Sec:     1083 || Lr: 0.000100
2024-01-31 01:55:22,022 Epoch  68: Total Training Recognition Loss 2129.38  Total Training Translation Loss 6848.92 
2024-01-31 01:55:22,022 EPOCH 69
2024-01-31 01:55:38,075 [Epoch: 069 Step: 00004600] Batch Recognition Loss:  17.052998 => Gls Tokens per Sec:      433 || Batch Translation Loss:  80.973450 => Txt Tokens per Sec:     1191 || Lr: 0.000100
2024-01-31 01:55:47,680 Epoch  69: Total Training Recognition Loss 2125.44  Total Training Translation Loss 6848.99 
2024-01-31 01:55:47,680 EPOCH 70
2024-01-31 01:56:13,289 Epoch  70: Total Training Recognition Loss 2125.66  Total Training Translation Loss 6849.06 
2024-01-31 01:56:13,289 EPOCH 71
2024-01-31 01:56:17,087 [Epoch: 071 Step: 00004700] Batch Recognition Loss:  38.175934 => Gls Tokens per Sec:      421 || Batch Translation Loss:  98.819397 => Txt Tokens per Sec:     1064 || Lr: 0.000100
2024-01-31 01:56:38,827 Epoch  71: Total Training Recognition Loss 2126.78  Total Training Translation Loss 6849.15 
2024-01-31 01:56:38,827 EPOCH 72
2024-01-31 01:56:57,217 [Epoch: 072 Step: 00004800] Batch Recognition Loss:  44.988365 => Gls Tokens per Sec:      369 || Batch Translation Loss: 122.618965 => Txt Tokens per Sec:     1050 || Lr: 0.000100
2024-01-31 01:57:04,520 Epoch  72: Total Training Recognition Loss 2127.23  Total Training Translation Loss 6847.36 
2024-01-31 01:57:04,520 EPOCH 73
2024-01-31 01:57:30,107 Epoch  73: Total Training Recognition Loss 2124.36  Total Training Translation Loss 6849.25 
2024-01-31 01:57:30,107 EPOCH 74
2024-01-31 01:57:34,676 [Epoch: 074 Step: 00004900] Batch Recognition Loss:  54.546860 => Gls Tokens per Sec:      315 || Batch Translation Loss: 132.673218 => Txt Tokens per Sec:      927 || Lr: 0.000100
2024-01-31 01:57:55,737 Epoch  74: Total Training Recognition Loss 2129.55  Total Training Translation Loss 6847.71 
2024-01-31 01:57:55,737 EPOCH 75
2024-01-31 01:58:10,360 [Epoch: 075 Step: 00005000] Batch Recognition Loss:  23.222425 => Gls Tokens per Sec:      460 || Batch Translation Loss:  80.056808 => Txt Tokens per Sec:     1246 || Lr: 0.000100
2024-01-31 01:58:21,172 Epoch  75: Total Training Recognition Loss 2125.26  Total Training Translation Loss 6849.21 
2024-01-31 01:58:21,172 EPOCH 76
2024-01-31 01:58:46,799 Epoch  76: Total Training Recognition Loss 2130.46  Total Training Translation Loss 6849.81 
2024-01-31 01:58:46,799 EPOCH 77
2024-01-31 01:58:51,213 [Epoch: 077 Step: 00005100] Batch Recognition Loss:  38.390991 => Gls Tokens per Sec:      270 || Batch Translation Loss: 103.882050 => Txt Tokens per Sec:      773 || Lr: 0.000100
2024-01-31 01:59:12,326 Epoch  77: Total Training Recognition Loss 2129.30  Total Training Translation Loss 6849.99 
2024-01-31 01:59:12,326 EPOCH 78
2024-01-31 01:59:27,197 [Epoch: 078 Step: 00005200] Batch Recognition Loss:  27.613625 => Gls Tokens per Sec:      435 || Batch Translation Loss:  85.604591 => Txt Tokens per Sec:     1166 || Lr: 0.000100
2024-01-31 01:59:37,789 Epoch  78: Total Training Recognition Loss 2126.79  Total Training Translation Loss 6846.77 
2024-01-31 01:59:37,790 EPOCH 79
2024-01-31 02:00:03,415 Epoch  79: Total Training Recognition Loss 2127.02  Total Training Translation Loss 6847.98 
2024-01-31 02:00:03,416 EPOCH 80
2024-01-31 02:00:06,171 [Epoch: 080 Step: 00005300] Batch Recognition Loss:  38.799080 => Gls Tokens per Sec:      407 || Batch Translation Loss: 126.685638 => Txt Tokens per Sec:     1104 || Lr: 0.000100
2024-01-31 02:00:29,041 Epoch  80: Total Training Recognition Loss 2130.81  Total Training Translation Loss 6847.17 
2024-01-31 02:00:29,041 EPOCH 81
2024-01-31 02:00:43,940 [Epoch: 081 Step: 00005400] Batch Recognition Loss:  37.296219 => Gls Tokens per Sec:      430 || Batch Translation Loss: 121.157227 => Txt Tokens per Sec:     1193 || Lr: 0.000100
2024-01-31 02:00:54,722 Epoch  81: Total Training Recognition Loss 2127.20  Total Training Translation Loss 6847.92 
2024-01-31 02:00:54,722 EPOCH 82
2024-01-31 02:01:20,398 Epoch  82: Total Training Recognition Loss 2124.72  Total Training Translation Loss 6848.56 
2024-01-31 02:01:20,398 EPOCH 83
2024-01-31 02:01:22,778 [Epoch: 083 Step: 00005500] Batch Recognition Loss:  41.613510 => Gls Tokens per Sec:      404 || Batch Translation Loss: 115.890373 => Txt Tokens per Sec:     1177 || Lr: 0.000100
2024-01-31 02:01:46,051 Epoch  83: Total Training Recognition Loss 2131.75  Total Training Translation Loss 6846.77 
2024-01-31 02:01:46,051 EPOCH 84
2024-01-31 02:02:02,594 [Epoch: 084 Step: 00005600] Batch Recognition Loss:  22.301287 => Gls Tokens per Sec:      372 || Batch Translation Loss:  80.620598 => Txt Tokens per Sec:     1081 || Lr: 0.000100
2024-01-31 02:02:11,736 Epoch  84: Total Training Recognition Loss 2131.23  Total Training Translation Loss 6848.47 
2024-01-31 02:02:11,736 EPOCH 85
2024-01-31 02:02:37,273 Epoch  85: Total Training Recognition Loss 2124.59  Total Training Translation Loss 6846.58 
2024-01-31 02:02:37,274 EPOCH 86
2024-01-31 02:02:38,760 [Epoch: 086 Step: 00005700] Batch Recognition Loss:  35.654591 => Gls Tokens per Sec:      538 || Batch Translation Loss: 123.855568 => Txt Tokens per Sec:     1457 || Lr: 0.000100
2024-01-31 02:03:02,869 Epoch  86: Total Training Recognition Loss 2125.24  Total Training Translation Loss 6850.00 
2024-01-31 02:03:02,869 EPOCH 87
2024-01-31 02:03:16,848 [Epoch: 087 Step: 00005800] Batch Recognition Loss:  18.101204 => Gls Tokens per Sec:      429 || Batch Translation Loss:  85.742897 => Txt Tokens per Sec:     1186 || Lr: 0.000100
2024-01-31 02:03:28,450 Epoch  87: Total Training Recognition Loss 2126.08  Total Training Translation Loss 6846.30 
2024-01-31 02:03:28,451 EPOCH 88
2024-01-31 02:03:53,959 Epoch  88: Total Training Recognition Loss 2126.34  Total Training Translation Loss 6849.49 
2024-01-31 02:03:53,960 EPOCH 89
2024-01-31 02:03:55,286 [Epoch: 089 Step: 00005900] Batch Recognition Loss:  11.516045 => Gls Tokens per Sec:      483 || Batch Translation Loss:  61.732246 => Txt Tokens per Sec:     1339 || Lr: 0.000100
2024-01-31 02:04:19,876 Epoch  89: Total Training Recognition Loss 2127.52  Total Training Translation Loss 6848.69 
2024-01-31 02:04:19,876 EPOCH 90
2024-01-31 02:04:33,837 [Epoch: 090 Step: 00006000] Batch Recognition Loss:  26.975475 => Gls Tokens per Sec:      418 || Batch Translation Loss: 109.250008 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 02:05:03,319 Validation result at epoch  90, step     6000: duration: 29.4818s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 699.02509	Translation Loss: 73453.59375	PPL: 1556.98254
	Eval Metric: BLEU
	WER 579.45	(DEL: 3.81,	INS: 491.31,	SUB: 84.32)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.41	ROUGE 0.00
2024-01-31 02:05:03,320 Logging Recognition and Translation Outputs
2024-01-31 02:05:03,320 ========================================================================================================================
2024-01-31 02:05:03,320 Logging Sequence: 89_111.00
2024-01-31 02:05:03,321 	Gloss Reference :	***** * ***** A ***** * ***** * ***** * ***** *** ***** *** ***** * ***** * B+C+D+E
2024-01-31 02:05:03,321 	Gloss Hypothesis:	<unk> C <unk> A <unk> D <unk> E <unk> C <unk> C+E <unk> E+C <unk> E <unk> E <unk>  
2024-01-31 02:05:03,321 	Gloss Alignment :	I     I I       I     I I     I I     I I     I   I     I   I     I I     I S      
2024-01-31 02:05:03,321 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:05:03,323 	Text Reference  :	***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** however selectors never selected me    for   the   team 
2024-01-31 02:05:03,323 	Text Hypothesis :	sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha   sabha     sabha sabha    sabha sabha sabha sabha
2024-01-31 02:05:03,323 	Text Alignment  :	I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S       S         S     S        S     S     S     S    
2024-01-31 02:05:03,323 ========================================================================================================================
2024-01-31 02:05:03,323 Logging Sequence: 137_23.00
2024-01-31 02:05:03,324 	Gloss Reference :	***** ***** ***** ***** ***** ***** ***** ***** ***** ***** * ***** A B+C+D+E
2024-01-31 02:05:03,324 	Gloss Hypothesis:	<unk> <pad> <unk> <pad> <unk> <pad> <unk> <pad> <unk> <pad> A <unk> A <unk>  
2024-01-31 02:05:03,324 	Gloss Alignment :	I     I     I     I     I     I     I     I     I     I     I I       S      
2024-01-31 02:05:03,324 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:05:03,327 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** fan from around the world are in  qatar for the fifa world cup
2024-01-31 02:05:03,327 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s>    <s> <s>   <s> <s> <s>   <s> <s> <s>  <s>   <s>
2024-01-31 02:05:03,327 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S    S      S   S     S   S   S     S   S   S    S     S  
2024-01-31 02:05:03,327 ========================================================================================================================
2024-01-31 02:05:03,328 Logging Sequence: 128_145.00
2024-01-31 02:05:03,328 	Gloss Reference :	***** ***** A ***** * ***** B+C+D+E
2024-01-31 02:05:03,328 	Gloss Hypothesis:	<unk> <pad> A <unk> E <unk> <pad>  
2024-01-31 02:05:03,328 	Gloss Alignment :	I     I       I     I I     S      
2024-01-31 02:05:03,328 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:05:03,330 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** icc also uploaded a   video of  the same
2024-01-31 02:05:03,330 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s>      <s> <s>   <s> <s> <s> 
2024-01-31 02:05:03,330 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S    S        S   S     S   S   S   
2024-01-31 02:05:03,330 ========================================================================================================================
2024-01-31 02:05:03,331 Logging Sequence: 165_192.00
2024-01-31 02:05:03,331 	Gloss Reference :	* ******* A     B+C+D+E                
2024-01-31 02:05:03,331 	Gloss Hypothesis:	E A+E+A+E <unk> E+C+E+C+A+C+E+A+E+C+E+C
2024-01-31 02:05:03,331 	Gloss Alignment :	I I       S     S                      
2024-01-31 02:05:03,331 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:05:03,333 	Text Reference  :	*** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* 3             ravichandran  ashwin        believes      that          his           bag           is            lucky        
2024-01-31 02:05:03,333 	Text Hypothesis :	<s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 02:05:03,334 	Text Alignment  :	I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S            
2024-01-31 02:05:03,334 ========================================================================================================================
2024-01-31 02:05:03,334 Logging Sequence: 180_494.00
2024-01-31 02:05:03,334 	Gloss Reference :	* ******************************* A     B+C+D+E            
2024-01-31 02:05:03,334 	Gloss Hypothesis:	C E+B+C+E+C+B+E+C+B+C+B+C+E+C+E+B <unk> C+E+C+E+B+C+B+C+B+C
2024-01-31 02:05:03,334 	Gloss Alignment :	I I                               S     S                  
2024-01-31 02:05:03,334 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:05:03,338 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** the women wrestlers spoke angrily against the police and the controversy in  front of  the media
2024-01-31 02:05:03,338 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s>       <s>   <s>     <s>     <s> <s>    <s> <s> <s>         <s> <s>   <s> <s> <s>  
2024-01-31 02:05:03,338 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S     S         S     S       S       S   S      S   S   S           S   S     S   S   S    
2024-01-31 02:05:03,338 ========================================================================================================================
2024-01-31 02:05:15,024 Epoch  90: Total Training Recognition Loss 2127.58  Total Training Translation Loss 6847.50 
2024-01-31 02:05:15,025 EPOCH 91
2024-01-31 02:05:40,604 Epoch  91: Total Training Recognition Loss 2130.53  Total Training Translation Loss 6849.38 
2024-01-31 02:05:40,604 EPOCH 92
2024-01-31 02:05:41,592 [Epoch: 092 Step: 00006100] Batch Recognition Loss:  33.743423 => Gls Tokens per Sec:      486 || Batch Translation Loss: 114.862740 => Txt Tokens per Sec:     1433 || Lr: 0.000100
2024-01-31 02:06:06,210 Epoch  92: Total Training Recognition Loss 2125.91  Total Training Translation Loss 6847.90 
2024-01-31 02:06:06,210 EPOCH 93
2024-01-31 02:06:19,688 [Epoch: 093 Step: 00006200] Batch Recognition Loss:  46.524643 => Gls Tokens per Sec:      427 || Batch Translation Loss: 127.974930 => Txt Tokens per Sec:     1205 || Lr: 0.000100
2024-01-31 02:06:31,465 Epoch  93: Total Training Recognition Loss 2128.66  Total Training Translation Loss 6848.97 
2024-01-31 02:06:31,465 EPOCH 94
2024-01-31 02:06:57,010 Epoch  94: Total Training Recognition Loss 2129.54  Total Training Translation Loss 6847.24 
2024-01-31 02:06:57,010 EPOCH 95
2024-01-31 02:06:57,399 [Epoch: 095 Step: 00006300] Batch Recognition Loss:  16.728790 => Gls Tokens per Sec:      826 || Batch Translation Loss:  76.452950 => Txt Tokens per Sec:     1779 || Lr: 0.000100
2024-01-31 02:07:22,484 Epoch  95: Total Training Recognition Loss 2131.07  Total Training Translation Loss 6847.10 
2024-01-31 02:07:22,484 EPOCH 96
2024-01-31 02:07:36,933 [Epoch: 096 Step: 00006400] Batch Recognition Loss:  38.287422 => Gls Tokens per Sec:      381 || Batch Translation Loss: 117.251015 => Txt Tokens per Sec:     1079 || Lr: 0.000100
2024-01-31 02:07:48,067 Epoch  96: Total Training Recognition Loss 2130.15  Total Training Translation Loss 6847.75 
2024-01-31 02:07:48,067 EPOCH 97
2024-01-31 02:08:13,775 Epoch  97: Total Training Recognition Loss 2127.06  Total Training Translation Loss 6849.91 
2024-01-31 02:08:13,775 EPOCH 98
2024-01-31 02:08:13,983 [Epoch: 098 Step: 00006500] Batch Recognition Loss:  22.470425 => Gls Tokens per Sec:      773 || Batch Translation Loss:  81.257881 => Txt Tokens per Sec:     1705 || Lr: 0.000100
2024-01-31 02:08:39,396 Epoch  98: Total Training Recognition Loss 2127.44  Total Training Translation Loss 6848.14 
2024-01-31 02:08:39,396 EPOCH 99
2024-01-31 02:08:52,477 [Epoch: 099 Step: 00006600] Batch Recognition Loss:  38.357590 => Gls Tokens per Sec:      416 || Batch Translation Loss: 116.916130 => Txt Tokens per Sec:     1138 || Lr: 0.000100
2024-01-31 02:09:04,872 Epoch  99: Total Training Recognition Loss 2123.48  Total Training Translation Loss 6850.02 
2024-01-31 02:09:04,873 EPOCH 100
2024-01-31 02:09:30,468 [Epoch: 100 Step: 00006700] Batch Recognition Loss:  30.742889 => Gls Tokens per Sec:      415 || Batch Translation Loss: 102.038223 => Txt Tokens per Sec:     1153 || Lr: 0.000100
2024-01-31 02:09:30,468 Epoch 100: Total Training Recognition Loss 2124.77  Total Training Translation Loss 6846.91 
2024-01-31 02:09:30,469 EPOCH 101
2024-01-31 02:09:56,090 Epoch 101: Total Training Recognition Loss 2125.34  Total Training Translation Loss 6848.87 
2024-01-31 02:09:56,090 EPOCH 102
2024-01-31 02:10:07,764 [Epoch: 102 Step: 00006800] Batch Recognition Loss:  23.231737 => Gls Tokens per Sec:      452 || Batch Translation Loss: 100.902763 => Txt Tokens per Sec:     1255 || Lr: 0.000100
2024-01-31 02:10:21,526 Epoch 102: Total Training Recognition Loss 2128.00  Total Training Translation Loss 6848.55 
2024-01-31 02:10:21,526 EPOCH 103
2024-01-31 02:10:46,755 [Epoch: 103 Step: 00006900] Batch Recognition Loss:  33.081139 => Gls Tokens per Sec:      415 || Batch Translation Loss: 108.927689 => Txt Tokens per Sec:     1154 || Lr: 0.000100
2024-01-31 02:10:47,010 Epoch 103: Total Training Recognition Loss 2128.05  Total Training Translation Loss 6847.26 
2024-01-31 02:10:47,010 EPOCH 104
2024-01-31 02:11:12,542 Epoch 104: Total Training Recognition Loss 2131.25  Total Training Translation Loss 6847.14 
2024-01-31 02:11:12,542 EPOCH 105
2024-01-31 02:11:25,777 [Epoch: 105 Step: 00007000] Batch Recognition Loss:  18.891064 => Gls Tokens per Sec:      380 || Batch Translation Loss:  96.886322 => Txt Tokens per Sec:     1083 || Lr: 0.000100
2024-01-31 02:11:38,151 Epoch 105: Total Training Recognition Loss 2126.05  Total Training Translation Loss 6849.66 
2024-01-31 02:11:38,151 EPOCH 106
2024-01-31 02:12:02,853 [Epoch: 106 Step: 00007100] Batch Recognition Loss:  27.494583 => Gls Tokens per Sec:      417 || Batch Translation Loss:  93.577652 => Txt Tokens per Sec:     1156 || Lr: 0.000100
2024-01-31 02:12:03,614 Epoch 106: Total Training Recognition Loss 2126.91  Total Training Translation Loss 6848.38 
2024-01-31 02:12:03,614 EPOCH 107
2024-01-31 02:12:29,228 Epoch 107: Total Training Recognition Loss 2128.67  Total Training Translation Loss 6848.21 
2024-01-31 02:12:29,228 EPOCH 108
2024-01-31 02:12:39,418 [Epoch: 108 Step: 00007200] Batch Recognition Loss:  36.000050 => Gls Tokens per Sec:      487 || Batch Translation Loss: 118.786667 => Txt Tokens per Sec:     1290 || Lr: 0.000100
2024-01-31 02:12:54,824 Epoch 108: Total Training Recognition Loss 2127.60  Total Training Translation Loss 6847.62 
2024-01-31 02:12:54,825 EPOCH 109
2024-01-31 02:13:19,713 [Epoch: 109 Step: 00007300] Batch Recognition Loss:   5.011722 => Gls Tokens per Sec:      408 || Batch Translation Loss:  44.455048 => Txt Tokens per Sec:     1138 || Lr: 0.000100
2024-01-31 02:13:20,590 Epoch 109: Total Training Recognition Loss 2128.01  Total Training Translation Loss 6846.90 
2024-01-31 02:13:20,591 EPOCH 110
2024-01-31 02:13:46,181 Epoch 110: Total Training Recognition Loss 2125.76  Total Training Translation Loss 6847.96 
2024-01-31 02:13:46,181 EPOCH 111
2024-01-31 02:13:58,935 [Epoch: 111 Step: 00007400] Batch Recognition Loss:  33.625412 => Gls Tokens per Sec:      369 || Batch Translation Loss: 103.130699 => Txt Tokens per Sec:     1072 || Lr: 0.000100
2024-01-31 02:14:11,770 Epoch 111: Total Training Recognition Loss 2128.93  Total Training Translation Loss 6847.74 
2024-01-31 02:14:11,771 EPOCH 112
2024-01-31 02:14:36,384 [Epoch: 112 Step: 00007500] Batch Recognition Loss:  50.136139 => Gls Tokens per Sec:      406 || Batch Translation Loss: 127.945953 => Txt Tokens per Sec:     1142 || Lr: 0.000100
2024-01-31 02:14:37,300 Epoch 112: Total Training Recognition Loss 2128.19  Total Training Translation Loss 6848.33 
2024-01-31 02:14:37,300 EPOCH 113
2024-01-31 02:15:03,043 Epoch 113: Total Training Recognition Loss 2126.09  Total Training Translation Loss 6848.33 
2024-01-31 02:15:03,043 EPOCH 114
2024-01-31 02:15:13,765 [Epoch: 114 Step: 00007600] Batch Recognition Loss:  21.993732 => Gls Tokens per Sec:      433 || Batch Translation Loss:  82.965973 => Txt Tokens per Sec:     1177 || Lr: 0.000100
2024-01-31 02:15:28,627 Epoch 114: Total Training Recognition Loss 2123.42  Total Training Translation Loss 6847.23 
2024-01-31 02:15:28,628 EPOCH 115
2024-01-31 02:15:52,265 [Epoch: 115 Step: 00007700] Batch Recognition Loss:  49.790581 => Gls Tokens per Sec:      416 || Batch Translation Loss: 125.718506 => Txt Tokens per Sec:     1145 || Lr: 0.000100
2024-01-31 02:15:54,424 Epoch 115: Total Training Recognition Loss 2126.33  Total Training Translation Loss 6849.57 
2024-01-31 02:15:54,424 EPOCH 116
2024-01-31 02:16:23,396 Epoch 116: Total Training Recognition Loss 2128.94  Total Training Translation Loss 6848.62 
2024-01-31 02:16:23,398 EPOCH 117
2024-01-31 02:16:35,239 [Epoch: 117 Step: 00007800] Batch Recognition Loss:  37.490936 => Gls Tokens per Sec:      371 || Batch Translation Loss: 113.707817 => Txt Tokens per Sec:     1038 || Lr: 0.000100
2024-01-31 02:16:49,827 Epoch 117: Total Training Recognition Loss 2126.86  Total Training Translation Loss 6847.22 
2024-01-31 02:16:49,827 EPOCH 118
2024-01-31 02:17:13,305 [Epoch: 118 Step: 00007900] Batch Recognition Loss:  28.009890 => Gls Tokens per Sec:      412 || Batch Translation Loss:  91.653320 => Txt Tokens per Sec:     1144 || Lr: 0.000100
2024-01-31 02:17:15,302 Epoch 118: Total Training Recognition Loss 2133.89  Total Training Translation Loss 6849.47 
2024-01-31 02:17:15,302 EPOCH 119
2024-01-31 02:17:40,812 Epoch 119: Total Training Recognition Loss 2129.00  Total Training Translation Loss 6847.66 
2024-01-31 02:17:40,812 EPOCH 120
2024-01-31 02:17:49,657 [Epoch: 120 Step: 00008000] Batch Recognition Loss:  19.178257 => Gls Tokens per Sec:      478 || Batch Translation Loss:  92.605850 => Txt Tokens per Sec:     1234 || Lr: 0.000100
2024-01-31 02:18:19,310 Validation result at epoch 120, step     8000: duration: 29.6519s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 679.99493	Translation Loss: 73474.72656	PPL: 1560.27856
	Eval Metric: BLEU
	WER 547.25	(DEL: 4.24,	INS: 459.25,	SUB: 83.76)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.46	ROUGE 0.00
2024-01-31 02:18:19,312 Logging Recognition and Translation Outputs
2024-01-31 02:18:19,312 ========================================================================================================================
2024-01-31 02:18:19,312 Logging Sequence: 88_57.00
2024-01-31 02:18:19,313 	Gloss Reference :	***** * ***** * ***** * ***** * ***** * ***** ***** * ***** * A     B+C+D+E
2024-01-31 02:18:19,313 	Gloss Hypothesis:	<pad> B <pad> B <unk> B <unk> B <unk> B <pad> <unk> B <pad> B <unk> B      
2024-01-31 02:18:19,313 	Gloss Alignment :	I     I I     I I     I I     I I     I I     I     I I     I S     S      
2024-01-31 02:18:19,313 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:18:19,317 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** which stated messi we're waiting for you to  come here you will be  finished when you come
2024-01-31 02:18:19,317 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s>    <s>   <s>   <s>     <s> <s> <s> <s>  <s>  <s> <s>  <s> <s>      <s>  <s> <s> 
2024-01-31 02:18:19,318 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S     S      S     S     S       S   S   S   S    S    S   S    S   S        S    S   S   
2024-01-31 02:18:19,318 ========================================================================================================================
2024-01-31 02:18:19,318 Logging Sequence: 171_142.00
2024-01-31 02:18:19,318 	Gloss Reference :	***** * ***** * ***** * A     B+C+D+E                                                                                                      
2024-01-31 02:18:19,318 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E+C+E+B+E+C+E+B+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+B+E+B+E+B+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E
2024-01-31 02:18:19,318 	Gloss Alignment :	I     I I     I I     I S     S                                                                                                            
2024-01-31 02:18:19,318 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:18:19,321 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** this   decision on     dhoni  made   a      significant impact as     pathirana claimed two    tough  wickets
2024-01-31 02:18:19,322 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen   chosen chosen chosen chosen chosen      chosen chosen chosen    chosen  chosen chosen chosen 
2024-01-31 02:18:19,322 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      S      S        S      S      S      S      S           S      S      S         S       S      S      S      
2024-01-31 02:18:19,322 ========================================================================================================================
2024-01-31 02:18:19,322 Logging Sequence: 125_207.00
2024-01-31 02:18:19,323 	Gloss Reference :	***** A ***** ***** ***** *** ***** ***** ***** *** ***** ***** ***** ******* ***** *** ***** ***** ********* ***** * ***** B+C+D+E
2024-01-31 02:18:19,323 	Gloss Hypothesis:	<unk> A <unk> <pad> <unk> A+B <unk> E+B+E <pad> C+B <unk> B+E+C <unk> E+B+C+B <unk> C+B <pad> <unk> B+C+B+E+B <pad> C <unk> C      
2024-01-31 02:18:19,323 	Gloss Alignment :	I       I     I     I     I   I     I     I     I   I     I     I     I       I     I   I     I     I         I     I I     S      
2024-01-31 02:18:19,323 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:18:19,326 	Text Reference  :	*** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** he    had   not   practised since he    returned and   he    had   also  fallen sick 
2024-01-31 02:18:19,326 	Text Hypothesis :	<s> <s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha     sabha sabha sabha    sabha sabha sabha sabha sabha  sabha
2024-01-31 02:18:19,326 	Text Alignment  :	I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S     S         S     S     S        S     S     S     S     S      S    
2024-01-31 02:18:19,326 ========================================================================================================================
2024-01-31 02:18:19,326 Logging Sequence: 68_230.00
2024-01-31 02:18:19,326 	Gloss Reference :	* ********* A     B+C+D+E            
2024-01-31 02:18:19,327 	Gloss Hypothesis:	E C+E+C+E+D <unk> E+C+E+C+E+C+E+C+E+C
2024-01-31 02:18:19,327 	Gloss Alignment :	I I         S     S                  
2024-01-31 02:18:19,327 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:18:19,329 	Text Reference  :	*** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** let   us    know  what  you   think in    the   comments below
2024-01-31 02:18:19,329 	Text Hypothesis :	<s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    sabha
2024-01-31 02:18:19,329 	Text Alignment  :	I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S     S     S     S     S     S     S        S    
2024-01-31 02:18:19,329 ========================================================================================================================
2024-01-31 02:18:19,329 Logging Sequence: 126_82.00
2024-01-31 02:18:19,330 	Gloss Reference :	***** *** ***** ***** ***** *************** ***** ********************************* A     B+C+D+E
2024-01-31 02:18:19,330 	Gloss Hypothesis:	<unk> E+D <pad> E+C+E <unk> E+D+C+E+C+E+C+E <unk> E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E <pad> C+E    
2024-01-31 02:18:19,330 	Gloss Alignment :	I     I   I     I     I     I               I     I                                 S     S      
2024-01-31 02:18:19,330 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:18:19,334 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ****** ****** ****** ****** ****** ****** ****** neeraj also   dedicated his    gold   medal  to     former indian olympians who    came   close  to     winning medals
2024-01-31 02:18:19,334 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> boards boards boards boards boards boards boards boards boards boards    boards boards boards boards boards boards boards    boards boards boards boards boards  boards
2024-01-31 02:18:19,334 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I      I      I      I      I      I      I      S      S      S         S      S      S      S      S      S      S         S      S      S      S      S       S     
2024-01-31 02:18:19,334 ========================================================================================================================
2024-01-31 02:18:36,175 Epoch 120: Total Training Recognition Loss 2126.51  Total Training Translation Loss 6848.96 
2024-01-31 02:18:36,175 EPOCH 121
2024-01-31 02:18:58,342 [Epoch: 121 Step: 00008100] Batch Recognition Loss:  27.593632 => Gls Tokens per Sec:      429 || Batch Translation Loss: 109.628815 => Txt Tokens per Sec:     1168 || Lr: 0.000100
2024-01-31 02:19:01,665 Epoch 121: Total Training Recognition Loss 2128.57  Total Training Translation Loss 6848.92 
2024-01-31 02:19:01,665 EPOCH 122
2024-01-31 02:19:27,202 Epoch 122: Total Training Recognition Loss 2129.65  Total Training Translation Loss 6848.27 
2024-01-31 02:19:27,203 EPOCH 123
2024-01-31 02:19:37,484 [Epoch: 123 Step: 00008200] Batch Recognition Loss:  30.609924 => Gls Tokens per Sec:      405 || Batch Translation Loss:  99.221077 => Txt Tokens per Sec:     1149 || Lr: 0.000100
2024-01-31 02:19:52,722 Epoch 123: Total Training Recognition Loss 2130.36  Total Training Translation Loss 6848.55 
2024-01-31 02:19:52,722 EPOCH 124
2024-01-31 02:20:16,154 [Epoch: 124 Step: 00008300] Batch Recognition Loss:  29.359573 => Gls Tokens per Sec:      399 || Batch Translation Loss:  93.484589 => Txt Tokens per Sec:     1127 || Lr: 0.000100
2024-01-31 02:20:18,392 Epoch 124: Total Training Recognition Loss 2128.32  Total Training Translation Loss 6848.40 
2024-01-31 02:20:18,392 EPOCH 125
2024-01-31 02:20:44,037 Epoch 125: Total Training Recognition Loss 2127.65  Total Training Translation Loss 6846.97 
2024-01-31 02:20:44,037 EPOCH 126
2024-01-31 02:20:54,052 [Epoch: 126 Step: 00008400] Batch Recognition Loss:  23.100368 => Gls Tokens per Sec:      399 || Batch Translation Loss:  84.895447 => Txt Tokens per Sec:     1166 || Lr: 0.000100
2024-01-31 02:21:09,562 Epoch 126: Total Training Recognition Loss 2127.37  Total Training Translation Loss 6848.20 
2024-01-31 02:21:09,562 EPOCH 127
2024-01-31 02:21:32,242 [Epoch: 127 Step: 00008500] Batch Recognition Loss:  49.938942 => Gls Tokens per Sec:      405 || Batch Translation Loss: 129.717377 => Txt Tokens per Sec:     1134 || Lr: 0.000100
2024-01-31 02:21:35,195 Epoch 127: Total Training Recognition Loss 2128.16  Total Training Translation Loss 6848.84 
2024-01-31 02:21:35,195 EPOCH 128
2024-01-31 02:22:00,841 Epoch 128: Total Training Recognition Loss 2126.67  Total Training Translation Loss 6848.13 
2024-01-31 02:22:00,841 EPOCH 129
2024-01-31 02:22:08,733 [Epoch: 129 Step: 00008600] Batch Recognition Loss:  27.087524 => Gls Tokens per Sec:      487 || Batch Translation Loss:  87.228523 => Txt Tokens per Sec:     1361 || Lr: 0.000100
2024-01-31 02:22:26,308 Epoch 129: Total Training Recognition Loss 2127.61  Total Training Translation Loss 6848.20 
2024-01-31 02:22:26,308 EPOCH 130
2024-01-31 02:22:47,959 [Epoch: 130 Step: 00008700] Batch Recognition Loss:  23.084335 => Gls Tokens per Sec:      417 || Batch Translation Loss:  83.989403 => Txt Tokens per Sec:     1161 || Lr: 0.000100
2024-01-31 02:22:51,895 Epoch 130: Total Training Recognition Loss 2126.89  Total Training Translation Loss 6846.47 
2024-01-31 02:22:51,896 EPOCH 131
2024-01-31 02:23:17,517 Epoch 131: Total Training Recognition Loss 2122.67  Total Training Translation Loss 6846.90 
2024-01-31 02:23:17,517 EPOCH 132
2024-01-31 02:23:27,587 [Epoch: 132 Step: 00008800] Batch Recognition Loss:  19.073360 => Gls Tokens per Sec:      357 || Batch Translation Loss:  92.147148 => Txt Tokens per Sec:      996 || Lr: 0.000100
2024-01-31 02:23:43,128 Epoch 132: Total Training Recognition Loss 2126.12  Total Training Translation Loss 6849.57 
2024-01-31 02:23:43,128 EPOCH 133
2024-01-31 02:24:05,174 [Epoch: 133 Step: 00008900] Batch Recognition Loss:  36.269775 => Gls Tokens per Sec:      402 || Batch Translation Loss: 115.544388 => Txt Tokens per Sec:     1122 || Lr: 0.000100
2024-01-31 02:24:08,668 Epoch 133: Total Training Recognition Loss 2124.85  Total Training Translation Loss 6849.23 
2024-01-31 02:24:08,668 EPOCH 134
2024-01-31 02:24:34,280 Epoch 134: Total Training Recognition Loss 2128.55  Total Training Translation Loss 6847.63 
2024-01-31 02:24:34,280 EPOCH 135
2024-01-31 02:24:44,313 [Epoch: 135 Step: 00009000] Batch Recognition Loss:  39.955467 => Gls Tokens per Sec:      342 || Batch Translation Loss: 106.691933 => Txt Tokens per Sec:      964 || Lr: 0.000100
2024-01-31 02:24:59,848 Epoch 135: Total Training Recognition Loss 2126.85  Total Training Translation Loss 6848.71 
2024-01-31 02:24:59,848 EPOCH 136
2024-01-31 02:25:19,487 [Epoch: 136 Step: 00009100] Batch Recognition Loss:  37.443527 => Gls Tokens per Sec:      444 || Batch Translation Loss: 126.049026 => Txt Tokens per Sec:     1208 || Lr: 0.000100
2024-01-31 02:25:25,360 Epoch 136: Total Training Recognition Loss 2132.75  Total Training Translation Loss 6847.25 
2024-01-31 02:25:25,360 EPOCH 137
2024-01-31 02:25:50,920 Epoch 137: Total Training Recognition Loss 2125.81  Total Training Translation Loss 6848.20 
2024-01-31 02:25:50,921 EPOCH 138
2024-01-31 02:25:58,844 [Epoch: 138 Step: 00009200] Batch Recognition Loss:  41.066452 => Gls Tokens per Sec:      424 || Batch Translation Loss: 139.399384 => Txt Tokens per Sec:     1136 || Lr: 0.000100
2024-01-31 02:26:16,498 Epoch 138: Total Training Recognition Loss 2126.35  Total Training Translation Loss 6849.77 
2024-01-31 02:26:16,499 EPOCH 139
2024-01-31 02:26:37,176 [Epoch: 139 Step: 00009300] Batch Recognition Loss:  40.954578 => Gls Tokens per Sec:      414 || Batch Translation Loss: 112.651558 => Txt Tokens per Sec:     1148 || Lr: 0.000100
2024-01-31 02:26:42,117 Epoch 139: Total Training Recognition Loss 2129.45  Total Training Translation Loss 6849.44 
2024-01-31 02:26:42,117 EPOCH 140
2024-01-31 02:27:07,746 Epoch 140: Total Training Recognition Loss 2123.53  Total Training Translation Loss 6848.31 
2024-01-31 02:27:07,746 EPOCH 141
2024-01-31 02:27:16,227 [Epoch: 141 Step: 00009400] Batch Recognition Loss:  36.982704 => Gls Tokens per Sec:      377 || Batch Translation Loss: 107.819145 => Txt Tokens per Sec:     1113 || Lr: 0.000100
2024-01-31 02:27:33,239 Epoch 141: Total Training Recognition Loss 2128.05  Total Training Translation Loss 6847.57 
2024-01-31 02:27:33,239 EPOCH 142
2024-01-31 02:27:53,433 [Epoch: 142 Step: 00009500] Batch Recognition Loss:  30.622971 => Gls Tokens per Sec:      415 || Batch Translation Loss: 103.351814 => Txt Tokens per Sec:     1165 || Lr: 0.000100
2024-01-31 02:27:58,791 Epoch 142: Total Training Recognition Loss 2128.92  Total Training Translation Loss 6848.06 
2024-01-31 02:27:58,791 EPOCH 143
2024-01-31 02:28:24,582 Epoch 143: Total Training Recognition Loss 2125.76  Total Training Translation Loss 6847.78 
2024-01-31 02:28:24,582 EPOCH 144
2024-01-31 02:28:33,937 [Epoch: 144 Step: 00009600] Batch Recognition Loss:  22.447416 => Gls Tokens per Sec:      315 || Batch Translation Loss:  83.086319 => Txt Tokens per Sec:      935 || Lr: 0.000100
2024-01-31 02:28:50,083 Epoch 144: Total Training Recognition Loss 2123.72  Total Training Translation Loss 6847.70 
2024-01-31 02:28:50,083 EPOCH 145
2024-01-31 02:29:10,981 [Epoch: 145 Step: 00009700] Batch Recognition Loss:  27.813465 => Gls Tokens per Sec:      394 || Batch Translation Loss:  88.774933 => Txt Tokens per Sec:     1097 || Lr: 0.000100
2024-01-31 02:29:15,619 Epoch 145: Total Training Recognition Loss 2126.44  Total Training Translation Loss 6848.70 
2024-01-31 02:29:15,619 EPOCH 146
2024-01-31 02:29:41,282 Epoch 146: Total Training Recognition Loss 2127.48  Total Training Translation Loss 6846.30 
2024-01-31 02:29:41,282 EPOCH 147
2024-01-31 02:29:47,612 [Epoch: 147 Step: 00009800] Batch Recognition Loss:  46.313293 => Gls Tokens per Sec:      455 || Batch Translation Loss: 123.605942 => Txt Tokens per Sec:     1220 || Lr: 0.000100
2024-01-31 02:30:06,807 Epoch 147: Total Training Recognition Loss 2130.93  Total Training Translation Loss 6848.20 
2024-01-31 02:30:06,808 EPOCH 148
2024-01-31 02:30:24,111 [Epoch: 148 Step: 00009900] Batch Recognition Loss:  23.156816 => Gls Tokens per Sec:      472 || Batch Translation Loss:  81.059464 => Txt Tokens per Sec:     1289 || Lr: 0.000100
2024-01-31 02:30:32,393 Epoch 148: Total Training Recognition Loss 2128.08  Total Training Translation Loss 6848.68 
2024-01-31 02:30:32,393 EPOCH 149
2024-01-31 02:30:58,015 Epoch 149: Total Training Recognition Loss 2126.80  Total Training Translation Loss 6849.36 
2024-01-31 02:30:58,015 EPOCH 150
2024-01-31 02:31:05,158 [Epoch: 150 Step: 00010000] Batch Recognition Loss:  27.407223 => Gls Tokens per Sec:      381 || Batch Translation Loss:  81.280151 => Txt Tokens per Sec:     1052 || Lr: 0.000100
2024-01-31 02:31:34,361 Validation result at epoch 150, step    10000: duration: 29.2031s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 678.12115	Translation Loss: 73501.31250	PPL: 1564.43445
	Eval Metric: BLEU
	WER 538.91	(DEL: 4.24,	INS: 451.55,	SUB: 83.12)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.47	ROUGE 0.01
2024-01-31 02:31:34,362 Logging Recognition and Translation Outputs
2024-01-31 02:31:34,362 ========================================================================================================================
2024-01-31 02:31:34,363 Logging Sequence: 159_139.00
2024-01-31 02:31:34,363 	Gloss Reference :	***** * ***** * ***** ***** ***** A ***** ******* ***** B+C+D+E
2024-01-31 02:31:34,363 	Gloss Hypothesis:	<unk> A <unk> A <unk> E+B+E <unk> A <unk> A+D+A+E <unk> E      
2024-01-31 02:31:34,363 	Gloss Alignment :	I     I I     I I     I     I       I     I       I     S      
2024-01-31 02:31:34,363 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:31:34,367 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* he      took    time    and     finally was     ready   for     the     asia    cup     where   he      scored  the     century
2024-01-31 02:31:34,367 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing
2024-01-31 02:31:34,367 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S       S       S       S       S       S       S       S       S       S       S       S      
2024-01-31 02:31:34,367 ========================================================================================================================
2024-01-31 02:31:34,367 Logging Sequence: 159_159.00
2024-01-31 02:31:34,367 	Gloss Reference :	A B+C+D+E    
2024-01-31 02:31:34,368 	Gloss Hypothesis:	E A+E+A+E+A+E
2024-01-31 02:31:34,368 	Gloss Alignment :	S S          
2024-01-31 02:31:34,368 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:31:34,373 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** he  said it  wasn't easy the mind has to  be  focussed and he  is  glad that he  is  back in  form with the asia cup century
2024-01-31 02:31:34,373 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s>    <s>  <s> <s>  <s> <s> <s> <s>      <s> <s> <s> <s>  <s>  <s> <s> <s>  <s> <s>  <s>  <s> <s>  <s> <s>    
2024-01-31 02:31:34,373 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S    S   S      S    S   S    S   S   S   S        S   S   S   S    S    S   S   S    S   S    S    S   S    S   S      
2024-01-31 02:31:34,373 ========================================================================================================================
2024-01-31 02:31:34,374 Logging Sequence: 103_8.00
2024-01-31 02:31:34,374 	Gloss Reference :	***** * ***** * ***** * ***** * ***** * ***** * ***** * ***** * A     B+C+D+E
2024-01-31 02:31:34,374 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E <unk> E <unk> E <unk> E <unk> E <unk> E      
2024-01-31 02:31:34,374 	Gloss Alignment :	I     I I     I I     I I     I I     I I     I I     I I     I S     S      
2024-01-31 02:31:34,374 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:31:34,377 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* were    going   on      in      birmingham england from    28th    july    to      8th     august  2022   
2024-01-31 02:31:34,377 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing    nothing nothing nothing nothing nothing nothing nothing nothing
2024-01-31 02:31:34,377 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       S       S       S       S       S          S       S       S       S       S       S       S       S      
2024-01-31 02:31:34,377 ========================================================================================================================
2024-01-31 02:31:34,378 Logging Sequence: 164_546.00
2024-01-31 02:31:34,378 	Gloss Reference :	A B+C+D+E
2024-01-31 02:31:34,378 	Gloss Hypothesis:	* <unk>  
2024-01-31 02:31:34,378 	Gloss Alignment :	D S      
2024-01-31 02:31:34,378 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:31:34,380 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** reliance has turned out to  be  the strongest company
2024-01-31 02:31:34,380 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>      <s> <s>    <s> <s> <s> <s> <s>       <s>    
2024-01-31 02:31:34,380 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S        S   S      S   S   S   S   S         S      
2024-01-31 02:31:34,381 ========================================================================================================================
2024-01-31 02:31:34,381 Logging Sequence: 132_173.00
2024-01-31 02:31:34,381 	Gloss Reference :	*** ***** ******* ***** ***************** ***** ********************************************* A     B+C+D+E                        
2024-01-31 02:31:34,381 	Gloss Hypothesis:	E+C <pad> E+C+E+C <unk> E+B+E+C+E+C+B+C+E <unk> C+E+B+E+C+B+E+C+B+C+E+C+E+C+B+C+E+C+E+C+B+E+C <pad> E+C+E+C+E+C+E+C+E+C+E+C+E+C+B+E
2024-01-31 02:31:34,381 	Gloss Alignment :	I   I     I       I     I                 I     I                                             S     S                              
2024-01-31 02:31:34,381 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:31:34,383 	Text Reference  :	************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ ************ usman        is           australia'   first        muslim       player      
2024-01-31 02:31:34,383 	Text Hypothesis :	competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions competitions
2024-01-31 02:31:34,383 	Text Alignment  :	I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            I            S            S            S            S            S            S           
2024-01-31 02:31:34,383 ========================================================================================================================
2024-01-31 02:31:52,776 Epoch 150: Total Training Recognition Loss 2124.34  Total Training Translation Loss 6848.56 
2024-01-31 02:31:52,777 EPOCH 151
2024-01-31 02:32:12,460 [Epoch: 151 Step: 00010100] Batch Recognition Loss:  45.428757 => Gls Tokens per Sec:      402 || Batch Translation Loss: 124.851883 => Txt Tokens per Sec:     1121 || Lr: 0.000100
2024-01-31 02:32:18,343 Epoch 151: Total Training Recognition Loss 2129.44  Total Training Translation Loss 6849.26 
2024-01-31 02:32:18,343 EPOCH 152
2024-01-31 02:32:43,855 Epoch 152: Total Training Recognition Loss 2127.80  Total Training Translation Loss 6849.26 
2024-01-31 02:32:43,856 EPOCH 153
2024-01-31 02:32:49,020 [Epoch: 153 Step: 00010200] Batch Recognition Loss:  36.202477 => Gls Tokens per Sec:      496 || Batch Translation Loss: 111.621872 => Txt Tokens per Sec:     1342 || Lr: 0.000100
2024-01-31 02:33:09,411 Epoch 153: Total Training Recognition Loss 2125.80  Total Training Translation Loss 6848.51 
2024-01-31 02:33:09,412 EPOCH 154
2024-01-31 02:33:28,695 [Epoch: 154 Step: 00010300] Batch Recognition Loss:  28.003662 => Gls Tokens per Sec:      402 || Batch Translation Loss:  90.514252 => Txt Tokens per Sec:     1132 || Lr: 0.000100
2024-01-31 02:33:34,976 Epoch 154: Total Training Recognition Loss 2129.23  Total Training Translation Loss 6846.71 
2024-01-31 02:33:34,976 EPOCH 155
2024-01-31 02:34:00,647 Epoch 155: Total Training Recognition Loss 2127.74  Total Training Translation Loss 6847.52 
2024-01-31 02:34:00,647 EPOCH 156
2024-01-31 02:34:07,222 [Epoch: 156 Step: 00010400] Batch Recognition Loss:  37.538227 => Gls Tokens per Sec:      365 || Batch Translation Loss: 120.200089 => Txt Tokens per Sec:     1083 || Lr: 0.000100
2024-01-31 02:34:26,301 Epoch 156: Total Training Recognition Loss 2129.08  Total Training Translation Loss 6846.38 
2024-01-31 02:34:26,301 EPOCH 157
2024-01-31 02:34:45,058 [Epoch: 157 Step: 00010500] Batch Recognition Loss:  36.668106 => Gls Tokens per Sec:      405 || Batch Translation Loss: 113.636169 => Txt Tokens per Sec:     1120 || Lr: 0.000100
2024-01-31 02:34:51,913 Epoch 157: Total Training Recognition Loss 2129.89  Total Training Translation Loss 6848.16 
2024-01-31 02:34:51,913 EPOCH 158
2024-01-31 02:35:17,781 Epoch 158: Total Training Recognition Loss 2127.09  Total Training Translation Loss 6848.78 
2024-01-31 02:35:17,781 EPOCH 159
2024-01-31 02:35:22,321 [Epoch: 159 Step: 00010600] Batch Recognition Loss:  33.671490 => Gls Tokens per Sec:      494 || Batch Translation Loss: 113.906754 => Txt Tokens per Sec:     1339 || Lr: 0.000100
2024-01-31 02:35:43,200 Epoch 159: Total Training Recognition Loss 2122.85  Total Training Translation Loss 6848.14 
2024-01-31 02:35:43,201 EPOCH 160
2024-01-31 02:35:59,333 [Epoch: 160 Step: 00010700] Batch Recognition Loss:  38.338425 => Gls Tokens per Sec:      466 || Batch Translation Loss: 127.797745 => Txt Tokens per Sec:     1281 || Lr: 0.000100
2024-01-31 02:36:08,736 Epoch 160: Total Training Recognition Loss 2127.08  Total Training Translation Loss 6847.87 
2024-01-31 02:36:08,737 EPOCH 161
2024-01-31 02:36:34,466 Epoch 161: Total Training Recognition Loss 2127.59  Total Training Translation Loss 6849.29 
2024-01-31 02:36:34,466 EPOCH 162
2024-01-31 02:36:41,286 [Epoch: 162 Step: 00010800] Batch Recognition Loss:  34.453896 => Gls Tokens per Sec:      292 || Batch Translation Loss: 113.439926 => Txt Tokens per Sec:      843 || Lr: 0.000100
2024-01-31 02:37:00,003 Epoch 162: Total Training Recognition Loss 2128.56  Total Training Translation Loss 6849.57 
2024-01-31 02:37:00,004 EPOCH 163
2024-01-31 02:37:16,925 [Epoch: 163 Step: 00010900] Batch Recognition Loss:  39.670250 => Gls Tokens per Sec:      430 || Batch Translation Loss: 113.043282 => Txt Tokens per Sec:     1193 || Lr: 0.000100
2024-01-31 02:37:25,595 Epoch 163: Total Training Recognition Loss 2131.79  Total Training Translation Loss 6849.38 
2024-01-31 02:37:25,596 EPOCH 164
2024-01-31 02:37:51,161 Epoch 164: Total Training Recognition Loss 2128.15  Total Training Translation Loss 6847.70 
2024-01-31 02:37:51,161 EPOCH 165
2024-01-31 02:37:55,709 [Epoch: 165 Step: 00011000] Batch Recognition Loss:  45.553413 => Gls Tokens per Sec:      422 || Batch Translation Loss: 125.144104 => Txt Tokens per Sec:     1171 || Lr: 0.000100
2024-01-31 02:38:16,681 Epoch 165: Total Training Recognition Loss 2125.62  Total Training Translation Loss 6847.34 
2024-01-31 02:38:16,681 EPOCH 166
2024-01-31 02:38:31,844 [Epoch: 166 Step: 00011100] Batch Recognition Loss:  30.580208 => Gls Tokens per Sec:      475 || Batch Translation Loss: 109.732941 => Txt Tokens per Sec:     1301 || Lr: 0.000100
2024-01-31 02:38:42,094 Epoch 166: Total Training Recognition Loss 2128.84  Total Training Translation Loss 6847.41 
2024-01-31 02:38:42,094 EPOCH 167
2024-01-31 02:39:07,749 Epoch 167: Total Training Recognition Loss 2129.65  Total Training Translation Loss 6847.30 
2024-01-31 02:39:07,749 EPOCH 168
2024-01-31 02:39:10,790 [Epoch: 168 Step: 00011200] Batch Recognition Loss:  23.221539 => Gls Tokens per Sec:      579 || Batch Translation Loss:  78.730522 => Txt Tokens per Sec:     1467 || Lr: 0.000100
2024-01-31 02:39:33,532 Epoch 168: Total Training Recognition Loss 2126.29  Total Training Translation Loss 6848.61 
2024-01-31 02:39:33,533 EPOCH 169
2024-01-31 02:39:51,078 [Epoch: 169 Step: 00011300] Batch Recognition Loss:  22.566940 => Gls Tokens per Sec:      396 || Batch Translation Loss:  82.999779 => Txt Tokens per Sec:     1089 || Lr: 0.000100
2024-01-31 02:39:59,117 Epoch 169: Total Training Recognition Loss 2130.19  Total Training Translation Loss 6849.49 
2024-01-31 02:39:59,117 EPOCH 170
2024-01-31 02:40:24,763 Epoch 170: Total Training Recognition Loss 2122.57  Total Training Translation Loss 6846.67 
2024-01-31 02:40:24,763 EPOCH 171
2024-01-31 02:40:28,976 [Epoch: 171 Step: 00011400] Batch Recognition Loss:  37.860870 => Gls Tokens per Sec:      380 || Batch Translation Loss: 118.158737 => Txt Tokens per Sec:     1029 || Lr: 0.000100
2024-01-31 02:40:50,281 Epoch 171: Total Training Recognition Loss 2126.52  Total Training Translation Loss 6847.70 
2024-01-31 02:40:50,282 EPOCH 172
2024-01-31 02:41:07,435 [Epoch: 172 Step: 00011500] Batch Recognition Loss:  36.701141 => Gls Tokens per Sec:      396 || Batch Translation Loss: 110.161728 => Txt Tokens per Sec:     1092 || Lr: 0.000100
2024-01-31 02:41:16,025 Epoch 172: Total Training Recognition Loss 2126.72  Total Training Translation Loss 6849.78 
2024-01-31 02:41:16,025 EPOCH 173
2024-01-31 02:41:42,280 Epoch 173: Total Training Recognition Loss 2121.89  Total Training Translation Loss 6847.45 
2024-01-31 02:41:42,281 EPOCH 174
2024-01-31 02:41:46,091 [Epoch: 174 Step: 00011600] Batch Recognition Loss:  11.497110 => Gls Tokens per Sec:      378 || Batch Translation Loss:  61.270683 => Txt Tokens per Sec:     1095 || Lr: 0.000100
2024-01-31 02:42:08,004 Epoch 174: Total Training Recognition Loss 2126.23  Total Training Translation Loss 6847.11 
2024-01-31 02:42:08,004 EPOCH 175
2024-01-31 02:42:24,916 [Epoch: 175 Step: 00011700] Batch Recognition Loss:  27.052656 => Gls Tokens per Sec:      392 || Batch Translation Loss: 106.620285 => Txt Tokens per Sec:     1108 || Lr: 0.000100
2024-01-31 02:42:33,506 Epoch 175: Total Training Recognition Loss 2125.69  Total Training Translation Loss 6849.78 
2024-01-31 02:42:33,506 EPOCH 176
2024-01-31 02:42:58,984 Epoch 176: Total Training Recognition Loss 2129.49  Total Training Translation Loss 6849.55 
2024-01-31 02:42:58,984 EPOCH 177
2024-01-31 02:43:03,083 [Epoch: 177 Step: 00011800] Batch Recognition Loss:  33.461948 => Gls Tokens per Sec:      312 || Batch Translation Loss: 107.773895 => Txt Tokens per Sec:      943 || Lr: 0.000100
2024-01-31 02:43:24,540 Epoch 177: Total Training Recognition Loss 2125.89  Total Training Translation Loss 6849.30 
2024-01-31 02:43:24,541 EPOCH 178
2024-01-31 02:43:41,045 [Epoch: 178 Step: 00011900] Batch Recognition Loss:  33.643513 => Gls Tokens per Sec:      392 || Batch Translation Loss: 106.060097 => Txt Tokens per Sec:     1089 || Lr: 0.000100
2024-01-31 02:43:50,152 Epoch 178: Total Training Recognition Loss 2126.61  Total Training Translation Loss 6847.17 
2024-01-31 02:43:50,152 EPOCH 179
2024-01-31 02:44:15,872 Epoch 179: Total Training Recognition Loss 2126.62  Total Training Translation Loss 6849.26 
2024-01-31 02:44:15,872 EPOCH 180
2024-01-31 02:44:18,729 [Epoch: 180 Step: 00012000] Batch Recognition Loss:  46.717957 => Gls Tokens per Sec:      392 || Batch Translation Loss: 127.185089 => Txt Tokens per Sec:     1153 || Lr: 0.000100
2024-01-31 02:44:47,999 Validation result at epoch 180, step    12000: duration: 29.2689s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 679.03662	Translation Loss: 73452.91406	PPL: 1556.87659
	Eval Metric: BLEU
	WER 549.79	(DEL: 4.45,	INS: 461.94,	SUB: 83.40)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.44	ROUGE 0.00
2024-01-31 02:44:48,000 Logging Recognition and Translation Outputs
2024-01-31 02:44:48,000 ========================================================================================================================
2024-01-31 02:44:48,000 Logging Sequence: 177_50.00
2024-01-31 02:44:48,001 	Gloss Reference :	***** ***** * ***** * ***** ******* ***** * ***** ******* ***** * ***** *** ***** *** ***** * ***** * ***** ***** ***** ***** ***** ***** ***** *********** ***** ******* ***** * ***** * ***** A         B+C+D+E
2024-01-31 02:44:48,001 	Gloss Hypothesis:	<pad> <unk> C <pad> C <pad> B+E+C+B <pad> E <pad> C+B+E+B <pad> B <pad> E+C <pad> E+C <pad> E <pad> E <pad> C+E+B <pad> C+E+B <pad> B+E+C <pad> C+E+C+E+C+E <pad> B+E+B+E <pad> E <pad> E <pad> C+E+C+E+C <pad>  
2024-01-31 02:44:48,001 	Gloss Alignment :	I     I     I I     I I     I       I     I I     I       I     I I     I   I     I   I     I I     I I     I     I     I     I     I     I     I           I     I       I     I I     I I     S         S      
2024-01-31 02:44:48,002 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:44:48,005 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** a   similar reward of  rs  50000 was announced for information against his associate ajay kumar
2024-01-31 02:44:48,005 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s>    <s> <s> <s>   <s> <s>       <s> <s>         <s>     <s> <s>       <s>  <s>  
2024-01-31 02:44:48,005 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S       S      S   S   S     S   S         S   S           S       S   S         S    S    
2024-01-31 02:44:48,005 ========================================================================================================================
2024-01-31 02:44:48,005 Logging Sequence: 122_86.00
2024-01-31 02:44:48,006 	Gloss Reference :	***** ***** ***** * ***** * ***** A B+C+D+E
2024-01-31 02:44:48,006 	Gloss Hypothesis:	<unk> <pad> <unk> E <unk> E <unk> E <unk>  
2024-01-31 02:44:48,006 	Gloss Alignment :	I     I     I     I I     I I     S S      
2024-01-31 02:44:48,006 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:44:48,008 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** after winning chanu spoke to  the media and said
2024-01-31 02:44:48,008 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s>     <s>   <s>   <s> <s> <s>   <s> <s> 
2024-01-31 02:44:48,008 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S     S       S     S     S   S   S     S   S   
2024-01-31 02:44:48,008 ========================================================================================================================
2024-01-31 02:44:48,008 Logging Sequence: 165_27.00
2024-01-31 02:44:48,009 	Gloss Reference :	* *** A     B+C+D+E      
2024-01-31 02:44:48,009 	Gloss Hypothesis:	E A+E <pad> E+A+E+B+E+C+E
2024-01-31 02:44:48,009 	Gloss Alignment :	I I   S     S            
2024-01-31 02:44:48,009 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:44:48,012 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** so    then  they  change their routes some  people believe in    this  while some  don't
2024-01-31 02:44:48,012 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha  sabha sabha  sabha sabha  sabha   sabha sabha sabha sabha sabha
2024-01-31 02:44:48,012 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S     S      S     S      S     S      S       S     S     S     S     S    
2024-01-31 02:44:48,012 ========================================================================================================================
2024-01-31 02:44:48,013 Logging Sequence: 70_65.00
2024-01-31 02:44:48,013 	Gloss Reference :	***** A   B+C+D+E
2024-01-31 02:44:48,013 	Gloss Hypothesis:	<unk> C+B <unk>  
2024-01-31 02:44:48,013 	Gloss Alignment :	I     S   S      
2024-01-31 02:44:48,013 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:44:48,016 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** during the press conference a   table was placed in  front of  the media
2024-01-31 02:44:48,016 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>    <s> <s>   <s>        <s> <s>   <s> <s>    <s> <s>   <s> <s> <s>  
2024-01-31 02:44:48,016 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S      S   S     S          S   S     S   S      S   S     S   S   S    
2024-01-31 02:44:48,016 ========================================================================================================================
2024-01-31 02:44:48,016 Logging Sequence: 149_65.00
2024-01-31 02:44:48,017 	Gloss Reference :	A B+C+D+E                                                  
2024-01-31 02:44:48,017 	Gloss Hypothesis:	E C+E+C+E+C+E+C+E+C+E+C+E+C+D+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C
2024-01-31 02:44:48,017 	Gloss Alignment :	S S                                                        
2024-01-31 02:44:48,017 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:44:48,021 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** at    6am   on    6th   november 2022  the   police reached sri   lankan team's hotel in    sydney australia's central business district cbd  
2024-01-31 02:44:48,021 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    sabha sabha sabha  sabha   sabha sabha  sabha  sabha sabha sabha  sabha       sabha   sabha    sabha    sabha
2024-01-31 02:44:48,021 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I     I     I     I     I     I     I     I     I     I     S     S     S     S     S        S     S     S      S       S     S      S      S     S     S      S           S       S        S        S    
2024-01-31 02:44:48,022 ========================================================================================================================
2024-01-31 02:45:10,653 Epoch 180: Total Training Recognition Loss 2128.12  Total Training Translation Loss 6848.06 
2024-01-31 02:45:10,653 EPOCH 181
2024-01-31 02:45:25,624 [Epoch: 181 Step: 00012100] Batch Recognition Loss:  13.603558 => Gls Tokens per Sec:      428 || Batch Translation Loss:  78.369881 => Txt Tokens per Sec:     1183 || Lr: 0.000100
2024-01-31 02:45:36,341 Epoch 181: Total Training Recognition Loss 2128.61  Total Training Translation Loss 6849.09 
2024-01-31 02:45:36,342 EPOCH 182
2024-01-31 02:46:02,138 Epoch 182: Total Training Recognition Loss 2126.87  Total Training Translation Loss 6848.31 
2024-01-31 02:46:02,139 EPOCH 183
2024-01-31 02:46:06,055 [Epoch: 183 Step: 00012200] Batch Recognition Loss:  72.604286 => Gls Tokens per Sec:      222 || Batch Translation Loss: 126.798134 => Txt Tokens per Sec:      664 || Lr: 0.000100
2024-01-31 02:46:30,367 Epoch 183: Total Training Recognition Loss 2126.92  Total Training Translation Loss 6849.31 
2024-01-31 02:46:30,369 EPOCH 184
2024-01-31 02:46:49,064 [Epoch: 184 Step: 00012300] Batch Recognition Loss:  38.998955 => Gls Tokens per Sec:      329 || Batch Translation Loss: 114.877098 => Txt Tokens per Sec:      939 || Lr: 0.000100
2024-01-31 02:46:57,946 Epoch 184: Total Training Recognition Loss 2124.28  Total Training Translation Loss 6848.57 
2024-01-31 02:46:57,946 EPOCH 185
2024-01-31 02:47:23,503 Epoch 185: Total Training Recognition Loss 2125.01  Total Training Translation Loss 6849.43 
2024-01-31 02:47:23,503 EPOCH 186
2024-01-31 02:47:25,253 [Epoch: 186 Step: 00012400] Batch Recognition Loss:  31.313547 => Gls Tokens per Sec:      458 || Batch Translation Loss:  96.432129 => Txt Tokens per Sec:     1333 || Lr: 0.000100
2024-01-31 02:47:49,149 Epoch 186: Total Training Recognition Loss 2126.14  Total Training Translation Loss 6847.61 
2024-01-31 02:47:49,149 EPOCH 187
2024-01-31 02:48:03,830 [Epoch: 187 Step: 00012500] Batch Recognition Loss:  31.868679 => Gls Tokens per Sec:      408 || Batch Translation Loss:  89.876755 => Txt Tokens per Sec:     1103 || Lr: 0.000100
2024-01-31 02:48:14,654 Epoch 187: Total Training Recognition Loss 2124.58  Total Training Translation Loss 6847.84 
2024-01-31 02:48:14,655 EPOCH 188
2024-01-31 02:48:40,170 Epoch 188: Total Training Recognition Loss 2126.14  Total Training Translation Loss 6847.62 
2024-01-31 02:48:40,170 EPOCH 189
2024-01-31 02:48:41,563 [Epoch: 189 Step: 00012600] Batch Recognition Loss:  40.516293 => Gls Tokens per Sec:      460 || Batch Translation Loss: 105.578011 => Txt Tokens per Sec:     1293 || Lr: 0.000100
2024-01-31 02:49:05,663 Epoch 189: Total Training Recognition Loss 2123.59  Total Training Translation Loss 6847.84 
2024-01-31 02:49:05,663 EPOCH 190
2024-01-31 02:49:18,209 [Epoch: 190 Step: 00012700] Batch Recognition Loss:  36.514267 => Gls Tokens per Sec:      472 || Batch Translation Loss: 117.011932 => Txt Tokens per Sec:     1299 || Lr: 0.000100
2024-01-31 02:49:31,201 Epoch 190: Total Training Recognition Loss 2126.40  Total Training Translation Loss 6848.33 
2024-01-31 02:49:31,201 EPOCH 191
2024-01-31 02:49:56,748 Epoch 191: Total Training Recognition Loss 2127.94  Total Training Translation Loss 6848.23 
2024-01-31 02:49:56,748 EPOCH 192
2024-01-31 02:49:58,741 [Epoch: 192 Step: 00012800] Batch Recognition Loss:  44.722115 => Gls Tokens per Sec:      241 || Batch Translation Loss: 130.520477 => Txt Tokens per Sec:      802 || Lr: 0.000100
2024-01-31 02:50:22,297 Epoch 192: Total Training Recognition Loss 2126.01  Total Training Translation Loss 6849.26 
2024-01-31 02:50:22,298 EPOCH 193
2024-01-31 02:50:35,052 [Epoch: 193 Step: 00012900] Batch Recognition Loss:  53.303333 => Gls Tokens per Sec:      452 || Batch Translation Loss: 127.614700 => Txt Tokens per Sec:     1207 || Lr: 0.000100
2024-01-31 02:50:47,855 Epoch 193: Total Training Recognition Loss 2125.83  Total Training Translation Loss 6849.34 
2024-01-31 02:50:47,855 EPOCH 194
2024-01-31 02:51:13,524 Epoch 194: Total Training Recognition Loss 2132.19  Total Training Translation Loss 6846.85 
2024-01-31 02:51:13,525 EPOCH 195
2024-01-31 02:51:14,762 [Epoch: 195 Step: 00013000] Batch Recognition Loss:  49.952789 => Gls Tokens per Sec:      259 || Batch Translation Loss: 126.688232 => Txt Tokens per Sec:      819 || Lr: 0.000100
2024-01-31 02:51:39,138 Epoch 195: Total Training Recognition Loss 2128.44  Total Training Translation Loss 6849.45 
2024-01-31 02:51:39,138 EPOCH 196
2024-01-31 02:51:52,905 [Epoch: 196 Step: 00013100] Batch Recognition Loss:  30.123606 => Gls Tokens per Sec:      400 || Batch Translation Loss: 103.773964 => Txt Tokens per Sec:     1097 || Lr: 0.000100
2024-01-31 02:52:04,785 Epoch 196: Total Training Recognition Loss 2128.26  Total Training Translation Loss 6847.91 
2024-01-31 02:52:04,785 EPOCH 197
2024-01-31 02:52:30,304 Epoch 197: Total Training Recognition Loss 2126.24  Total Training Translation Loss 6849.70 
2024-01-31 02:52:30,304 EPOCH 198
2024-01-31 02:52:30,515 [Epoch: 198 Step: 00013200] Batch Recognition Loss:  22.023067 => Gls Tokens per Sec:      762 || Batch Translation Loss:  82.216278 => Txt Tokens per Sec:     1705 || Lr: 0.000100
2024-01-31 02:52:55,971 Epoch 198: Total Training Recognition Loss 2124.60  Total Training Translation Loss 6848.41 
2024-01-31 02:52:55,971 EPOCH 199
2024-01-31 02:53:09,135 [Epoch: 199 Step: 00013300] Batch Recognition Loss:  23.337671 => Gls Tokens per Sec:      413 || Batch Translation Loss:  89.518066 => Txt Tokens per Sec:     1139 || Lr: 0.000100
2024-01-31 02:53:21,412 Epoch 199: Total Training Recognition Loss 2127.70  Total Training Translation Loss 6848.77 
2024-01-31 02:53:21,413 EPOCH 200
2024-01-31 02:53:46,742 [Epoch: 200 Step: 00013400] Batch Recognition Loss:  17.992548 => Gls Tokens per Sec:      420 || Batch Translation Loss:  84.552612 => Txt Tokens per Sec:     1165 || Lr: 0.000100
2024-01-31 02:53:46,743 Epoch 200: Total Training Recognition Loss 2128.66  Total Training Translation Loss 6848.86 
2024-01-31 02:53:46,743 EPOCH 201
2024-01-31 02:54:12,083 Epoch 201: Total Training Recognition Loss 2127.60  Total Training Translation Loss 6849.11 
2024-01-31 02:54:12,083 EPOCH 202
2024-01-31 02:54:25,373 [Epoch: 202 Step: 00013500] Batch Recognition Loss:  27.482292 => Gls Tokens per Sec:      391 || Batch Translation Loss: 105.225403 => Txt Tokens per Sec:     1104 || Lr: 0.000100
2024-01-31 02:54:37,355 Epoch 202: Total Training Recognition Loss 2125.09  Total Training Translation Loss 6848.41 
2024-01-31 02:54:37,356 EPOCH 203
2024-01-31 02:55:01,783 [Epoch: 203 Step: 00013600] Batch Recognition Loss:  23.689671 => Gls Tokens per Sec:      429 || Batch Translation Loss: 106.659058 => Txt Tokens per Sec:     1185 || Lr: 0.000100
2024-01-31 02:55:02,678 Epoch 203: Total Training Recognition Loss 2128.87  Total Training Translation Loss 6848.94 
2024-01-31 02:55:02,678 EPOCH 204
2024-01-31 02:55:28,127 Epoch 204: Total Training Recognition Loss 2128.38  Total Training Translation Loss 6850.19 
2024-01-31 02:55:28,127 EPOCH 205
2024-01-31 02:55:39,367 [Epoch: 205 Step: 00013700] Batch Recognition Loss:  33.906223 => Gls Tokens per Sec:      456 || Batch Translation Loss: 105.690582 => Txt Tokens per Sec:     1248 || Lr: 0.000100
2024-01-31 02:55:53,729 Epoch 205: Total Training Recognition Loss 2120.70  Total Training Translation Loss 6848.51 
2024-01-31 02:55:53,729 EPOCH 206
2024-01-31 02:56:19,022 [Epoch: 206 Step: 00013800] Batch Recognition Loss:  23.020199 => Gls Tokens per Sec:      408 || Batch Translation Loss:  86.971191 => Txt Tokens per Sec:     1135 || Lr: 0.000100
2024-01-31 02:56:19,477 Epoch 206: Total Training Recognition Loss 2128.68  Total Training Translation Loss 6848.08 
2024-01-31 02:56:19,477 EPOCH 207
2024-01-31 02:56:45,074 Epoch 207: Total Training Recognition Loss 2123.80  Total Training Translation Loss 6846.50 
2024-01-31 02:56:45,074 EPOCH 208
2024-01-31 02:56:57,836 [Epoch: 208 Step: 00013900] Batch Recognition Loss:  54.452343 => Gls Tokens per Sec:      382 || Batch Translation Loss: 130.355515 => Txt Tokens per Sec:     1083 || Lr: 0.000100
2024-01-31 02:57:10,559 Epoch 208: Total Training Recognition Loss 2125.49  Total Training Translation Loss 6848.74 
2024-01-31 02:57:10,559 EPOCH 209
2024-01-31 02:57:35,432 [Epoch: 209 Step: 00014000] Batch Recognition Loss:  28.128065 => Gls Tokens per Sec:      408 || Batch Translation Loss:  84.888596 => Txt Tokens per Sec:     1138 || Lr: 0.000100
2024-01-31 02:58:05,061 Validation result at epoch 209, step    14000: duration: 29.6298s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 666.61511	Translation Loss: 73488.84375	PPL: 1562.48413
	Eval Metric: BLEU
	WER 526.41	(DEL: 4.52,	INS: 438.49,	SUB: 83.40)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.48	ROUGE 0.00
2024-01-31 02:58:05,062 Logging Recognition and Translation Outputs
2024-01-31 02:58:05,063 ========================================================================================================================
2024-01-31 02:58:05,063 Logging Sequence: 141_40.00
2024-01-31 02:58:05,063 	Gloss Reference :	***** * ***** * ***** * ***** * ***** * ***** * A     B+C+D+E  
2024-01-31 02:58:05,063 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E <unk> E <unk> E <unk> E+D+E+C+E
2024-01-31 02:58:05,063 	Gloss Alignment :	I     I I     I I     I I     I I     I I     I S     S        
2024-01-31 02:58:05,063 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:58:05,067 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ********* ********* ********* ********* ********* ********* got       infected  with      covid-19  he        was       quarantined and       could     not       take      part      in        the       warmup    match    
2024-01-31 02:58:05,067 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently   patiently patiently patiently patiently patiently patiently patiently patiently patiently
2024-01-31 02:58:05,067 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I         I         I         I         I         I         S         S         S         S         S         S         S           S         S         S         S         S         S         S         S         S        
2024-01-31 02:58:05,067 ========================================================================================================================
2024-01-31 02:58:05,068 Logging Sequence: 117_37.00
2024-01-31 02:58:05,068 	Gloss Reference :	***** * ***** * ***** *** ***** * ***** * ***** * ***** A ***** ***** ***** * ***** ******* B+C+D+E
2024-01-31 02:58:05,068 	Gloss Hypothesis:	<unk> A <unk> C <unk> C+E <unk> E <unk> C <unk> C <unk> A <unk> <pad> <unk> C <unk> C+E+C+E <unk>  
2024-01-31 02:58:05,068 	Gloss Alignment :	I     I I     I I     I   I     I I     I I     I I       I     I     I     I I     I       S      
2024-01-31 02:58:05,068 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:58:05,071 	Text Reference  :	*** *** *** *** *** *** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** shikhar  dhawan   put      up       a        wonderful performance scoring  98       runs    
2024-01-31 02:58:05,071 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas  casillas    casillas casillas casillas
2024-01-31 02:58:05,071 	Text Alignment  :	I   I   I   I   I   I   I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S        S        S        S        S         S           S        S        S       
2024-01-31 02:58:05,071 ========================================================================================================================
2024-01-31 02:58:05,071 Logging Sequence: 64_13.00
2024-01-31 02:58:05,072 	Gloss Reference :	***** ***** ***** ***** ***** A     B+C+D+E
2024-01-31 02:58:05,072 	Gloss Hypothesis:	<unk> <pad> <unk> <pad> <unk> <pad> <unk>  
2024-01-31 02:58:05,072 	Gloss Alignment :	I     I     I     I     I     S     S      
2024-01-31 02:58:05,072 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:58:05,075 	Text Reference  :	*** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* arrangements  were          made          to            move          all           the           ipl           matches       to            the           wankhede      stadium       in            mumbai       
2024-01-31 02:58:05,075 	Text Hypothesis :	<s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 02:58:05,076 	Text Alignment  :	I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 02:58:05,076 ========================================================================================================================
2024-01-31 02:58:05,076 Logging Sequence: 98_121.00
2024-01-31 02:58:05,076 	Gloss Reference :	***** * ***** * ***** *** ***** ***** ***** A B+C+D+E
2024-01-31 02:58:05,076 	Gloss Hypothesis:	<unk> C <unk> C <unk> C+B <unk> C+B+C <unk> C <unk>  
2024-01-31 02:58:05,076 	Gloss Alignment :	I     I I     I I     I   I     I     I     S S      
2024-01-31 02:58:05,077 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:58:05,079 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* so      then    england legends and     bangladesh legends were    added   to      the     tournament
2024-01-31 02:58:05,079 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing    nothing nothing nothing nothing nothing nothing   
2024-01-31 02:58:05,079 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S       S          S       S       S       S       S       S         
2024-01-31 02:58:05,080 ========================================================================================================================
2024-01-31 02:58:05,080 Logging Sequence: 179_414.00
2024-01-31 02:58:05,080 	Gloss Reference :	***** *** ***** * ***** A   B+C+D+E
2024-01-31 02:58:05,080 	Gloss Hypothesis:	<unk> E+B <unk> C <unk> B+E <unk>  
2024-01-31 02:58:05,080 	Gloss Alignment :	I     I   I     I I     S   S      
2024-01-31 02:58:05,080 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 02:58:05,084 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** we  could not travel to  delhi as  there was a   lockdown in  our home town haryana
2024-01-31 02:58:05,084 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s> <s>    <s> <s>   <s> <s>   <s> <s> <s>      <s> <s> <s>  <s>  <s>    
2024-01-31 02:58:05,084 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S     S   S      S   S     S   S     S   S   S        S   S   S    S    S      
2024-01-31 02:58:05,084 ========================================================================================================================
2024-01-31 02:58:05,734 Epoch 209: Total Training Recognition Loss 2126.39  Total Training Translation Loss 6848.01 
2024-01-31 02:58:05,734 EPOCH 210
2024-01-31 02:58:31,208 Epoch 210: Total Training Recognition Loss 2124.49  Total Training Translation Loss 6849.77 
2024-01-31 02:58:31,208 EPOCH 211
2024-01-31 02:58:43,812 [Epoch: 211 Step: 00014100] Batch Recognition Loss:  35.981117 => Gls Tokens per Sec:      374 || Batch Translation Loss: 119.879135 => Txt Tokens per Sec:     1062 || Lr: 0.000100
2024-01-31 02:58:56,996 Epoch 211: Total Training Recognition Loss 2131.41  Total Training Translation Loss 6847.74 
2024-01-31 02:58:56,997 EPOCH 212
2024-01-31 02:59:21,285 [Epoch: 212 Step: 00014200] Batch Recognition Loss:  32.220123 => Gls Tokens per Sec:      411 || Batch Translation Loss:  98.724899 => Txt Tokens per Sec:     1142 || Lr: 0.000100
2024-01-31 02:59:22,492 Epoch 212: Total Training Recognition Loss 2127.66  Total Training Translation Loss 6847.93 
2024-01-31 02:59:22,493 EPOCH 213
2024-01-31 02:59:47,884 Epoch 213: Total Training Recognition Loss 2130.00  Total Training Translation Loss 6848.82 
2024-01-31 02:59:47,884 EPOCH 214
2024-01-31 02:59:57,280 [Epoch: 214 Step: 00014300] Batch Recognition Loss:  27.636227 => Gls Tokens per Sec:      494 || Batch Translation Loss:  85.436821 => Txt Tokens per Sec:     1339 || Lr: 0.000100
2024-01-31 03:00:13,389 Epoch 214: Total Training Recognition Loss 2124.97  Total Training Translation Loss 6848.23 
2024-01-31 03:00:13,390 EPOCH 215
2024-01-31 03:00:37,441 [Epoch: 215 Step: 00014400] Batch Recognition Loss:  11.487144 => Gls Tokens per Sec:      409 || Batch Translation Loss:  62.450867 => Txt Tokens per Sec:     1140 || Lr: 0.000100
2024-01-31 03:00:39,138 Epoch 215: Total Training Recognition Loss 2127.18  Total Training Translation Loss 6850.26 
2024-01-31 03:00:39,138 EPOCH 216
2024-01-31 03:01:04,688 Epoch 216: Total Training Recognition Loss 2126.13  Total Training Translation Loss 6847.13 
2024-01-31 03:01:04,688 EPOCH 217
2024-01-31 03:01:15,639 [Epoch: 217 Step: 00014500] Batch Recognition Loss:  10.328802 => Gls Tokens per Sec:      401 || Batch Translation Loss:  63.570305 => Txt Tokens per Sec:     1082 || Lr: 0.000100
2024-01-31 03:01:30,605 Epoch 217: Total Training Recognition Loss 2127.61  Total Training Translation Loss 6848.27 
2024-01-31 03:01:30,606 EPOCH 218
2024-01-31 03:01:54,463 [Epoch: 218 Step: 00014600] Batch Recognition Loss:  17.734377 => Gls Tokens per Sec:      405 || Batch Translation Loss:  87.176384 => Txt Tokens per Sec:     1129 || Lr: 0.000100
2024-01-31 03:01:56,232 Epoch 218: Total Training Recognition Loss 2125.63  Total Training Translation Loss 6848.02 
2024-01-31 03:01:56,232 EPOCH 219
2024-01-31 03:02:21,908 Epoch 219: Total Training Recognition Loss 2130.45  Total Training Translation Loss 6847.70 
2024-01-31 03:02:21,908 EPOCH 220
2024-01-31 03:02:31,347 [Epoch: 220 Step: 00014700] Batch Recognition Loss:  36.903896 => Gls Tokens per Sec:      448 || Batch Translation Loss: 103.498535 => Txt Tokens per Sec:     1208 || Lr: 0.000100
2024-01-31 03:02:47,570 Epoch 220: Total Training Recognition Loss 2125.70  Total Training Translation Loss 6850.16 
2024-01-31 03:02:47,570 EPOCH 221
2024-01-31 03:03:10,643 [Epoch: 221 Step: 00014800] Batch Recognition Loss:  28.184187 => Gls Tokens per Sec:      412 || Batch Translation Loss:  97.166077 => Txt Tokens per Sec:     1146 || Lr: 0.000100
2024-01-31 03:03:13,072 Epoch 221: Total Training Recognition Loss 2130.30  Total Training Translation Loss 6849.78 
2024-01-31 03:03:13,073 EPOCH 222
2024-01-31 03:03:38,716 Epoch 222: Total Training Recognition Loss 2130.79  Total Training Translation Loss 6848.31 
2024-01-31 03:03:38,716 EPOCH 223
2024-01-31 03:03:48,392 [Epoch: 223 Step: 00014900] Batch Recognition Loss:  28.638367 => Gls Tokens per Sec:      421 || Batch Translation Loss:  83.870056 => Txt Tokens per Sec:     1069 || Lr: 0.000100
2024-01-31 03:04:04,453 Epoch 223: Total Training Recognition Loss 2127.40  Total Training Translation Loss 6846.54 
2024-01-31 03:04:04,453 EPOCH 224
2024-01-31 03:04:26,733 [Epoch: 224 Step: 00015000] Batch Recognition Loss:  33.615601 => Gls Tokens per Sec:      420 || Batch Translation Loss:  96.173950 => Txt Tokens per Sec:     1172 || Lr: 0.000100
2024-01-31 03:04:30,218 Epoch 224: Total Training Recognition Loss 2121.52  Total Training Translation Loss 6848.33 
2024-01-31 03:04:30,218 EPOCH 225
2024-01-31 03:04:55,606 Epoch 225: Total Training Recognition Loss 2123.56  Total Training Translation Loss 6847.70 
2024-01-31 03:04:55,606 EPOCH 226
2024-01-31 03:05:03,989 [Epoch: 226 Step: 00015100] Batch Recognition Loss:  38.188972 => Gls Tokens per Sec:      477 || Batch Translation Loss: 114.303917 => Txt Tokens per Sec:     1288 || Lr: 0.000100
2024-01-31 03:05:21,000 Epoch 226: Total Training Recognition Loss 2127.63  Total Training Translation Loss 6846.24 
2024-01-31 03:05:21,000 EPOCH 227
2024-01-31 03:05:42,726 [Epoch: 227 Step: 00015200] Batch Recognition Loss:  38.562057 => Gls Tokens per Sec:      423 || Batch Translation Loss: 114.657547 => Txt Tokens per Sec:     1169 || Lr: 0.000100
2024-01-31 03:05:46,450 Epoch 227: Total Training Recognition Loss 2123.17  Total Training Translation Loss 6848.52 
2024-01-31 03:05:46,450 EPOCH 228
2024-01-31 03:06:11,882 Epoch 228: Total Training Recognition Loss 2129.95  Total Training Translation Loss 6848.36 
2024-01-31 03:06:11,882 EPOCH 229
2024-01-31 03:06:19,999 [Epoch: 229 Step: 00015300] Batch Recognition Loss:  36.874378 => Gls Tokens per Sec:      473 || Batch Translation Loss: 107.518570 => Txt Tokens per Sec:     1295 || Lr: 0.000100
2024-01-31 03:06:37,396 Epoch 229: Total Training Recognition Loss 2124.64  Total Training Translation Loss 6847.69 
2024-01-31 03:06:37,396 EPOCH 230
2024-01-31 03:06:59,839 [Epoch: 230 Step: 00015400] Batch Recognition Loss:  37.337208 => Gls Tokens per Sec:      402 || Batch Translation Loss: 107.662315 => Txt Tokens per Sec:     1128 || Lr: 0.000100
2024-01-31 03:07:02,893 Epoch 230: Total Training Recognition Loss 2127.88  Total Training Translation Loss 6848.57 
2024-01-31 03:07:02,894 EPOCH 231
2024-01-31 03:07:28,575 Epoch 231: Total Training Recognition Loss 2130.55  Total Training Translation Loss 6847.78 
2024-01-31 03:07:28,575 EPOCH 232
2024-01-31 03:07:36,849 [Epoch: 232 Step: 00015500] Batch Recognition Loss:  22.516834 => Gls Tokens per Sec:      445 || Batch Translation Loss:  80.819267 => Txt Tokens per Sec:     1201 || Lr: 0.000100
2024-01-31 03:07:54,154 Epoch 232: Total Training Recognition Loss 2126.36  Total Training Translation Loss 6848.84 
2024-01-31 03:07:54,154 EPOCH 233
2024-01-31 03:08:15,602 [Epoch: 233 Step: 00015600] Batch Recognition Loss:  37.589100 => Gls Tokens per Sec:      414 || Batch Translation Loss: 119.942429 => Txt Tokens per Sec:     1150 || Lr: 0.000100
2024-01-31 03:08:19,673 Epoch 233: Total Training Recognition Loss 2128.13  Total Training Translation Loss 6847.85 
2024-01-31 03:08:19,673 EPOCH 234
2024-01-31 03:08:45,323 Epoch 234: Total Training Recognition Loss 2126.53  Total Training Translation Loss 6848.38 
2024-01-31 03:08:45,323 EPOCH 235
2024-01-31 03:08:52,376 [Epoch: 235 Step: 00015700] Batch Recognition Loss:  28.104361 => Gls Tokens per Sec:      499 || Batch Translation Loss:  94.882797 => Txt Tokens per Sec:     1352 || Lr: 0.000100
2024-01-31 03:09:10,979 Epoch 235: Total Training Recognition Loss 2126.07  Total Training Translation Loss 6846.68 
2024-01-31 03:09:10,980 EPOCH 236
2024-01-31 03:09:31,212 [Epoch: 236 Step: 00015800] Batch Recognition Loss:  36.438927 => Gls Tokens per Sec:      431 || Batch Translation Loss: 118.798248 => Txt Tokens per Sec:     1179 || Lr: 0.000100
2024-01-31 03:09:36,699 Epoch 236: Total Training Recognition Loss 2127.69  Total Training Translation Loss 6849.86 
2024-01-31 03:09:36,699 EPOCH 237
2024-01-31 03:10:02,331 Epoch 237: Total Training Recognition Loss 2129.67  Total Training Translation Loss 6848.16 
2024-01-31 03:10:02,331 EPOCH 238
2024-01-31 03:10:10,687 [Epoch: 238 Step: 00015900] Batch Recognition Loss:  36.433628 => Gls Tokens per Sec:      391 || Batch Translation Loss: 115.151337 => Txt Tokens per Sec:     1129 || Lr: 0.000100
2024-01-31 03:10:27,926 Epoch 238: Total Training Recognition Loss 2127.90  Total Training Translation Loss 6847.39 
2024-01-31 03:10:27,927 EPOCH 239
2024-01-31 03:10:48,664 [Epoch: 239 Step: 00016000] Batch Recognition Loss:  11.444644 => Gls Tokens per Sec:      417 || Batch Translation Loss:  62.653622 => Txt Tokens per Sec:     1161 || Lr: 0.000100
2024-01-31 03:11:17,991 Validation result at epoch 239, step    16000: duration: 29.3270s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 672.95862	Translation Loss: 73502.17188	PPL: 1564.56982
	Eval Metric: BLEU
	WER 533.55	(DEL: 4.38,	INS: 445.76,	SUB: 83.40)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.44	ROUGE 0.00
2024-01-31 03:11:17,992 Logging Recognition and Translation Outputs
2024-01-31 03:11:17,992 ========================================================================================================================
2024-01-31 03:11:17,993 Logging Sequence: 147_132.00
2024-01-31 03:11:17,993 	Gloss Reference :	* ***** *** ***** A ***** ************************************* ***** ***** *** ***** B+C+D+E    
2024-01-31 03:11:17,993 	Gloss Hypothesis:	E <unk> B+E <unk> A <pad> B+E+B+C+E+C+B+E+B+E+C+B+E+C+B+C+E+B+E <unk> <pad> B+E <unk> B+E+B+C+B+E
2024-01-31 03:11:17,993 	Gloss Alignment :	I I     I   I       I     I                                     I     I     I   I     S          
2024-01-31 03:11:17,993 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:11:17,996 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** i   can not earlier i   used to  have fun in  gymnastics
2024-01-31 03:11:17,996 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s> <s>  <s> <s>  <s> <s> <s>       
2024-01-31 03:11:17,996 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S   S   S       S   S    S   S    S   S   S         
2024-01-31 03:11:17,996 ========================================================================================================================
2024-01-31 03:11:17,996 Logging Sequence: 116_162.00
2024-01-31 03:11:17,996 	Gloss Reference :	A B+C+D+E
2024-01-31 03:11:17,997 	Gloss Hypothesis:	* E+C+E  
2024-01-31 03:11:17,997 	Gloss Alignment :	D S      
2024-01-31 03:11:17,997 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:11:18,000 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* turned        out           the           video         was           shared        on            social        media         by            a             staff         at            the           hotel        
2024-01-31 03:11:18,000 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions
2024-01-31 03:11:18,000 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 03:11:18,000 ========================================================================================================================
2024-01-31 03:11:18,001 Logging Sequence: 73_79.00
2024-01-31 03:11:18,001 	Gloss Reference :	***** ***** ***** A ***** * ***** * ***** * ***** ************* ***** * ***** ******* B+C+D+E
2024-01-31 03:11:18,001 	Gloss Hypothesis:	<unk> B+C+A <unk> A <unk> C <unk> B <unk> B <unk> C+B+C+B+C+B+A <unk> C <unk> B+C+B+C <unk>  
2024-01-31 03:11:18,001 	Gloss Alignment :	I     I     I       I     I I     I I     I I     I             I     I I     I       S      
2024-01-31 03:11:18,001 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:11:18,005 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** raina resturant has   food  from  the   rich  spices of    north india to    the   aromatic curries of    south india
2024-01-31 03:11:18,005 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo     mateo mateo mateo mateo mateo mateo  mateo mateo mateo mateo mateo mateo    mateo   mateo mateo mateo
2024-01-31 03:11:18,005 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     S     S         S     S     S     S     S     S      S     S     S     S     S     S        S       S     S     S    
2024-01-31 03:11:18,005 ========================================================================================================================
2024-01-31 03:11:18,006 Logging Sequence: 165_523.00
2024-01-31 03:11:18,006 	Gloss Reference :	***** ***** *** ***** * ***** A ***** * ***** ********* ***** *** B+C+D+E
2024-01-31 03:11:18,006 	Gloss Hypothesis:	<pad> <unk> B+C <unk> B <unk> A <unk> E <unk> E+B+E+B+E <unk> C+B <unk>  
2024-01-31 03:11:18,006 	Gloss Alignment :	I     I     I   I     I I       I     I I     I         I     I   S      
2024-01-31 03:11:18,006 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:11:18,010 	Text Reference  :	******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** as       he       believed that     his      team     might    lose     if       he       takes    off      his      batting  pads    
2024-01-31 03:11:18,010 	Text Hypothesis :	reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared
2024-01-31 03:11:18,010 	Text Alignment  :	I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S        S        S        S        S        S        S        S        S        S        S        S        S        S       
2024-01-31 03:11:18,010 ========================================================================================================================
2024-01-31 03:11:18,010 Logging Sequence: 125_72.00
2024-01-31 03:11:18,011 	Gloss Reference :	***** ***** A ***** * ***** ***** ***** *** ***** ******* ***** ***** ***** * ***** ***** ******* ***** * ***** * ***** ************************* ***** B+C+D+E
2024-01-31 03:11:18,011 	Gloss Hypothesis:	<unk> <pad> A <pad> E <unk> E+B+C <unk> E+B <pad> B+E+B+E <pad> E+B+E <unk> E <pad> <unk> C+E+B+E <pad> E <unk> E <unk> E+B+E+B+E+B+C+B+C+E+C+B+E <pad> C+E+C+E
2024-01-31 03:11:18,011 	Gloss Alignment :	I     I       I     I I     I     I     I   I     I       I     I     I     I I     I     I       I     I I     I I     I                         I     S      
2024-01-31 03:11:18,011 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:11:18,014 	Text Reference  :	*** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** some  said  the   pakistani javelineer had   milicious intentions of    tampering with  the   javelin out   of    jealousy
2024-01-31 03:11:18,015 	Text Hypothesis :	<s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha     sabha      sabha sabha     sabha      sabha sabha     sabha sabha sabha   sabha sabha sabha   
2024-01-31 03:11:18,015 	Text Alignment  :	I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S     S         S          S     S         S          S     S         S     S     S       S     S     S       
2024-01-31 03:11:18,015 ========================================================================================================================
2024-01-31 03:11:22,765 Epoch 239: Total Training Recognition Loss 2124.61  Total Training Translation Loss 6847.76 
2024-01-31 03:11:22,765 EPOCH 240
2024-01-31 03:11:48,334 Epoch 240: Total Training Recognition Loss 2126.00  Total Training Translation Loss 6847.21 
2024-01-31 03:11:48,334 EPOCH 241
2024-01-31 03:11:55,309 [Epoch: 241 Step: 00016100] Batch Recognition Loss:  30.276567 => Gls Tokens per Sec:      459 || Batch Translation Loss:  99.396538 => Txt Tokens per Sec:     1204 || Lr: 0.000100
2024-01-31 03:12:13,814 Epoch 241: Total Training Recognition Loss 2125.99  Total Training Translation Loss 6848.42 
2024-01-31 03:12:13,814 EPOCH 242
2024-01-31 03:12:35,254 [Epoch: 242 Step: 00016200] Batch Recognition Loss:  44.494839 => Gls Tokens per Sec:      391 || Batch Translation Loss: 129.632629 => Txt Tokens per Sec:     1106 || Lr: 0.000100
2024-01-31 03:12:39,501 Epoch 242: Total Training Recognition Loss 2126.99  Total Training Translation Loss 6846.90 
2024-01-31 03:12:39,502 EPOCH 243
2024-01-31 03:13:05,001 Epoch 243: Total Training Recognition Loss 2128.34  Total Training Translation Loss 6848.98 
2024-01-31 03:13:05,001 EPOCH 244
2024-01-31 03:13:11,998 [Epoch: 244 Step: 00016300] Batch Recognition Loss:  19.627750 => Gls Tokens per Sec:      435 || Batch Translation Loss:  98.633942 => Txt Tokens per Sec:     1191 || Lr: 0.000100
2024-01-31 03:13:30,624 Epoch 244: Total Training Recognition Loss 2122.15  Total Training Translation Loss 6850.43 
2024-01-31 03:13:30,625 EPOCH 245
2024-01-31 03:13:51,483 [Epoch: 245 Step: 00016400] Batch Recognition Loss:  30.127464 => Gls Tokens per Sec:      395 || Batch Translation Loss:  98.344246 => Txt Tokens per Sec:     1108 || Lr: 0.000100
2024-01-31 03:13:56,203 Epoch 245: Total Training Recognition Loss 2130.50  Total Training Translation Loss 6848.94 
2024-01-31 03:13:56,203 EPOCH 246
2024-01-31 03:14:21,822 Epoch 246: Total Training Recognition Loss 2125.08  Total Training Translation Loss 6848.24 
2024-01-31 03:14:21,822 EPOCH 247
2024-01-31 03:14:27,543 [Epoch: 247 Step: 00016500] Batch Recognition Loss:  38.318497 => Gls Tokens per Sec:      503 || Batch Translation Loss: 115.623039 => Txt Tokens per Sec:     1339 || Lr: 0.000100
2024-01-31 03:14:47,507 Epoch 247: Total Training Recognition Loss 2127.33  Total Training Translation Loss 6848.19 
2024-01-31 03:14:47,507 EPOCH 248
2024-01-31 03:15:04,567 [Epoch: 248 Step: 00016600] Batch Recognition Loss:  52.286442 => Gls Tokens per Sec:      473 || Batch Translation Loss: 133.876404 => Txt Tokens per Sec:     1272 || Lr: 0.000100
2024-01-31 03:15:13,124 Epoch 248: Total Training Recognition Loss 2122.01  Total Training Translation Loss 6849.79 
2024-01-31 03:15:13,124 EPOCH 249
2024-01-31 03:15:38,666 Epoch 249: Total Training Recognition Loss 2126.91  Total Training Translation Loss 6849.14 
2024-01-31 03:15:38,667 EPOCH 250
2024-01-31 03:15:45,428 [Epoch: 250 Step: 00016700] Batch Recognition Loss:  36.112919 => Gls Tokens per Sec:      389 || Batch Translation Loss: 113.030624 => Txt Tokens per Sec:     1064 || Lr: 0.000100
2024-01-31 03:16:04,341 Epoch 250: Total Training Recognition Loss 2126.13  Total Training Translation Loss 6849.97 
2024-01-31 03:16:04,341 EPOCH 251
2024-01-31 03:16:24,217 [Epoch: 251 Step: 00016800] Batch Recognition Loss:  19.795082 => Gls Tokens per Sec:      398 || Batch Translation Loss:  93.987816 => Txt Tokens per Sec:     1112 || Lr: 0.000100
2024-01-31 03:16:30,947 Epoch 251: Total Training Recognition Loss 2123.48  Total Training Translation Loss 6849.68 
2024-01-31 03:16:30,947 EPOCH 252
2024-01-31 03:16:59,455 Epoch 252: Total Training Recognition Loss 2129.74  Total Training Translation Loss 6848.88 
2024-01-31 03:16:59,455 EPOCH 253
2024-01-31 03:17:04,892 [Epoch: 253 Step: 00016900] Batch Recognition Loss:  32.901741 => Gls Tokens per Sec:      471 || Batch Translation Loss: 110.090599 => Txt Tokens per Sec:     1268 || Lr: 0.000100
2024-01-31 03:17:25,119 Epoch 253: Total Training Recognition Loss 2125.91  Total Training Translation Loss 6848.24 
2024-01-31 03:17:25,119 EPOCH 254
2024-01-31 03:17:41,386 [Epoch: 254 Step: 00017000] Batch Recognition Loss:  17.449188 => Gls Tokens per Sec:      476 || Batch Translation Loss:  77.358406 => Txt Tokens per Sec:     1263 || Lr: 0.000100
2024-01-31 03:17:50,798 Epoch 254: Total Training Recognition Loss 2130.46  Total Training Translation Loss 6849.88 
2024-01-31 03:17:50,798 EPOCH 255
2024-01-31 03:18:16,327 Epoch 255: Total Training Recognition Loss 2122.27  Total Training Translation Loss 6848.18 
2024-01-31 03:18:16,327 EPOCH 256
2024-01-31 03:18:22,676 [Epoch: 256 Step: 00017100] Batch Recognition Loss:  13.976141 => Gls Tokens per Sec:      378 || Batch Translation Loss:  82.077507 => Txt Tokens per Sec:     1066 || Lr: 0.000100
2024-01-31 03:18:41,772 Epoch 256: Total Training Recognition Loss 2130.36  Total Training Translation Loss 6846.87 
2024-01-31 03:18:41,772 EPOCH 257
2024-01-31 03:18:59,909 [Epoch: 257 Step: 00017200] Batch Recognition Loss:  30.115711 => Gls Tokens per Sec:      423 || Batch Translation Loss:  99.582855 => Txt Tokens per Sec:     1170 || Lr: 0.000100
2024-01-31 03:19:07,256 Epoch 257: Total Training Recognition Loss 2127.71  Total Training Translation Loss 6846.61 
2024-01-31 03:19:07,256 EPOCH 258
2024-01-31 03:19:32,745 Epoch 258: Total Training Recognition Loss 2125.55  Total Training Translation Loss 6849.02 
2024-01-31 03:19:32,745 EPOCH 259
2024-01-31 03:19:38,175 [Epoch: 259 Step: 00017300] Batch Recognition Loss:  36.854126 => Gls Tokens per Sec:      413 || Batch Translation Loss: 129.761414 => Txt Tokens per Sec:     1161 || Lr: 0.000100
2024-01-31 03:19:58,176 Epoch 259: Total Training Recognition Loss 2124.93  Total Training Translation Loss 6850.11 
2024-01-31 03:19:58,176 EPOCH 260
2024-01-31 03:20:17,476 [Epoch: 260 Step: 00017400] Batch Recognition Loss:  37.176292 => Gls Tokens per Sec:      385 || Batch Translation Loss: 132.212234 => Txt Tokens per Sec:     1078 || Lr: 0.000100
2024-01-31 03:20:23,822 Epoch 260: Total Training Recognition Loss 2123.89  Total Training Translation Loss 6847.63 
2024-01-31 03:20:23,822 EPOCH 261
2024-01-31 03:20:49,394 Epoch 261: Total Training Recognition Loss 2121.47  Total Training Translation Loss 6848.94 
2024-01-31 03:20:49,394 EPOCH 262
2024-01-31 03:20:54,806 [Epoch: 262 Step: 00017500] Batch Recognition Loss:  16.988331 => Gls Tokens per Sec:      384 || Batch Translation Loss:  76.086884 => Txt Tokens per Sec:     1149 || Lr: 0.000100
2024-01-31 03:21:15,041 Epoch 262: Total Training Recognition Loss 2122.63  Total Training Translation Loss 6850.30 
2024-01-31 03:21:15,042 EPOCH 263
2024-01-31 03:21:34,165 [Epoch: 263 Step: 00017600] Batch Recognition Loss:  37.280666 => Gls Tokens per Sec:      385 || Batch Translation Loss: 108.143921 => Txt Tokens per Sec:     1110 || Lr: 0.000100
2024-01-31 03:21:40,709 Epoch 263: Total Training Recognition Loss 2125.66  Total Training Translation Loss 6849.43 
2024-01-31 03:21:40,709 EPOCH 264
2024-01-31 03:22:06,757 Epoch 264: Total Training Recognition Loss 2125.91  Total Training Translation Loss 6847.98 
2024-01-31 03:22:06,757 EPOCH 265
2024-01-31 03:22:11,474 [Epoch: 265 Step: 00017700] Batch Recognition Loss:  61.008476 => Gls Tokens per Sec:      407 || Batch Translation Loss: 133.832672 => Txt Tokens per Sec:     1093 || Lr: 0.000100
2024-01-31 03:22:32,503 Epoch 265: Total Training Recognition Loss 2127.96  Total Training Translation Loss 6848.30 
2024-01-31 03:22:32,504 EPOCH 266
2024-01-31 03:22:49,693 [Epoch: 266 Step: 00017800] Batch Recognition Loss:  23.838810 => Gls Tokens per Sec:      414 || Batch Translation Loss:  95.344620 => Txt Tokens per Sec:     1144 || Lr: 0.000100
2024-01-31 03:22:57,867 Epoch 266: Total Training Recognition Loss 2128.66  Total Training Translation Loss 6849.88 
2024-01-31 03:22:57,867 EPOCH 267
2024-01-31 03:23:23,308 Epoch 267: Total Training Recognition Loss 2125.80  Total Training Translation Loss 6846.28 
2024-01-31 03:23:23,308 EPOCH 268
2024-01-31 03:23:27,636 [Epoch: 268 Step: 00017900] Batch Recognition Loss:  41.703308 => Gls Tokens per Sec:      407 || Batch Translation Loss: 137.847015 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 03:23:48,785 Epoch 268: Total Training Recognition Loss 2126.98  Total Training Translation Loss 6848.23 
2024-01-31 03:23:48,785 EPOCH 269
2024-01-31 03:24:06,184 [Epoch: 269 Step: 00018000] Batch Recognition Loss:  17.174728 => Gls Tokens per Sec:      399 || Batch Translation Loss:  74.070915 => Txt Tokens per Sec:     1108 || Lr: 0.000100
2024-01-31 03:24:35,874 Validation result at epoch 269, step    18000: duration: 29.6904s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 671.96411	Translation Loss: 73472.26562	PPL: 1559.89380
	Eval Metric: BLEU
	WER 537.36	(DEL: 4.17,	INS: 449.22,	SUB: 83.97)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.43	ROUGE 0.00
2024-01-31 03:24:35,876 Logging Recognition and Translation Outputs
2024-01-31 03:24:35,876 ========================================================================================================================
2024-01-31 03:24:35,876 Logging Sequence: 155_119.00
2024-01-31 03:24:35,876 	Gloss Reference :	A B+C+D+E                  
2024-01-31 03:24:35,876 	Gloss Hypothesis:	C A+E+C+E+C+E+B+C+B+C+B+E+C
2024-01-31 03:24:35,876 	Gloss Alignment :	S S                        
2024-01-31 03:24:35,876 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:24:35,880 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** a   report said that the taliban wanted icc to  replace the afghan flag with its own
2024-01-31 03:24:35,880 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>    <s>  <s>  <s> <s>     <s>    <s> <s> <s>     <s> <s>    <s>  <s>  <s> <s>
2024-01-31 03:24:35,880 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S      S    S    S   S       S      S   S   S       S   S      S    S    S   S  
2024-01-31 03:24:35,880 ========================================================================================================================
2024-01-31 03:24:35,880 Logging Sequence: 153_43.00
2024-01-31 03:24:35,880 	Gloss Reference :	A B+C+D+E
2024-01-31 03:24:35,881 	Gloss Hypothesis:	* <unk>  
2024-01-31 03:24:35,881 	Gloss Alignment :	D S      
2024-01-31 03:24:35,881 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:24:35,883 	Text Reference  :	******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* these   runs    were    all     because of      hardik  pandya  and     virat   kohli  
2024-01-31 03:24:35,883 	Text Hypothesis :	nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing
2024-01-31 03:24:35,883 	Text Alignment  :	I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S       S       S       S       S       S       S      
2024-01-31 03:24:35,884 ========================================================================================================================
2024-01-31 03:24:35,884 Logging Sequence: 150_35.00
2024-01-31 03:24:35,884 	Gloss Reference :	*** ***** *** A     B+C+D+E
2024-01-31 03:24:35,884 	Gloss Hypothesis:	E+A <pad> E+A <unk> E      
2024-01-31 03:24:35,884 	Gloss Alignment :	I   I     I   S     S      
2024-01-31 03:24:35,884 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:24:35,886 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** wow india football team is  really strong
2024-01-31 03:24:35,886 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s>      <s>  <s> <s>    <s>   
2024-01-31 03:24:35,886 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S     S        S    S   S      S     
2024-01-31 03:24:35,886 ========================================================================================================================
2024-01-31 03:24:35,887 Logging Sequence: 146_154.00
2024-01-31 03:24:35,887 	Gloss Reference :	***** *********** ***** ******* ***** * ***** ******* ***** ******************* ***** * A     B+C+D+E
2024-01-31 03:24:35,887 	Gloss Hypothesis:	<unk> C+E+B+C+E+B <unk> E+C+B+E <unk> E <unk> E+C+E+C <unk> C+E+B+E+C+E+C+E+C+E <pad> E <unk> E+C    
2024-01-31 03:24:35,887 	Gloss Alignment :	I     I           I     I       I     I I     I       I     I                   I     I S     S      
2024-01-31 03:24:35,887 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:24:35,891 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* bwf           said          that          testing       protocols     have          been          implemented   to            ensure        the           health        and           safety        of            all           participants 
2024-01-31 03:24:35,891 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions
2024-01-31 03:24:35,891 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 03:24:35,891 ========================================================================================================================
2024-01-31 03:24:35,891 Logging Sequence: 76_79.00
2024-01-31 03:24:35,892 	Gloss Reference :	***** ***** ***** * A     B+C+D+E  
2024-01-31 03:24:35,892 	Gloss Hypothesis:	<unk> E+A+E <unk> C <unk> E+C+E+B+E
2024-01-31 03:24:35,892 	Gloss Alignment :	I     I     I     I S     S        
2024-01-31 03:24:35,892 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:24:35,894 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* speaking to      ani     csk     ceo     kasi    viswanathan said   
2024-01-31 03:24:35,894 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing  nothing nothing nothing nothing nothing nothing     nothing
2024-01-31 03:24:35,894 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S        S       S       S       S       S       S           S      
2024-01-31 03:24:35,894 ========================================================================================================================
2024-01-31 03:24:43,942 Epoch 269: Total Training Recognition Loss 2128.98  Total Training Translation Loss 6849.13 
2024-01-31 03:24:43,942 EPOCH 270
2024-01-31 03:25:09,542 Epoch 270: Total Training Recognition Loss 2130.11  Total Training Translation Loss 6848.37 
2024-01-31 03:25:09,542 EPOCH 271
2024-01-31 03:25:13,013 [Epoch: 271 Step: 00018100] Batch Recognition Loss:   7.234928 => Gls Tokens per Sec:      435 || Batch Translation Loss:  57.420300 => Txt Tokens per Sec:     1076 || Lr: 0.000100
2024-01-31 03:25:34,942 Epoch 271: Total Training Recognition Loss 2130.47  Total Training Translation Loss 6847.86 
2024-01-31 03:25:34,942 EPOCH 272
2024-01-31 03:25:50,835 [Epoch: 272 Step: 00018200] Batch Recognition Loss:  37.296219 => Gls Tokens per Sec:      427 || Batch Translation Loss: 119.340012 => Txt Tokens per Sec:     1152 || Lr: 0.000100
2024-01-31 03:26:00,647 Epoch 272: Total Training Recognition Loss 2126.75  Total Training Translation Loss 6847.86 
2024-01-31 03:26:00,647 EPOCH 273
2024-01-31 03:26:26,366 Epoch 273: Total Training Recognition Loss 2126.77  Total Training Translation Loss 6847.84 
2024-01-31 03:26:26,366 EPOCH 274
2024-01-31 03:26:29,746 [Epoch: 274 Step: 00018300] Batch Recognition Loss:  55.472717 => Gls Tokens per Sec:      426 || Batch Translation Loss: 132.558136 => Txt Tokens per Sec:     1157 || Lr: 0.000100
2024-01-31 03:26:51,919 Epoch 274: Total Training Recognition Loss 2123.76  Total Training Translation Loss 6849.25 
2024-01-31 03:26:51,920 EPOCH 275
2024-01-31 03:27:06,927 [Epoch: 275 Step: 00018400] Batch Recognition Loss:  38.241222 => Gls Tokens per Sec:      442 || Batch Translation Loss: 104.510529 => Txt Tokens per Sec:     1209 || Lr: 0.000100
2024-01-31 03:27:17,355 Epoch 275: Total Training Recognition Loss 2126.96  Total Training Translation Loss 6849.30 
2024-01-31 03:27:17,355 EPOCH 276
2024-01-31 03:27:43,183 Epoch 276: Total Training Recognition Loss 2123.18  Total Training Translation Loss 6848.35 
2024-01-31 03:27:43,184 EPOCH 277
2024-01-31 03:27:46,469 [Epoch: 277 Step: 00018500] Batch Recognition Loss:  19.130814 => Gls Tokens per Sec:      390 || Batch Translation Loss:  87.079536 => Txt Tokens per Sec:     1131 || Lr: 0.000100
2024-01-31 03:28:08,713 Epoch 277: Total Training Recognition Loss 2127.65  Total Training Translation Loss 6848.54 
2024-01-31 03:28:08,713 EPOCH 278
2024-01-31 03:28:23,472 [Epoch: 278 Step: 00018600] Batch Recognition Loss:  45.984150 => Gls Tokens per Sec:      438 || Batch Translation Loss: 121.539612 => Txt Tokens per Sec:     1180 || Lr: 0.000100
2024-01-31 03:28:34,312 Epoch 278: Total Training Recognition Loss 2130.16  Total Training Translation Loss 6848.51 
2024-01-31 03:28:34,312 EPOCH 279
2024-01-31 03:28:59,986 Epoch 279: Total Training Recognition Loss 2129.03  Total Training Translation Loss 6848.03 
2024-01-31 03:28:59,987 EPOCH 280
2024-01-31 03:29:03,306 [Epoch: 280 Step: 00018700] Batch Recognition Loss:  40.867741 => Gls Tokens per Sec:      338 || Batch Translation Loss: 137.426422 => Txt Tokens per Sec:     1058 || Lr: 0.000100
2024-01-31 03:29:25,413 Epoch 280: Total Training Recognition Loss 2125.15  Total Training Translation Loss 6848.70 
2024-01-31 03:29:25,413 EPOCH 281
2024-01-31 03:29:39,437 [Epoch: 281 Step: 00018800] Batch Recognition Loss:  23.924294 => Gls Tokens per Sec:      456 || Batch Translation Loss: 102.403946 => Txt Tokens per Sec:     1277 || Lr: 0.000100
2024-01-31 03:29:50,883 Epoch 281: Total Training Recognition Loss 2126.49  Total Training Translation Loss 6847.27 
2024-01-31 03:29:50,883 EPOCH 282
2024-01-31 03:30:16,448 Epoch 282: Total Training Recognition Loss 2124.12  Total Training Translation Loss 6848.93 
2024-01-31 03:30:16,449 EPOCH 283
2024-01-31 03:30:19,626 [Epoch: 283 Step: 00018900] Batch Recognition Loss:  60.394531 => Gls Tokens per Sec:      302 || Batch Translation Loss: 131.042770 => Txt Tokens per Sec:      896 || Lr: 0.000100
2024-01-31 03:30:42,171 Epoch 283: Total Training Recognition Loss 2125.03  Total Training Translation Loss 6848.78 
2024-01-31 03:30:42,172 EPOCH 284
2024-01-31 03:30:56,748 [Epoch: 284 Step: 00019000] Batch Recognition Loss:  46.866730 => Gls Tokens per Sec:      422 || Batch Translation Loss: 126.482071 => Txt Tokens per Sec:     1127 || Lr: 0.000100
2024-01-31 03:31:07,712 Epoch 284: Total Training Recognition Loss 2127.10  Total Training Translation Loss 6849.08 
2024-01-31 03:31:07,712 EPOCH 285
2024-01-31 03:31:33,122 Epoch 285: Total Training Recognition Loss 2127.70  Total Training Translation Loss 6848.83 
2024-01-31 03:31:33,122 EPOCH 286
2024-01-31 03:31:34,595 [Epoch: 286 Step: 00019100] Batch Recognition Loss:  31.858742 => Gls Tokens per Sec:      543 || Batch Translation Loss:  96.652344 => Txt Tokens per Sec:     1445 || Lr: 0.000100
2024-01-31 03:31:58,590 Epoch 286: Total Training Recognition Loss 2124.55  Total Training Translation Loss 6849.40 
2024-01-31 03:31:58,590 EPOCH 287
2024-01-31 03:32:14,836 [Epoch: 287 Step: 00019200] Batch Recognition Loss:  15.884548 => Gls Tokens per Sec:      369 || Batch Translation Loss:  73.173981 => Txt Tokens per Sec:     1061 || Lr: 0.000100
2024-01-31 03:32:24,152 Epoch 287: Total Training Recognition Loss 2126.35  Total Training Translation Loss 6848.71 
2024-01-31 03:32:24,152 EPOCH 288
2024-01-31 03:32:49,578 Epoch 288: Total Training Recognition Loss 2132.79  Total Training Translation Loss 6848.40 
2024-01-31 03:32:49,579 EPOCH 289
2024-01-31 03:32:50,601 [Epoch: 289 Step: 00019300] Batch Recognition Loss:  35.866631 => Gls Tokens per Sec:      627 || Batch Translation Loss: 118.991180 => Txt Tokens per Sec:     1630 || Lr: 0.000100
2024-01-31 03:33:14,996 Epoch 289: Total Training Recognition Loss 2126.60  Total Training Translation Loss 6849.18 
2024-01-31 03:33:14,997 EPOCH 290
2024-01-31 03:33:27,509 [Epoch: 290 Step: 00019400] Batch Recognition Loss:  22.963913 => Gls Tokens per Sec:      466 || Batch Translation Loss:  89.168060 => Txt Tokens per Sec:     1227 || Lr: 0.000100
2024-01-31 03:33:40,351 Epoch 290: Total Training Recognition Loss 2124.05  Total Training Translation Loss 6849.53 
2024-01-31 03:33:40,351 EPOCH 291
2024-01-31 03:34:05,820 Epoch 291: Total Training Recognition Loss 2129.27  Total Training Translation Loss 6849.80 
2024-01-31 03:34:05,820 EPOCH 292
2024-01-31 03:34:06,810 [Epoch: 292 Step: 00019500] Batch Recognition Loss:  35.765682 => Gls Tokens per Sec:      486 || Batch Translation Loss: 114.922363 => Txt Tokens per Sec:     1371 || Lr: 0.000100
2024-01-31 03:34:31,364 Epoch 292: Total Training Recognition Loss 2128.19  Total Training Translation Loss 6848.52 
2024-01-31 03:34:31,365 EPOCH 293
2024-01-31 03:34:44,641 [Epoch: 293 Step: 00019600] Batch Recognition Loss:  18.879972 => Gls Tokens per Sec:      434 || Batch Translation Loss:  96.145584 => Txt Tokens per Sec:     1186 || Lr: 0.000100
2024-01-31 03:34:56,837 Epoch 293: Total Training Recognition Loss 2123.31  Total Training Translation Loss 6849.37 
2024-01-31 03:34:56,837 EPOCH 294
2024-01-31 03:35:22,182 Epoch 294: Total Training Recognition Loss 2128.43  Total Training Translation Loss 6848.84 
2024-01-31 03:35:22,182 EPOCH 295
2024-01-31 03:35:22,972 [Epoch: 295 Step: 00019700] Batch Recognition Loss:  33.496021 => Gls Tokens per Sec:      406 || Batch Translation Loss: 112.873306 => Txt Tokens per Sec:     1298 || Lr: 0.000100
2024-01-31 03:35:47,783 Epoch 295: Total Training Recognition Loss 2125.19  Total Training Translation Loss 6849.30 
2024-01-31 03:35:47,783 EPOCH 296
2024-01-31 03:36:00,261 [Epoch: 296 Step: 00019800] Batch Recognition Loss:  37.162865 => Gls Tokens per Sec:      449 || Batch Translation Loss: 120.315170 => Txt Tokens per Sec:     1240 || Lr: 0.000100
2024-01-31 03:36:13,322 Epoch 296: Total Training Recognition Loss 2125.59  Total Training Translation Loss 6848.04 
2024-01-31 03:36:13,323 EPOCH 297
2024-01-31 03:36:38,756 Epoch 297: Total Training Recognition Loss 2127.03  Total Training Translation Loss 6850.04 
2024-01-31 03:36:38,756 EPOCH 298
2024-01-31 03:36:38,961 [Epoch: 298 Step: 00019900] Batch Recognition Loss:  22.302273 => Gls Tokens per Sec:      786 || Batch Translation Loss:  81.904961 => Txt Tokens per Sec:     1748 || Lr: 0.000100
2024-01-31 03:37:04,268 Epoch 298: Total Training Recognition Loss 2134.57  Total Training Translation Loss 6848.09 
2024-01-31 03:37:04,268 EPOCH 299
2024-01-31 03:37:17,372 [Epoch: 299 Step: 00020000] Batch Recognition Loss:  38.703941 => Gls Tokens per Sec:      415 || Batch Translation Loss: 118.787415 => Txt Tokens per Sec:     1163 || Lr: 0.000100
2024-01-31 03:37:46,790 Validation result at epoch 299, step    20000: duration: 29.4178s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 681.72479	Translation Loss: 73469.76562	PPL: 1559.50415
	Eval Metric: BLEU
	WER 546.54	(DEL: 4.10,	INS: 459.53,	SUB: 82.91)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.44	ROUGE 0.01
2024-01-31 03:37:46,791 Logging Recognition and Translation Outputs
2024-01-31 03:37:46,791 ========================================================================================================================
2024-01-31 03:37:46,791 Logging Sequence: 174_121.00
2024-01-31 03:37:46,792 	Gloss Reference :	***** * ***** * ***** A ***** * ***** * ***** *** ***** ***** ***** ********* ***** B+C+D+E
2024-01-31 03:37:46,792 	Gloss Hypothesis:	<unk> E <unk> A <unk> A <unk> E <unk> E <unk> C+E <unk> E+A+C <unk> E+A+E+C+E <unk> E      
2024-01-31 03:37:46,792 	Gloss Alignment :	I     I I     I I       I     I I     I I     I   I     I     I     I         I     S      
2024-01-31 03:37:46,792 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:37:46,795 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* there   was     a       strong  competition and     a       difficult auction for     the     5       franchise owners 
2024-01-31 03:37:46,795 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing     nothing nothing nothing   nothing nothing nothing nothing nothing   nothing
2024-01-31 03:37:46,795 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S           S       S       S         S       S       S       S       S         S      
2024-01-31 03:37:46,795 ========================================================================================================================
2024-01-31 03:37:46,795 Logging Sequence: 170_24.00
2024-01-31 03:37:46,796 	Gloss Reference :	A B+C+D+E
2024-01-31 03:37:46,796 	Gloss Hypothesis:	* E      
2024-01-31 03:37:46,796 	Gloss Alignment :	D S      
2024-01-31 03:37:46,796 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:37:46,797 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** let      me       tell     you      about    it      
2024-01-31 03:37:46,798 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas
2024-01-31 03:37:46,798 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S        S        S        S        S       
2024-01-31 03:37:46,798 ========================================================================================================================
2024-01-31 03:37:46,798 Logging Sequence: 73_79.00
2024-01-31 03:37:46,798 	Gloss Reference :	***** ***** ***** A ***** * ***** * ***** ***** ***** ***************** ***** * ***** ******* B+C+D+E
2024-01-31 03:37:46,799 	Gloss Hypothesis:	<unk> B+C+A <unk> A <unk> C <unk> B <unk> <pad> <unk> C+B+C+B+C+B+C+B+A <unk> C <unk> B+C+B+C <unk>  
2024-01-31 03:37:46,799 	Gloss Alignment :	I     I     I       I     I I     I I     I     I     I                 I     I I     I       S      
2024-01-31 03:37:46,799 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:37:46,803 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** raina resturant has   food  from  the   rich  spices of    north india to    the   aromatic curries of    south india
2024-01-31 03:37:46,803 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo     mateo mateo mateo mateo mateo mateo  mateo mateo mateo mateo mateo mateo    mateo   mateo mateo mateo
2024-01-31 03:37:46,803 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I     I     I     I     I     I     I     I     I     I     I     S     S         S     S     S     S     S     S      S     S     S     S     S     S        S       S     S     S    
2024-01-31 03:37:46,803 ========================================================================================================================
2024-01-31 03:37:46,803 Logging Sequence: 140_2.00
2024-01-31 03:37:46,803 	Gloss Reference :	A ***** ***** B+C+D+E
2024-01-31 03:37:46,803 	Gloss Hypothesis:	A E+A+E <unk> E      
2024-01-31 03:37:46,803 	Gloss Alignment :	  I     I     S      
2024-01-31 03:37:46,804 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:37:46,806 	Text Reference  :	*** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* indian        batsman-wicket keeper        rishabh       pant          has           outstanding   skills        in            cricket      
2024-01-31 03:37:46,806 	Text Hypothesis :	<s> <s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand  misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 03:37:46,806 	Text Alignment  :	I   I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S              S             S             S             S             S             S             S             S            
2024-01-31 03:37:46,806 ========================================================================================================================
2024-01-31 03:37:46,806 Logging Sequence: 81_470.00
2024-01-31 03:37:46,807 	Gloss Reference :	***** A B+C+D+E
2024-01-31 03:37:46,807 	Gloss Hypothesis:	<unk> C <unk>  
2024-01-31 03:37:46,807 	Gloss Alignment :	I     S S      
2024-01-31 03:37:46,807 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:37:46,810 	Text Reference  :	*** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** or    you   don't know  if    you   do    let   us    know  in    the   comments
2024-01-31 03:37:46,810 	Text Hypothesis :	<s> <s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha   
2024-01-31 03:37:46,810 	Text Alignment  :	I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S     S     S     S     S     S     S     S     S     S     S       
2024-01-31 03:37:46,810 ========================================================================================================================
2024-01-31 03:37:59,274 Epoch 299: Total Training Recognition Loss 2130.50  Total Training Translation Loss 6847.82 
2024-01-31 03:37:59,274 EPOCH 300
2024-01-31 03:38:24,787 [Epoch: 300 Step: 00020100] Batch Recognition Loss:  10.478252 => Gls Tokens per Sec:      417 || Batch Translation Loss:  61.207272 => Txt Tokens per Sec:     1157 || Lr: 0.000100
2024-01-31 03:38:24,787 Epoch 300: Total Training Recognition Loss 2125.70  Total Training Translation Loss 6850.93 
2024-01-31 03:38:24,787 EPOCH 301
2024-01-31 03:38:50,298 Epoch 301: Total Training Recognition Loss 2128.08  Total Training Translation Loss 6849.42 
2024-01-31 03:38:50,298 EPOCH 302
2024-01-31 03:39:04,709 [Epoch: 302 Step: 00020200] Batch Recognition Loss:  32.475441 => Gls Tokens per Sec:      360 || Batch Translation Loss: 123.318802 => Txt Tokens per Sec:     1063 || Lr: 0.000100
2024-01-31 03:39:15,807 Epoch 302: Total Training Recognition Loss 2124.56  Total Training Translation Loss 6846.46 
2024-01-31 03:39:15,807 EPOCH 303
2024-01-31 03:39:41,291 [Epoch: 303 Step: 00020300] Batch Recognition Loss:  38.340923 => Gls Tokens per Sec:      411 || Batch Translation Loss: 126.266327 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 03:39:41,479 Epoch 303: Total Training Recognition Loss 2130.12  Total Training Translation Loss 6849.55 
2024-01-31 03:39:41,480 EPOCH 304
2024-01-31 03:40:06,986 Epoch 304: Total Training Recognition Loss 2132.36  Total Training Translation Loss 6848.68 
2024-01-31 03:40:06,986 EPOCH 305
2024-01-31 03:40:18,177 [Epoch: 305 Step: 00020400] Batch Recognition Loss:  38.723999 => Gls Tokens per Sec:      458 || Batch Translation Loss: 115.791069 => Txt Tokens per Sec:     1257 || Lr: 0.000100
2024-01-31 03:40:32,644 Epoch 305: Total Training Recognition Loss 2127.92  Total Training Translation Loss 6847.46 
2024-01-31 03:40:32,644 EPOCH 306
2024-01-31 03:40:57,644 [Epoch: 306 Step: 00020500] Batch Recognition Loss:  28.988995 => Gls Tokens per Sec:      412 || Batch Translation Loss: 102.879791 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 03:40:58,230 Epoch 306: Total Training Recognition Loss 2127.84  Total Training Translation Loss 6845.56 
2024-01-31 03:40:58,230 EPOCH 307
2024-01-31 03:41:23,791 Epoch 307: Total Training Recognition Loss 2129.01  Total Training Translation Loss 6848.82 
2024-01-31 03:41:23,791 EPOCH 308
2024-01-31 03:41:35,525 [Epoch: 308 Step: 00020600] Batch Recognition Loss:  34.104713 => Gls Tokens per Sec:      423 || Batch Translation Loss: 113.083061 => Txt Tokens per Sec:     1203 || Lr: 0.000100
2024-01-31 03:41:49,341 Epoch 308: Total Training Recognition Loss 2127.07  Total Training Translation Loss 6848.73 
2024-01-31 03:41:49,341 EPOCH 309
2024-01-31 03:42:14,081 [Epoch: 309 Step: 00020700] Batch Recognition Loss:  36.545654 => Gls Tokens per Sec:      410 || Batch Translation Loss: 114.019394 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 03:42:14,946 Epoch 309: Total Training Recognition Loss 2124.39  Total Training Translation Loss 6848.62 
2024-01-31 03:42:14,947 EPOCH 310
2024-01-31 03:42:40,441 Epoch 310: Total Training Recognition Loss 2128.50  Total Training Translation Loss 6847.59 
2024-01-31 03:42:40,441 EPOCH 311
2024-01-31 03:42:52,466 [Epoch: 311 Step: 00020800] Batch Recognition Loss:  59.995720 => Gls Tokens per Sec:      399 || Batch Translation Loss: 133.775345 => Txt Tokens per Sec:     1123 || Lr: 0.000100
2024-01-31 03:43:06,018 Epoch 311: Total Training Recognition Loss 2129.42  Total Training Translation Loss 6848.38 
2024-01-31 03:43:06,018 EPOCH 312
2024-01-31 03:43:30,628 [Epoch: 312 Step: 00020900] Batch Recognition Loss:  28.906185 => Gls Tokens per Sec:      406 || Batch Translation Loss: 119.038422 => Txt Tokens per Sec:     1131 || Lr: 0.000100
2024-01-31 03:43:31,569 Epoch 312: Total Training Recognition Loss 2126.01  Total Training Translation Loss 6847.69 
2024-01-31 03:43:31,569 EPOCH 313
2024-01-31 03:43:57,071 Epoch 313: Total Training Recognition Loss 2126.46  Total Training Translation Loss 6849.30 
2024-01-31 03:43:57,071 EPOCH 314
2024-01-31 03:44:08,833 [Epoch: 314 Step: 00021000] Batch Recognition Loss:  36.841011 => Gls Tokens per Sec:      395 || Batch Translation Loss: 119.631050 => Txt Tokens per Sec:     1084 || Lr: 0.000100
2024-01-31 03:44:22,684 Epoch 314: Total Training Recognition Loss 2129.82  Total Training Translation Loss 6847.72 
2024-01-31 03:44:22,685 EPOCH 315
2024-01-31 03:44:46,854 [Epoch: 315 Step: 00021100] Batch Recognition Loss:  52.989136 => Gls Tokens per Sec:      407 || Batch Translation Loss: 129.576111 => Txt Tokens per Sec:     1138 || Lr: 0.000100
2024-01-31 03:44:48,183 Epoch 315: Total Training Recognition Loss 2125.90  Total Training Translation Loss 6849.28 
2024-01-31 03:44:48,183 EPOCH 316
2024-01-31 03:45:13,734 Epoch 316: Total Training Recognition Loss 2124.61  Total Training Translation Loss 6849.89 
2024-01-31 03:45:13,735 EPOCH 317
2024-01-31 03:45:24,787 [Epoch: 317 Step: 00021200] Batch Recognition Loss:  33.111866 => Gls Tokens per Sec:      397 || Batch Translation Loss: 104.842834 => Txt Tokens per Sec:     1132 || Lr: 0.000100
2024-01-31 03:45:39,191 Epoch 317: Total Training Recognition Loss 2126.56  Total Training Translation Loss 6846.77 
2024-01-31 03:45:39,191 EPOCH 318
2024-01-31 03:46:03,131 [Epoch: 318 Step: 00021300] Batch Recognition Loss:  72.410789 => Gls Tokens per Sec:      404 || Batch Translation Loss: 126.630112 => Txt Tokens per Sec:     1136 || Lr: 0.000100
2024-01-31 03:46:04,652 Epoch 318: Total Training Recognition Loss 2126.86  Total Training Translation Loss 6849.00 
2024-01-31 03:46:04,652 EPOCH 319
2024-01-31 03:46:30,220 Epoch 319: Total Training Recognition Loss 2123.22  Total Training Translation Loss 6849.32 
2024-01-31 03:46:30,221 EPOCH 320
2024-01-31 03:46:42,060 [Epoch: 320 Step: 00021400] Batch Recognition Loss:  10.177606 => Gls Tokens per Sec:      357 || Batch Translation Loss:  61.846596 => Txt Tokens per Sec:      990 || Lr: 0.000100
2024-01-31 03:46:59,851 Epoch 320: Total Training Recognition Loss 2122.34  Total Training Translation Loss 6850.07 
2024-01-31 03:46:59,851 EPOCH 321
2024-01-31 03:47:23,610 [Epoch: 321 Step: 00021500] Batch Recognition Loss:  35.857742 => Gls Tokens per Sec:      400 || Batch Translation Loss: 102.854645 => Txt Tokens per Sec:     1118 || Lr: 0.000100
2024-01-31 03:47:25,903 Epoch 321: Total Training Recognition Loss 2124.75  Total Training Translation Loss 6845.72 
2024-01-31 03:47:25,903 EPOCH 322
2024-01-31 03:47:51,643 Epoch 322: Total Training Recognition Loss 2124.62  Total Training Translation Loss 6848.33 
2024-01-31 03:47:51,643 EPOCH 323
2024-01-31 03:48:01,131 [Epoch: 323 Step: 00021600] Batch Recognition Loss:  17.276245 => Gls Tokens per Sec:      439 || Batch Translation Loss:  77.756104 => Txt Tokens per Sec:     1229 || Lr: 0.000100
2024-01-31 03:48:17,181 Epoch 323: Total Training Recognition Loss 2130.28  Total Training Translation Loss 6848.63 
2024-01-31 03:48:17,181 EPOCH 324
2024-01-31 03:48:40,320 [Epoch: 324 Step: 00021700] Batch Recognition Loss:  21.434782 => Gls Tokens per Sec:      404 || Batch Translation Loss:  81.672707 => Txt Tokens per Sec:     1127 || Lr: 0.000100
2024-01-31 03:48:42,744 Epoch 324: Total Training Recognition Loss 2122.41  Total Training Translation Loss 6850.44 
2024-01-31 03:48:42,744 EPOCH 325
2024-01-31 03:49:08,416 Epoch 325: Total Training Recognition Loss 2131.55  Total Training Translation Loss 6850.51 
2024-01-31 03:49:08,416 EPOCH 326
2024-01-31 03:49:18,666 [Epoch: 326 Step: 00021800] Batch Recognition Loss:  12.208153 => Gls Tokens per Sec:      390 || Batch Translation Loss:  65.734909 => Txt Tokens per Sec:     1102 || Lr: 0.000100
2024-01-31 03:49:34,055 Epoch 326: Total Training Recognition Loss 2127.64  Total Training Translation Loss 6848.63 
2024-01-31 03:49:34,056 EPOCH 327
2024-01-31 03:49:56,866 [Epoch: 327 Step: 00021900] Batch Recognition Loss:  44.321201 => Gls Tokens per Sec:      403 || Batch Translation Loss: 133.311386 => Txt Tokens per Sec:     1123 || Lr: 0.000100
2024-01-31 03:49:59,800 Epoch 327: Total Training Recognition Loss 2129.41  Total Training Translation Loss 6849.55 
2024-01-31 03:49:59,801 EPOCH 328
2024-01-31 03:50:25,231 Epoch 328: Total Training Recognition Loss 2124.16  Total Training Translation Loss 6848.73 
2024-01-31 03:50:25,231 EPOCH 329
2024-01-31 03:50:34,351 [Epoch: 329 Step: 00022000] Batch Recognition Loss:  28.456272 => Gls Tokens per Sec:      411 || Batch Translation Loss:  90.305740 => Txt Tokens per Sec:     1126 || Lr: 0.000100
2024-01-31 03:51:04,150 Validation result at epoch 329, step    22000: duration: 29.7997s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 688.79706	Translation Loss: 73491.91406	PPL: 1562.96448
	Eval Metric: BLEU
	WER 564.62	(DEL: 4.59,	INS: 476.34,	SUB: 83.69)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.39	ROUGE 0.00
2024-01-31 03:51:04,151 Logging Recognition and Translation Outputs
2024-01-31 03:51:04,152 ========================================================================================================================
2024-01-31 03:51:04,152 Logging Sequence: 146_56.00
2024-01-31 03:51:04,152 	Gloss Reference :	*** ***** * ***** * ***** * ***** * ***** ***** ***** ***************** A     B+C+D+E
2024-01-31 03:51:04,152 	Gloss Hypothesis:	E+C <pad> E <unk> E <unk> E <unk> C <unk> E+C+E <unk> E+C+E+C+E+C+E+C+E <unk> E+C    
2024-01-31 03:51:04,152 	Gloss Alignment :	I   I     I I     I I     I I     I I     I     I     I                 S     S      
2024-01-31 03:51:04,152 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:51:04,157 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ** ** ** ** ** ** ** ** when the players go back to the hotel as per rules all of them have to undergo rtpcr test for covid-19 everyday
2024-01-31 03:51:04,157 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> kl kl kl kl kl kl kl kl kl   kl  kl      kl kl   kl kl  kl    kl kl  kl    kl  kl kl   kl   kl kl      kl    kl   kl  kl       kl      
2024-01-31 03:51:04,158 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I  I  I  I  I  I  I  I  S    S   S       S  S    S  S   S     S  S   S     S   S  S    S    S  S       S     S    S   S        S       
2024-01-31 03:51:04,158 ========================================================================================================================
2024-01-31 03:51:04,158 Logging Sequence: 118_338.00
2024-01-31 03:51:04,158 	Gloss Reference :	***** * ***** * ***** *** ***** A   B+C+D+E
2024-01-31 03:51:04,158 	Gloss Hypothesis:	<unk> C <unk> C <unk> E+C <unk> C+E <unk>  
2024-01-31 03:51:04,159 	Gloss Alignment :	I     I I     I I     I   I     S   S      
2024-01-31 03:51:04,159 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:51:04,160 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** this is  why even messi wore it 
2024-01-31 03:51:04,160 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s>  <s>   <s>  <s>
2024-01-31 03:51:04,161 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S    S   S   S    S     S    S  
2024-01-31 03:51:04,161 ========================================================================================================================
2024-01-31 03:51:04,161 Logging Sequence: 66_61.00
2024-01-31 03:51:04,162 	Gloss Reference :	***** *** ***** * ***** A B+C+D+E
2024-01-31 03:51:04,162 	Gloss Hypothesis:	<unk> E+B <unk> B <unk> E <unk>  
2024-01-31 03:51:04,162 	Gloss Alignment :	I     I   I     I I     S S      
2024-01-31 03:51:04,162 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:51:04,164 	Text Reference  :	*** *** *** *** *** *** *** *** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** instead  of       returning back     to       his      homeland because  of       his      injury  
2024-01-31 03:51:04,164 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas  casillas casillas casillas casillas casillas casillas casillas casillas
2024-01-31 03:51:04,164 	Text Alignment  :	I   I   I   I   I   I   I   I   I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S        S         S        S        S        S        S        S        S        S       
2024-01-31 03:51:04,164 ========================================================================================================================
2024-01-31 03:51:04,164 Logging Sequence: 81_278.00
2024-01-31 03:51:04,165 	Gloss Reference :	A B+C+D+E                        
2024-01-31 03:51:04,165 	Gloss Hypothesis:	E C+E+C+E+C+E+C+E+C+E+C+E+C+E+B+E
2024-01-31 03:51:04,165 	Gloss Alignment :	S S                              
2024-01-31 03:51:04,165 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:51:04,170 	Text Reference  :	***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** of    this  amrapali group paid  rs    3570  crore the   remaining rs    652   crore was   paid  by    amrapali sapphire developers a     subsidiary of    amrapali group
2024-01-31 03:51:04,171 	Text Hypothesis :	sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    sabha sabha sabha sabha sabha sabha sabha     sabha sabha sabha sabha sabha sabha sabha    sabha    sabha      sabha sabha      sabha sabha    sabha
2024-01-31 03:51:04,171 	Text Alignment  :	I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S        S     S     S     S     S     S     S         S     S     S     S     S     S     S        S        S          S     S          S     S        S    
2024-01-31 03:51:04,171 ========================================================================================================================
2024-01-31 03:51:04,171 Logging Sequence: 162_125.00
2024-01-31 03:51:04,171 	Gloss Reference :	***** * ***** * ***** * A     B+C+D+E    
2024-01-31 03:51:04,171 	Gloss Hypothesis:	<pad> B <pad> B <pad> E <pad> B+E+B+E+B+E
2024-01-31 03:51:04,172 	Gloss Alignment :	I     I I     I I     I S     S          
2024-01-31 03:51:04,172 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 03:51:04,175 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** in  response to  this kohli received many hate comments on  social media
2024-01-31 03:51:04,175 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>      <s> <s>  <s>   <s>      <s>  <s>  <s>      <s> <s>    <s>  
2024-01-31 03:51:04,175 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S        S   S    S     S        S    S    S        S   S      S    
2024-01-31 03:51:04,175 ========================================================================================================================
2024-01-31 03:51:20,532 Epoch 329: Total Training Recognition Loss 2125.84  Total Training Translation Loss 6848.77 
2024-01-31 03:51:20,532 EPOCH 330
2024-01-31 03:51:43,197 [Epoch: 330 Step: 00022100] Batch Recognition Loss:  61.253334 => Gls Tokens per Sec:      398 || Batch Translation Loss: 130.778534 => Txt Tokens per Sec:     1107 || Lr: 0.000100
2024-01-31 03:51:46,110 Epoch 330: Total Training Recognition Loss 2132.82  Total Training Translation Loss 6848.11 
2024-01-31 03:51:46,111 EPOCH 331
2024-01-31 03:52:11,689 Epoch 331: Total Training Recognition Loss 2125.21  Total Training Translation Loss 6848.33 
2024-01-31 03:52:11,690 EPOCH 332
2024-01-31 03:52:19,013 [Epoch: 332 Step: 00022200] Batch Recognition Loss:  27.729544 => Gls Tokens per Sec:      503 || Batch Translation Loss:  89.368050 => Txt Tokens per Sec:     1357 || Lr: 0.000100
2024-01-31 03:52:37,231 Epoch 332: Total Training Recognition Loss 2128.39  Total Training Translation Loss 6848.53 
2024-01-31 03:52:37,231 EPOCH 333
2024-01-31 03:52:59,697 [Epoch: 333 Step: 00022300] Batch Recognition Loss:  18.525465 => Gls Tokens per Sec:      395 || Batch Translation Loss:  85.357468 => Txt Tokens per Sec:     1122 || Lr: 0.000100
2024-01-31 03:53:02,710 Epoch 333: Total Training Recognition Loss 2124.85  Total Training Translation Loss 6848.62 
2024-01-31 03:53:02,710 EPOCH 334
2024-01-31 03:53:28,254 Epoch 334: Total Training Recognition Loss 2133.21  Total Training Translation Loss 6849.22 
2024-01-31 03:53:28,254 EPOCH 335
2024-01-31 03:53:37,163 [Epoch: 335 Step: 00022400] Batch Recognition Loss:  27.783646 => Gls Tokens per Sec:      385 || Batch Translation Loss:  92.969620 => Txt Tokens per Sec:     1026 || Lr: 0.000100
2024-01-31 03:53:53,675 Epoch 335: Total Training Recognition Loss 2124.09  Total Training Translation Loss 6848.76 
2024-01-31 03:53:53,675 EPOCH 336
2024-01-31 03:54:15,553 [Epoch: 336 Step: 00022500] Batch Recognition Loss:  24.012039 => Gls Tokens per Sec:      398 || Batch Translation Loss:  96.110420 => Txt Tokens per Sec:     1109 || Lr: 0.000100
2024-01-31 03:54:19,255 Epoch 336: Total Training Recognition Loss 2128.21  Total Training Translation Loss 6849.75 
2024-01-31 03:54:19,255 EPOCH 337
2024-01-31 03:54:44,678 Epoch 337: Total Training Recognition Loss 2128.41  Total Training Translation Loss 6849.20 
2024-01-31 03:54:44,678 EPOCH 338
2024-01-31 03:54:53,886 [Epoch: 338 Step: 00022600] Batch Recognition Loss:  43.774586 => Gls Tokens per Sec:      365 || Batch Translation Loss: 132.786255 => Txt Tokens per Sec:     1081 || Lr: 0.000100
2024-01-31 03:55:10,396 Epoch 338: Total Training Recognition Loss 2130.13  Total Training Translation Loss 6847.70 
2024-01-31 03:55:10,396 EPOCH 339
2024-01-31 03:55:31,253 [Epoch: 339 Step: 00022700] Batch Recognition Loss:  23.235527 => Gls Tokens per Sec:      414 || Batch Translation Loss:  81.388580 => Txt Tokens per Sec:     1158 || Lr: 0.000100
2024-01-31 03:55:36,047 Epoch 339: Total Training Recognition Loss 2127.03  Total Training Translation Loss 6846.92 
2024-01-31 03:55:36,047 EPOCH 340
2024-01-31 03:56:01,534 Epoch 340: Total Training Recognition Loss 2129.38  Total Training Translation Loss 6848.23 
2024-01-31 03:56:01,534 EPOCH 341
2024-01-31 03:56:10,296 [Epoch: 341 Step: 00022800] Batch Recognition Loss:  49.681393 => Gls Tokens per Sec:      365 || Batch Translation Loss: 126.617767 => Txt Tokens per Sec:     1100 || Lr: 0.000100
2024-01-31 03:56:27,135 Epoch 341: Total Training Recognition Loss 2126.76  Total Training Translation Loss 6848.63 
2024-01-31 03:56:27,135 EPOCH 342
2024-01-31 03:56:47,443 [Epoch: 342 Step: 00022900] Batch Recognition Loss:  37.546066 => Gls Tokens per Sec:      413 || Batch Translation Loss: 118.065041 => Txt Tokens per Sec:     1142 || Lr: 0.000100
2024-01-31 03:56:52,793 Epoch 342: Total Training Recognition Loss 2122.72  Total Training Translation Loss 6847.65 
2024-01-31 03:56:52,793 EPOCH 343
2024-01-31 03:57:18,411 Epoch 343: Total Training Recognition Loss 2126.90  Total Training Translation Loss 6848.69 
2024-01-31 03:57:18,412 EPOCH 344
2024-01-31 03:57:25,526 [Epoch: 344 Step: 00023000] Batch Recognition Loss:  26.986778 => Gls Tokens per Sec:      415 || Batch Translation Loss: 104.734810 => Txt Tokens per Sec:     1113 || Lr: 0.000100
2024-01-31 03:57:43,979 Epoch 344: Total Training Recognition Loss 2125.19  Total Training Translation Loss 6846.69 
2024-01-31 03:57:43,979 EPOCH 345
2024-01-31 03:58:03,797 [Epoch: 345 Step: 00023100] Batch Recognition Loss:  44.508659 => Gls Tokens per Sec:      415 || Batch Translation Loss: 122.040268 => Txt Tokens per Sec:     1141 || Lr: 0.000100
2024-01-31 03:58:09,567 Epoch 345: Total Training Recognition Loss 2122.03  Total Training Translation Loss 6848.89 
2024-01-31 03:58:09,567 EPOCH 346
2024-01-31 03:58:35,148 Epoch 346: Total Training Recognition Loss 2129.63  Total Training Translation Loss 6846.37 
2024-01-31 03:58:35,148 EPOCH 347
2024-01-31 03:58:42,451 [Epoch: 347 Step: 00023200] Batch Recognition Loss:  29.308956 => Gls Tokens per Sec:      394 || Batch Translation Loss: 106.879974 => Txt Tokens per Sec:     1114 || Lr: 0.000100
2024-01-31 03:59:00,961 Epoch 347: Total Training Recognition Loss 2124.50  Total Training Translation Loss 6847.41 
2024-01-31 03:59:00,961 EPOCH 348
2024-01-31 03:59:21,982 [Epoch: 348 Step: 00023300] Batch Recognition Loss:  36.425095 => Gls Tokens per Sec:      384 || Batch Translation Loss: 120.670395 => Txt Tokens per Sec:     1076 || Lr: 0.000100
2024-01-31 03:59:26,559 Epoch 348: Total Training Recognition Loss 2125.53  Total Training Translation Loss 6847.35 
2024-01-31 03:59:26,560 EPOCH 349
2024-01-31 03:59:52,072 Epoch 349: Total Training Recognition Loss 2129.69  Total Training Translation Loss 6848.42 
2024-01-31 03:59:52,072 EPOCH 350
2024-01-31 03:59:58,435 [Epoch: 350 Step: 00023400] Batch Recognition Loss:  11.428312 => Gls Tokens per Sec:      428 || Batch Translation Loss:  62.166065 => Txt Tokens per Sec:     1135 || Lr: 0.000100
2024-01-31 04:00:17,577 Epoch 350: Total Training Recognition Loss 2128.70  Total Training Translation Loss 6848.38 
2024-01-31 04:00:17,577 EPOCH 351
2024-01-31 04:00:34,632 [Epoch: 351 Step: 00023500] Batch Recognition Loss:  54.587929 => Gls Tokens per Sec:      469 || Batch Translation Loss: 128.285019 => Txt Tokens per Sec:     1289 || Lr: 0.000100
2024-01-31 04:00:42,981 Epoch 351: Total Training Recognition Loss 2128.62  Total Training Translation Loss 6847.86 
2024-01-31 04:00:42,981 EPOCH 352
2024-01-31 04:01:08,675 Epoch 352: Total Training Recognition Loss 2127.04  Total Training Translation Loss 6845.72 
2024-01-31 04:01:08,676 EPOCH 353
2024-01-31 04:01:13,816 [Epoch: 353 Step: 00023600] Batch Recognition Loss:  29.663729 => Gls Tokens per Sec:      498 || Batch Translation Loss:  97.685959 => Txt Tokens per Sec:     1388 || Lr: 0.000100
2024-01-31 04:01:34,150 Epoch 353: Total Training Recognition Loss 2127.57  Total Training Translation Loss 6848.24 
2024-01-31 04:01:34,150 EPOCH 354
2024-01-31 04:01:52,991 [Epoch: 354 Step: 00023700] Batch Recognition Loss:  26.680634 => Gls Tokens per Sec:      416 || Batch Translation Loss: 105.656380 => Txt Tokens per Sec:     1156 || Lr: 0.000100
2024-01-31 04:01:59,610 Epoch 354: Total Training Recognition Loss 2129.75  Total Training Translation Loss 6849.63 
2024-01-31 04:01:59,610 EPOCH 355
2024-01-31 04:02:25,081 Epoch 355: Total Training Recognition Loss 2123.63  Total Training Translation Loss 6847.29 
2024-01-31 04:02:25,081 EPOCH 356
2024-01-31 04:02:30,626 [Epoch: 356 Step: 00023800] Batch Recognition Loss:  44.208687 => Gls Tokens per Sec:      433 || Batch Translation Loss: 125.632172 => Txt Tokens per Sec:     1249 || Lr: 0.000100
2024-01-31 04:02:50,616 Epoch 356: Total Training Recognition Loss 2128.37  Total Training Translation Loss 6848.16 
2024-01-31 04:02:50,616 EPOCH 357
2024-01-31 04:03:09,069 [Epoch: 357 Step: 00023900] Batch Recognition Loss:  37.581726 => Gls Tokens per Sec:      411 || Batch Translation Loss: 113.938614 => Txt Tokens per Sec:     1138 || Lr: 0.000100
2024-01-31 04:03:16,267 Epoch 357: Total Training Recognition Loss 2127.98  Total Training Translation Loss 6849.69 
2024-01-31 04:03:16,267 EPOCH 358
2024-01-31 04:03:41,780 Epoch 358: Total Training Recognition Loss 2125.53  Total Training Translation Loss 6849.67 
2024-01-31 04:03:41,780 EPOCH 359
2024-01-31 04:03:46,158 [Epoch: 359 Step: 00024000] Batch Recognition Loss:  14.171915 => Gls Tokens per Sec:      512 || Batch Translation Loss:  78.882820 => Txt Tokens per Sec:     1358 || Lr: 0.000100
2024-01-31 04:04:15,422 Validation result at epoch 359, step    24000: duration: 29.2643s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 680.69763	Translation Loss: 73479.19531	PPL: 1560.97693
	Eval Metric: BLEU
	WER 549.65	(DEL: 4.24,	INS: 461.09,	SUB: 84.32)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.43	ROUGE 0.00
2024-01-31 04:04:15,424 Logging Recognition and Translation Outputs
2024-01-31 04:04:15,424 ========================================================================================================================
2024-01-31 04:04:15,424 Logging Sequence: 169_165.00
2024-01-31 04:04:15,424 	Gloss Reference :	A B+C+D+E            
2024-01-31 04:04:15,424 	Gloss Hypothesis:	E D+E+D+E+D+E+C+E+C+E
2024-01-31 04:04:15,424 	Gloss Alignment :	S S                  
2024-01-31 04:04:15,425 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:04:15,428 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ****** ****** ****** ****** ****** ****** ****** the    indian government was    outraged by     the    incident and    these  changes were   undone by     wikipedia
2024-01-31 04:04:15,428 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> boards boards boards boards boards boards boards boards boards boards     boards boards   boards boards boards   boards boards boards  boards boards boards boards   
2024-01-31 04:04:15,428 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I      I      I      I      I      I      I      S      S      S          S      S        S      S      S        S      S      S       S      S      S      S        
2024-01-31 04:04:15,428 ========================================================================================================================
2024-01-31 04:04:15,428 Logging Sequence: 175_60.00
2024-01-31 04:04:15,429 	Gloss Reference :	***** A ***** *** ***** B+C+D+E
2024-01-31 04:04:15,429 	Gloss Hypothesis:	<unk> A <unk> A+E <unk> E      
2024-01-31 04:04:15,429 	Gloss Alignment :	I       I     I   I     S      
2024-01-31 04:04:15,429 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:04:15,431 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** that     is       how      india    bagged   9        medals   in       the      youth    tournament
2024-01-31 04:04:15,431 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas  
2024-01-31 04:04:15,432 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S        S        S        S        S        S        S        S        S        S         
2024-01-31 04:04:15,432 ========================================================================================================================
2024-01-31 04:04:15,432 Logging Sequence: 61_255.00
2024-01-31 04:04:15,432 	Gloss Reference :	* ***** * ***** * ***** * ***** * ***** *** ***** A ***** *** ***** * ***** * ***** * ***** ***** ***** B+C+D+E
2024-01-31 04:04:15,432 	Gloss Hypothesis:	E <unk> E <unk> A <unk> E <unk> E <unk> B+E <unk> A <unk> A+E <unk> E <unk> E <unk> E <unk> E+C+E <unk> A+C    
2024-01-31 04:04:15,433 	Gloss Alignment :	I I     I I     I I     I I     I I     I   I       I     I   I     I I     I I     I I     I     I     S      
2024-01-31 04:04:15,433 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:04:15,435 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* in            2011          we            decided       to            marry         and           informed      our           families     
2024-01-31 04:04:15,435 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions
2024-01-31 04:04:15,435 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S            
2024-01-31 04:04:15,435 ========================================================================================================================
2024-01-31 04:04:15,436 Logging Sequence: 173_39.00
2024-01-31 04:04:15,436 	Gloss Reference :	A B+C+D+E
2024-01-31 04:04:15,436 	Gloss Hypothesis:	* E      
2024-01-31 04:04:15,436 	Gloss Alignment :	D S      
2024-01-31 04:04:15,436 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:04:15,438 	Text Reference  :	*** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* kohli   will    step    down    as      india'  captain
2024-01-31 04:04:15,438 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing
2024-01-31 04:04:15,438 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S       S       S      
2024-01-31 04:04:15,438 ========================================================================================================================
2024-01-31 04:04:15,438 Logging Sequence: 172_82.00
2024-01-31 04:04:15,439 	Gloss Reference :	***** * ***** *** ***** * ***** *** ***** *** ***** A B+C+D+E
2024-01-31 04:04:15,439 	Gloss Hypothesis:	<unk> C <unk> E+C <unk> E <unk> E+C <unk> C+E <unk> E <unk>  
2024-01-31 04:04:15,439 	Gloss Alignment :	I     I I     I   I     I I     I   I     I   I     S S      
2024-01-31 04:04:15,439 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:04:15,443 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** you all know that the toss was about to  start at  700 pm  but it  started raining at  around 630 pm 
2024-01-31 04:04:15,443 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s>  <s> <s>  <s> <s>   <s> <s>   <s> <s> <s> <s> <s> <s>     <s>     <s> <s>    <s> <s>
2024-01-31 04:04:15,443 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S   S    S    S   S    S   S     S   S     S   S   S   S   S   S       S       S   S      S   S  
2024-01-31 04:04:15,444 ========================================================================================================================
2024-01-31 04:04:36,667 Epoch 359: Total Training Recognition Loss 2128.05  Total Training Translation Loss 6846.86 
2024-01-31 04:04:36,667 EPOCH 360
2024-01-31 04:04:54,357 [Epoch: 360 Step: 00024100] Batch Recognition Loss:  38.656990 => Gls Tokens per Sec:      420 || Batch Translation Loss: 103.542702 => Txt Tokens per Sec:     1139 || Lr: 0.000100
2024-01-31 04:05:02,371 Epoch 360: Total Training Recognition Loss 2121.52  Total Training Translation Loss 6848.89 
2024-01-31 04:05:02,371 EPOCH 361
2024-01-31 04:05:27,954 Epoch 361: Total Training Recognition Loss 2124.90  Total Training Translation Loss 6848.10 
2024-01-31 04:05:27,954 EPOCH 362
2024-01-31 04:05:31,861 [Epoch: 362 Step: 00024200] Batch Recognition Loss:  21.529743 => Gls Tokens per Sec:      533 || Batch Translation Loss:  80.034912 => Txt Tokens per Sec:     1383 || Lr: 0.000100
2024-01-31 04:05:53,741 Epoch 362: Total Training Recognition Loss 2127.42  Total Training Translation Loss 6848.25 
2024-01-31 04:05:53,741 EPOCH 363
2024-01-31 04:06:12,869 [Epoch: 363 Step: 00024300] Batch Recognition Loss:  13.701660 => Gls Tokens per Sec:      380 || Batch Translation Loss:  75.323669 => Txt Tokens per Sec:     1080 || Lr: 0.000100
2024-01-31 04:06:19,359 Epoch 363: Total Training Recognition Loss 2129.42  Total Training Translation Loss 6848.11 
2024-01-31 04:06:19,360 EPOCH 364
2024-01-31 04:06:44,933 Epoch 364: Total Training Recognition Loss 2123.72  Total Training Translation Loss 6847.65 
2024-01-31 04:06:44,933 EPOCH 365
2024-01-31 04:06:49,346 [Epoch: 365 Step: 00024400] Batch Recognition Loss:  40.714668 => Gls Tokens per Sec:      435 || Batch Translation Loss: 114.529556 => Txt Tokens per Sec:     1266 || Lr: 0.000100
2024-01-31 04:07:10,520 Epoch 365: Total Training Recognition Loss 2122.42  Total Training Translation Loss 6847.40 
2024-01-31 04:07:10,520 EPOCH 366
2024-01-31 04:07:29,703 [Epoch: 366 Step: 00024500] Batch Recognition Loss:  40.697884 => Gls Tokens per Sec:      371 || Batch Translation Loss: 138.684784 => Txt Tokens per Sec:     1049 || Lr: 0.000100
2024-01-31 04:07:37,249 Epoch 366: Total Training Recognition Loss 2130.29  Total Training Translation Loss 6849.48 
2024-01-31 04:07:37,249 EPOCH 367
2024-01-31 04:08:03,059 Epoch 367: Total Training Recognition Loss 2129.08  Total Training Translation Loss 6848.39 
2024-01-31 04:08:03,060 EPOCH 368
2024-01-31 04:08:07,405 [Epoch: 368 Step: 00024600] Batch Recognition Loss:  41.315849 => Gls Tokens per Sec:      384 || Batch Translation Loss: 117.194046 => Txt Tokens per Sec:     1050 || Lr: 0.000100
2024-01-31 04:08:28,528 Epoch 368: Total Training Recognition Loss 2124.31  Total Training Translation Loss 6848.94 
2024-01-31 04:08:28,528 EPOCH 369
2024-01-31 04:08:45,556 [Epoch: 369 Step: 00024700] Batch Recognition Loss:  41.224510 => Gls Tokens per Sec:      408 || Batch Translation Loss: 137.222961 => Txt Tokens per Sec:     1144 || Lr: 0.000100
2024-01-31 04:08:54,137 Epoch 369: Total Training Recognition Loss 2123.44  Total Training Translation Loss 6849.50 
2024-01-31 04:08:54,137 EPOCH 370
2024-01-31 04:09:19,579 Epoch 370: Total Training Recognition Loss 2125.37  Total Training Translation Loss 6846.83 
2024-01-31 04:09:19,580 EPOCH 371
2024-01-31 04:09:23,814 [Epoch: 371 Step: 00024800] Batch Recognition Loss:  23.555016 => Gls Tokens per Sec:      378 || Batch Translation Loss:  99.535995 => Txt Tokens per Sec:     1135 || Lr: 0.000100
2024-01-31 04:09:44,935 Epoch 371: Total Training Recognition Loss 2128.44  Total Training Translation Loss 6847.52 
2024-01-31 04:09:44,935 EPOCH 372
2024-01-31 04:10:01,659 [Epoch: 372 Step: 00024900] Batch Recognition Loss:  18.535234 => Gls Tokens per Sec:      406 || Batch Translation Loss:  86.970490 => Txt Tokens per Sec:     1146 || Lr: 0.000100
2024-01-31 04:10:10,391 Epoch 372: Total Training Recognition Loss 2130.88  Total Training Translation Loss 6849.33 
2024-01-31 04:10:10,391 EPOCH 373
2024-01-31 04:10:35,674 Epoch 373: Total Training Recognition Loss 2125.91  Total Training Translation Loss 6848.98 
2024-01-31 04:10:35,674 EPOCH 374
2024-01-31 04:10:39,073 [Epoch: 374 Step: 00025000] Batch Recognition Loss:  26.441343 => Gls Tokens per Sec:      424 || Batch Translation Loss: 105.703888 => Txt Tokens per Sec:     1197 || Lr: 0.000100
2024-01-31 04:11:01,127 Epoch 374: Total Training Recognition Loss 2128.97  Total Training Translation Loss 6847.26 
2024-01-31 04:11:01,128 EPOCH 375
2024-01-31 04:11:17,116 [Epoch: 375 Step: 00025100] Batch Recognition Loss:  29.144230 => Gls Tokens per Sec:      415 || Batch Translation Loss:  95.495041 => Txt Tokens per Sec:     1163 || Lr: 0.000100
2024-01-31 04:11:26,699 Epoch 375: Total Training Recognition Loss 2126.48  Total Training Translation Loss 6849.85 
2024-01-31 04:11:26,699 EPOCH 376
2024-01-31 04:11:52,372 Epoch 376: Total Training Recognition Loss 2127.16  Total Training Translation Loss 6848.04 
2024-01-31 04:11:52,372 EPOCH 377
2024-01-31 04:11:55,098 [Epoch: 377 Step: 00025200] Batch Recognition Loss:  38.279633 => Gls Tokens per Sec:      470 || Batch Translation Loss: 117.019829 => Txt Tokens per Sec:     1220 || Lr: 0.000100
2024-01-31 04:12:17,901 Epoch 377: Total Training Recognition Loss 2129.13  Total Training Translation Loss 6848.66 
2024-01-31 04:12:17,901 EPOCH 378
2024-01-31 04:12:32,724 [Epoch: 378 Step: 00025300] Batch Recognition Loss:  24.043407 => Gls Tokens per Sec:      443 || Batch Translation Loss: 100.138817 => Txt Tokens per Sec:     1211 || Lr: 0.000100
2024-01-31 04:12:43,641 Epoch 378: Total Training Recognition Loss 2134.71  Total Training Translation Loss 6847.44 
2024-01-31 04:12:43,641 EPOCH 379
2024-01-31 04:13:09,288 Epoch 379: Total Training Recognition Loss 2125.65  Total Training Translation Loss 6848.02 
2024-01-31 04:13:09,288 EPOCH 380
2024-01-31 04:13:12,102 [Epoch: 380 Step: 00025400] Batch Recognition Loss:  38.334190 => Gls Tokens per Sec:      398 || Batch Translation Loss: 120.928085 => Txt Tokens per Sec:     1175 || Lr: 0.000100
2024-01-31 04:13:35,009 Epoch 380: Total Training Recognition Loss 2129.65  Total Training Translation Loss 6847.17 
2024-01-31 04:13:35,009 EPOCH 381
2024-01-31 04:13:51,590 [Epoch: 381 Step: 00025500] Batch Recognition Loss:  49.860233 => Gls Tokens per Sec:      381 || Batch Translation Loss: 132.016006 => Txt Tokens per Sec:     1059 || Lr: 0.000100
2024-01-31 04:14:00,649 Epoch 381: Total Training Recognition Loss 2127.91  Total Training Translation Loss 6849.28 
2024-01-31 04:14:00,650 EPOCH 382
2024-01-31 04:14:26,289 Epoch 382: Total Training Recognition Loss 2128.13  Total Training Translation Loss 6847.61 
2024-01-31 04:14:26,289 EPOCH 383
2024-01-31 04:14:28,220 [Epoch: 383 Step: 00025600] Batch Recognition Loss:  50.184044 => Gls Tokens per Sec:      497 || Batch Translation Loss: 126.363174 => Txt Tokens per Sec:     1279 || Lr: 0.000100
2024-01-31 04:14:52,052 Epoch 383: Total Training Recognition Loss 2129.23  Total Training Translation Loss 6849.51 
2024-01-31 04:14:52,053 EPOCH 384
2024-01-31 04:15:07,029 [Epoch: 384 Step: 00025700] Batch Recognition Loss:  46.308281 => Gls Tokens per Sec:      417 || Batch Translation Loss: 125.376572 => Txt Tokens per Sec:     1176 || Lr: 0.000100
2024-01-31 04:15:17,306 Epoch 384: Total Training Recognition Loss 2124.98  Total Training Translation Loss 6848.71 
2024-01-31 04:15:17,306 EPOCH 385
2024-01-31 04:15:42,704 Epoch 385: Total Training Recognition Loss 2131.20  Total Training Translation Loss 6847.33 
2024-01-31 04:15:42,705 EPOCH 386
2024-01-31 04:15:44,367 [Epoch: 386 Step: 00025800] Batch Recognition Loss:  40.416725 => Gls Tokens per Sec:      482 || Batch Translation Loss: 111.352417 => Txt Tokens per Sec:     1270 || Lr: 0.000100
2024-01-31 04:16:08,289 Epoch 386: Total Training Recognition Loss 2126.75  Total Training Translation Loss 6849.66 
2024-01-31 04:16:08,289 EPOCH 387
2024-01-31 04:16:23,786 [Epoch: 387 Step: 00025900] Batch Recognition Loss:  46.804642 => Gls Tokens per Sec:      387 || Batch Translation Loss: 123.312057 => Txt Tokens per Sec:     1108 || Lr: 0.000100
2024-01-31 04:16:33,698 Epoch 387: Total Training Recognition Loss 2128.35  Total Training Translation Loss 6846.35 
2024-01-31 04:16:33,698 EPOCH 388
2024-01-31 04:17:02,498 Epoch 388: Total Training Recognition Loss 2127.97  Total Training Translation Loss 6850.35 
2024-01-31 04:17:02,499 EPOCH 389
2024-01-31 04:17:05,426 [Epoch: 389 Step: 00026000] Batch Recognition Loss:  11.109947 => Gls Tokens per Sec:      219 || Batch Translation Loss:  63.034340 => Txt Tokens per Sec:      641 || Lr: 0.000100
2024-01-31 04:17:35,208 Validation result at epoch 389, step    26000: duration: 29.7808s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 687.03723	Translation Loss: 73472.39062	PPL: 1559.91345
	Eval Metric: BLEU
	WER 559.32	(DEL: 4.17,	INS: 471.12,	SUB: 84.04)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.42	ROUGE 0.00
2024-01-31 04:17:35,210 Logging Recognition and Translation Outputs
2024-01-31 04:17:35,210 ========================================================================================================================
2024-01-31 04:17:35,210 Logging Sequence: 130_139.00
2024-01-31 04:17:35,211 	Gloss Reference :	***** ***** *** ***** *** ***** ***** ***** * ***** *********************** ***** ***** ***** * ***** * ***** ********* ***** *************** A     B+C+D+E        
2024-01-31 04:17:35,211 	Gloss Hypothesis:	<unk> <pad> B+D <pad> E+B <unk> E+B+C <unk> D <unk> E+B+E+B+E+D+E+D+C+B+C+D <unk> B+C+E <unk> E <unk> E <unk> C+E+B+C+E <unk> C+E+B+E+C+E+C+E <unk> E+B+E+B+E+B+E+C
2024-01-31 04:17:35,211 	Gloss Alignment :	I     I     I   I     I   I     I     I     I I     I                       I     I     I     I I     I I     I         I     I               S     S              
2024-01-31 04:17:35,211 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:17:35,217 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** he  shared a   picture of  a   little pouch he  knit for his olympic gold medal with uk  flag on  one side and japanese flag on  the other
2024-01-31 04:17:35,217 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>    <s> <s>     <s> <s> <s>    <s>   <s> <s>  <s> <s> <s>     <s>  <s>   <s>  <s> <s>  <s> <s> <s>  <s> <s>      <s>  <s> <s> <s>  
2024-01-31 04:17:35,217 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   S   S      S   S       S   S   S      S     S   S    S   S   S       S    S     S    S   S    S   S   S    S   S        S    S   S   S    
2024-01-31 04:17:35,217 ========================================================================================================================
2024-01-31 04:17:35,217 Logging Sequence: 72_194.00
2024-01-31 04:17:35,217 	Gloss Reference :	* ***** * ***** A ***** B+C+D+E
2024-01-31 04:17:35,218 	Gloss Hypothesis:	A <unk> A <unk> A <unk> E+A    
2024-01-31 04:17:35,218 	Gloss Alignment :	I I     I I       I     S      
2024-01-31 04:17:35,218 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:17:35,221 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** shah told her to  do  what she wants and filed a   police complaint against her
2024-01-31 04:17:35,221 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s>  <s> <s> <s> <s>  <s> <s>   <s> <s>   <s> <s>    <s>       <s>     <s>
2024-01-31 04:17:35,221 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S    S    S   S   S   S    S   S     S   S     S   S      S         S       S  
2024-01-31 04:17:35,221 ========================================================================================================================
2024-01-31 04:17:35,221 Logging Sequence: 69_177.00
2024-01-31 04:17:35,222 	Gloss Reference :	A B+C+D+E
2024-01-31 04:17:35,222 	Gloss Hypothesis:	* E+A+E  
2024-01-31 04:17:35,222 	Gloss Alignment :	D S      
2024-01-31 04:17:35,222 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:17:35,226 	Text Reference  :	*** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* he      said    'i      will    continue playing i       know    it's    about   time    i       retire  i       also    have    a       knee    condition
2024-01-31 04:17:35,226 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing  nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing  
2024-01-31 04:17:35,226 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S        S       S       S       S       S       S       S       S       S       S       S       S       S       S        
2024-01-31 04:17:35,226 ========================================================================================================================
2024-01-31 04:17:35,226 Logging Sequence: 95_118.00
2024-01-31 04:17:35,227 	Gloss Reference :	***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** *** ***** *** ***** * ***** * ***** *** ***** * ***** * ***** ***** * A     B+C+D+E        
2024-01-31 04:17:35,227 	Gloss Hypothesis:	<unk> <pad> <unk> <pad> <unk> A+C+A <unk> B+C+A <unk> E+C+B <unk> C+E <unk> E+A <unk> C <unk> C <unk> C+A <unk> E <unk> C <pad> <unk> E <unk> B+E+B+C+B+E+B+C
2024-01-31 04:17:35,227 	Gloss Alignment :	I     I     I     I     I     I     I     I     I     I     I     I   I     I   I     I I     I I     I   I     I I     I I     I     I S     S              
2024-01-31 04:17:35,227 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:17:35,230 	Text Reference  :	*** *** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** the  game was  stopped strangely due  to   excessive sunlight
2024-01-31 04:17:35,230 	Text Hypothesis :	<s> <s> iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker    iker      iker iker iker      iker    
2024-01-31 04:17:35,230 	Text Alignment  :	I   I   I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    S    S    S    S       S         S    S    S         S       
2024-01-31 04:17:35,230 ========================================================================================================================
2024-01-31 04:17:35,230 Logging Sequence: 112_8.00
2024-01-31 04:17:35,230 	Gloss Reference :	A B+C+D+E
2024-01-31 04:17:35,230 	Gloss Hypothesis:	* E      
2024-01-31 04:17:35,230 	Gloss Alignment :	D S      
2024-01-31 04:17:35,231 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:17:35,235 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ****** ****** ****** ****** ****** ****** before there  were   8      teams  such   as     mumbai indians delhi  capitals punjab kings  etc    and    now    there  will   be     10     teams  in     2022  
2024-01-31 04:17:35,235 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards  boards boards   boards boards boards boards boards boards boards boards boards boards boards boards
2024-01-31 04:17:35,236 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I      I      I      I      I      I      S      S      S      S      S      S      S      S      S       S      S        S      S      S      S      S      S      S      S      S      S      S      S     
2024-01-31 04:17:35,236 ========================================================================================================================
2024-01-31 04:17:59,115 Epoch 389: Total Training Recognition Loss 2128.40  Total Training Translation Loss 6848.18 
2024-01-31 04:17:59,115 EPOCH 390
2024-01-31 04:18:13,815 [Epoch: 390 Step: 00026100] Batch Recognition Loss:  23.110374 => Gls Tokens per Sec:      403 || Batch Translation Loss: 106.747162 => Txt Tokens per Sec:     1155 || Lr: 0.000100
2024-01-31 04:18:24,825 Epoch 390: Total Training Recognition Loss 2127.82  Total Training Translation Loss 6848.02 
2024-01-31 04:18:24,825 EPOCH 391
2024-01-31 04:18:50,617 Epoch 391: Total Training Recognition Loss 2132.88  Total Training Translation Loss 6848.07 
2024-01-31 04:18:50,618 EPOCH 392
2024-01-31 04:18:51,275 [Epoch: 392 Step: 00026200] Batch Recognition Loss:  22.923985 => Gls Tokens per Sec:      732 || Batch Translation Loss:  82.635696 => Txt Tokens per Sec:     1826 || Lr: 0.000100
2024-01-31 04:19:16,059 Epoch 392: Total Training Recognition Loss 2127.41  Total Training Translation Loss 6848.21 
2024-01-31 04:19:16,060 EPOCH 393
2024-01-31 04:19:30,220 [Epoch: 393 Step: 00026300] Batch Recognition Loss:  59.867615 => Gls Tokens per Sec:      407 || Batch Translation Loss: 133.171738 => Txt Tokens per Sec:     1140 || Lr: 0.000100
2024-01-31 04:19:41,836 Epoch 393: Total Training Recognition Loss 2123.17  Total Training Translation Loss 6849.78 
2024-01-31 04:19:41,836 EPOCH 394
2024-01-31 04:20:07,442 Epoch 394: Total Training Recognition Loss 2126.15  Total Training Translation Loss 6849.12 
2024-01-31 04:20:07,442 EPOCH 395
2024-01-31 04:20:08,412 [Epoch: 395 Step: 00026400] Batch Recognition Loss:  44.967537 => Gls Tokens per Sec:      331 || Batch Translation Loss: 118.618065 => Txt Tokens per Sec:     1049 || Lr: 0.000100
2024-01-31 04:20:32,787 Epoch 395: Total Training Recognition Loss 2123.95  Total Training Translation Loss 6849.06 
2024-01-31 04:20:32,787 EPOCH 396
2024-01-31 04:20:45,912 [Epoch: 396 Step: 00026500] Batch Recognition Loss:  18.843014 => Gls Tokens per Sec:      427 || Batch Translation Loss:  93.985245 => Txt Tokens per Sec:     1199 || Lr: 0.000100
2024-01-31 04:20:58,422 Epoch 396: Total Training Recognition Loss 2125.37  Total Training Translation Loss 6848.78 
2024-01-31 04:20:58,422 EPOCH 397
2024-01-31 04:21:24,070 Epoch 397: Total Training Recognition Loss 2124.19  Total Training Translation Loss 6847.38 
2024-01-31 04:21:24,070 EPOCH 398
2024-01-31 04:21:24,355 [Epoch: 398 Step: 00026600] Batch Recognition Loss:  30.554176 => Gls Tokens per Sec:      567 || Batch Translation Loss: 101.422073 => Txt Tokens per Sec:     1569 || Lr: 0.000100
2024-01-31 04:21:51,782 Epoch 398: Total Training Recognition Loss 2127.96  Total Training Translation Loss 6847.49 
2024-01-31 04:21:51,782 EPOCH 399
2024-01-31 04:22:04,627 [Epoch: 399 Step: 00026700] Batch Recognition Loss:  30.915701 => Gls Tokens per Sec:      424 || Batch Translation Loss:  94.672607 => Txt Tokens per Sec:     1160 || Lr: 0.000100
2024-01-31 04:22:19,220 Epoch 399: Total Training Recognition Loss 2125.22  Total Training Translation Loss 6849.32 
2024-01-31 04:22:19,220 EPOCH 400
2024-01-31 04:22:44,832 [Epoch: 400 Step: 00026800] Batch Recognition Loss:  26.752167 => Gls Tokens per Sec:      415 || Batch Translation Loss:  81.860260 => Txt Tokens per Sec:     1152 || Lr: 0.000100
2024-01-31 04:22:44,833 Epoch 400: Total Training Recognition Loss 2120.03  Total Training Translation Loss 6847.61 
2024-01-31 04:22:44,833 EPOCH 401
2024-01-31 04:23:10,429 Epoch 401: Total Training Recognition Loss 2124.53  Total Training Translation Loss 6849.14 
2024-01-31 04:23:10,429 EPOCH 402
2024-01-31 04:23:22,741 [Epoch: 402 Step: 00026900] Batch Recognition Loss:  38.017708 => Gls Tokens per Sec:      422 || Batch Translation Loss:  99.931000 => Txt Tokens per Sec:     1146 || Lr: 0.000100
2024-01-31 04:23:36,047 Epoch 402: Total Training Recognition Loss 2124.50  Total Training Translation Loss 6847.88 
2024-01-31 04:23:36,047 EPOCH 403
2024-01-31 04:24:01,597 [Epoch: 403 Step: 00027000] Batch Recognition Loss:  24.138622 => Gls Tokens per Sec:      410 || Batch Translation Loss:  98.778671 => Txt Tokens per Sec:     1144 || Lr: 0.000100
2024-01-31 04:24:01,732 Epoch 403: Total Training Recognition Loss 2128.00  Total Training Translation Loss 6847.33 
2024-01-31 04:24:01,732 EPOCH 404
2024-01-31 04:24:27,299 Epoch 404: Total Training Recognition Loss 2123.83  Total Training Translation Loss 6848.05 
2024-01-31 04:24:27,299 EPOCH 405
2024-01-31 04:24:39,550 [Epoch: 405 Step: 00027100] Batch Recognition Loss:  72.231239 => Gls Tokens per Sec:      411 || Batch Translation Loss: 126.960899 => Txt Tokens per Sec:     1104 || Lr: 0.000100
2024-01-31 04:24:52,904 Epoch 405: Total Training Recognition Loss 2128.98  Total Training Translation Loss 6847.28 
2024-01-31 04:24:52,905 EPOCH 406
2024-01-31 04:25:17,395 [Epoch: 406 Step: 00027200] Batch Recognition Loss:  12.560995 => Gls Tokens per Sec:      425 || Batch Translation Loss:  64.744194 => Txt Tokens per Sec:     1187 || Lr: 0.000100
2024-01-31 04:25:18,666 Epoch 406: Total Training Recognition Loss 2128.10  Total Training Translation Loss 6847.36 
2024-01-31 04:25:18,666 EPOCH 407
2024-01-31 04:25:44,249 Epoch 407: Total Training Recognition Loss 2129.55  Total Training Translation Loss 6848.78 
2024-01-31 04:25:44,249 EPOCH 408
2024-01-31 04:25:55,340 [Epoch: 408 Step: 00027300] Batch Recognition Loss:  54.014595 => Gls Tokens per Sec:      439 || Batch Translation Loss: 133.922058 => Txt Tokens per Sec:     1198 || Lr: 0.000100
2024-01-31 04:26:09,865 Epoch 408: Total Training Recognition Loss 2128.57  Total Training Translation Loss 6846.11 
2024-01-31 04:26:09,865 EPOCH 409
2024-01-31 04:26:34,146 [Epoch: 409 Step: 00027400] Batch Recognition Loss:  53.837936 => Gls Tokens per Sec:      418 || Batch Translation Loss: 126.476685 => Txt Tokens per Sec:     1161 || Lr: 0.000100
2024-01-31 04:26:35,389 Epoch 409: Total Training Recognition Loss 2125.88  Total Training Translation Loss 6846.09 
2024-01-31 04:26:35,389 EPOCH 410
2024-01-31 04:27:00,803 Epoch 410: Total Training Recognition Loss 2125.44  Total Training Translation Loss 6847.44 
2024-01-31 04:27:00,804 EPOCH 411
2024-01-31 04:27:12,271 [Epoch: 411 Step: 00027500] Batch Recognition Loss:  24.381754 => Gls Tokens per Sec:      411 || Batch Translation Loss:  94.137207 => Txt Tokens per Sec:     1147 || Lr: 0.000100
2024-01-31 04:27:26,387 Epoch 411: Total Training Recognition Loss 2126.29  Total Training Translation Loss 6848.05 
2024-01-31 04:27:26,387 EPOCH 412
2024-01-31 04:27:48,900 [Epoch: 412 Step: 00027600] Batch Recognition Loss:  33.525116 => Gls Tokens per Sec:      448 || Batch Translation Loss: 104.752739 => Txt Tokens per Sec:     1231 || Lr: 0.000100
2024-01-31 04:27:51,936 Epoch 412: Total Training Recognition Loss 2128.84  Total Training Translation Loss 6847.48 
2024-01-31 04:27:51,936 EPOCH 413
2024-01-31 04:28:17,704 Epoch 413: Total Training Recognition Loss 2126.34  Total Training Translation Loss 6846.92 
2024-01-31 04:28:17,704 EPOCH 414
2024-01-31 04:28:26,616 [Epoch: 414 Step: 00027700] Batch Recognition Loss:  28.273933 => Gls Tokens per Sec:      521 || Batch Translation Loss:  81.394974 => Txt Tokens per Sec:     1400 || Lr: 0.000100
2024-01-31 04:28:43,298 Epoch 414: Total Training Recognition Loss 2126.99  Total Training Translation Loss 6847.08 
2024-01-31 04:28:43,298 EPOCH 415
2024-01-31 04:29:06,609 [Epoch: 415 Step: 00027800] Batch Recognition Loss:  46.151588 => Gls Tokens per Sec:      422 || Batch Translation Loss: 124.242111 => Txt Tokens per Sec:     1174 || Lr: 0.000100
2024-01-31 04:29:08,970 Epoch 415: Total Training Recognition Loss 2128.77  Total Training Translation Loss 6849.04 
2024-01-31 04:29:08,970 EPOCH 416
2024-01-31 04:29:34,467 Epoch 416: Total Training Recognition Loss 2126.70  Total Training Translation Loss 6848.74 
2024-01-31 04:29:34,468 EPOCH 417
2024-01-31 04:29:44,900 [Epoch: 417 Step: 00027900] Batch Recognition Loss:  44.676949 => Gls Tokens per Sec:      429 || Batch Translation Loss: 117.526367 => Txt Tokens per Sec:     1179 || Lr: 0.000100
2024-01-31 04:30:00,111 Epoch 417: Total Training Recognition Loss 2127.23  Total Training Translation Loss 6848.46 
2024-01-31 04:30:00,112 EPOCH 418
2024-01-31 04:30:23,931 [Epoch: 418 Step: 00028000] Batch Recognition Loss:  19.242731 => Gls Tokens per Sec:      406 || Batch Translation Loss:  89.096695 => Txt Tokens per Sec:     1125 || Lr: 0.000100
2024-01-31 04:30:53,425 Validation result at epoch 418, step    28000: duration: 29.4933s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 678.34021	Translation Loss: 73459.85156	PPL: 1557.95752
	Eval Metric: BLEU
	WER 543.29	(DEL: 4.31,	INS: 455.79,	SUB: 83.19)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.50	ROUGE 0.00
2024-01-31 04:30:53,427 Logging Recognition and Translation Outputs
2024-01-31 04:30:53,427 ========================================================================================================================
2024-01-31 04:30:53,427 Logging Sequence: 67_98.00
2024-01-31 04:30:53,427 	Gloss Reference :	* ***** ******* ***** ********************* A     B+C+D+E                    
2024-01-31 04:30:53,427 	Gloss Hypothesis:	E <pad> C+E+B+E <unk> E+B+E+C+E+C+B+C+E+C+E <unk> E+B+E+B+E+C+E+B+E+C+E+A+E+B
2024-01-31 04:30:53,427 	Gloss Alignment :	I I     I       I     I                     S     S                          
2024-01-31 04:30:53,428 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:30:53,431 	Text Reference  :	*** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* it            saddens       me            to            see           people        suffering     and           dying         due           to            lack          of            oxygen       
2024-01-31 04:30:53,431 	Text Hypothesis :	<s> <s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 04:30:53,431 	Text Alignment  :	I   I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 04:30:53,431 ========================================================================================================================
2024-01-31 04:30:53,431 Logging Sequence: 157_83.00
2024-01-31 04:30:53,431 	Gloss Reference :	A B+C+D+E
2024-01-31 04:30:53,431 	Gloss Hypothesis:	* E      
2024-01-31 04:30:53,432 	Gloss Alignment :	D S      
2024-01-31 04:30:53,432 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:30:53,436 	Text Reference  :	*** *** *** *** *** *** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* also          when          you           eat           sandwich      at            a             streetside    hawker        or            stall         the           sandwich      maker         will          first         apply         butter        with          a             knife        
2024-01-31 04:30:53,436 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions
2024-01-31 04:30:53,436 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 04:30:53,436 ========================================================================================================================
2024-01-31 04:30:53,437 Logging Sequence: 76_35.00
2024-01-31 04:30:53,437 	Gloss Reference :	***** ***** ***** A ***** *** ***** * ***** * ***** * ***** *** B+C+D+E
2024-01-31 04:30:53,437 	Gloss Hypothesis:	<pad> <unk> <pad> A <unk> E+A <unk> E <unk> E <unk> E <unk> A+E <unk>  
2024-01-31 04:30:53,437 	Gloss Alignment :	I     I     I       I     I   I     I I     I I     I I     I   S      
2024-01-31 04:30:53,437 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:30:53,440 	Text Reference  :	*** *** *** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** bcci     president sourav   ganguly  along    with     board    secretary jay      shah    
2024-01-31 04:30:53,440 	Text Hypothesis :	<s> <s> <s> reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared reshared  reshared reshared reshared reshared reshared reshared  reshared reshared
2024-01-31 04:30:53,440 	Text Alignment  :	I   I   I   I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S         S        S        S        S        S        S         S        S       
2024-01-31 04:30:53,440 ========================================================================================================================
2024-01-31 04:30:53,440 Logging Sequence: 139_180.00
2024-01-31 04:30:53,440 	Gloss Reference :	***** * ***** A ***** ***** ***** * ***** *** ***** B+C+D+E  
2024-01-31 04:30:53,441 	Gloss Hypothesis:	<unk> E <unk> A <unk> A+E+A <unk> C <unk> A+E <unk> E+C+E+C+E
2024-01-31 04:30:53,441 	Gloss Alignment :	I     I I       I     I     I     I I     I   I     S        
2024-01-31 04:30:53,441 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:30:53,442 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* netherlands also    faced   similar riots  
2024-01-31 04:30:53,442 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing     nothing nothing nothing nothing
2024-01-31 04:30:53,443 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S           S       S       S       S      
2024-01-31 04:30:53,443 ========================================================================================================================
2024-01-31 04:30:53,443 Logging Sequence: 98_87.00
2024-01-31 04:30:53,443 	Gloss Reference :	***** * ***** *********************** ***** ***** ***** * ***** * ***** * ***** ******* A     B+C+D+E    
2024-01-31 04:30:53,443 	Gloss Hypothesis:	<unk> E <unk> C+E+C+E+C+E+C+E+C+E+C+E <unk> C+E+C <unk> E <unk> E <unk> E <unk> C+E+B+C <unk> C+E+A+B+C+E
2024-01-31 04:30:53,443 	Gloss Alignment :	I     I I     I                       I     I     I     I I     I I     I I     I       S     S          
2024-01-31 04:30:53,444 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:30:53,447 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** instead of  starting afresh in  2021 the organizers opted to  resume with the previous edition
2024-01-31 04:30:53,447 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s> <s>      <s>    <s> <s>  <s> <s>        <s>   <s> <s>    <s>  <s> <s>      <s>    
2024-01-31 04:30:53,447 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S       S   S        S      S   S    S   S          S     S   S      S    S   S        S      
2024-01-31 04:30:53,447 ========================================================================================================================
2024-01-31 04:30:55,322 Epoch 418: Total Training Recognition Loss 2128.90  Total Training Translation Loss 6849.43 
2024-01-31 04:30:55,322 EPOCH 419
2024-01-31 04:31:21,028 Epoch 419: Total Training Recognition Loss 2129.26  Total Training Translation Loss 6847.66 
2024-01-31 04:31:21,028 EPOCH 420
2024-01-31 04:31:32,248 [Epoch: 420 Step: 00028100] Batch Recognition Loss:  32.860855 => Gls Tokens per Sec:      377 || Batch Translation Loss: 108.276321 => Txt Tokens per Sec:     1074 || Lr: 0.000050
2024-01-31 04:31:46,523 Epoch 420: Total Training Recognition Loss 2126.86  Total Training Translation Loss 6848.81 
2024-01-31 04:31:46,524 EPOCH 421
2024-01-31 04:32:09,866 [Epoch: 421 Step: 00028200] Batch Recognition Loss:  11.468319 => Gls Tokens per Sec:      407 || Batch Translation Loss:  63.148823 => Txt Tokens per Sec:     1129 || Lr: 0.000050
2024-01-31 04:32:12,137 Epoch 421: Total Training Recognition Loss 2128.49  Total Training Translation Loss 6848.00 
2024-01-31 04:32:12,138 EPOCH 422
2024-01-31 04:32:37,750 Epoch 422: Total Training Recognition Loss 2124.30  Total Training Translation Loss 6850.07 
2024-01-31 04:32:37,751 EPOCH 423
2024-01-31 04:32:47,879 [Epoch: 423 Step: 00028300] Batch Recognition Loss:  54.661297 => Gls Tokens per Sec:      402 || Batch Translation Loss: 131.868073 => Txt Tokens per Sec:     1103 || Lr: 0.000050
2024-01-31 04:33:03,401 Epoch 423: Total Training Recognition Loss 2122.48  Total Training Translation Loss 6848.15 
2024-01-31 04:33:03,402 EPOCH 424
2024-01-31 04:33:26,728 [Epoch: 424 Step: 00028400] Batch Recognition Loss:  72.914146 => Gls Tokens per Sec:      401 || Batch Translation Loss: 126.481117 => Txt Tokens per Sec:     1123 || Lr: 0.000050
2024-01-31 04:33:28,994 Epoch 424: Total Training Recognition Loss 2127.92  Total Training Translation Loss 6847.05 
2024-01-31 04:33:28,994 EPOCH 425
2024-01-31 04:33:54,673 Epoch 425: Total Training Recognition Loss 2130.37  Total Training Translation Loss 6849.37 
2024-01-31 04:33:54,674 EPOCH 426
2024-01-31 04:34:03,334 [Epoch: 426 Step: 00028500] Batch Recognition Loss:  39.749836 => Gls Tokens per Sec:      462 || Batch Translation Loss: 109.205681 => Txt Tokens per Sec:     1273 || Lr: 0.000050
2024-01-31 04:34:20,164 Epoch 426: Total Training Recognition Loss 2128.42  Total Training Translation Loss 6847.30 
2024-01-31 04:34:20,164 EPOCH 427
2024-01-31 04:34:42,778 [Epoch: 427 Step: 00028600] Batch Recognition Loss:  40.671623 => Gls Tokens per Sec:      410 || Batch Translation Loss: 114.899994 => Txt Tokens per Sec:     1158 || Lr: 0.000050
2024-01-31 04:34:45,829 Epoch 427: Total Training Recognition Loss 2126.29  Total Training Translation Loss 6847.66 
2024-01-31 04:34:45,829 EPOCH 428
2024-01-31 04:35:11,481 Epoch 428: Total Training Recognition Loss 2122.70  Total Training Translation Loss 6847.76 
2024-01-31 04:35:11,481 EPOCH 429
2024-01-31 04:35:20,449 [Epoch: 429 Step: 00028700] Batch Recognition Loss:  16.546371 => Gls Tokens per Sec:      418 || Batch Translation Loss:  76.831337 => Txt Tokens per Sec:     1165 || Lr: 0.000050
2024-01-31 04:35:37,092 Epoch 429: Total Training Recognition Loss 2121.27  Total Training Translation Loss 6848.19 
2024-01-31 04:35:37,092 EPOCH 430
2024-01-31 04:35:59,246 [Epoch: 430 Step: 00028800] Batch Recognition Loss:  38.390728 => Gls Tokens per Sec:      408 || Batch Translation Loss: 111.137123 => Txt Tokens per Sec:     1120 || Lr: 0.000050
2024-01-31 04:36:02,813 Epoch 430: Total Training Recognition Loss 2127.46  Total Training Translation Loss 6849.72 
2024-01-31 04:36:02,814 EPOCH 431
2024-01-31 04:36:28,349 Epoch 431: Total Training Recognition Loss 2124.46  Total Training Translation Loss 6849.45 
2024-01-31 04:36:28,349 EPOCH 432
2024-01-31 04:36:35,321 [Epoch: 432 Step: 00028900] Batch Recognition Loss:   7.136548 => Gls Tokens per Sec:      528 || Batch Translation Loss:  57.274483 => Txt Tokens per Sec:     1432 || Lr: 0.000050
2024-01-31 04:36:53,999 Epoch 432: Total Training Recognition Loss 2127.38  Total Training Translation Loss 6848.73 
2024-01-31 04:36:54,000 EPOCH 433
2024-01-31 04:37:16,970 [Epoch: 433 Step: 00029000] Batch Recognition Loss:  28.555704 => Gls Tokens per Sec:      390 || Batch Translation Loss:  94.068573 => Txt Tokens per Sec:     1093 || Lr: 0.000050
2024-01-31 04:37:22,880 Epoch 433: Total Training Recognition Loss 2128.05  Total Training Translation Loss 6847.88 
2024-01-31 04:37:22,880 EPOCH 434
2024-01-31 04:37:49,436 Epoch 434: Total Training Recognition Loss 2126.13  Total Training Translation Loss 6849.64 
2024-01-31 04:37:49,436 EPOCH 435
2024-01-31 04:37:57,584 [Epoch: 435 Step: 00029100] Batch Recognition Loss:  30.023787 => Gls Tokens per Sec:      432 || Batch Translation Loss: 102.135742 => Txt Tokens per Sec:     1165 || Lr: 0.000050
2024-01-31 04:38:14,951 Epoch 435: Total Training Recognition Loss 2127.67  Total Training Translation Loss 6847.57 
2024-01-31 04:38:14,951 EPOCH 436
2024-01-31 04:38:35,827 [Epoch: 436 Step: 00029200] Batch Recognition Loss:   7.147487 => Gls Tokens per Sec:      417 || Batch Translation Loss:  57.457447 => Txt Tokens per Sec:     1152 || Lr: 0.000050
2024-01-31 04:38:40,480 Epoch 436: Total Training Recognition Loss 2126.31  Total Training Translation Loss 6848.97 
2024-01-31 04:38:40,480 EPOCH 437
2024-01-31 04:39:05,954 Epoch 437: Total Training Recognition Loss 2130.19  Total Training Translation Loss 6847.54 
2024-01-31 04:39:05,954 EPOCH 438
2024-01-31 04:39:16,298 [Epoch: 438 Step: 00029300] Batch Recognition Loss:  33.502800 => Gls Tokens per Sec:      316 || Batch Translation Loss: 107.373535 => Txt Tokens per Sec:      932 || Lr: 0.000050
2024-01-31 04:39:31,439 Epoch 438: Total Training Recognition Loss 2129.95  Total Training Translation Loss 6847.57 
2024-01-31 04:39:31,439 EPOCH 439
2024-01-31 04:39:53,038 [Epoch: 439 Step: 00029400] Batch Recognition Loss:  30.143999 => Gls Tokens per Sec:      396 || Batch Translation Loss: 105.997879 => Txt Tokens per Sec:     1101 || Lr: 0.000050
2024-01-31 04:39:57,084 Epoch 439: Total Training Recognition Loss 2125.54  Total Training Translation Loss 6846.86 
2024-01-31 04:39:57,084 EPOCH 440
2024-01-31 04:40:22,542 Epoch 440: Total Training Recognition Loss 2127.03  Total Training Translation Loss 6849.66 
2024-01-31 04:40:22,543 EPOCH 441
2024-01-31 04:40:31,492 [Epoch: 441 Step: 00029500] Batch Recognition Loss:  53.467216 => Gls Tokens per Sec:      348 || Batch Translation Loss: 127.806091 => Txt Tokens per Sec:     1020 || Lr: 0.000050
2024-01-31 04:40:48,120 Epoch 441: Total Training Recognition Loss 2128.78  Total Training Translation Loss 6849.09 
2024-01-31 04:40:48,120 EPOCH 442
2024-01-31 04:41:08,377 [Epoch: 442 Step: 00029600] Batch Recognition Loss:  45.413918 => Gls Tokens per Sec:      414 || Batch Translation Loss: 120.582443 => Txt Tokens per Sec:     1154 || Lr: 0.000050
2024-01-31 04:41:13,640 Epoch 442: Total Training Recognition Loss 2124.71  Total Training Translation Loss 6847.29 
2024-01-31 04:41:13,641 EPOCH 443
2024-01-31 04:41:39,152 Epoch 443: Total Training Recognition Loss 2131.12  Total Training Translation Loss 6849.51 
2024-01-31 04:41:39,152 EPOCH 444
2024-01-31 04:41:47,088 [Epoch: 444 Step: 00029700] Batch Recognition Loss:  28.264565 => Gls Tokens per Sec:      383 || Batch Translation Loss:  94.955078 => Txt Tokens per Sec:     1127 || Lr: 0.000050
2024-01-31 04:42:04,707 Epoch 444: Total Training Recognition Loss 2128.42  Total Training Translation Loss 6849.30 
2024-01-31 04:42:04,707 EPOCH 445
2024-01-31 04:42:24,793 [Epoch: 445 Step: 00029800] Batch Recognition Loss:  33.662601 => Gls Tokens per Sec:      410 || Batch Translation Loss:  94.687698 => Txt Tokens per Sec:     1146 || Lr: 0.000050
2024-01-31 04:42:30,169 Epoch 445: Total Training Recognition Loss 2126.23  Total Training Translation Loss 6848.53 
2024-01-31 04:42:30,170 EPOCH 446
2024-01-31 04:42:55,829 Epoch 446: Total Training Recognition Loss 2123.41  Total Training Translation Loss 6847.19 
2024-01-31 04:42:55,829 EPOCH 447
2024-01-31 04:43:01,340 [Epoch: 447 Step: 00029900] Batch Recognition Loss:  33.436607 => Gls Tokens per Sec:      523 || Batch Translation Loss: 107.436836 => Txt Tokens per Sec:     1406 || Lr: 0.000050
2024-01-31 04:43:21,610 Epoch 447: Total Training Recognition Loss 2127.59  Total Training Translation Loss 6847.32 
2024-01-31 04:43:21,611 EPOCH 448
2024-01-31 04:43:42,209 [Epoch: 448 Step: 00030000] Batch Recognition Loss:  22.783073 => Gls Tokens per Sec:      392 || Batch Translation Loss:  83.450363 => Txt Tokens per Sec:     1115 || Lr: 0.000050
2024-01-31 04:44:12,023 Validation result at epoch 448, step    30000: duration: 29.8134s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 681.30206	Translation Loss: 73475.25781	PPL: 1560.36108
	Eval Metric: BLEU
	WER 545.69	(DEL: 4.17,	INS: 457.63,	SUB: 83.90)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.33	ROUGE 0.00
2024-01-31 04:44:12,024 Logging Recognition and Translation Outputs
2024-01-31 04:44:12,024 ========================================================================================================================
2024-01-31 04:44:12,024 Logging Sequence: 165_502.00
2024-01-31 04:44:12,025 	Gloss Reference :	A B+C+D+E
2024-01-31 04:44:12,025 	Gloss Hypothesis:	* E+C+E  
2024-01-31 04:44:12,025 	Gloss Alignment :	D S      
2024-01-31 04:44:12,025 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:44:12,028 	Text Reference  :	*** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** tendulkar would sit   in    the   pavilion wearing both  his   batting pads  even  after he    got   out  
2024-01-31 04:44:12,029 	Text Hypothesis :	<s> <s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha     sabha sabha sabha sabha sabha    sabha   sabha sabha sabha   sabha sabha sabha sabha sabha sabha
2024-01-31 04:44:12,029 	Text Alignment  :	I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S         S     S     S     S     S        S       S     S     S       S     S     S     S     S     S    
2024-01-31 04:44:12,029 ========================================================================================================================
2024-01-31 04:44:12,029 Logging Sequence: 127_57.00
2024-01-31 04:44:12,029 	Gloss Reference :	* ***** ***** ***** * ***** ******* ***** * ***** * ***** * A     B+C+D+E              
2024-01-31 04:44:12,030 	Gloss Hypothesis:	E <unk> E+A+E <unk> E <unk> E+C+E+C <unk> E <unk> E <unk> E <unk> E+A+E+C+E+C+E+A+E+C+A
2024-01-31 04:44:12,030 	Gloss Alignment :	I I     I     I     I I     I       I     I I     I I     I S     S                    
2024-01-31 04:44:12,030 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:44:12,034 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* till          date          india         had           won           only          2             medals        at            the           championships which         like          the           olympics      is            the           highest       level         championship 
2024-01-31 04:44:12,034 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions
2024-01-31 04:44:12,034 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 04:44:12,034 ========================================================================================================================
2024-01-31 04:44:12,034 Logging Sequence: 169_10.00
2024-01-31 04:44:12,035 	Gloss Reference :	* *** ***** ********* ***** ***** A     B+C+D+E            
2024-01-31 04:44:12,035 	Gloss Hypothesis:	E D+E <unk> E+D+E+D+E <unk> E+D+E <unk> E+D+C+E+C+E+D+E+C+E
2024-01-31 04:44:12,035 	Gloss Alignment :	I I   I     I         I     I     S     S                  
2024-01-31 04:44:12,035 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:44:12,039 	Text Reference  :	*** *** *** *** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** ****** the    18th   over   was    bowled by     ravi   bishnoi with   khushdil shah   and    asif   ali    on     the    crease
2024-01-31 04:44:12,039 	Text Hypothesis :	<s> <s> <s> <s> boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards boards  boards boards   boards boards boards boards boards boards boards
2024-01-31 04:44:12,039 	Text Alignment  :	I   I   I   I   I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      I      S      S      S      S      S      S      S      S       S      S        S      S      S      S      S      S      S     
2024-01-31 04:44:12,039 ========================================================================================================================
2024-01-31 04:44:12,039 Logging Sequence: 64_89.00
2024-01-31 04:44:12,039 	Gloss Reference :	***** ***** ***** ***** ***** ***** ***** A     B+C+D+E
2024-01-31 04:44:12,040 	Gloss Hypothesis:	<unk> <pad> <unk> <pad> <unk> <pad> <unk> <pad> <unk>  
2024-01-31 04:44:12,040 	Gloss Alignment :	I     I     I     I     I     I     I     S     S      
2024-01-31 04:44:12,040 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:44:12,043 	Text Reference  :	**** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** but  this can  not  go   on   amidst the  rising cases human lives need to   be   safeguarded
2024-01-31 04:44:12,043 	Text Hypothesis :	fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine   fine fine   fine  fine  fine  fine fine fine fine       
2024-01-31 04:44:12,043 	Text Alignment  :	I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    S    S    S    S    S    S    S      S    S      S     S     S     S    S    S    S          
2024-01-31 04:44:12,044 ========================================================================================================================
2024-01-31 04:44:12,044 Logging Sequence: 166_261.00
2024-01-31 04:44:12,044 	Gloss Reference :	A     B+C+D+E
2024-01-31 04:44:12,044 	Gloss Hypothesis:	<unk> E      
2024-01-31 04:44:12,044 	Gloss Alignment :	S     S      
2024-01-31 04:44:12,044 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:44:12,046 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* for     all     organizational matters and     the     schedule
2024-01-31 04:44:12,046 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing        nothing nothing nothing nothing 
2024-01-31 04:44:12,046 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S              S       S       S       S       
2024-01-31 04:44:12,046 ========================================================================================================================
2024-01-31 04:44:17,080 Epoch 448: Total Training Recognition Loss 2127.67  Total Training Translation Loss 6847.22 
2024-01-31 04:44:17,080 EPOCH 449
2024-01-31 04:44:42,595 Epoch 449: Total Training Recognition Loss 2129.42  Total Training Translation Loss 6850.35 
2024-01-31 04:44:42,595 EPOCH 450
2024-01-31 04:44:48,635 [Epoch: 450 Step: 00030100] Batch Recognition Loss:  45.222397 => Gls Tokens per Sec:      435 || Batch Translation Loss: 120.570549 => Txt Tokens per Sec:     1159 || Lr: 0.000050
2024-01-31 04:45:08,267 Epoch 450: Total Training Recognition Loss 2130.82  Total Training Translation Loss 6848.33 
2024-01-31 04:45:08,267 EPOCH 451
2024-01-31 04:45:26,381 [Epoch: 451 Step: 00030200] Batch Recognition Loss:  13.629849 => Gls Tokens per Sec:      437 || Batch Translation Loss:  79.228058 => Txt Tokens per Sec:     1192 || Lr: 0.000050
2024-01-31 04:45:33,834 Epoch 451: Total Training Recognition Loss 2129.22  Total Training Translation Loss 6849.49 
2024-01-31 04:45:33,835 EPOCH 452
2024-01-31 04:45:59,521 Epoch 452: Total Training Recognition Loss 2126.74  Total Training Translation Loss 6848.00 
2024-01-31 04:45:59,521 EPOCH 453
2024-01-31 04:46:05,362 [Epoch: 453 Step: 00030300] Batch Recognition Loss:  13.957912 => Gls Tokens per Sec:      438 || Batch Translation Loss:  79.675201 => Txt Tokens per Sec:     1253 || Lr: 0.000050
2024-01-31 04:46:25,164 Epoch 453: Total Training Recognition Loss 2124.48  Total Training Translation Loss 6848.85 
2024-01-31 04:46:25,164 EPOCH 454
2024-01-31 04:46:45,112 [Epoch: 454 Step: 00030400] Batch Recognition Loss:  33.487438 => Gls Tokens per Sec:      389 || Batch Translation Loss: 115.400528 => Txt Tokens per Sec:     1091 || Lr: 0.000050
2024-01-31 04:46:50,623 Epoch 454: Total Training Recognition Loss 2131.26  Total Training Translation Loss 6850.68 
2024-01-31 04:46:50,623 EPOCH 455
2024-01-31 04:47:19,448 Epoch 455: Total Training Recognition Loss 2127.09  Total Training Translation Loss 6846.90 
2024-01-31 04:47:19,450 EPOCH 456
2024-01-31 04:47:24,652 [Epoch: 456 Step: 00030500] Batch Recognition Loss:  27.065504 => Gls Tokens per Sec:      462 || Batch Translation Loss:  82.121071 => Txt Tokens per Sec:     1251 || Lr: 0.000050
2024-01-31 04:47:45,739 Epoch 456: Total Training Recognition Loss 2128.10  Total Training Translation Loss 6849.33 
2024-01-31 04:47:45,739 EPOCH 457
2024-01-31 04:48:05,009 [Epoch: 457 Step: 00030600] Batch Recognition Loss:  49.772480 => Gls Tokens per Sec:      394 || Batch Translation Loss: 129.986450 => Txt Tokens per Sec:     1101 || Lr: 0.000050
2024-01-31 04:48:11,312 Epoch 457: Total Training Recognition Loss 2127.13  Total Training Translation Loss 6847.85 
2024-01-31 04:48:11,312 EPOCH 458
2024-01-31 04:48:36,843 Epoch 458: Total Training Recognition Loss 2129.54  Total Training Translation Loss 6849.31 
2024-01-31 04:48:36,844 EPOCH 459
2024-01-31 04:48:42,331 [Epoch: 459 Step: 00030700] Batch Recognition Loss:  46.149162 => Gls Tokens per Sec:      408 || Batch Translation Loss: 124.543304 => Txt Tokens per Sec:     1179 || Lr: 0.000050
2024-01-31 04:49:02,301 Epoch 459: Total Training Recognition Loss 2123.34  Total Training Translation Loss 6848.25 
2024-01-31 04:49:02,301 EPOCH 460
2024-01-31 04:49:19,416 [Epoch: 460 Step: 00030800] Batch Recognition Loss:  30.900951 => Gls Tokens per Sec:      434 || Batch Translation Loss: 112.920578 => Txt Tokens per Sec:     1180 || Lr: 0.000050
2024-01-31 04:49:27,814 Epoch 460: Total Training Recognition Loss 2126.18  Total Training Translation Loss 6845.72 
2024-01-31 04:49:27,814 EPOCH 461
2024-01-31 04:49:53,298 Epoch 461: Total Training Recognition Loss 2127.49  Total Training Translation Loss 6847.60 
2024-01-31 04:49:53,298 EPOCH 462
2024-01-31 04:49:57,329 [Epoch: 462 Step: 00030900] Batch Recognition Loss:  41.123146 => Gls Tokens per Sec:      516 || Batch Translation Loss: 117.938950 => Txt Tokens per Sec:     1383 || Lr: 0.000050
2024-01-31 04:50:18,907 Epoch 462: Total Training Recognition Loss 2119.24  Total Training Translation Loss 6849.77 
2024-01-31 04:50:18,908 EPOCH 463
2024-01-31 04:50:38,521 [Epoch: 463 Step: 00031000] Batch Recognition Loss:  43.877937 => Gls Tokens per Sec:      371 || Batch Translation Loss: 124.487091 => Txt Tokens per Sec:     1037 || Lr: 0.000050
2024-01-31 04:50:44,623 Epoch 463: Total Training Recognition Loss 2125.34  Total Training Translation Loss 6847.90 
2024-01-31 04:50:44,623 EPOCH 464
2024-01-31 04:51:10,333 Epoch 464: Total Training Recognition Loss 2126.83  Total Training Translation Loss 6848.58 
2024-01-31 04:51:10,333 EPOCH 465
2024-01-31 04:51:13,505 [Epoch: 465 Step: 00031100] Batch Recognition Loss:  35.748726 => Gls Tokens per Sec:      606 || Batch Translation Loss: 119.062874 => Txt Tokens per Sec:     1546 || Lr: 0.000050
2024-01-31 04:51:35,990 Epoch 465: Total Training Recognition Loss 2128.29  Total Training Translation Loss 6848.81 
2024-01-31 04:51:35,990 EPOCH 466
2024-01-31 04:51:55,052 [Epoch: 466 Step: 00031200] Batch Recognition Loss:  44.354733 => Gls Tokens per Sec:      373 || Batch Translation Loss: 134.417175 => Txt Tokens per Sec:     1066 || Lr: 0.000050
2024-01-31 04:52:01,789 Epoch 466: Total Training Recognition Loss 2125.81  Total Training Translation Loss 6848.59 
2024-01-31 04:52:01,789 EPOCH 467
2024-01-31 04:52:27,422 Epoch 467: Total Training Recognition Loss 2124.13  Total Training Translation Loss 6848.31 
2024-01-31 04:52:27,422 EPOCH 468
2024-01-31 04:52:31,408 [Epoch: 468 Step: 00031300] Batch Recognition Loss:  26.438107 => Gls Tokens per Sec:      442 || Batch Translation Loss:  85.330559 => Txt Tokens per Sec:     1259 || Lr: 0.000050
2024-01-31 04:52:53,018 Epoch 468: Total Training Recognition Loss 2126.54  Total Training Translation Loss 6848.59 
2024-01-31 04:52:53,018 EPOCH 469
2024-01-31 04:53:09,551 [Epoch: 469 Step: 00031400] Batch Recognition Loss:  27.798904 => Gls Tokens per Sec:      420 || Batch Translation Loss:  93.160683 => Txt Tokens per Sec:     1137 || Lr: 0.000050
2024-01-31 04:53:18,585 Epoch 469: Total Training Recognition Loss 2123.82  Total Training Translation Loss 6849.61 
2024-01-31 04:53:18,585 EPOCH 470
2024-01-31 04:53:44,241 Epoch 470: Total Training Recognition Loss 2121.10  Total Training Translation Loss 6848.71 
2024-01-31 04:53:44,241 EPOCH 471
2024-01-31 04:53:47,829 [Epoch: 471 Step: 00031500] Batch Recognition Loss:  37.295784 => Gls Tokens per Sec:      446 || Batch Translation Loss: 128.902847 => Txt Tokens per Sec:     1296 || Lr: 0.000050
2024-01-31 04:54:09,812 Epoch 471: Total Training Recognition Loss 2124.54  Total Training Translation Loss 6847.60 
2024-01-31 04:54:09,812 EPOCH 472
2024-01-31 04:54:24,629 [Epoch: 472 Step: 00031600] Batch Recognition Loss:  23.243677 => Gls Tokens per Sec:      458 || Batch Translation Loss:  84.791809 => Txt Tokens per Sec:     1242 || Lr: 0.000050
2024-01-31 04:54:35,432 Epoch 472: Total Training Recognition Loss 2126.98  Total Training Translation Loss 6849.25 
2024-01-31 04:54:35,432 EPOCH 473
2024-01-31 04:55:00,842 Epoch 473: Total Training Recognition Loss 2123.73  Total Training Translation Loss 6847.53 
2024-01-31 04:55:00,842 EPOCH 474
2024-01-31 04:55:04,417 [Epoch: 474 Step: 00031700] Batch Recognition Loss:  44.262741 => Gls Tokens per Sec:      403 || Batch Translation Loss: 123.812897 => Txt Tokens per Sec:     1231 || Lr: 0.000050
2024-01-31 04:55:26,269 Epoch 474: Total Training Recognition Loss 2125.39  Total Training Translation Loss 6848.85 
2024-01-31 04:55:26,269 EPOCH 475
2024-01-31 04:55:40,981 [Epoch: 475 Step: 00031800] Batch Recognition Loss:  33.094021 => Gls Tokens per Sec:      457 || Batch Translation Loss: 103.901978 => Txt Tokens per Sec:     1279 || Lr: 0.000050
2024-01-31 04:55:51,779 Epoch 475: Total Training Recognition Loss 2120.71  Total Training Translation Loss 6848.75 
2024-01-31 04:55:51,779 EPOCH 476
2024-01-31 04:56:17,313 Epoch 476: Total Training Recognition Loss 2122.33  Total Training Translation Loss 6848.02 
2024-01-31 04:56:17,313 EPOCH 477
2024-01-31 04:56:20,428 [Epoch: 477 Step: 00031900] Batch Recognition Loss:  38.378601 => Gls Tokens per Sec:      411 || Batch Translation Loss: 128.671768 => Txt Tokens per Sec:     1195 || Lr: 0.000050
2024-01-31 04:56:42,882 Epoch 477: Total Training Recognition Loss 2130.92  Total Training Translation Loss 6848.87 
2024-01-31 04:56:42,882 EPOCH 478
2024-01-31 04:56:58,620 [Epoch: 478 Step: 00032000] Batch Recognition Loss:  32.715870 => Gls Tokens per Sec:      411 || Batch Translation Loss: 113.589012 => Txt Tokens per Sec:     1126 || Lr: 0.000050
2024-01-31 04:57:28,358 Validation result at epoch 478, step    32000: duration: 29.7375s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 676.63416	Translation Loss: 73476.86719	PPL: 1560.61279
	Eval Metric: BLEU
	WER 541.67	(DEL: 4.38,	INS: 453.74,	SUB: 83.55)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.40	ROUGE 0.00
2024-01-31 04:57:28,359 Logging Recognition and Translation Outputs
2024-01-31 04:57:28,360 ========================================================================================================================
2024-01-31 04:57:28,360 Logging Sequence: 86_11.00
2024-01-31 04:57:28,360 	Gloss Reference :	***** ***** A B+C+D+E
2024-01-31 04:57:28,360 	Gloss Hypothesis:	<unk> <pad> A <unk>  
2024-01-31 04:57:28,360 	Gloss Alignment :	I     I       S      
2024-01-31 04:57:28,360 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:57:28,362 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* he      was     66      years   old    
2024-01-31 04:57:28,362 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing
2024-01-31 04:57:28,362 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S      
2024-01-31 04:57:28,362 ========================================================================================================================
2024-01-31 04:57:28,362 Logging Sequence: 67_16.00
2024-01-31 04:57:28,363 	Gloss Reference :	***** *** ***** * ***** * ***** ******************* A     B+C+D+E
2024-01-31 04:57:28,363 	Gloss Hypothesis:	<unk> E+A <unk> E <unk> E <unk> B+E+C+B+A+B+A+E+B+E <unk> E      
2024-01-31 04:57:28,363 	Gloss Alignment :	I     I   I     I I     I I     I                   S     S      
2024-01-31 04:57:28,363 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:57:28,365 	Text Reference  :	*** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* to            help          india's       fight         against       the           covid-19      pandemic     
2024-01-31 04:57:28,365 	Text Hypothesis :	<s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 04:57:28,365 	Text Alignment  :	I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S            
2024-01-31 04:57:28,365 ========================================================================================================================
2024-01-31 04:57:28,365 Logging Sequence: 69_177.00
2024-01-31 04:57:28,366 	Gloss Reference :	A B+C+D+E
2024-01-31 04:57:28,366 	Gloss Hypothesis:	* E+A+E  
2024-01-31 04:57:28,366 	Gloss Alignment :	D S      
2024-01-31 04:57:28,366 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:57:28,370 	Text Reference  :	*** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* he      said    'i      will    continue playing i       know    it's    about   time    i       retire  i       also    have    a       knee    condition
2024-01-31 04:57:28,370 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing  nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing  
2024-01-31 04:57:28,370 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S        S       S       S       S       S       S       S       S       S       S       S       S       S       S        
2024-01-31 04:57:28,370 ========================================================================================================================
2024-01-31 04:57:28,371 Logging Sequence: 165_615.00
2024-01-31 04:57:28,371 	Gloss Reference :	A B+C+D+E
2024-01-31 04:57:28,371 	Gloss Hypothesis:	* E+A+E  
2024-01-31 04:57:28,371 	Gloss Alignment :	D S      
2024-01-31 04:57:28,371 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:57:28,372 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** *********** we          defeated    pakistan    too        
2024-01-31 04:57:28,372 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious unconscious
2024-01-31 04:57:28,373 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           I           S           S           S           S          
2024-01-31 04:57:28,373 ========================================================================================================================
2024-01-31 04:57:28,373 Logging Sequence: 61_5.00
2024-01-31 04:57:28,373 	Gloss Reference :	***** * ***** A ***** * ***** *** B+C+D+E
2024-01-31 04:57:28,373 	Gloss Hypothesis:	<unk> A <unk> A <unk> E <unk> A+E <unk>  
2024-01-31 04:57:28,374 	Gloss Alignment :	I     I I       I     I I     I   S      
2024-01-31 04:57:28,374 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 04:57:28,376 	Text Reference  :	*** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* they          rivalry       is            seen          the           most          during        india         pakistan      cricket       matches      
2024-01-31 04:57:28,376 	Text Hypothesis :	<s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 04:57:28,376 	Text Alignment  :	I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 04:57:28,377 ========================================================================================================================
2024-01-31 04:57:38,138 Epoch 478: Total Training Recognition Loss 2124.43  Total Training Translation Loss 6846.78 
2024-01-31 04:57:38,138 EPOCH 479
2024-01-31 04:58:03,725 Epoch 479: Total Training Recognition Loss 2121.14  Total Training Translation Loss 6848.08 
2024-01-31 04:58:03,725 EPOCH 480
2024-01-31 04:58:05,378 [Epoch: 480 Step: 00032100] Batch Recognition Loss:   5.200484 => Gls Tokens per Sec:      679 || Batch Translation Loss:  45.708931 => Txt Tokens per Sec:     1529 || Lr: 0.000050
2024-01-31 04:58:29,409 Epoch 480: Total Training Recognition Loss 2128.62  Total Training Translation Loss 6848.30 
2024-01-31 04:58:29,409 EPOCH 481
2024-01-31 04:58:44,214 [Epoch: 481 Step: 00032200] Batch Recognition Loss:  37.030033 => Gls Tokens per Sec:      432 || Batch Translation Loss: 120.101997 => Txt Tokens per Sec:     1195 || Lr: 0.000050
2024-01-31 04:58:54,949 Epoch 481: Total Training Recognition Loss 2124.53  Total Training Translation Loss 6846.76 
2024-01-31 04:58:54,949 EPOCH 482
2024-01-31 04:59:20,573 Epoch 482: Total Training Recognition Loss 2125.78  Total Training Translation Loss 6847.94 
2024-01-31 04:59:20,574 EPOCH 483
2024-01-31 04:59:22,538 [Epoch: 483 Step: 00032300] Batch Recognition Loss:  38.747604 => Gls Tokens per Sec:      489 || Batch Translation Loss: 115.030334 => Txt Tokens per Sec:     1383 || Lr: 0.000050
2024-01-31 04:59:46,127 Epoch 483: Total Training Recognition Loss 2123.98  Total Training Translation Loss 6848.95 
2024-01-31 04:59:46,127 EPOCH 484
2024-01-31 05:00:00,628 [Epoch: 484 Step: 00032400] Batch Recognition Loss:  30.496269 => Gls Tokens per Sec:      430 || Batch Translation Loss: 107.464844 => Txt Tokens per Sec:     1196 || Lr: 0.000050
2024-01-31 05:00:11,868 Epoch 484: Total Training Recognition Loss 2127.70  Total Training Translation Loss 6849.59 
2024-01-31 05:00:11,868 EPOCH 485
2024-01-31 05:00:37,459 Epoch 485: Total Training Recognition Loss 2126.67  Total Training Translation Loss 6847.04 
2024-01-31 05:00:37,460 EPOCH 486
2024-01-31 05:00:39,209 [Epoch: 486 Step: 00032500] Batch Recognition Loss:  10.389350 => Gls Tokens per Sec:      458 || Batch Translation Loss:  62.406708 => Txt Tokens per Sec:     1194 || Lr: 0.000050
2024-01-31 05:01:03,092 Epoch 486: Total Training Recognition Loss 2126.19  Total Training Translation Loss 6848.48 
2024-01-31 05:01:03,092 EPOCH 487
2024-01-31 05:01:15,403 [Epoch: 487 Step: 00032600] Batch Recognition Loss:  23.728024 => Gls Tokens per Sec:      494 || Batch Translation Loss:  99.262604 => Txt Tokens per Sec:     1325 || Lr: 0.000050
2024-01-31 05:01:28,613 Epoch 487: Total Training Recognition Loss 2126.71  Total Training Translation Loss 6849.60 
2024-01-31 05:01:28,613 EPOCH 488
2024-01-31 05:01:54,120 Epoch 488: Total Training Recognition Loss 2130.42  Total Training Translation Loss 6848.68 
2024-01-31 05:01:54,120 EPOCH 489
2024-01-31 05:01:55,346 [Epoch: 489 Step: 00032700] Batch Recognition Loss:  27.979931 => Gls Tokens per Sec:      522 || Batch Translation Loss:  85.461212 => Txt Tokens per Sec:     1427 || Lr: 0.000050
2024-01-31 05:02:19,922 Epoch 489: Total Training Recognition Loss 2129.56  Total Training Translation Loss 6846.81 
2024-01-31 05:02:19,922 EPOCH 490
2024-01-31 05:02:34,390 [Epoch: 490 Step: 00032800] Batch Recognition Loss:  49.981361 => Gls Tokens per Sec:      403 || Batch Translation Loss: 122.768288 => Txt Tokens per Sec:     1122 || Lr: 0.000050
2024-01-31 05:02:45,681 Epoch 490: Total Training Recognition Loss 2130.37  Total Training Translation Loss 6847.48 
2024-01-31 05:02:45,681 EPOCH 491
2024-01-31 05:03:11,389 Epoch 491: Total Training Recognition Loss 2127.77  Total Training Translation Loss 6847.53 
2024-01-31 05:03:11,389 EPOCH 492
2024-01-31 05:03:12,289 [Epoch: 492 Step: 00032900] Batch Recognition Loss:  38.230259 => Gls Tokens per Sec:      535 || Batch Translation Loss: 111.301865 => Txt Tokens per Sec:     1291 || Lr: 0.000050
2024-01-31 05:03:36,972 Epoch 492: Total Training Recognition Loss 2125.37  Total Training Translation Loss 6847.97 
2024-01-31 05:03:36,972 EPOCH 493
2024-01-31 05:03:51,194 [Epoch: 493 Step: 00033000] Batch Recognition Loss:  33.899490 => Gls Tokens per Sec:      399 || Batch Translation Loss: 115.061966 => Txt Tokens per Sec:     1109 || Lr: 0.000050
2024-01-31 05:04:02,643 Epoch 493: Total Training Recognition Loss 2126.20  Total Training Translation Loss 6848.50 
2024-01-31 05:04:02,643 EPOCH 494
2024-01-31 05:04:28,311 Epoch 494: Total Training Recognition Loss 2128.48  Total Training Translation Loss 6847.94 
2024-01-31 05:04:28,311 EPOCH 495
2024-01-31 05:04:28,753 [Epoch: 495 Step: 00033100] Batch Recognition Loss:  23.448055 => Gls Tokens per Sec:      727 || Batch Translation Loss:  79.519669 => Txt Tokens per Sec:     1620 || Lr: 0.000050
2024-01-31 05:04:54,021 Epoch 495: Total Training Recognition Loss 2123.31  Total Training Translation Loss 6847.21 
2024-01-31 05:04:54,021 EPOCH 496
2024-01-31 05:05:07,793 [Epoch: 496 Step: 00033200] Batch Recognition Loss:  54.119057 => Gls Tokens per Sec:      400 || Batch Translation Loss: 133.967026 => Txt Tokens per Sec:     1122 || Lr: 0.000050
2024-01-31 05:05:19,330 Epoch 496: Total Training Recognition Loss 2128.79  Total Training Translation Loss 6847.73 
2024-01-31 05:05:19,330 EPOCH 497
2024-01-31 05:05:44,826 Epoch 497: Total Training Recognition Loss 2130.32  Total Training Translation Loss 6848.05 
2024-01-31 05:05:44,826 EPOCH 498
2024-01-31 05:05:45,025 [Epoch: 498 Step: 00033300] Batch Recognition Loss:  22.776718 => Gls Tokens per Sec:      812 || Batch Translation Loss:  81.904068 => Txt Tokens per Sec:     1817 || Lr: 0.000050
2024-01-31 05:06:10,215 Epoch 498: Total Training Recognition Loss 2127.83  Total Training Translation Loss 6848.66 
2024-01-31 05:06:10,215 EPOCH 499
2024-01-31 05:06:22,804 [Epoch: 499 Step: 00033400] Batch Recognition Loss:  23.969963 => Gls Tokens per Sec:      432 || Batch Translation Loss:  96.767288 => Txt Tokens per Sec:     1192 || Lr: 0.000050
2024-01-31 05:06:35,500 Epoch 499: Total Training Recognition Loss 2126.82  Total Training Translation Loss 6846.17 
2024-01-31 05:06:35,500 EPOCH 500
2024-01-31 05:07:00,814 [Epoch: 500 Step: 00033500] Batch Recognition Loss:  38.127861 => Gls Tokens per Sec:      420 || Batch Translation Loss: 119.824409 => Txt Tokens per Sec:     1166 || Lr: 0.000050
2024-01-31 05:07:00,814 Epoch 500: Total Training Recognition Loss 2121.65  Total Training Translation Loss 6849.23 
2024-01-31 05:07:00,814 EPOCH 501
2024-01-31 05:07:26,265 Epoch 501: Total Training Recognition Loss 2126.53  Total Training Translation Loss 6849.25 
2024-01-31 05:07:26,265 EPOCH 502
2024-01-31 05:07:40,517 [Epoch: 502 Step: 00033600] Batch Recognition Loss:  26.743191 => Gls Tokens per Sec:      364 || Batch Translation Loss:  85.762238 => Txt Tokens per Sec:     1035 || Lr: 0.000050
2024-01-31 05:07:51,644 Epoch 502: Total Training Recognition Loss 2123.97  Total Training Translation Loss 6848.17 
2024-01-31 05:07:51,644 EPOCH 503
2024-01-31 05:08:16,829 [Epoch: 503 Step: 00033700] Batch Recognition Loss:  19.433826 => Gls Tokens per Sec:      416 || Batch Translation Loss:  97.967102 => Txt Tokens per Sec:     1154 || Lr: 0.000050
2024-01-31 05:08:17,167 Epoch 503: Total Training Recognition Loss 2125.10  Total Training Translation Loss 6846.85 
2024-01-31 05:08:17,167 EPOCH 504
2024-01-31 05:08:42,707 Epoch 504: Total Training Recognition Loss 2126.05  Total Training Translation Loss 6848.52 
2024-01-31 05:08:42,707 EPOCH 505
2024-01-31 05:08:54,983 [Epoch: 505 Step: 00033800] Batch Recognition Loss:  41.252609 => Gls Tokens per Sec:      417 || Batch Translation Loss: 136.573135 => Txt Tokens per Sec:     1168 || Lr: 0.000050
2024-01-31 05:09:08,063 Epoch 505: Total Training Recognition Loss 2130.64  Total Training Translation Loss 6849.17 
2024-01-31 05:09:08,063 EPOCH 506
2024-01-31 05:09:32,628 [Epoch: 506 Step: 00033900] Batch Recognition Loss:  38.808372 => Gls Tokens per Sec:      420 || Batch Translation Loss: 127.588608 => Txt Tokens per Sec:     1160 || Lr: 0.000050
2024-01-31 05:09:33,530 Epoch 506: Total Training Recognition Loss 2125.57  Total Training Translation Loss 6847.37 
2024-01-31 05:09:33,530 EPOCH 507
2024-01-31 05:09:58,981 Epoch 507: Total Training Recognition Loss 2125.75  Total Training Translation Loss 6848.38 
2024-01-31 05:09:58,981 EPOCH 508
2024-01-31 05:10:09,935 [Epoch: 508 Step: 00034000] Batch Recognition Loss:  27.914665 => Gls Tokens per Sec:      453 || Batch Translation Loss:  91.577240 => Txt Tokens per Sec:     1254 || Lr: 0.000050
2024-01-31 05:10:39,050 Validation result at epoch 508, step    34000: duration: 29.1140s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 664.10925	Translation Loss: 73512.68750	PPL: 1566.21619
	Eval Metric: BLEU
	WER 525.92	(DEL: 4.59,	INS: 436.86,	SUB: 84.46)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.45	ROUGE 0.00
2024-01-31 05:10:39,052 Logging Recognition and Translation Outputs
2024-01-31 05:10:39,052 ========================================================================================================================
2024-01-31 05:10:39,052 Logging Sequence: 92_199.00
2024-01-31 05:10:39,052 	Gloss Reference :	***** ***** *** ***** A ***** ***** * ***** * ***** * ***** B+C+D+E
2024-01-31 05:10:39,052 	Gloss Hypothesis:	<unk> <pad> B+A <unk> A <pad> <unk> C <unk> B <pad> C <unk> E      
2024-01-31 05:10:39,052 	Gloss Alignment :	I     I     I   I       I     I     I I     I I     I I     S      
2024-01-31 05:10:39,053 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:10:39,054 	Text Reference  :	***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** people on    social media said  that 
2024-01-31 05:10:39,054 	Text Hypothesis :	sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha  sabha sabha  sabha sabha sabha
2024-01-31 05:10:39,054 	Text Alignment  :	I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S      S     S      S     S     S    
2024-01-31 05:10:39,054 ========================================================================================================================
2024-01-31 05:10:39,055 Logging Sequence: 109_64.00
2024-01-31 05:10:39,055 	Gloss Reference :	***** ***** * ***** *** ***** * ***** ******* ***** *** ***** * ***** * ***** * ***** * ***** * ***** ******* ***** *** A     B+C+D+E  
2024-01-31 05:10:39,055 	Gloss Hypothesis:	<unk> <pad> E <unk> E+B <unk> E <unk> E+B+E+C <unk> B+E <unk> E <unk> E <unk> B <unk> C <unk> E <unk> E+B+E+C <unk> B+C <unk> E+C+E+B+E
2024-01-31 05:10:39,055 	Gloss Alignment :	I     I     I I     I   I     I I     I       I     I   I     I I     I I     I I     I I     I I     I       I     I   S     S        
2024-01-31 05:10:39,055 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:10:39,058 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** the 2   players as  well as  the entire kkr team have been quarantined
2024-01-31 05:10:39,058 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s> <s>  <s> <s> <s>    <s> <s>  <s>  <s>  <s>        
2024-01-31 05:10:39,058 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S   S       S   S    S   S   S      S   S    S    S    S          
2024-01-31 05:10:39,059 ========================================================================================================================
2024-01-31 05:10:39,059 Logging Sequence: 84_108.00
2024-01-31 05:10:39,059 	Gloss Reference :	***** * ***** A ***** * ***** * ***** * ***** * ***** * ***** * B+C+D+E
2024-01-31 05:10:39,059 	Gloss Hypothesis:	<unk> C <unk> A <unk> C <unk> C <unk> C <unk> C <unk> C <unk> C <unk>  
2024-01-31 05:10:39,059 	Gloss Alignment :	I     I I       I     I I     I I     I I     I I     I I     I S      
2024-01-31 05:10:39,059 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:10:39,063 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* so      in      order   to      show    their   protest they    covered their   mouth   in      the     photos  which   then    went    viral  
2024-01-31 05:10:39,063 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing
2024-01-31 05:10:39,064 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       S       S       S       S       S       S       S       S       S       S       S       S       S       S       S       S       S       S      
2024-01-31 05:10:39,064 ========================================================================================================================
2024-01-31 05:10:39,064 Logging Sequence: 115_24.00
2024-01-31 05:10:39,064 	Gloss Reference :	***** *** ***** ***** A     B+C+D+E
2024-01-31 05:10:39,064 	Gloss Hypothesis:	<unk> E+B <unk> E+B+E <unk> E      
2024-01-31 05:10:39,064 	Gloss Alignment :	I     I   I     I     S     S      
2024-01-31 05:10:39,064 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:10:39,067 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** bumrah also did not participate in  the 5   match t20 series
2024-01-31 05:10:39,067 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>    <s>  <s> <s> <s>         <s> <s> <s> <s>   <s> <s>   
2024-01-31 05:10:39,067 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S      S    S   S   S           S   S   S   S     S   S     
2024-01-31 05:10:39,067 ========================================================================================================================
2024-01-31 05:10:39,067 Logging Sequence: 96_129.00
2024-01-31 05:10:39,068 	Gloss Reference :	A B+C+D+E  
2024-01-31 05:10:39,068 	Gloss Hypothesis:	A E+A+E+A+E
2024-01-31 05:10:39,068 	Gloss Alignment :	  S        
2024-01-31 05:10:39,068 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:10:39,069 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* viewers were    very    stressed
2024-01-31 05:10:39,069 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing 
2024-01-31 05:10:39,069 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       
2024-01-31 05:10:39,069 ========================================================================================================================
2024-01-31 05:10:53,617 Epoch 508: Total Training Recognition Loss 2125.01  Total Training Translation Loss 6846.86 
2024-01-31 05:10:53,617 EPOCH 509
2024-01-31 05:11:18,558 [Epoch: 509 Step: 00034100] Batch Recognition Loss:  37.274132 => Gls Tokens per Sec:      407 || Batch Translation Loss:  98.216667 => Txt Tokens per Sec:     1132 || Lr: 0.000050
2024-01-31 05:11:19,281 Epoch 509: Total Training Recognition Loss 2130.23  Total Training Translation Loss 6846.53 
2024-01-31 05:11:19,281 EPOCH 510
2024-01-31 05:11:44,934 Epoch 510: Total Training Recognition Loss 2129.61  Total Training Translation Loss 6849.33 
2024-01-31 05:11:44,934 EPOCH 511
2024-01-31 05:11:56,301 [Epoch: 511 Step: 00034200] Batch Recognition Loss:  27.453905 => Gls Tokens per Sec:      414 || Batch Translation Loss:  93.517624 => Txt Tokens per Sec:     1124 || Lr: 0.000050
2024-01-31 05:12:10,542 Epoch 511: Total Training Recognition Loss 2128.22  Total Training Translation Loss 6848.58 
2024-01-31 05:12:10,543 EPOCH 512
2024-01-31 05:12:35,176 [Epoch: 512 Step: 00034300] Batch Recognition Loss:  29.787697 => Gls Tokens per Sec:      406 || Batch Translation Loss:  98.858116 => Txt Tokens per Sec:     1136 || Lr: 0.000050
2024-01-31 05:12:36,125 Epoch 512: Total Training Recognition Loss 2131.65  Total Training Translation Loss 6848.54 
2024-01-31 05:12:36,126 EPOCH 513
2024-01-31 05:13:01,583 Epoch 513: Total Training Recognition Loss 2127.39  Total Training Translation Loss 6847.44 
2024-01-31 05:13:01,584 EPOCH 514
2024-01-31 05:13:14,325 [Epoch: 514 Step: 00034400] Batch Recognition Loss:  60.265282 => Gls Tokens per Sec:      357 || Batch Translation Loss: 133.223526 => Txt Tokens per Sec:     1026 || Lr: 0.000050
2024-01-31 05:13:27,102 Epoch 514: Total Training Recognition Loss 2124.73  Total Training Translation Loss 6849.13 
2024-01-31 05:13:27,103 EPOCH 515
2024-01-31 05:13:51,100 [Epoch: 515 Step: 00034500] Batch Recognition Loss:  33.189312 => Gls Tokens per Sec:      410 || Batch Translation Loss:  94.058388 => Txt Tokens per Sec:     1148 || Lr: 0.000050
2024-01-31 05:13:52,691 Epoch 515: Total Training Recognition Loss 2127.05  Total Training Translation Loss 6847.60 
2024-01-31 05:13:52,691 EPOCH 516
2024-01-31 05:14:18,391 Epoch 516: Total Training Recognition Loss 2129.49  Total Training Translation Loss 6848.01 
2024-01-31 05:14:18,391 EPOCH 517
2024-01-31 05:14:29,571 [Epoch: 517 Step: 00034600] Batch Recognition Loss:  45.323086 => Gls Tokens per Sec:      401 || Batch Translation Loss: 125.211411 => Txt Tokens per Sec:     1116 || Lr: 0.000050
2024-01-31 05:14:44,050 Epoch 517: Total Training Recognition Loss 2123.57  Total Training Translation Loss 6848.71 
2024-01-31 05:14:44,050 EPOCH 518
2024-01-31 05:15:07,654 [Epoch: 518 Step: 00034700] Batch Recognition Loss:  31.232040 => Gls Tokens per Sec:      410 || Batch Translation Loss: 107.656700 => Txt Tokens per Sec:     1137 || Lr: 0.000050
2024-01-31 05:15:09,637 Epoch 518: Total Training Recognition Loss 2126.86  Total Training Translation Loss 6849.63 
2024-01-31 05:15:09,637 EPOCH 519
2024-01-31 05:15:35,232 Epoch 519: Total Training Recognition Loss 2124.07  Total Training Translation Loss 6847.64 
2024-01-31 05:15:35,232 EPOCH 520
2024-01-31 05:15:44,558 [Epoch: 520 Step: 00034800] Batch Recognition Loss:  22.887314 => Gls Tokens per Sec:      463 || Batch Translation Loss:  88.812592 => Txt Tokens per Sec:     1277 || Lr: 0.000050
2024-01-31 05:16:00,809 Epoch 520: Total Training Recognition Loss 2127.05  Total Training Translation Loss 6849.09 
2024-01-31 05:16:00,809 EPOCH 521
2024-01-31 05:16:23,404 [Epoch: 521 Step: 00034900] Batch Recognition Loss:  18.081120 => Gls Tokens per Sec:      421 || Batch Translation Loss:  87.725418 => Txt Tokens per Sec:     1164 || Lr: 0.000050
2024-01-31 05:16:26,405 Epoch 521: Total Training Recognition Loss 2128.54  Total Training Translation Loss 6847.65 
2024-01-31 05:16:26,405 EPOCH 522
2024-01-31 05:16:52,037 Epoch 522: Total Training Recognition Loss 2126.95  Total Training Translation Loss 6847.82 
2024-01-31 05:16:52,037 EPOCH 523
2024-01-31 05:17:02,689 [Epoch: 523 Step: 00035000] Batch Recognition Loss:  32.739639 => Gls Tokens per Sec:      391 || Batch Translation Loss: 123.759308 => Txt Tokens per Sec:     1110 || Lr: 0.000050
2024-01-31 05:17:20,359 Epoch 523: Total Training Recognition Loss 2136.11  Total Training Translation Loss 6849.80 
2024-01-31 05:17:20,361 EPOCH 524
2024-01-31 05:17:43,309 [Epoch: 524 Step: 00035100] Batch Recognition Loss:  36.569805 => Gls Tokens per Sec:      407 || Batch Translation Loss: 127.531929 => Txt Tokens per Sec:     1120 || Lr: 0.000050
2024-01-31 05:17:47,588 Epoch 524: Total Training Recognition Loss 2123.11  Total Training Translation Loss 6846.53 
2024-01-31 05:17:47,589 EPOCH 525
2024-01-31 05:18:13,088 Epoch 525: Total Training Recognition Loss 2128.40  Total Training Translation Loss 6848.58 
2024-01-31 05:18:13,089 EPOCH 526
2024-01-31 05:18:22,297 [Epoch: 526 Step: 00035200] Batch Recognition Loss:  10.467234 => Gls Tokens per Sec:      434 || Batch Translation Loss:  64.452141 => Txt Tokens per Sec:     1191 || Lr: 0.000050
2024-01-31 05:18:38,700 Epoch 526: Total Training Recognition Loss 2129.10  Total Training Translation Loss 6851.48 
2024-01-31 05:18:38,700 EPOCH 527
2024-01-31 05:19:00,022 [Epoch: 527 Step: 00035300] Batch Recognition Loss:  41.119133 => Gls Tokens per Sec:      431 || Batch Translation Loss: 116.445663 => Txt Tokens per Sec:     1174 || Lr: 0.000050
2024-01-31 05:19:04,316 Epoch 527: Total Training Recognition Loss 2127.95  Total Training Translation Loss 6851.06 
2024-01-31 05:19:04,316 EPOCH 528
2024-01-31 05:19:29,888 Epoch 528: Total Training Recognition Loss 2129.03  Total Training Translation Loss 6848.19 
2024-01-31 05:19:29,888 EPOCH 529
2024-01-31 05:19:38,507 [Epoch: 529 Step: 00035400] Batch Recognition Loss:  32.178066 => Gls Tokens per Sec:      446 || Batch Translation Loss:  95.458382 => Txt Tokens per Sec:     1223 || Lr: 0.000050
2024-01-31 05:19:55,268 Epoch 529: Total Training Recognition Loss 2124.88  Total Training Translation Loss 6846.67 
2024-01-31 05:19:55,268 EPOCH 530
2024-01-31 05:20:16,395 [Epoch: 530 Step: 00035500] Batch Recognition Loss:  37.613991 => Gls Tokens per Sec:      427 || Batch Translation Loss: 112.148109 => Txt Tokens per Sec:     1183 || Lr: 0.000050
2024-01-31 05:20:20,914 Epoch 530: Total Training Recognition Loss 2125.65  Total Training Translation Loss 6848.64 
2024-01-31 05:20:20,914 EPOCH 531
2024-01-31 05:20:46,218 Epoch 531: Total Training Recognition Loss 2122.45  Total Training Translation Loss 6847.26 
2024-01-31 05:20:46,218 EPOCH 532
2024-01-31 05:20:52,795 [Epoch: 532 Step: 00035600] Batch Recognition Loss:  32.629723 => Gls Tokens per Sec:      560 || Batch Translation Loss: 123.479927 => Txt Tokens per Sec:     1471 || Lr: 0.000050
2024-01-31 05:21:11,680 Epoch 532: Total Training Recognition Loss 2127.39  Total Training Translation Loss 6847.89 
2024-01-31 05:21:11,680 EPOCH 533
2024-01-31 05:21:33,024 [Epoch: 533 Step: 00035700] Batch Recognition Loss:  10.409079 => Gls Tokens per Sec:      416 || Batch Translation Loss:  62.168751 => Txt Tokens per Sec:     1158 || Lr: 0.000050
2024-01-31 05:21:37,230 Epoch 533: Total Training Recognition Loss 2125.70  Total Training Translation Loss 6849.40 
2024-01-31 05:21:37,231 EPOCH 534
2024-01-31 05:22:02,885 Epoch 534: Total Training Recognition Loss 2127.68  Total Training Translation Loss 6848.83 
2024-01-31 05:22:02,886 EPOCH 535
2024-01-31 05:22:10,032 [Epoch: 535 Step: 00035800] Batch Recognition Loss:  37.630459 => Gls Tokens per Sec:      493 || Batch Translation Loss:  97.534668 => Txt Tokens per Sec:     1312 || Lr: 0.000050
2024-01-31 05:22:28,453 Epoch 535: Total Training Recognition Loss 2130.53  Total Training Translation Loss 6848.59 
2024-01-31 05:22:28,454 EPOCH 536
2024-01-31 05:22:50,023 [Epoch: 536 Step: 00035900] Batch Recognition Loss:  37.989708 => Gls Tokens per Sec:      404 || Batch Translation Loss: 110.305443 => Txt Tokens per Sec:     1132 || Lr: 0.000050
2024-01-31 05:22:54,036 Epoch 536: Total Training Recognition Loss 2128.37  Total Training Translation Loss 6848.67 
2024-01-31 05:22:54,036 EPOCH 537
2024-01-31 05:23:19,566 Epoch 537: Total Training Recognition Loss 2129.00  Total Training Translation Loss 6849.92 
2024-01-31 05:23:19,566 EPOCH 538
2024-01-31 05:23:27,193 [Epoch: 538 Step: 00036000] Batch Recognition Loss:  72.321793 => Gls Tokens per Sec:      429 || Batch Translation Loss: 126.549385 => Txt Tokens per Sec:     1191 || Lr: 0.000050
2024-01-31 05:23:56,757 Validation result at epoch 538, step    36000: duration: 29.5627s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 671.92505	Translation Loss: 73471.75000	PPL: 1559.81348
	Eval Metric: BLEU
	WER 535.38	(DEL: 4.59,	INS: 447.18,	SUB: 83.62)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.46	ROUGE 0.00
2024-01-31 05:23:56,758 Logging Recognition and Translation Outputs
2024-01-31 05:23:56,758 ========================================================================================================================
2024-01-31 05:23:56,759 Logging Sequence: 78_198.00
2024-01-31 05:23:56,759 	Gloss Reference :	***** * ***** * ***** * ***** ***** ***** * ***** * ***** * ***** ***** A     B+C+D+E
2024-01-31 05:23:56,759 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E+B+E <unk> E <unk> E <unk> E <unk> E+C+E <unk> E      
2024-01-31 05:23:56,759 	Gloss Alignment :	I     I I     I I     I I     I     I     I I     I I     I I     I     S     S      
2024-01-31 05:23:56,759 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:23:56,761 	Text Reference  :	*** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* they          have          been          flooded       with          congratulations comments     
2024-01-31 05:23:56,761 	Text Hypothesis :	<s> <s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand   misunderstand
2024-01-31 05:23:56,762 	Text Alignment  :	I   I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S               S            
2024-01-31 05:23:56,762 ========================================================================================================================
2024-01-31 05:23:56,762 Logging Sequence: 145_216.00
2024-01-31 05:23:56,762 	Gloss Reference :	* *** ***** A B+C+D+E
2024-01-31 05:23:56,762 	Gloss Hypothesis:	E A+E <unk> E <unk>  
2024-01-31 05:23:56,762 	Gloss Alignment :	I I   I     S S      
2024-01-31 05:23:56,762 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:23:56,766 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* asking  him     to      include sameeha in      the     world   championship as      she     was     a       talented athlete
2024-01-31 05:23:56,766 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing      nothing nothing nothing nothing nothing  nothing
2024-01-31 05:23:56,766 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       S       S       S       S       S       S       S       S       S            S       S       S       S       S        S      
2024-01-31 05:23:56,766 ========================================================================================================================
2024-01-31 05:23:56,766 Logging Sequence: 70_137.00
2024-01-31 05:23:56,767 	Gloss Reference :	***** * ***** * ***** * ***** * ***** *** ***** * ***** * ***** * ***** * ***** * ***** *** ***** * ***** *** A     B+C+D+E
2024-01-31 05:23:56,767 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E <unk> E+C <unk> E <unk> E <unk> E <unk> E <unk> E <unk> E+C <unk> C <unk> C+E <unk> E+C    
2024-01-31 05:23:56,767 	Gloss Alignment :	I     I I     I I     I I     I I     I   I     I I     I I     I I     I I     I I     I   I     I I     I   S     S      
2024-01-31 05:23:56,767 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:23:56,770 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** the small gesture appeared to  encourage people to  drink water instead of  aerated drinks
2024-01-31 05:23:56,770 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s>     <s>      <s> <s>       <s>    <s> <s>   <s>   <s>     <s> <s>     <s>   
2024-01-31 05:23:56,770 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S     S       S        S   S         S      S   S     S     S       S   S       S     
2024-01-31 05:23:56,770 ========================================================================================================================
2024-01-31 05:23:56,771 Logging Sequence: 119_20.00
2024-01-31 05:23:56,771 	Gloss Reference :	* ***** ***** ***** * ***** * ***** * ***** * ***** ***** ***** *** A     B+C+D+E
2024-01-31 05:23:56,771 	Gloss Hypothesis:	B <pad> B+E+B <pad> B <pad> B <pad> B <pad> B <pad> B+E+B <pad> E+B <pad> B+E+B  
2024-01-31 05:23:56,771 	Gloss Alignment :	I I     I     I     I I     I I     I I     I I     I     I     I   S     S      
2024-01-31 05:23:56,771 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:23:56,775 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* messi         intended      to            gift          something     to            all           the           players       and           the           staff         to            special       to            celebrate     the           moment       
2024-01-31 05:23:56,775 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions contributions
2024-01-31 05:23:56,775 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 05:23:56,775 ========================================================================================================================
2024-01-31 05:23:56,776 Logging Sequence: 106_15.00
2024-01-31 05:23:56,776 	Gloss Reference :	***** A ***** *** ***** *** ***** * B+C+D+E
2024-01-31 05:23:56,776 	Gloss Hypothesis:	<unk> A <unk> C+E <unk> E+C <unk> C <unk>  
2024-01-31 05:23:56,776 	Gloss Alignment :	I       I     I   I     I   I     I S      
2024-01-31 05:23:56,776 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:23:56,779 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** but what about women's cricket earlier we  never spoke about it 
2024-01-31 05:23:56,779 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s>   <s>     <s>     <s>     <s> <s>   <s>   <s>   <s>
2024-01-31 05:23:56,779 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S    S     S       S       S       S   S     S     S     S  
2024-01-31 05:23:56,779 ========================================================================================================================
2024-01-31 05:24:14,678 Epoch 538: Total Training Recognition Loss 2118.11  Total Training Translation Loss 6848.51 
2024-01-31 05:24:14,678 EPOCH 539
2024-01-31 05:24:34,992 [Epoch: 539 Step: 00036100] Batch Recognition Loss:  54.344063 => Gls Tokens per Sec:      421 || Batch Translation Loss: 130.975250 => Txt Tokens per Sec:     1166 || Lr: 0.000050
2024-01-31 05:24:40,390 Epoch 539: Total Training Recognition Loss 2127.88  Total Training Translation Loss 6848.49 
2024-01-31 05:24:40,390 EPOCH 540
2024-01-31 05:25:06,004 Epoch 540: Total Training Recognition Loss 2127.34  Total Training Translation Loss 6849.52 
2024-01-31 05:25:06,004 EPOCH 541
2024-01-31 05:25:13,597 [Epoch: 541 Step: 00036200] Batch Recognition Loss:  29.700113 => Gls Tokens per Sec:      410 || Batch Translation Loss: 112.588272 => Txt Tokens per Sec:     1108 || Lr: 0.000050
2024-01-31 05:25:31,612 Epoch 541: Total Training Recognition Loss 2130.33  Total Training Translation Loss 6847.85 
2024-01-31 05:25:31,612 EPOCH 542
2024-01-31 05:25:51,642 [Epoch: 542 Step: 00036300] Batch Recognition Loss:  27.378235 => Gls Tokens per Sec:      423 || Batch Translation Loss: 104.494659 => Txt Tokens per Sec:     1176 || Lr: 0.000050
2024-01-31 05:25:57,168 Epoch 542: Total Training Recognition Loss 2123.20  Total Training Translation Loss 6847.08 
2024-01-31 05:25:57,168 EPOCH 543
2024-01-31 05:26:22,587 Epoch 543: Total Training Recognition Loss 2131.37  Total Training Translation Loss 6847.59 
2024-01-31 05:26:22,587 EPOCH 544
2024-01-31 05:26:29,079 [Epoch: 544 Step: 00036400] Batch Recognition Loss:  38.754642 => Gls Tokens per Sec:      468 || Batch Translation Loss: 117.018410 => Txt Tokens per Sec:     1291 || Lr: 0.000050
2024-01-31 05:26:48,009 Epoch 544: Total Training Recognition Loss 2123.62  Total Training Translation Loss 6848.09 
2024-01-31 05:26:48,009 EPOCH 545
2024-01-31 05:27:07,336 [Epoch: 545 Step: 00036500] Batch Recognition Loss:  37.126972 => Gls Tokens per Sec:      431 || Batch Translation Loss: 110.351700 => Txt Tokens per Sec:     1188 || Lr: 0.000050
2024-01-31 05:27:13,660 Epoch 545: Total Training Recognition Loss 2128.98  Total Training Translation Loss 6848.11 
2024-01-31 05:27:13,661 EPOCH 546
2024-01-31 05:27:39,266 Epoch 546: Total Training Recognition Loss 2121.48  Total Training Translation Loss 6849.21 
2024-01-31 05:27:39,266 EPOCH 547
2024-01-31 05:27:45,838 [Epoch: 547 Step: 00036600] Batch Recognition Loss:  30.326029 => Gls Tokens per Sec:      438 || Batch Translation Loss: 107.478165 => Txt Tokens per Sec:     1201 || Lr: 0.000050
2024-01-31 05:28:04,927 Epoch 547: Total Training Recognition Loss 2127.18  Total Training Translation Loss 6848.84 
2024-01-31 05:28:04,927 EPOCH 548
2024-01-31 05:28:23,378 [Epoch: 548 Step: 00036700] Batch Recognition Loss:  36.825108 => Gls Tokens per Sec:      442 || Batch Translation Loss: 108.519333 => Txt Tokens per Sec:     1214 || Lr: 0.000050
2024-01-31 05:28:30,487 Epoch 548: Total Training Recognition Loss 2126.41  Total Training Translation Loss 6848.48 
2024-01-31 05:28:30,488 EPOCH 549
2024-01-31 05:28:56,033 Epoch 549: Total Training Recognition Loss 2127.91  Total Training Translation Loss 6847.70 
2024-01-31 05:28:56,034 EPOCH 550
2024-01-31 05:29:02,589 [Epoch: 550 Step: 00036800] Batch Recognition Loss:  22.776684 => Gls Tokens per Sec:      415 || Batch Translation Loss: 100.265907 => Txt Tokens per Sec:     1209 || Lr: 0.000050
2024-01-31 05:29:21,595 Epoch 550: Total Training Recognition Loss 2127.97  Total Training Translation Loss 6848.53 
2024-01-31 05:29:21,595 EPOCH 551
2024-01-31 05:29:40,904 [Epoch: 551 Step: 00036900] Batch Recognition Loss:   5.084069 => Gls Tokens per Sec:      414 || Batch Translation Loss:  44.730499 => Txt Tokens per Sec:     1145 || Lr: 0.000050
2024-01-31 05:29:47,341 Epoch 551: Total Training Recognition Loss 2128.91  Total Training Translation Loss 6849.34 
2024-01-31 05:29:47,342 EPOCH 552
2024-01-31 05:30:12,926 Epoch 552: Total Training Recognition Loss 2126.92  Total Training Translation Loss 6849.85 
2024-01-31 05:30:12,926 EPOCH 553
2024-01-31 05:30:18,715 [Epoch: 553 Step: 00037000] Batch Recognition Loss:  22.956760 => Gls Tokens per Sec:      442 || Batch Translation Loss:  81.874893 => Txt Tokens per Sec:     1221 || Lr: 0.000050
2024-01-31 05:30:38,453 Epoch 553: Total Training Recognition Loss 2127.03  Total Training Translation Loss 6847.89 
2024-01-31 05:30:38,453 EPOCH 554
2024-01-31 05:30:58,406 [Epoch: 554 Step: 00037100] Batch Recognition Loss:  38.182419 => Gls Tokens per Sec:      388 || Batch Translation Loss: 114.311760 => Txt Tokens per Sec:     1093 || Lr: 0.000050
2024-01-31 05:31:04,018 Epoch 554: Total Training Recognition Loss 2125.59  Total Training Translation Loss 6847.39 
2024-01-31 05:31:04,019 EPOCH 555
2024-01-31 05:31:29,613 Epoch 555: Total Training Recognition Loss 2126.42  Total Training Translation Loss 6847.32 
2024-01-31 05:31:29,613 EPOCH 556
2024-01-31 05:31:36,653 [Epoch: 556 Step: 00037200] Batch Recognition Loss:  27.895138 => Gls Tokens per Sec:      328 || Batch Translation Loss:  94.026230 => Txt Tokens per Sec:      888 || Lr: 0.000050
2024-01-31 05:31:55,140 Epoch 556: Total Training Recognition Loss 2124.17  Total Training Translation Loss 6847.98 
2024-01-31 05:31:55,140 EPOCH 557
2024-01-31 05:32:14,837 [Epoch: 557 Step: 00037300] Batch Recognition Loss:  73.318924 => Gls Tokens per Sec:      385 || Batch Translation Loss: 126.642342 => Txt Tokens per Sec:     1092 || Lr: 0.000050
2024-01-31 05:32:20,753 Epoch 557: Total Training Recognition Loss 2133.10  Total Training Translation Loss 6849.54 
2024-01-31 05:32:20,753 EPOCH 558
2024-01-31 05:32:46,143 Epoch 558: Total Training Recognition Loss 2126.24  Total Training Translation Loss 6846.68 
2024-01-31 05:32:46,143 EPOCH 559
2024-01-31 05:32:51,562 [Epoch: 559 Step: 00037400] Batch Recognition Loss:  18.927578 => Gls Tokens per Sec:      413 || Batch Translation Loss:  98.464523 => Txt Tokens per Sec:     1193 || Lr: 0.000050
2024-01-31 05:33:11,718 Epoch 559: Total Training Recognition Loss 2126.32  Total Training Translation Loss 6847.92 
2024-01-31 05:33:11,718 EPOCH 560
2024-01-31 05:33:30,202 [Epoch: 560 Step: 00037500] Batch Recognition Loss:  32.624729 => Gls Tokens per Sec:      402 || Batch Translation Loss: 107.420235 => Txt Tokens per Sec:     1111 || Lr: 0.000050
2024-01-31 05:33:37,179 Epoch 560: Total Training Recognition Loss 2129.64  Total Training Translation Loss 6848.53 
2024-01-31 05:33:37,179 EPOCH 561
2024-01-31 05:34:02,517 Epoch 561: Total Training Recognition Loss 2125.75  Total Training Translation Loss 6850.84 
2024-01-31 05:34:02,517 EPOCH 562
2024-01-31 05:34:07,650 [Epoch: 562 Step: 00037600] Batch Recognition Loss:  39.078812 => Gls Tokens per Sec:      405 || Batch Translation Loss: 129.028610 => Txt Tokens per Sec:     1157 || Lr: 0.000050
2024-01-31 05:34:27,933 Epoch 562: Total Training Recognition Loss 2120.29  Total Training Translation Loss 6847.50 
2024-01-31 05:34:27,933 EPOCH 563
2024-01-31 05:34:46,210 [Epoch: 563 Step: 00037700] Batch Recognition Loss:  71.334984 => Gls Tokens per Sec:      398 || Batch Translation Loss: 126.794228 => Txt Tokens per Sec:     1102 || Lr: 0.000050
2024-01-31 05:34:53,587 Epoch 563: Total Training Recognition Loss 2127.83  Total Training Translation Loss 6848.86 
2024-01-31 05:34:53,587 EPOCH 564
2024-01-31 05:35:19,195 Epoch 564: Total Training Recognition Loss 2129.29  Total Training Translation Loss 6847.20 
2024-01-31 05:35:19,195 EPOCH 565
2024-01-31 05:35:26,118 [Epoch: 565 Step: 00037800] Batch Recognition Loss:  60.309704 => Gls Tokens per Sec:      264 || Batch Translation Loss: 131.035492 => Txt Tokens per Sec:      779 || Lr: 0.000050
2024-01-31 05:35:44,835 Epoch 565: Total Training Recognition Loss 2128.70  Total Training Translation Loss 6849.66 
2024-01-31 05:35:44,836 EPOCH 566
2024-01-31 05:36:00,868 [Epoch: 566 Step: 00037900] Batch Recognition Loss:  46.979507 => Gls Tokens per Sec:      444 || Batch Translation Loss: 127.845901 => Txt Tokens per Sec:     1235 || Lr: 0.000050
2024-01-31 05:36:10,244 Epoch 566: Total Training Recognition Loss 2128.77  Total Training Translation Loss 6848.58 
2024-01-31 05:36:10,245 EPOCH 567
2024-01-31 05:36:35,735 Epoch 567: Total Training Recognition Loss 2126.66  Total Training Translation Loss 6846.73 
2024-01-31 05:36:35,736 EPOCH 568
2024-01-31 05:36:39,172 [Epoch: 568 Step: 00038000] Batch Recognition Loss:  13.444151 => Gls Tokens per Sec:      512 || Batch Translation Loss:  81.073898 => Txt Tokens per Sec:     1407 || Lr: 0.000050
2024-01-31 05:37:08,420 Validation result at epoch 568, step    38000: duration: 29.2465s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 673.10284	Translation Loss: 73471.43750	PPL: 1559.76501
	Eval Metric: BLEU
	WER 539.76	(DEL: 4.24,	INS: 451.69,	SUB: 83.83)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.44	ROUGE 0.00
2024-01-31 05:37:08,421 Logging Recognition and Translation Outputs
2024-01-31 05:37:08,421 ========================================================================================================================
2024-01-31 05:37:08,421 Logging Sequence: 72_194.00
2024-01-31 05:37:08,421 	Gloss Reference :	* ***** * ***** * ***** A ***** B+C+D+E
2024-01-31 05:37:08,422 	Gloss Hypothesis:	A <unk> A <unk> A <unk> A <unk> A      
2024-01-31 05:37:08,422 	Gloss Alignment :	I I     I I     I I       I     S      
2024-01-31 05:37:08,422 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:37:08,425 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** shah told her to  do  what she wants and filed a   police complaint against her
2024-01-31 05:37:08,425 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s>  <s> <s> <s> <s>  <s> <s>   <s> <s>   <s> <s>    <s>       <s>     <s>
2024-01-31 05:37:08,425 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S    S    S   S   S   S    S   S     S   S     S   S      S         S       S  
2024-01-31 05:37:08,425 ========================================================================================================================
2024-01-31 05:37:08,426 Logging Sequence: 108_59.00
2024-01-31 05:37:08,426 	Gloss Reference :	A B+C+D+E
2024-01-31 05:37:08,426 	Gloss Hypothesis:	* E      
2024-01-31 05:37:08,426 	Gloss Alignment :	D S      
2024-01-31 05:37:08,426 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:37:08,430 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ****** ****** ****** ****** ****** ****** ****** ****** ****** ishan  kishan remained the    biggest buy    of     ipl    as     mumbai indians paid   a      whopping rs     1525   crore  to     keep   him   
2024-01-31 05:37:08,430 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen chosen   chosen chosen  chosen chosen chosen chosen chosen chosen  chosen chosen chosen   chosen chosen chosen chosen chosen chosen
2024-01-31 05:37:08,431 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I      I      I      I      I      I      I      I      I      S      S      S        S      S       S      S      S      S      S      S       S      S      S        S      S      S      S      S      S     
2024-01-31 05:37:08,431 ========================================================================================================================
2024-01-31 05:37:08,431 Logging Sequence: 109_10.00
2024-01-31 05:37:08,431 	Gloss Reference :	***** * ***** * ***** * ***** A B+C+D+E
2024-01-31 05:37:08,431 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E <unk>  
2024-01-31 05:37:08,431 	Gloss Alignment :	I     I I     I I     I I     S S      
2024-01-31 05:37:08,431 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:37:08,434 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** was  scheduled to   be   played at   the  narendra modi stadium in   ahmedabad
2024-01-31 05:37:08,434 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine fine      fine fine fine   fine fine fine     fine fine    fine fine     
2024-01-31 05:37:08,434 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    S    S         S    S    S      S    S    S        S    S       S    S        
2024-01-31 05:37:08,435 ========================================================================================================================
2024-01-31 05:37:08,435 Logging Sequence: 103_202.00
2024-01-31 05:37:08,435 	Gloss Reference :	***** * ***** * ***** *** ***** * ***** ***** ***** ***** ***** ******* ***** * ***** * ***** * ***** ***** ***** ********* ***** ***** ***** A   B+C+D+E
2024-01-31 05:37:08,435 	Gloss Hypothesis:	<unk> D <unk> D <unk> D+E <unk> D <unk> D+E+D <unk> D+E+D <unk> E+D+E+D <unk> E <unk> E <unk> E <unk> E+D+E <unk> D+C+D+E+D <unk> E+C+E <unk> D+E <unk>  
2024-01-31 05:37:08,435 	Gloss Alignment :	I     I I     I I     I   I     I I     I     I     I     I     I       I     I I     I I     I I     I     I     I         I     I     I     S   S      
2024-01-31 05:37:08,436 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:37:08,439 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ** ** ** ** ** ** ** ** ** ** ** ** india in total has won 61 medals including 22 gold medals 16 silver medals 23 bronze medals
2024-01-31 05:37:08,439 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> kl kl kl kl kl kl kl kl kl kl kl kl kl    kl kl    kl  kl  kl kl     kl        kl kl   kl     kl kl     kl     kl kl     kl    
2024-01-31 05:37:08,439 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I  I  I  I  I  I  I  I  I  I  I  I  S     S  S     S   S   S  S      S         S  S    S      S  S      S      S  S      S     
2024-01-31 05:37:08,440 ========================================================================================================================
2024-01-31 05:37:08,440 Logging Sequence: 149_77.00
2024-01-31 05:37:08,440 	Gloss Reference :	***** ******* A     B+C+D+E
2024-01-31 05:37:08,440 	Gloss Hypothesis:	<unk> C+D+E+C <unk> C      
2024-01-31 05:37:08,440 	Gloss Alignment :	I     I       S     S      
2024-01-31 05:37:08,440 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:37:08,444 	Text Reference  :	***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** and   arrested danushka for   alleged sexual assault of    a     29    year  old   woman whose name  has   not   been  disclosed
2024-01-31 05:37:08,444 	Text Hypothesis :	sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    sabha    sabha sabha   sabha  sabha   sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    
2024-01-31 05:37:08,444 	Text Alignment  :	I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S        S        S     S       S      S       S     S     S     S     S     S     S     S     S     S     S     S        
2024-01-31 05:37:08,445 ========================================================================================================================
2024-01-31 05:37:30,669 Epoch 568: Total Training Recognition Loss 2129.06  Total Training Translation Loss 6848.72 
2024-01-31 05:37:30,670 EPOCH 569
2024-01-31 05:37:45,593 [Epoch: 569 Step: 00038100] Batch Recognition Loss:  39.345970 => Gls Tokens per Sec:      472 || Batch Translation Loss: 109.131142 => Txt Tokens per Sec:     1302 || Lr: 0.000050
2024-01-31 05:37:56,098 Epoch 569: Total Training Recognition Loss 2123.05  Total Training Translation Loss 6847.84 
2024-01-31 05:37:56,099 EPOCH 570
2024-01-31 05:38:21,499 Epoch 570: Total Training Recognition Loss 2125.57  Total Training Translation Loss 6848.17 
2024-01-31 05:38:21,499 EPOCH 571
2024-01-31 05:38:25,741 [Epoch: 571 Step: 00038200] Batch Recognition Loss:  16.964609 => Gls Tokens per Sec:      377 || Batch Translation Loss:  68.044830 => Txt Tokens per Sec:     1016 || Lr: 0.000050
2024-01-31 05:38:47,084 Epoch 571: Total Training Recognition Loss 2125.81  Total Training Translation Loss 6848.65 
2024-01-31 05:38:47,084 EPOCH 572
2024-01-31 05:39:01,799 [Epoch: 572 Step: 00038300] Batch Recognition Loss:  17.002998 => Gls Tokens per Sec:      468 || Batch Translation Loss:  75.340286 => Txt Tokens per Sec:     1267 || Lr: 0.000050
2024-01-31 05:39:12,590 Epoch 572: Total Training Recognition Loss 2125.37  Total Training Translation Loss 6848.78 
2024-01-31 05:39:12,590 EPOCH 573
2024-01-31 05:39:38,145 Epoch 573: Total Training Recognition Loss 2126.82  Total Training Translation Loss 6848.13 
2024-01-31 05:39:38,146 EPOCH 574
2024-01-31 05:39:40,852 [Epoch: 574 Step: 00038400] Batch Recognition Loss:  27.527470 => Gls Tokens per Sec:      532 || Batch Translation Loss:  84.709793 => Txt Tokens per Sec:     1424 || Lr: 0.000050
2024-01-31 05:40:03,730 Epoch 574: Total Training Recognition Loss 2124.26  Total Training Translation Loss 6848.96 
2024-01-31 05:40:03,730 EPOCH 575
2024-01-31 05:40:20,469 [Epoch: 575 Step: 00038500] Batch Recognition Loss:  26.715393 => Gls Tokens per Sec:      396 || Batch Translation Loss: 111.943054 => Txt Tokens per Sec:     1098 || Lr: 0.000050
2024-01-31 05:40:29,320 Epoch 575: Total Training Recognition Loss 2127.05  Total Training Translation Loss 6848.88 
2024-01-31 05:40:29,320 EPOCH 576
2024-01-31 05:40:54,804 Epoch 576: Total Training Recognition Loss 2127.68  Total Training Translation Loss 6847.28 
2024-01-31 05:40:54,804 EPOCH 577
2024-01-31 05:40:58,441 [Epoch: 577 Step: 00038600] Batch Recognition Loss:  16.453480 => Gls Tokens per Sec:      352 || Batch Translation Loss:  76.782791 => Txt Tokens per Sec:     1004 || Lr: 0.000050
2024-01-31 05:41:20,241 Epoch 577: Total Training Recognition Loss 2122.07  Total Training Translation Loss 6848.66 
2024-01-31 05:41:20,241 EPOCH 578
2024-01-31 05:41:34,623 [Epoch: 578 Step: 00038700] Batch Recognition Loss:  46.461983 => Gls Tokens per Sec:      456 || Batch Translation Loss: 126.265038 => Txt Tokens per Sec:     1269 || Lr: 0.000050
2024-01-31 05:41:45,685 Epoch 578: Total Training Recognition Loss 2121.22  Total Training Translation Loss 6846.72 
2024-01-31 05:41:45,686 EPOCH 579
2024-01-31 05:42:11,218 Epoch 579: Total Training Recognition Loss 2125.08  Total Training Translation Loss 6848.95 
2024-01-31 05:42:11,219 EPOCH 580
2024-01-31 05:42:13,958 [Epoch: 580 Step: 00038800] Batch Recognition Loss:  37.287361 => Gls Tokens per Sec:      409 || Batch Translation Loss: 118.485802 => Txt Tokens per Sec:     1125 || Lr: 0.000050
2024-01-31 05:42:36,774 Epoch 580: Total Training Recognition Loss 2121.36  Total Training Translation Loss 6848.87 
2024-01-31 05:42:36,774 EPOCH 581
2024-01-31 05:42:51,755 [Epoch: 581 Step: 00038900] Batch Recognition Loss:  30.704037 => Gls Tokens per Sec:      427 || Batch Translation Loss:  99.067482 => Txt Tokens per Sec:     1216 || Lr: 0.000050
2024-01-31 05:43:02,376 Epoch 581: Total Training Recognition Loss 2126.00  Total Training Translation Loss 6848.95 
2024-01-31 05:43:02,376 EPOCH 582
2024-01-31 05:43:27,874 Epoch 582: Total Training Recognition Loss 2125.52  Total Training Translation Loss 6847.21 
2024-01-31 05:43:27,874 EPOCH 583
2024-01-31 05:43:29,703 [Epoch: 583 Step: 00039000] Batch Recognition Loss:  36.756477 => Gls Tokens per Sec:      525 || Batch Translation Loss: 124.922409 => Txt Tokens per Sec:     1367 || Lr: 0.000050
2024-01-31 05:43:53,699 Epoch 583: Total Training Recognition Loss 2122.56  Total Training Translation Loss 6846.70 
2024-01-31 05:43:53,699 EPOCH 584
2024-01-31 05:44:08,965 [Epoch: 584 Step: 00039100] Batch Recognition Loss:  16.854502 => Gls Tokens per Sec:      403 || Batch Translation Loss:  78.702179 => Txt Tokens per Sec:     1162 || Lr: 0.000050
2024-01-31 05:44:19,541 Epoch 584: Total Training Recognition Loss 2125.50  Total Training Translation Loss 6846.87 
2024-01-31 05:44:19,541 EPOCH 585
2024-01-31 05:44:45,282 Epoch 585: Total Training Recognition Loss 2125.08  Total Training Translation Loss 6848.30 
2024-01-31 05:44:45,283 EPOCH 586
2024-01-31 05:44:47,521 [Epoch: 586 Step: 00039200] Batch Recognition Loss:  37.023651 => Gls Tokens per Sec:      358 || Batch Translation Loss: 106.273071 => Txt Tokens per Sec:     1122 || Lr: 0.000050
2024-01-31 05:45:10,806 Epoch 586: Total Training Recognition Loss 2131.39  Total Training Translation Loss 6848.22 
2024-01-31 05:45:10,806 EPOCH 587
2024-01-31 05:45:25,754 [Epoch: 587 Step: 00039300] Batch Recognition Loss:  33.425049 => Gls Tokens per Sec:      401 || Batch Translation Loss: 110.134293 => Txt Tokens per Sec:     1096 || Lr: 0.000050
2024-01-31 05:45:36,626 Epoch 587: Total Training Recognition Loss 2126.56  Total Training Translation Loss 6848.70 
2024-01-31 05:45:36,626 EPOCH 588
2024-01-31 05:46:02,189 Epoch 588: Total Training Recognition Loss 2127.79  Total Training Translation Loss 6846.53 
2024-01-31 05:46:02,189 EPOCH 589
2024-01-31 05:46:03,502 [Epoch: 589 Step: 00039400] Batch Recognition Loss:  40.831192 => Gls Tokens per Sec:      488 || Batch Translation Loss: 138.048370 => Txt Tokens per Sec:     1379 || Lr: 0.000050
2024-01-31 05:46:27,532 Epoch 589: Total Training Recognition Loss 2126.26  Total Training Translation Loss 6848.90 
2024-01-31 05:46:27,532 EPOCH 590
2024-01-31 05:46:42,413 [Epoch: 590 Step: 00039500] Batch Recognition Loss:  37.488068 => Gls Tokens per Sec:      392 || Batch Translation Loss: 114.309212 => Txt Tokens per Sec:     1109 || Lr: 0.000050
2024-01-31 05:46:52,863 Epoch 590: Total Training Recognition Loss 2125.31  Total Training Translation Loss 6848.05 
2024-01-31 05:46:52,864 EPOCH 591
2024-01-31 05:47:18,699 Epoch 591: Total Training Recognition Loss 2127.03  Total Training Translation Loss 6848.41 
2024-01-31 05:47:18,699 EPOCH 592
2024-01-31 05:47:20,137 [Epoch: 592 Step: 00039600] Batch Recognition Loss:  29.963789 => Gls Tokens per Sec:      334 || Batch Translation Loss: 107.179230 => Txt Tokens per Sec:      941 || Lr: 0.000050
2024-01-31 05:47:48,003 Epoch 592: Total Training Recognition Loss 2130.32  Total Training Translation Loss 6847.89 
2024-01-31 05:47:48,004 EPOCH 593
2024-01-31 05:48:01,432 [Epoch: 593 Step: 00039700] Batch Recognition Loss:  36.366623 => Gls Tokens per Sec:      429 || Batch Translation Loss: 111.397606 => Txt Tokens per Sec:     1226 || Lr: 0.000050
2024-01-31 05:48:13,396 Epoch 593: Total Training Recognition Loss 2130.80  Total Training Translation Loss 6847.96 
2024-01-31 05:48:13,397 EPOCH 594
2024-01-31 05:48:38,696 Epoch 594: Total Training Recognition Loss 2125.77  Total Training Translation Loss 6849.15 
2024-01-31 05:48:38,696 EPOCH 595
2024-01-31 05:48:39,082 [Epoch: 595 Step: 00039800] Batch Recognition Loss:  15.829199 => Gls Tokens per Sec:      832 || Batch Translation Loss:  75.372826 => Txt Tokens per Sec:     1917 || Lr: 0.000050
2024-01-31 05:49:04,050 Epoch 595: Total Training Recognition Loss 2126.41  Total Training Translation Loss 6847.45 
2024-01-31 05:49:04,050 EPOCH 596
2024-01-31 05:49:18,869 [Epoch: 596 Step: 00039900] Batch Recognition Loss:  14.172248 => Gls Tokens per Sec:      372 || Batch Translation Loss:  74.826088 => Txt Tokens per Sec:     1081 || Lr: 0.000050
2024-01-31 05:49:29,439 Epoch 596: Total Training Recognition Loss 2127.68  Total Training Translation Loss 6847.68 
2024-01-31 05:49:29,439 EPOCH 597
2024-01-31 05:49:55,108 Epoch 597: Total Training Recognition Loss 2126.33  Total Training Translation Loss 6848.94 
2024-01-31 05:49:55,109 EPOCH 598
2024-01-31 05:49:55,594 [Epoch: 598 Step: 00040000] Batch Recognition Loss:  36.987617 => Gls Tokens per Sec:      331 || Batch Translation Loss: 121.541168 => Txt Tokens per Sec:     1091 || Lr: 0.000050
2024-01-31 05:50:25,311 Validation result at epoch 598, step    40000: duration: 29.7171s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 680.58643	Translation Loss: 73473.33594	PPL: 1560.06091
	Eval Metric: BLEU
	WER 544.00	(DEL: 3.95,	INS: 455.86,	SUB: 84.18)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.44	ROUGE 0.00
2024-01-31 05:50:25,313 Logging Recognition and Translation Outputs
2024-01-31 05:50:25,313 ========================================================================================================================
2024-01-31 05:50:25,313 Logging Sequence: 123_104.00
2024-01-31 05:50:25,314 	Gloss Reference :	***** * ***** * ***** * ***** * ***** * ***** A     B+C+D+E
2024-01-31 05:50:25,314 	Gloss Hypothesis:	<unk> D <unk> E <unk> E <unk> E <unk> E <unk> <pad> <unk>  
2024-01-31 05:50:25,314 	Gloss Alignment :	I     I I     I I     I I     I I     I I     S     S      
2024-01-31 05:50:25,314 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:50:25,317 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ********* ********* ********* ********* ********* ********* ********* ********* ********* ********* the       car       was       presented to        the       former    india     cricketer from      an        unknown   person   
2024-01-31 05:50:25,317 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently patiently
2024-01-31 05:50:25,317 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I         I         I         I         I         I         I         I         I         I         S         S         S         S         S         S         S         S         S         S         S         S         S        
2024-01-31 05:50:25,317 ========================================================================================================================
2024-01-31 05:50:25,317 Logging Sequence: 107_23.00
2024-01-31 05:50:25,318 	Gloss Reference :	A B+C+D+E
2024-01-31 05:50:25,318 	Gloss Hypothesis:	* <unk>  
2024-01-31 05:50:25,318 	Gloss Alignment :	D S      
2024-01-31 05:50:25,318 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:50:25,320 	Text Reference  :	*** *** *** *** *** *** *** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** and   viktor lilov who   is    also  from  the   usa  
2024-01-31 05:50:25,320 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha  sabha sabha sabha sabha sabha sabha sabha
2024-01-31 05:50:25,320 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S      S     S     S     S     S     S     S    
2024-01-31 05:50:25,321 ========================================================================================================================
2024-01-31 05:50:25,321 Logging Sequence: 134_212.00
2024-01-31 05:50:25,321 	Gloss Reference :	A B+C+D+E            
2024-01-31 05:50:25,321 	Gloss Hypothesis:	C B+C+E+C+B+C+B+C+B+C
2024-01-31 05:50:25,321 	Gloss Alignment :	S S                  
2024-01-31 05:50:25,321 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:50:25,323 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** dhanush said that he  practises little yoga
2024-01-31 05:50:25,323 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s>  <s>  <s> <s>       <s>    <s> 
2024-01-31 05:50:25,323 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S       S    S    S   S         S      S   
2024-01-31 05:50:25,323 ========================================================================================================================
2024-01-31 05:50:25,323 Logging Sequence: 165_577.00
2024-01-31 05:50:25,324 	Gloss Reference :	* ***** ********************* ***** * A     B+C+D+E
2024-01-31 05:50:25,324 	Gloss Hypothesis:	E <unk> E+A+E+B+E+B+E+A+E+A+E <unk> E <unk> E      
2024-01-31 05:50:25,324 	Gloss Alignment :	I I     I                     I     I S     S      
2024-01-31 05:50:25,324 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:50:25,327 	Text Reference  :	*** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* then          after         28            years         india         won           the           world         cup           again         in            2011         
2024-01-31 05:50:25,327 	Text Hypothesis :	<s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 05:50:25,327 	Text Alignment  :	I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 05:50:25,327 ========================================================================================================================
2024-01-31 05:50:25,327 Logging Sequence: 88_142.00
2024-01-31 05:50:25,327 	Gloss Reference :	***** ***** * ***** * ***** * ***** * ***** * ***** A B+C+D+E
2024-01-31 05:50:25,328 	Gloss Hypothesis:	<unk> <pad> B <pad> B <unk> B <unk> B <pad> B <unk> B <unk>  
2024-01-31 05:50:25,328 	Gloss Alignment :	I     I     I I     I I     I I     I I     I I     S S      
2024-01-31 05:50:25,328 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 05:50:25,330 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** this is  because the police does not do  anything
2024-01-31 05:50:25,330 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s>     <s> <s>    <s>  <s> <s> <s>     
2024-01-31 05:50:25,330 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S    S   S       S   S      S    S   S   S       
2024-01-31 05:50:25,330 ========================================================================================================================
2024-01-31 05:50:50,443 Epoch 598: Total Training Recognition Loss 2128.16  Total Training Translation Loss 6847.74 
2024-01-31 05:50:50,443 EPOCH 599
2024-01-31 05:51:04,292 [Epoch: 599 Step: 00040100] Batch Recognition Loss:  53.735966 => Gls Tokens per Sec:      386 || Batch Translation Loss: 129.736084 => Txt Tokens per Sec:     1095 || Lr: 0.000050
2024-01-31 05:51:16,033 Epoch 599: Total Training Recognition Loss 2126.29  Total Training Translation Loss 6848.47 
2024-01-31 05:51:16,033 EPOCH 600
2024-01-31 05:51:41,618 [Epoch: 600 Step: 00040200] Batch Recognition Loss:  39.638668 => Gls Tokens per Sec:      415 || Batch Translation Loss: 117.169167 => Txt Tokens per Sec:     1153 || Lr: 0.000050
2024-01-31 05:51:41,619 Epoch 600: Total Training Recognition Loss 2127.38  Total Training Translation Loss 6848.58 
2024-01-31 05:51:41,619 EPOCH 601
2024-01-31 05:52:07,252 Epoch 601: Total Training Recognition Loss 2124.65  Total Training Translation Loss 6847.47 
2024-01-31 05:52:07,252 EPOCH 602
2024-01-31 05:52:20,430 [Epoch: 602 Step: 00040300] Batch Recognition Loss:  44.133961 => Gls Tokens per Sec:      401 || Batch Translation Loss: 131.057251 => Txt Tokens per Sec:     1160 || Lr: 0.000050
2024-01-31 05:52:32,879 Epoch 602: Total Training Recognition Loss 2127.46  Total Training Translation Loss 6847.94 
2024-01-31 05:52:32,879 EPOCH 603
2024-01-31 05:52:57,792 [Epoch: 603 Step: 00040400] Batch Recognition Loss:  23.885742 => Gls Tokens per Sec:      420 || Batch Translation Loss: 102.198830 => Txt Tokens per Sec:     1161 || Lr: 0.000050
2024-01-31 05:52:58,484 Epoch 603: Total Training Recognition Loss 2126.61  Total Training Translation Loss 6848.51 
2024-01-31 05:52:58,484 EPOCH 604
2024-01-31 05:53:24,109 Epoch 604: Total Training Recognition Loss 2123.86  Total Training Translation Loss 6847.67 
2024-01-31 05:53:24,109 EPOCH 605
2024-01-31 05:53:37,163 [Epoch: 605 Step: 00040500] Batch Recognition Loss:  18.765760 => Gls Tokens per Sec:      385 || Batch Translation Loss:  83.943420 => Txt Tokens per Sec:     1097 || Lr: 0.000050
2024-01-31 05:53:49,748 Epoch 605: Total Training Recognition Loss 2122.49  Total Training Translation Loss 6848.91 
2024-01-31 05:53:49,748 EPOCH 606
2024-01-31 05:54:14,354 [Epoch: 606 Step: 00040600] Batch Recognition Loss:   7.245581 => Gls Tokens per Sec:      419 || Batch Translation Loss:  56.674370 => Txt Tokens per Sec:     1157 || Lr: 0.000050
2024-01-31 05:54:15,291 Epoch 606: Total Training Recognition Loss 2123.58  Total Training Translation Loss 6848.43 
2024-01-31 05:54:15,293 EPOCH 607
2024-01-31 05:54:40,913 Epoch 607: Total Training Recognition Loss 2125.92  Total Training Translation Loss 6848.10 
2024-01-31 05:54:40,913 EPOCH 608
2024-01-31 05:54:52,712 [Epoch: 608 Step: 00040700] Batch Recognition Loss:  54.355755 => Gls Tokens per Sec:      420 || Batch Translation Loss: 132.355728 => Txt Tokens per Sec:     1209 || Lr: 0.000050
2024-01-31 05:55:06,507 Epoch 608: Total Training Recognition Loss 2129.69  Total Training Translation Loss 6846.83 
2024-01-31 05:55:06,507 EPOCH 609
2024-01-31 05:55:31,057 [Epoch: 609 Step: 00040800] Batch Recognition Loss:  22.986366 => Gls Tokens per Sec:      413 || Batch Translation Loss:  85.606415 => Txt Tokens per Sec:     1145 || Lr: 0.000050
2024-01-31 05:55:32,174 Epoch 609: Total Training Recognition Loss 2127.76  Total Training Translation Loss 6849.37 
2024-01-31 05:55:32,174 EPOCH 610
2024-01-31 05:55:57,835 Epoch 610: Total Training Recognition Loss 2131.24  Total Training Translation Loss 6848.34 
2024-01-31 05:55:57,836 EPOCH 611
2024-01-31 05:56:10,512 [Epoch: 611 Step: 00040900] Batch Recognition Loss:  11.349730 => Gls Tokens per Sec:      372 || Batch Translation Loss:  62.309082 => Txt Tokens per Sec:     1051 || Lr: 0.000050
2024-01-31 05:56:23,337 Epoch 611: Total Training Recognition Loss 2128.70  Total Training Translation Loss 6849.99 
2024-01-31 05:56:23,338 EPOCH 612
2024-01-31 05:56:46,675 [Epoch: 612 Step: 00041000] Batch Recognition Loss:  23.558300 => Gls Tokens per Sec:      428 || Batch Translation Loss:  96.973701 => Txt Tokens per Sec:     1175 || Lr: 0.000050
2024-01-31 05:56:49,016 Epoch 612: Total Training Recognition Loss 2126.99  Total Training Translation Loss 6846.99 
2024-01-31 05:56:49,016 EPOCH 613
2024-01-31 05:57:14,493 Epoch 613: Total Training Recognition Loss 2124.19  Total Training Translation Loss 6847.33 
2024-01-31 05:57:14,493 EPOCH 614
2024-01-31 05:57:25,668 [Epoch: 614 Step: 00041100] Batch Recognition Loss:  32.578922 => Gls Tokens per Sec:      415 || Batch Translation Loss:  93.961197 => Txt Tokens per Sec:     1156 || Lr: 0.000050
2024-01-31 05:57:40,156 Epoch 614: Total Training Recognition Loss 2124.54  Total Training Translation Loss 6849.38 
2024-01-31 05:57:40,157 EPOCH 615
2024-01-31 05:58:04,471 [Epoch: 615 Step: 00041200] Batch Recognition Loss:  37.522297 => Gls Tokens per Sec:      404 || Batch Translation Loss: 106.239487 => Txt Tokens per Sec:     1129 || Lr: 0.000050
2024-01-31 05:58:05,818 Epoch 615: Total Training Recognition Loss 2123.79  Total Training Translation Loss 6848.07 
2024-01-31 05:58:05,818 EPOCH 616
2024-01-31 05:58:31,464 Epoch 616: Total Training Recognition Loss 2124.38  Total Training Translation Loss 6848.43 
2024-01-31 05:58:31,464 EPOCH 617
2024-01-31 05:58:42,019 [Epoch: 617 Step: 00041300] Batch Recognition Loss:  37.525673 => Gls Tokens per Sec:      416 || Batch Translation Loss: 119.581764 => Txt Tokens per Sec:     1114 || Lr: 0.000050
2024-01-31 05:58:57,195 Epoch 617: Total Training Recognition Loss 2126.76  Total Training Translation Loss 6847.15 
2024-01-31 05:58:57,195 EPOCH 618
2024-01-31 05:59:19,949 [Epoch: 618 Step: 00041400] Batch Recognition Loss:  39.953457 => Gls Tokens per Sec:      425 || Batch Translation Loss: 126.103165 => Txt Tokens per Sec:     1171 || Lr: 0.000050
2024-01-31 05:59:23,087 Epoch 618: Total Training Recognition Loss 2131.10  Total Training Translation Loss 6848.33 
2024-01-31 05:59:23,087 EPOCH 619
2024-01-31 05:59:48,748 Epoch 619: Total Training Recognition Loss 2126.83  Total Training Translation Loss 6848.11 
2024-01-31 05:59:48,748 EPOCH 620
2024-01-31 05:59:59,402 [Epoch: 620 Step: 00041500] Batch Recognition Loss:  33.610188 => Gls Tokens per Sec:      406 || Batch Translation Loss: 106.124001 => Txt Tokens per Sec:     1155 || Lr: 0.000050
2024-01-31 06:00:14,445 Epoch 620: Total Training Recognition Loss 2128.14  Total Training Translation Loss 6848.60 
2024-01-31 06:00:14,445 EPOCH 621
2024-01-31 06:00:38,112 [Epoch: 621 Step: 00041600] Batch Recognition Loss:  22.611462 => Gls Tokens per Sec:      402 || Batch Translation Loss: 102.427696 => Txt Tokens per Sec:     1125 || Lr: 0.000050
2024-01-31 06:00:40,082 Epoch 621: Total Training Recognition Loss 2128.35  Total Training Translation Loss 6847.84 
2024-01-31 06:00:40,083 EPOCH 622
2024-01-31 06:01:05,789 Epoch 622: Total Training Recognition Loss 2125.02  Total Training Translation Loss 6847.72 
2024-01-31 06:01:05,789 EPOCH 623
2024-01-31 06:01:15,175 [Epoch: 623 Step: 00041700] Batch Recognition Loss:  11.274587 => Gls Tokens per Sec:      443 || Batch Translation Loss:  62.850357 => Txt Tokens per Sec:     1235 || Lr: 0.000050
2024-01-31 06:01:31,429 Epoch 623: Total Training Recognition Loss 2125.88  Total Training Translation Loss 6849.46 
2024-01-31 06:01:31,429 EPOCH 624
2024-01-31 06:01:53,602 [Epoch: 624 Step: 00041800] Batch Recognition Loss:  19.440502 => Gls Tokens per Sec:      426 || Batch Translation Loss:  93.709183 => Txt Tokens per Sec:     1182 || Lr: 0.000050
2024-01-31 06:01:57,066 Epoch 624: Total Training Recognition Loss 2122.91  Total Training Translation Loss 6846.34 
2024-01-31 06:01:57,066 EPOCH 625
2024-01-31 06:02:22,600 Epoch 625: Total Training Recognition Loss 2129.01  Total Training Translation Loss 6848.21 
2024-01-31 06:02:22,600 EPOCH 626
2024-01-31 06:02:31,157 [Epoch: 626 Step: 00041900] Batch Recognition Loss:  33.986221 => Gls Tokens per Sec:      467 || Batch Translation Loss: 100.466263 => Txt Tokens per Sec:     1243 || Lr: 0.000050
2024-01-31 06:02:48,340 Epoch 626: Total Training Recognition Loss 2126.74  Total Training Translation Loss 6849.89 
2024-01-31 06:02:48,340 EPOCH 627
2024-01-31 06:03:11,372 [Epoch: 627 Step: 00042000] Batch Recognition Loss:  10.310874 => Gls Tokens per Sec:      399 || Batch Translation Loss:  62.780571 => Txt Tokens per Sec:     1122 || Lr: 0.000050
2024-01-31 06:03:40,634 Validation result at epoch 627, step    42000: duration: 29.2615s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 681.77856	Translation Loss: 73445.17969	PPL: 1555.67188
	Eval Metric: BLEU
	WER 552.97	(DEL: 4.10,	INS: 465.68,	SUB: 83.19)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.45	ROUGE 0.00
2024-01-31 06:03:40,635 Logging Recognition and Translation Outputs
2024-01-31 06:03:40,635 ========================================================================================================================
2024-01-31 06:03:40,635 Logging Sequence: 81_8.00
2024-01-31 06:03:40,636 	Gloss Reference :	***** * ***** * ***** * ***** * ***** * ***** * A     B+C+D+E
2024-01-31 06:03:40,636 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E <unk> E <unk> E <unk> E+C+E  
2024-01-31 06:03:40,636 	Gloss Alignment :	I     I I     I I     I I     I I     I I     I S     S      
2024-01-31 06:03:40,636 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:03:40,640 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* have    been    involved in      a       huge    controversy in      connection to      real    estate  developer amrapali group   since   last    7       years  
2024-01-31 06:03:40,640 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing  nothing nothing nothing nothing     nothing nothing    nothing nothing nothing nothing   nothing  nothing nothing nothing nothing nothing
2024-01-31 06:03:40,640 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       S       S       S        S       S       S       S           S       S          S       S       S       S         S        S       S       S       S       S      
2024-01-31 06:03:40,640 ========================================================================================================================
2024-01-31 06:03:40,641 Logging Sequence: 148_239.00
2024-01-31 06:03:40,641 	Gloss Reference :	***** A ***** ***** ***** * ***** * ***** * ***** * ***** *********** ***** B+C+D+E
2024-01-31 06:03:40,641 	Gloss Hypothesis:	<unk> A <unk> E+A+E <unk> E <unk> E <unk> E <unk> E <unk> E+B+E+C+E+B <unk> C+E    
2024-01-31 06:03:40,641 	Gloss Alignment :	I       I     I     I     I I     I I     I I     I I     I           I     S      
2024-01-31 06:03:40,641 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:03:40,644 	Text Reference  :	*** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* the           ground        staff         were          very          happy         and           thanked       the           bowler        for           his           kind          gesture      
2024-01-31 06:03:40,645 	Text Hypothesis :	<s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 06:03:40,645 	Text Alignment  :	I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 06:03:40,645 ========================================================================================================================
2024-01-31 06:03:40,645 Logging Sequence: 165_8.00
2024-01-31 06:03:40,645 	Gloss Reference :	***** ************* A     B+C+D+E
2024-01-31 06:03:40,645 	Gloss Hypothesis:	<unk> E+A+E+A+E+A+E <unk> E      
2024-01-31 06:03:40,646 	Gloss Alignment :	I     I             S     S      
2024-01-31 06:03:40,646 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:03:40,648 	Text Reference  :	*** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** however many  don't believe in    it    it    varies among people
2024-01-31 06:03:40,648 	Text Hypothesis :	<s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha   sabha sabha sabha   sabha sabha sabha sabha  sabha sabha 
2024-01-31 06:03:40,648 	Text Alignment  :	I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S       S     S     S       S     S     S     S      S     S     
2024-01-31 06:03:40,648 ========================================================================================================================
2024-01-31 06:03:40,648 Logging Sequence: 93_93.00
2024-01-31 06:03:40,649 	Gloss Reference :	***** *** ***** ***** * ***** * ***** ******* ***** *** ***** *** ***** * ***** A B+C+D+E
2024-01-31 06:03:40,649 	Gloss Hypothesis:	<unk> B+C <pad> <unk> C <unk> C <unk> E+B+E+B <pad> B+E <unk> B+E <unk> C <unk> C <unk>  
2024-01-31 06:03:40,649 	Gloss Alignment :	I     I   I     I     I I     I I     I       I     I   I     I   I     I I     S S      
2024-01-31 06:03:40,649 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:03:40,651 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* rooney  was     at      the     club    as      well   
2024-01-31 06:03:40,651 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing
2024-01-31 06:03:40,651 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S       S       S      
2024-01-31 06:03:40,651 ========================================================================================================================
2024-01-31 06:03:40,651 Logging Sequence: 96_129.00
2024-01-31 06:03:40,652 	Gloss Reference :	A B+C+D+E
2024-01-31 06:03:40,652 	Gloss Hypothesis:	A E+A+E  
2024-01-31 06:03:40,652 	Gloss Alignment :	  S      
2024-01-31 06:03:40,652 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:03:40,653 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* viewers were    very    stressed
2024-01-31 06:03:40,653 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing 
2024-01-31 06:03:40,653 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       
2024-01-31 06:03:40,653 ========================================================================================================================
2024-01-31 06:03:43,086 Epoch 627: Total Training Recognition Loss 2124.89  Total Training Translation Loss 6848.22 
2024-01-31 06:03:43,086 EPOCH 628
2024-01-31 06:04:08,729 Epoch 628: Total Training Recognition Loss 2128.42  Total Training Translation Loss 6848.06 
2024-01-31 06:04:08,729 EPOCH 629
2024-01-31 06:04:16,085 [Epoch: 629 Step: 00042100] Batch Recognition Loss:  28.111462 => Gls Tokens per Sec:      522 || Batch Translation Loss: 101.992081 => Txt Tokens per Sec:     1367 || Lr: 0.000050
2024-01-31 06:04:34,330 Epoch 629: Total Training Recognition Loss 2128.17  Total Training Translation Loss 6847.97 
2024-01-31 06:04:34,330 EPOCH 630
2024-01-31 06:04:55,457 [Epoch: 630 Step: 00042200] Batch Recognition Loss:  23.109587 => Gls Tokens per Sec:      432 || Batch Translation Loss:  97.337036 => Txt Tokens per Sec:     1208 || Lr: 0.000050
2024-01-31 06:04:59,937 Epoch 630: Total Training Recognition Loss 2121.99  Total Training Translation Loss 6848.35 
2024-01-31 06:04:59,937 EPOCH 631
2024-01-31 06:05:25,467 Epoch 631: Total Training Recognition Loss 2124.67  Total Training Translation Loss 6849.52 
2024-01-31 06:05:25,468 EPOCH 632
2024-01-31 06:05:33,414 [Epoch: 632 Step: 00042300] Batch Recognition Loss:  36.474815 => Gls Tokens per Sec:      452 || Batch Translation Loss: 121.105965 => Txt Tokens per Sec:     1189 || Lr: 0.000050
2024-01-31 06:05:51,061 Epoch 632: Total Training Recognition Loss 2128.92  Total Training Translation Loss 6848.37 
2024-01-31 06:05:51,061 EPOCH 633
2024-01-31 06:06:11,907 [Epoch: 633 Step: 00042400] Batch Recognition Loss:  44.065250 => Gls Tokens per Sec:      426 || Batch Translation Loss: 126.433472 => Txt Tokens per Sec:     1159 || Lr: 0.000050
2024-01-31 06:06:16,776 Epoch 633: Total Training Recognition Loss 2127.08  Total Training Translation Loss 6847.73 
2024-01-31 06:06:16,777 EPOCH 634
2024-01-31 06:06:42,394 Epoch 634: Total Training Recognition Loss 2125.95  Total Training Translation Loss 6848.92 
2024-01-31 06:06:42,394 EPOCH 635
2024-01-31 06:06:51,279 [Epoch: 635 Step: 00042500] Batch Recognition Loss:  38.228004 => Gls Tokens per Sec:      386 || Batch Translation Loss: 117.064056 => Txt Tokens per Sec:     1076 || Lr: 0.000050
2024-01-31 06:07:08,062 Epoch 635: Total Training Recognition Loss 2129.54  Total Training Translation Loss 6848.44 
2024-01-31 06:07:08,062 EPOCH 636
2024-01-31 06:07:30,062 [Epoch: 636 Step: 00042600] Batch Recognition Loss:  22.394360 => Gls Tokens per Sec:      396 || Batch Translation Loss:  84.482681 => Txt Tokens per Sec:     1103 || Lr: 0.000050
2024-01-31 06:07:33,818 Epoch 636: Total Training Recognition Loss 2124.73  Total Training Translation Loss 6849.24 
2024-01-31 06:07:33,818 EPOCH 637
2024-01-31 06:07:59,571 Epoch 637: Total Training Recognition Loss 2128.45  Total Training Translation Loss 6848.80 
2024-01-31 06:07:59,572 EPOCH 638
2024-01-31 06:08:06,613 [Epoch: 638 Step: 00042700] Batch Recognition Loss:  46.466003 => Gls Tokens per Sec:      477 || Batch Translation Loss: 127.879570 => Txt Tokens per Sec:     1305 || Lr: 0.000050
2024-01-31 06:08:25,392 Epoch 638: Total Training Recognition Loss 2120.62  Total Training Translation Loss 6847.40 
2024-01-31 06:08:25,392 EPOCH 639
2024-01-31 06:08:45,173 [Epoch: 639 Step: 00042800] Batch Recognition Loss:  38.393219 => Gls Tokens per Sec:      432 || Batch Translation Loss: 113.453445 => Txt Tokens per Sec:     1188 || Lr: 0.000050
2024-01-31 06:08:50,741 Epoch 639: Total Training Recognition Loss 2128.75  Total Training Translation Loss 6848.97 
2024-01-31 06:08:50,742 EPOCH 640
2024-01-31 06:09:16,026 Epoch 640: Total Training Recognition Loss 2126.11  Total Training Translation Loss 6847.75 
2024-01-31 06:09:16,026 EPOCH 641
2024-01-31 06:09:23,725 [Epoch: 641 Step: 00042900] Batch Recognition Loss:  17.279297 => Gls Tokens per Sec:      404 || Batch Translation Loss:  72.807983 => Txt Tokens per Sec:     1110 || Lr: 0.000050
2024-01-31 06:09:41,587 Epoch 641: Total Training Recognition Loss 2128.25  Total Training Translation Loss 6849.24 
2024-01-31 06:09:41,587 EPOCH 642
2024-01-31 06:10:01,250 [Epoch: 642 Step: 00043000] Batch Recognition Loss:  60.738983 => Gls Tokens per Sec:      431 || Batch Translation Loss: 135.395782 => Txt Tokens per Sec:     1196 || Lr: 0.000050
2024-01-31 06:10:07,194 Epoch 642: Total Training Recognition Loss 2126.93  Total Training Translation Loss 6848.71 
2024-01-31 06:10:07,195 EPOCH 643
2024-01-31 06:10:32,628 Epoch 643: Total Training Recognition Loss 2124.80  Total Training Translation Loss 6849.81 
2024-01-31 06:10:32,629 EPOCH 644
2024-01-31 06:10:39,423 [Epoch: 644 Step: 00043100] Batch Recognition Loss:  27.528374 => Gls Tokens per Sec:      448 || Batch Translation Loss:  81.891495 => Txt Tokens per Sec:     1221 || Lr: 0.000050
2024-01-31 06:10:58,200 Epoch 644: Total Training Recognition Loss 2131.57  Total Training Translation Loss 6848.76 
2024-01-31 06:10:58,200 EPOCH 645
2024-01-31 06:11:16,757 [Epoch: 645 Step: 00043200] Batch Recognition Loss:  37.138084 => Gls Tokens per Sec:      444 || Batch Translation Loss: 102.490433 => Txt Tokens per Sec:     1202 || Lr: 0.000050
2024-01-31 06:11:23,873 Epoch 645: Total Training Recognition Loss 2128.33  Total Training Translation Loss 6847.44 
2024-01-31 06:11:23,873 EPOCH 646
2024-01-31 06:11:49,582 Epoch 646: Total Training Recognition Loss 2127.06  Total Training Translation Loss 6849.32 
2024-01-31 06:11:49,582 EPOCH 647
2024-01-31 06:11:55,609 [Epoch: 647 Step: 00043300] Batch Recognition Loss:  36.679016 => Gls Tokens per Sec:      463 || Batch Translation Loss: 108.061142 => Txt Tokens per Sec:     1200 || Lr: 0.000050
2024-01-31 06:12:15,435 Epoch 647: Total Training Recognition Loss 2125.22  Total Training Translation Loss 6847.17 
2024-01-31 06:12:15,435 EPOCH 648
2024-01-31 06:12:35,232 [Epoch: 648 Step: 00043400] Batch Recognition Loss:  34.021515 => Gls Tokens per Sec:      408 || Batch Translation Loss: 112.935112 => Txt Tokens per Sec:     1136 || Lr: 0.000050
2024-01-31 06:12:41,111 Epoch 648: Total Training Recognition Loss 2125.08  Total Training Translation Loss 6847.95 
2024-01-31 06:12:41,112 EPOCH 649
2024-01-31 06:13:06,820 Epoch 649: Total Training Recognition Loss 2127.14  Total Training Translation Loss 6847.55 
2024-01-31 06:13:06,821 EPOCH 650
2024-01-31 06:13:13,691 [Epoch: 650 Step: 00043500] Batch Recognition Loss:  22.693214 => Gls Tokens per Sec:      383 || Batch Translation Loss:  85.770309 => Txt Tokens per Sec:     1040 || Lr: 0.000050
2024-01-31 06:13:32,415 Epoch 650: Total Training Recognition Loss 2126.04  Total Training Translation Loss 6849.33 
2024-01-31 06:13:32,416 EPOCH 651
2024-01-31 06:13:52,512 [Epoch: 651 Step: 00043600] Batch Recognition Loss:  27.145863 => Gls Tokens per Sec:      394 || Batch Translation Loss: 106.983154 => Txt Tokens per Sec:     1104 || Lr: 0.000050
2024-01-31 06:13:58,099 Epoch 651: Total Training Recognition Loss 2125.54  Total Training Translation Loss 6848.49 
2024-01-31 06:13:58,100 EPOCH 652
2024-01-31 06:14:23,617 Epoch 652: Total Training Recognition Loss 2128.80  Total Training Translation Loss 6847.18 
2024-01-31 06:14:23,617 EPOCH 653
2024-01-31 06:14:29,853 [Epoch: 653 Step: 00043700] Batch Recognition Loss:  37.425610 => Gls Tokens per Sec:      411 || Batch Translation Loss: 120.512375 => Txt Tokens per Sec:     1147 || Lr: 0.000050
2024-01-31 06:14:49,322 Epoch 653: Total Training Recognition Loss 2129.23  Total Training Translation Loss 6846.97 
2024-01-31 06:14:49,322 EPOCH 654
2024-01-31 06:15:08,134 [Epoch: 654 Step: 00043800] Batch Recognition Loss:  46.934635 => Gls Tokens per Sec:      417 || Batch Translation Loss: 123.898682 => Txt Tokens per Sec:     1166 || Lr: 0.000050
2024-01-31 06:15:14,832 Epoch 654: Total Training Recognition Loss 2123.55  Total Training Translation Loss 6848.17 
2024-01-31 06:15:14,832 EPOCH 655
2024-01-31 06:15:40,559 Epoch 655: Total Training Recognition Loss 2128.21  Total Training Translation Loss 6847.70 
2024-01-31 06:15:40,559 EPOCH 656
2024-01-31 06:15:45,888 [Epoch: 656 Step: 00043900] Batch Recognition Loss:  31.301104 => Gls Tokens per Sec:      434 || Batch Translation Loss: 112.399498 => Txt Tokens per Sec:     1140 || Lr: 0.000050
2024-01-31 06:16:06,163 Epoch 656: Total Training Recognition Loss 2125.21  Total Training Translation Loss 6848.77 
2024-01-31 06:16:06,163 EPOCH 657
2024-01-31 06:16:26,176 [Epoch: 657 Step: 00044000] Batch Recognition Loss:  39.538216 => Gls Tokens per Sec:      379 || Batch Translation Loss: 112.939529 => Txt Tokens per Sec:     1063 || Lr: 0.000050
2024-01-31 06:16:55,201 Validation result at epoch 657, step    44000: duration: 29.0255s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 674.72321	Translation Loss: 73489.62500	PPL: 1562.60608
	Eval Metric: BLEU
	WER 537.71	(DEL: 4.52,	INS: 449.44,	SUB: 83.76)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.44	ROUGE 0.00
2024-01-31 06:16:55,202 Logging Recognition and Translation Outputs
2024-01-31 06:16:55,203 ========================================================================================================================
2024-01-31 06:16:55,203 Logging Sequence: 117_29.00
2024-01-31 06:16:55,203 	Gloss Reference :	***** ***** ***** * ***** * ***** A         B+C+D+E
2024-01-31 06:16:55,203 	Gloss Hypothesis:	<unk> <pad> <unk> C <unk> C <unk> B+C+E+C+E <unk>  
2024-01-31 06:16:55,203 	Gloss Alignment :	I     I     I     I I     I I     S         S      
2024-01-31 06:16:55,203 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:16:55,207 	Text Reference  :	*** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** however england was   unable to    reach the   target they  were  all   out   lost  by    66    runs 
2024-01-31 06:16:55,207 	Text Hypothesis :	<s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha   sabha   sabha sabha  sabha sabha sabha sabha  sabha sabha sabha sabha sabha sabha sabha sabha
2024-01-31 06:16:55,207 	Text Alignment  :	I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S       S       S     S      S     S     S     S      S     S     S     S     S     S     S     S    
2024-01-31 06:16:55,207 ========================================================================================================================
2024-01-31 06:16:55,207 Logging Sequence: 84_176.00
2024-01-31 06:16:55,208 	Gloss Reference :	***** *********** ***** * ***** * ***** * ***** ************* ***** *** A     B+C+D+E
2024-01-31 06:16:55,208 	Gloss Hypothesis:	<unk> E+C+A+E+C+E <unk> E <unk> E <unk> E <unk> C+E+C+E+C+E+C <unk> C+E <unk> E+C+E+C
2024-01-31 06:16:55,208 	Gloss Alignment :	I     I           I     I I     I I     I I     I             I     I   S     S      
2024-01-31 06:16:55,208 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:16:55,211 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** germany's nancy faeser who attended the game in doha against japan said
2024-01-31 06:16:55,211 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> kl kl kl kl kl kl kl kl kl kl kl kl kl kl kl kl kl kl        kl    kl     kl  kl       kl  kl   kl kl   kl      kl    kl  
2024-01-31 06:16:55,211 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I  I  I  I  I  I  I  I  I  I  I  I  I  I  I  I  I  S         S     S      S   S        S   S    S  S    S       S     S   
2024-01-31 06:16:55,211 ========================================================================================================================
2024-01-31 06:16:55,211 Logging Sequence: 172_98.00
2024-01-31 06:16:55,211 	Gloss Reference :	***** A ***** * ***** ******* ***** * ***** * ***** *** ***** * ***** B+C+D+E              
2024-01-31 06:16:55,212 	Gloss Hypothesis:	<unk> A <unk> E <unk> E+B+E+B <unk> B <unk> E <unk> B+E <unk> E <unk> B+E+C+B+E+B+E+B+E+C+E
2024-01-31 06:16:55,212 	Gloss Alignment :	I       I     I I     I       I     I I     I I     I   I     I I     S                    
2024-01-31 06:16:55,212 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:16:55,214 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** since 700 pm  it  kept raining the intensity plunged around 915 pm 
2024-01-31 06:16:55,215 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> bid bid bid bid bid bid bid bid bid bid bid bid bid bid bid bid bid bid   bid bid bid bid  bid     bid bid       bid     bid    bid bid
2024-01-31 06:16:55,215 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S     S   S   S   S    S       S   S         S       S      S   S  
2024-01-31 06:16:55,215 ========================================================================================================================
2024-01-31 06:16:55,215 Logging Sequence: 135_92.00
2024-01-31 06:16:55,215 	Gloss Reference :	***** *** ***** * ***** ******* ***** *** ***** * ***** A ***** *** ***** *** ***** *** ***** B+C+D+E  
2024-01-31 06:16:55,216 	Gloss Hypothesis:	<unk> E+A <unk> A <unk> E+B+E+B <unk> B+E <unk> A <unk> A <unk> A+E <unk> E+A <unk> E+A <unk> A+B+E+B+E
2024-01-31 06:16:55,216 	Gloss Alignment :	I     I   I     I I     I       I     I   I     I I       I     I   I     I   I     I   I     S        
2024-01-31 06:16:55,216 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:16:55,219 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** she wrote that half had already been raised by  the family's online fundraiser
2024-01-31 06:16:55,219 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s>  <s>  <s> <s>     <s>  <s>    <s> <s> <s>      <s>    <s>       
2024-01-31 06:16:55,219 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S     S    S    S   S       S    S      S   S   S        S      S         
2024-01-31 06:16:55,219 ========================================================================================================================
2024-01-31 06:16:55,219 Logging Sequence: 180_332.00
2024-01-31 06:16:55,219 	Gloss Reference :	* *********************************************** A     B+C+D+E    
2024-01-31 06:16:55,219 	Gloss Hypothesis:	C E+C+A+E+C+E+C+E+C+E+C+E+C+E+C+B+C+E+C+E+C+E+C+E <unk> E+C+E+C+E+C
2024-01-31 06:16:55,220 	Gloss Alignment :	I I                                               S     S          
2024-01-31 06:16:55,220 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:16:55,223 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** did i   eat roti made of  shilajit that i   got energy to  assault so  many girls
2024-01-31 06:16:55,223 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s>  <s> <s>      <s>  <s> <s> <s>    <s> <s>     <s> <s>  <s>  
2024-01-31 06:16:55,223 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S   S   S    S    S   S        S    S   S   S      S   S       S   S    S    
2024-01-31 06:16:55,223 ========================================================================================================================
2024-01-31 06:17:00,933 Epoch 657: Total Training Recognition Loss 2127.61  Total Training Translation Loss 6846.90 
2024-01-31 06:17:00,934 EPOCH 658
2024-01-31 06:17:26,656 Epoch 658: Total Training Recognition Loss 2128.35  Total Training Translation Loss 6846.60 
2024-01-31 06:17:26,657 EPOCH 659
2024-01-31 06:17:33,357 [Epoch: 659 Step: 00044100] Batch Recognition Loss:  46.434948 => Gls Tokens per Sec:      334 || Batch Translation Loss: 125.333420 => Txt Tokens per Sec:      939 || Lr: 0.000050
2024-01-31 06:17:55,900 Epoch 659: Total Training Recognition Loss 2129.46  Total Training Translation Loss 6848.73 
2024-01-31 06:17:55,900 EPOCH 660
2024-01-31 06:18:13,835 [Epoch: 660 Step: 00044200] Batch Recognition Loss:  31.194805 => Gls Tokens per Sec:      419 || Batch Translation Loss: 113.212868 => Txt Tokens per Sec:     1156 || Lr: 0.000050
2024-01-31 06:18:21,664 Epoch 660: Total Training Recognition Loss 2125.66  Total Training Translation Loss 6849.15 
2024-01-31 06:18:21,664 EPOCH 661
2024-01-31 06:18:47,200 Epoch 661: Total Training Recognition Loss 2121.10  Total Training Translation Loss 6848.96 
2024-01-31 06:18:47,201 EPOCH 662
2024-01-31 06:18:51,485 [Epoch: 662 Step: 00044300] Batch Recognition Loss:  22.563702 => Gls Tokens per Sec:      486 || Batch Translation Loss:  87.347046 => Txt Tokens per Sec:     1299 || Lr: 0.000050
2024-01-31 06:19:12,896 Epoch 662: Total Training Recognition Loss 2124.20  Total Training Translation Loss 6847.59 
2024-01-31 06:19:12,896 EPOCH 663
2024-01-31 06:19:31,593 [Epoch: 663 Step: 00044400] Batch Recognition Loss:  44.550446 => Gls Tokens per Sec:      389 || Batch Translation Loss: 124.621460 => Txt Tokens per Sec:     1088 || Lr: 0.000050
2024-01-31 06:19:38,616 Epoch 663: Total Training Recognition Loss 2126.54  Total Training Translation Loss 6849.01 
2024-01-31 06:19:38,616 EPOCH 664
2024-01-31 06:20:04,149 Epoch 664: Total Training Recognition Loss 2124.86  Total Training Translation Loss 6848.82 
2024-01-31 06:20:04,149 EPOCH 665
2024-01-31 06:20:10,583 [Epoch: 665 Step: 00044500] Batch Recognition Loss:  44.104729 => Gls Tokens per Sec:      284 || Batch Translation Loss: 124.575966 => Txt Tokens per Sec:      868 || Lr: 0.000050
2024-01-31 06:20:29,702 Epoch 665: Total Training Recognition Loss 2124.24  Total Training Translation Loss 6848.56 
2024-01-31 06:20:29,702 EPOCH 666
2024-01-31 06:20:46,195 [Epoch: 666 Step: 00044600] Batch Recognition Loss:   5.234772 => Gls Tokens per Sec:      431 || Batch Translation Loss:  44.606682 => Txt Tokens per Sec:     1194 || Lr: 0.000050
2024-01-31 06:20:55,207 Epoch 666: Total Training Recognition Loss 2128.98  Total Training Translation Loss 6849.26 
2024-01-31 06:20:55,207 EPOCH 667
2024-01-31 06:21:20,701 Epoch 667: Total Training Recognition Loss 2126.41  Total Training Translation Loss 6848.76 
2024-01-31 06:21:20,701 EPOCH 668
2024-01-31 06:21:24,565 [Epoch: 668 Step: 00044700] Batch Recognition Loss:  38.356506 => Gls Tokens per Sec:      456 || Batch Translation Loss: 119.056992 => Txt Tokens per Sec:     1183 || Lr: 0.000050
2024-01-31 06:21:46,390 Epoch 668: Total Training Recognition Loss 2127.52  Total Training Translation Loss 6848.76 
2024-01-31 06:21:46,390 EPOCH 669
2024-01-31 06:22:03,934 [Epoch: 669 Step: 00044800] Batch Recognition Loss:  49.371063 => Gls Tokens per Sec:      401 || Batch Translation Loss: 134.298981 => Txt Tokens per Sec:     1139 || Lr: 0.000050
2024-01-31 06:22:12,117 Epoch 669: Total Training Recognition Loss 2128.75  Total Training Translation Loss 6847.12 
2024-01-31 06:22:12,118 EPOCH 670
2024-01-31 06:22:37,761 Epoch 670: Total Training Recognition Loss 2125.27  Total Training Translation Loss 6846.97 
2024-01-31 06:22:37,761 EPOCH 671
2024-01-31 06:22:41,122 [Epoch: 671 Step: 00044900] Batch Recognition Loss:  46.699310 => Gls Tokens per Sec:      476 || Batch Translation Loss: 124.847771 => Txt Tokens per Sec:     1282 || Lr: 0.000050
2024-01-31 06:23:03,238 Epoch 671: Total Training Recognition Loss 2128.24  Total Training Translation Loss 6846.99 
2024-01-31 06:23:03,239 EPOCH 672
2024-01-31 06:23:20,816 [Epoch: 672 Step: 00045000] Batch Recognition Loss:  38.539505 => Gls Tokens per Sec:      386 || Batch Translation Loss: 109.662506 => Txt Tokens per Sec:     1085 || Lr: 0.000050
2024-01-31 06:23:28,815 Epoch 672: Total Training Recognition Loss 2127.72  Total Training Translation Loss 6847.85 
2024-01-31 06:23:28,815 EPOCH 673
2024-01-31 06:23:54,447 Epoch 673: Total Training Recognition Loss 2129.88  Total Training Translation Loss 6847.46 
2024-01-31 06:23:54,448 EPOCH 674
2024-01-31 06:23:58,522 [Epoch: 674 Step: 00045100] Batch Recognition Loss:  38.389732 => Gls Tokens per Sec:      331 || Batch Translation Loss: 101.031174 => Txt Tokens per Sec:      956 || Lr: 0.000050
2024-01-31 06:24:20,021 Epoch 674: Total Training Recognition Loss 2127.94  Total Training Translation Loss 6849.18 
2024-01-31 06:24:20,021 EPOCH 675
2024-01-31 06:24:34,249 [Epoch: 675 Step: 00045200] Batch Recognition Loss:  32.769127 => Gls Tokens per Sec:      472 || Batch Translation Loss: 118.707603 => Txt Tokens per Sec:     1292 || Lr: 0.000050
2024-01-31 06:24:45,473 Epoch 675: Total Training Recognition Loss 2125.40  Total Training Translation Loss 6848.83 
2024-01-31 06:24:45,473 EPOCH 676
2024-01-31 06:25:10,796 Epoch 676: Total Training Recognition Loss 2128.49  Total Training Translation Loss 6847.30 
2024-01-31 06:25:10,796 EPOCH 677
2024-01-31 06:25:13,236 [Epoch: 677 Step: 00045300] Batch Recognition Loss:  40.264465 => Gls Tokens per Sec:      525 || Batch Translation Loss: 115.804825 => Txt Tokens per Sec:     1445 || Lr: 0.000050
2024-01-31 06:25:36,158 Epoch 677: Total Training Recognition Loss 2127.09  Total Training Translation Loss 6848.38 
2024-01-31 06:25:36,158 EPOCH 678
2024-01-31 06:25:53,839 [Epoch: 678 Step: 00045400] Batch Recognition Loss:  54.290825 => Gls Tokens per Sec:      366 || Batch Translation Loss: 131.198059 => Txt Tokens per Sec:     1040 || Lr: 0.000050
2024-01-31 06:26:01,547 Epoch 678: Total Training Recognition Loss 2127.19  Total Training Translation Loss 6848.64 
2024-01-31 06:26:01,547 EPOCH 679
2024-01-31 06:26:26,965 Epoch 679: Total Training Recognition Loss 2128.49  Total Training Translation Loss 6849.52 
2024-01-31 06:26:26,965 EPOCH 680
2024-01-31 06:26:29,421 [Epoch: 680 Step: 00045500] Batch Recognition Loss:  34.141281 => Gls Tokens per Sec:      456 || Batch Translation Loss:  97.014427 => Txt Tokens per Sec:     1287 || Lr: 0.000050
2024-01-31 06:26:52,419 Epoch 680: Total Training Recognition Loss 2129.39  Total Training Translation Loss 6847.99 
2024-01-31 06:26:52,419 EPOCH 681
2024-01-31 06:27:07,111 [Epoch: 681 Step: 00045600] Batch Recognition Loss:  13.810049 => Gls Tokens per Sec:      430 || Batch Translation Loss:  79.560333 => Txt Tokens per Sec:     1168 || Lr: 0.000050
2024-01-31 06:27:17,926 Epoch 681: Total Training Recognition Loss 2127.77  Total Training Translation Loss 6849.45 
2024-01-31 06:27:17,926 EPOCH 682
2024-01-31 06:27:43,671 Epoch 682: Total Training Recognition Loss 2124.75  Total Training Translation Loss 6847.02 
2024-01-31 06:27:43,671 EPOCH 683
2024-01-31 06:27:45,846 [Epoch: 683 Step: 00045700] Batch Recognition Loss:  14.037065 => Gls Tokens per Sec:      441 || Batch Translation Loss:  74.583710 => Txt Tokens per Sec:     1163 || Lr: 0.000050
2024-01-31 06:28:09,402 Epoch 683: Total Training Recognition Loss 2122.67  Total Training Translation Loss 6847.73 
2024-01-31 06:28:09,402 EPOCH 684
2024-01-31 06:28:24,280 [Epoch: 684 Step: 00045800] Batch Recognition Loss:  38.202950 => Gls Tokens per Sec:      419 || Batch Translation Loss: 105.130539 => Txt Tokens per Sec:     1178 || Lr: 0.000050
2024-01-31 06:28:35,008 Epoch 684: Total Training Recognition Loss 2128.23  Total Training Translation Loss 6850.57 
2024-01-31 06:28:35,008 EPOCH 685
2024-01-31 06:29:00,465 Epoch 685: Total Training Recognition Loss 2131.55  Total Training Translation Loss 6849.53 
2024-01-31 06:29:00,466 EPOCH 686
2024-01-31 06:29:02,300 [Epoch: 686 Step: 00045900] Batch Recognition Loss:  38.503872 => Gls Tokens per Sec:      437 || Batch Translation Loss: 129.710556 => Txt Tokens per Sec:     1221 || Lr: 0.000050
2024-01-31 06:29:26,249 Epoch 686: Total Training Recognition Loss 2129.53  Total Training Translation Loss 6846.98 
2024-01-31 06:29:26,249 EPOCH 687
2024-01-31 06:29:40,695 [Epoch: 687 Step: 00046000] Batch Recognition Loss:  33.948830 => Gls Tokens per Sec:      415 || Batch Translation Loss:  98.372772 => Txt Tokens per Sec:     1147 || Lr: 0.000050
2024-01-31 06:30:10,292 Validation result at epoch 687, step    46000: duration: 29.5971s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 675.11212	Translation Loss: 73489.01562	PPL: 1562.51099
	Eval Metric: BLEU
	WER 534.18	(DEL: 4.45,	INS: 446.47,	SUB: 83.26)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.46	ROUGE 0.00
2024-01-31 06:30:10,294 Logging Recognition and Translation Outputs
2024-01-31 06:30:10,294 ========================================================================================================================
2024-01-31 06:30:10,294 Logging Sequence: 126_121.00
2024-01-31 06:30:10,295 	Gloss Reference :	***** * ***** * ***** * ***** A B+C+D+E
2024-01-31 06:30:10,295 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E <unk>  
2024-01-31 06:30:10,295 	Gloss Alignment :	I     I I     I I     I I     S S      
2024-01-31 06:30:10,295 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:30:10,297 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** everyone was very happy by  his victory
2024-01-31 06:30:10,297 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>      <s> <s>  <s>   <s> <s> <s>    
2024-01-31 06:30:10,297 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S        S   S    S     S   S   S      
2024-01-31 06:30:10,297 ========================================================================================================================
2024-01-31 06:30:10,297 Logging Sequence: 73_79.00
2024-01-31 06:30:10,298 	Gloss Reference :	***** ***** ***** A ***** * ***** * ***** ***** ***** *************** ***** * ***** ******* B+C+D+E
2024-01-31 06:30:10,298 	Gloss Hypothesis:	<unk> B+C+A <unk> A <unk> C <unk> B <unk> <pad> <unk> C+B+C+B+C+A+B+A <unk> C <unk> B+C+B+C <unk>  
2024-01-31 06:30:10,298 	Gloss Alignment :	I     I     I       I     I I     I I     I     I     I               I     I I     I       S      
2024-01-31 06:30:10,298 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:30:10,302 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** raina resturant has   food  from  the   rich  spices of    north india to    the   aromatic curries of    south india
2024-01-31 06:30:10,302 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo mateo     mateo mateo mateo mateo mateo mateo  mateo mateo mateo mateo mateo mateo    mateo   mateo mateo mateo
2024-01-31 06:30:10,302 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I     I     I     I     I     I     I     I     I     I     I     S     S         S     S     S     S     S     S      S     S     S     S     S     S        S       S     S     S    
2024-01-31 06:30:10,302 ========================================================================================================================
2024-01-31 06:30:10,302 Logging Sequence: 95_152.00
2024-01-31 06:30:10,302 	Gloss Reference :	A ***** B+C+D+E
2024-01-31 06:30:10,303 	Gloss Hypothesis:	A <unk> A+E+A  
2024-01-31 06:30:10,303 	Gloss Alignment :	  I     S      
2024-01-31 06:30:10,303 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:30:10,304 	Text Reference  :	*** *** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** how      strange 
2024-01-31 06:30:10,304 	Text Hypothesis :	<s> <s> indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit indrajit
2024-01-31 06:30:10,304 	Text Alignment  :	I   I   I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S       
2024-01-31 06:30:10,304 ========================================================================================================================
2024-01-31 06:30:10,304 Logging Sequence: 135_39.00
2024-01-31 06:30:10,304 	Gloss Reference :	***** ******* ***** * ***** * ***** *************** ***** * ***** * ***** * ***** ********************* ***** A B+C+D+E
2024-01-31 06:30:10,305 	Gloss Hypothesis:	<unk> E+A+B+A <unk> B <unk> B <unk> E+B+E+B+E+B+E+B <unk> E <unk> B <unk> E <unk> B+C+E+B+E+A+E+C+A+C+E <unk> E <unk>  
2024-01-31 06:30:10,305 	Gloss Alignment :	I     I       I     I I     I I     I               I     I I     I I     I I     I                     I     S S      
2024-01-31 06:30:10,305 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:30:10,307 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** who needs to  travel from poland to  stanford university in  california
2024-01-31 06:30:10,307 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>   <s> <s>    <s>  <s>    <s> <s>      <s>        <s> <s>       
2024-01-31 06:30:10,308 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S     S   S      S    S      S   S        S          S   S         
2024-01-31 06:30:10,308 ========================================================================================================================
2024-01-31 06:30:10,308 Logging Sequence: 87_2.00
2024-01-31 06:30:10,308 	Gloss Reference :	* ***** ***** * ***** ******* ***** * ***** ********* A     B+C+D+E              
2024-01-31 06:30:10,308 	Gloss Hypothesis:	D E+D+E <unk> E <unk> E+D+E+D <unk> E <unk> D+E+D+E+D <unk> E+D+E+D+E+D+E+D+E+D+E
2024-01-31 06:30:10,308 	Gloss Alignment :	I I     I     I I     I       I     I I     I         S     S                    
2024-01-31 06:30:10,308 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:30:10,312 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** cricketer gautam gambhir's jealousy against ms  dhoni and virat kohli has been increasing day by  day
2024-01-31 06:30:10,312 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>       <s>    <s>       <s>      <s>     <s> <s>   <s> <s>   <s>   <s> <s>  <s>        <s> <s> <s>
2024-01-31 06:30:10,312 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S         S      S         S        S       S   S     S   S     S     S   S    S          S   S   S  
2024-01-31 06:30:10,312 ========================================================================================================================
2024-01-31 06:30:21,365 Epoch 687: Total Training Recognition Loss 2121.61  Total Training Translation Loss 6847.56 
2024-01-31 06:30:21,366 EPOCH 688
2024-01-31 06:30:46,905 Epoch 688: Total Training Recognition Loss 2125.28  Total Training Translation Loss 6848.62 
2024-01-31 06:30:46,906 EPOCH 689
2024-01-31 06:30:47,836 [Epoch: 689 Step: 00046100] Batch Recognition Loss:  22.893959 => Gls Tokens per Sec:      689 || Batch Translation Loss: 100.070503 => Txt Tokens per Sec:     1681 || Lr: 0.000050
2024-01-31 06:31:12,535 Epoch 689: Total Training Recognition Loss 2125.98  Total Training Translation Loss 6849.67 
2024-01-31 06:31:12,535 EPOCH 690
2024-01-31 06:31:28,152 [Epoch: 690 Step: 00046200] Batch Recognition Loss:  18.466110 => Gls Tokens per Sec:      373 || Batch Translation Loss:  92.913223 => Txt Tokens per Sec:     1058 || Lr: 0.000050
2024-01-31 06:31:38,133 Epoch 690: Total Training Recognition Loss 2127.25  Total Training Translation Loss 6849.81 
2024-01-31 06:31:38,134 EPOCH 691
2024-01-31 06:32:03,761 Epoch 691: Total Training Recognition Loss 2126.50  Total Training Translation Loss 6850.41 
2024-01-31 06:32:03,762 EPOCH 692
2024-01-31 06:32:04,696 [Epoch: 692 Step: 00046300] Batch Recognition Loss:  19.601368 => Gls Tokens per Sec:      514 || Batch Translation Loss:  94.815186 => Txt Tokens per Sec:     1383 || Lr: 0.000050
2024-01-31 06:32:29,198 Epoch 692: Total Training Recognition Loss 2131.19  Total Training Translation Loss 6849.39 
2024-01-31 06:32:29,198 EPOCH 693
2024-01-31 06:32:43,755 [Epoch: 693 Step: 00046400] Batch Recognition Loss:  45.035538 => Gls Tokens per Sec:      390 || Batch Translation Loss: 124.669548 => Txt Tokens per Sec:     1086 || Lr: 0.000050
2024-01-31 06:32:54,842 Epoch 693: Total Training Recognition Loss 2125.88  Total Training Translation Loss 6848.92 
2024-01-31 06:32:54,842 EPOCH 694
2024-01-31 06:33:20,475 Epoch 694: Total Training Recognition Loss 2127.87  Total Training Translation Loss 6848.85 
2024-01-31 06:33:20,476 EPOCH 695
2024-01-31 06:33:20,902 [Epoch: 695 Step: 00046500] Batch Recognition Loss:  22.900982 => Gls Tokens per Sec:      755 || Batch Translation Loss:  82.473900 => Txt Tokens per Sec:     1700 || Lr: 0.000050
2024-01-31 06:33:46,058 Epoch 695: Total Training Recognition Loss 2129.80  Total Training Translation Loss 6848.30 
2024-01-31 06:33:46,058 EPOCH 696
2024-01-31 06:33:59,756 [Epoch: 696 Step: 00046600] Batch Recognition Loss:  33.301926 => Gls Tokens per Sec:      402 || Batch Translation Loss: 100.425003 => Txt Tokens per Sec:     1081 || Lr: 0.000050
2024-01-31 06:34:11,776 Epoch 696: Total Training Recognition Loss 2127.81  Total Training Translation Loss 6850.15 
2024-01-31 06:34:11,776 EPOCH 697
2024-01-31 06:34:37,281 Epoch 697: Total Training Recognition Loss 2126.62  Total Training Translation Loss 6847.82 
2024-01-31 06:34:37,281 EPOCH 698
2024-01-31 06:34:37,624 [Epoch: 698 Step: 00046700] Batch Recognition Loss:  33.644867 => Gls Tokens per Sec:      468 || Batch Translation Loss: 108.111900 => Txt Tokens per Sec:     1371 || Lr: 0.000050
2024-01-31 06:35:02,923 Epoch 698: Total Training Recognition Loss 2125.93  Total Training Translation Loss 6846.84 
2024-01-31 06:35:02,923 EPOCH 699
2024-01-31 06:35:16,334 [Epoch: 699 Step: 00046800] Batch Recognition Loss:  19.973297 => Gls Tokens per Sec:      399 || Batch Translation Loss:  85.983200 => Txt Tokens per Sec:     1091 || Lr: 0.000050
2024-01-31 06:35:28,610 Epoch 699: Total Training Recognition Loss 2127.80  Total Training Translation Loss 6847.83 
2024-01-31 06:35:28,610 EPOCH 700
2024-01-31 06:35:54,200 [Epoch: 700 Step: 00046900] Batch Recognition Loss:  37.716923 => Gls Tokens per Sec:      415 || Batch Translation Loss: 111.670891 => Txt Tokens per Sec:     1153 || Lr: 0.000050
2024-01-31 06:35:54,200 Epoch 700: Total Training Recognition Loss 2132.67  Total Training Translation Loss 6848.80 
2024-01-31 06:35:54,200 EPOCH 701
2024-01-31 06:36:19,835 Epoch 701: Total Training Recognition Loss 2125.50  Total Training Translation Loss 6846.58 
2024-01-31 06:36:19,835 EPOCH 702
2024-01-31 06:36:31,992 [Epoch: 702 Step: 00047000] Batch Recognition Loss:  37.272591 => Gls Tokens per Sec:      427 || Batch Translation Loss: 103.924927 => Txt Tokens per Sec:     1177 || Lr: 0.000050
2024-01-31 06:36:45,342 Epoch 702: Total Training Recognition Loss 2127.86  Total Training Translation Loss 6848.47 
2024-01-31 06:36:45,343 EPOCH 703
2024-01-31 06:37:10,618 [Epoch: 703 Step: 00047100] Batch Recognition Loss:  18.755167 => Gls Tokens per Sec:      414 || Batch Translation Loss:  89.571701 => Txt Tokens per Sec:     1149 || Lr: 0.000050
2024-01-31 06:37:10,958 Epoch 703: Total Training Recognition Loss 2124.27  Total Training Translation Loss 6850.05 
2024-01-31 06:37:10,959 EPOCH 704
2024-01-31 06:37:36,516 Epoch 704: Total Training Recognition Loss 2124.07  Total Training Translation Loss 6846.73 
2024-01-31 06:37:36,516 EPOCH 705
2024-01-31 06:37:47,594 [Epoch: 705 Step: 00047200] Batch Recognition Loss:  33.477394 => Gls Tokens per Sec:      454 || Batch Translation Loss:  96.578934 => Txt Tokens per Sec:     1210 || Lr: 0.000050
2024-01-31 06:38:02,032 Epoch 705: Total Training Recognition Loss 2129.25  Total Training Translation Loss 6846.79 
2024-01-31 06:38:02,032 EPOCH 706
2024-01-31 06:38:25,930 [Epoch: 706 Step: 00047300] Batch Recognition Loss:  32.225571 => Gls Tokens per Sec:      435 || Batch Translation Loss: 100.421600 => Txt Tokens per Sec:     1204 || Lr: 0.000050
2024-01-31 06:38:27,584 Epoch 706: Total Training Recognition Loss 2127.82  Total Training Translation Loss 6846.83 
2024-01-31 06:38:27,585 EPOCH 707
2024-01-31 06:38:53,223 Epoch 707: Total Training Recognition Loss 2128.83  Total Training Translation Loss 6847.93 
2024-01-31 06:38:53,223 EPOCH 708
2024-01-31 06:39:05,281 [Epoch: 708 Step: 00047400] Batch Recognition Loss:  45.559753 => Gls Tokens per Sec:      404 || Batch Translation Loss: 128.421417 => Txt Tokens per Sec:     1108 || Lr: 0.000050
2024-01-31 06:39:18,793 Epoch 708: Total Training Recognition Loss 2127.95  Total Training Translation Loss 6848.71 
2024-01-31 06:39:18,793 EPOCH 709
2024-01-31 06:39:42,823 [Epoch: 709 Step: 00047500] Batch Recognition Loss:  39.847767 => Gls Tokens per Sec:      422 || Batch Translation Loss: 116.473846 => Txt Tokens per Sec:     1162 || Lr: 0.000050
2024-01-31 06:39:44,198 Epoch 709: Total Training Recognition Loss 2124.07  Total Training Translation Loss 6848.76 
2024-01-31 06:39:44,199 EPOCH 710
2024-01-31 06:40:09,803 Epoch 710: Total Training Recognition Loss 2126.31  Total Training Translation Loss 6849.29 
2024-01-31 06:40:09,803 EPOCH 711
2024-01-31 06:40:19,623 [Epoch: 711 Step: 00047600] Batch Recognition Loss:  29.738899 => Gls Tokens per Sec:      489 || Batch Translation Loss: 108.972229 => Txt Tokens per Sec:     1349 || Lr: 0.000050
2024-01-31 06:40:35,395 Epoch 711: Total Training Recognition Loss 2127.82  Total Training Translation Loss 6849.59 
2024-01-31 06:40:35,395 EPOCH 712
2024-01-31 06:40:59,492 [Epoch: 712 Step: 00047700] Batch Recognition Loss:  37.771465 => Gls Tokens per Sec:      415 || Batch Translation Loss: 117.112122 => Txt Tokens per Sec:     1145 || Lr: 0.000050
2024-01-31 06:41:00,854 Epoch 712: Total Training Recognition Loss 2122.36  Total Training Translation Loss 6848.82 
2024-01-31 06:41:00,854 EPOCH 713
2024-01-31 06:41:26,347 Epoch 713: Total Training Recognition Loss 2119.75  Total Training Translation Loss 6849.74 
2024-01-31 06:41:26,347 EPOCH 714
2024-01-31 06:41:36,640 [Epoch: 714 Step: 00047800] Batch Recognition Loss:  36.166267 => Gls Tokens per Sec:      442 || Batch Translation Loss: 116.393433 => Txt Tokens per Sec:     1189 || Lr: 0.000050
2024-01-31 06:41:51,920 Epoch 714: Total Training Recognition Loss 2127.71  Total Training Translation Loss 6850.45 
2024-01-31 06:41:51,920 EPOCH 715
2024-01-31 06:42:15,782 [Epoch: 715 Step: 00047900] Batch Recognition Loss:  37.817696 => Gls Tokens per Sec:      412 || Batch Translation Loss: 109.538803 => Txt Tokens per Sec:     1138 || Lr: 0.000050
2024-01-31 06:42:17,509 Epoch 715: Total Training Recognition Loss 2127.01  Total Training Translation Loss 6847.58 
2024-01-31 06:42:17,509 EPOCH 716
2024-01-31 06:42:43,037 Epoch 716: Total Training Recognition Loss 2126.21  Total Training Translation Loss 6849.53 
2024-01-31 06:42:43,038 EPOCH 717
2024-01-31 06:42:54,331 [Epoch: 717 Step: 00048000] Batch Recognition Loss:  38.333405 => Gls Tokens per Sec:      389 || Batch Translation Loss: 102.723648 => Txt Tokens per Sec:     1090 || Lr: 0.000050
2024-01-31 06:43:23,444 Validation result at epoch 717, step    48000: duration: 29.1114s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 674.36646	Translation Loss: 73495.90625	PPL: 1563.58862
	Eval Metric: BLEU
	WER 535.10	(DEL: 4.45,	INS: 447.18,	SUB: 83.47)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.46	ROUGE 0.01
2024-01-31 06:43:23,445 Logging Recognition and Translation Outputs
2024-01-31 06:43:23,445 ========================================================================================================================
2024-01-31 06:43:23,445 Logging Sequence: 88_159.00
2024-01-31 06:43:23,446 	Gloss Reference :	***** * ***** * ***** A B+C+D+E
2024-01-31 06:43:23,446 	Gloss Hypothesis:	<unk> B <unk> B <unk> B <unk>  
2024-01-31 06:43:23,446 	Gloss Alignment :	I     I I     I I     S S      
2024-01-31 06:43:23,446 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:43:23,448 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** however he  often comes to  the town to  meet his relatives
2024-01-31 06:43:23,448 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s> <s>   <s>   <s> <s> <s>  <s> <s>  <s> <s>      
2024-01-31 06:43:23,449 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S       S   S     S     S   S   S    S   S    S   S        
2024-01-31 06:43:23,449 ========================================================================================================================
2024-01-31 06:43:23,449 Logging Sequence: 180_53.00
2024-01-31 06:43:23,449 	Gloss Reference :	A ***** *********** ***** *** ***** B+C+D+E
2024-01-31 06:43:23,449 	Gloss Hypothesis:	A <unk> E+A+C+E+A+C <unk> E+A <unk> E      
2024-01-31 06:43:23,449 	Gloss Alignment :	  I     I           I     I   I     S      
2024-01-31 06:43:23,450 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:43:23,451 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** the protest is  against singh again
2024-01-31 06:43:23,451 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s> <s>     <s>   <s>  
2024-01-31 06:43:23,451 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S       S   S       S     S    
2024-01-31 06:43:23,451 ========================================================================================================================
2024-01-31 06:43:23,452 Logging Sequence: 163_30.00
2024-01-31 06:43:23,452 	Gloss Reference :	***** ***** ***** ***** A ***** ***** ***** ***** * ***** ***** * ***** * ***** ***** ***** * ***** ***** ***** B+C+D+E
2024-01-31 06:43:23,452 	Gloss Hypothesis:	<pad> <unk> <pad> <unk> A <unk> <pad> <unk> <pad> E <pad> <unk> E <unk> E <unk> <pad> <unk> E <unk> <pad> <unk> <pad>  
2024-01-31 06:43:23,452 	Gloss Alignment :	I     I     I     I       I     I     I     I     I I     I     I I     I I     I     I     I I     I     I     S      
2024-01-31 06:43:23,452 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:43:23,454 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** they  never permitted anyone to    reveal her   face 
2024-01-31 06:43:23,454 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby bobby     bobby  bobby bobby  bobby bobby
2024-01-31 06:43:23,455 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S         S      S     S      S     S    
2024-01-31 06:43:23,455 ========================================================================================================================
2024-01-31 06:43:23,455 Logging Sequence: 51_110.00
2024-01-31 06:43:23,455 	Gloss Reference :	A B+C+D+E
2024-01-31 06:43:23,455 	Gloss Hypothesis:	* E      
2024-01-31 06:43:23,455 	Gloss Alignment :	D S      
2024-01-31 06:43:23,455 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:43:23,457 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** the aussies were very happy with their victory
2024-01-31 06:43:23,457 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s>  <s>  <s>   <s>  <s>   <s>    
2024-01-31 06:43:23,457 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S       S    S    S     S    S     S      
2024-01-31 06:43:23,458 ========================================================================================================================
2024-01-31 06:43:23,458 Logging Sequence: 70_249.00
2024-01-31 06:43:23,458 	Gloss Reference :	***** * ***** * ***** * ***** ***** ***** * ***** * ***** * ***** A B+C+D+E
2024-01-31 06:43:23,458 	Gloss Hypothesis:	<unk> E <unk> E <unk> E <unk> E+C+E <unk> E <unk> E <unk> C <unk> E <unk>  
2024-01-31 06:43:23,458 	Gloss Alignment :	I     I I     I I     I I     I     I     I I     I I     I I     S S      
2024-01-31 06:43:23,458 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:43:23,460 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** have a   look at  this video
2024-01-31 06:43:23,460 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s>  <s> <s>  <s>  
2024-01-31 06:43:23,460 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S    S   S    S   S    S    
2024-01-31 06:43:23,460 ========================================================================================================================
2024-01-31 06:43:37,742 Epoch 717: Total Training Recognition Loss 2128.21  Total Training Translation Loss 6850.65 
2024-01-31 06:43:37,743 EPOCH 718
2024-01-31 06:44:01,465 [Epoch: 718 Step: 00048100] Batch Recognition Loss:  36.814117 => Gls Tokens per Sec:      408 || Batch Translation Loss: 107.449005 => Txt Tokens per Sec:     1143 || Lr: 0.000050
2024-01-31 06:44:03,381 Epoch 718: Total Training Recognition Loss 2126.07  Total Training Translation Loss 6847.33 
2024-01-31 06:44:03,381 EPOCH 719
2024-01-31 06:44:29,130 Epoch 719: Total Training Recognition Loss 2127.83  Total Training Translation Loss 6849.22 
2024-01-31 06:44:29,130 EPOCH 720
2024-01-31 06:44:41,380 [Epoch: 720 Step: 00048200] Batch Recognition Loss:  27.789082 => Gls Tokens per Sec:      345 || Batch Translation Loss:  91.366867 => Txt Tokens per Sec:     1021 || Lr: 0.000050
2024-01-31 06:44:54,687 Epoch 720: Total Training Recognition Loss 2125.39  Total Training Translation Loss 6848.51 
2024-01-31 06:44:54,687 EPOCH 721
2024-01-31 06:45:18,223 [Epoch: 721 Step: 00048300] Batch Recognition Loss:  23.153759 => Gls Tokens per Sec:      404 || Batch Translation Loss: 101.047943 => Txt Tokens per Sec:     1124 || Lr: 0.000050
2024-01-31 06:45:20,361 Epoch 721: Total Training Recognition Loss 2129.39  Total Training Translation Loss 6847.98 
2024-01-31 06:45:20,361 EPOCH 722
2024-01-31 06:45:46,009 Epoch 722: Total Training Recognition Loss 2126.00  Total Training Translation Loss 6847.91 
2024-01-31 06:45:46,010 EPOCH 723
2024-01-31 06:45:56,169 [Epoch: 723 Step: 00048400] Batch Recognition Loss:  44.747360 => Gls Tokens per Sec:      410 || Batch Translation Loss: 121.141167 => Txt Tokens per Sec:     1173 || Lr: 0.000050
2024-01-31 06:46:11,812 Epoch 723: Total Training Recognition Loss 2123.45  Total Training Translation Loss 6846.16 
2024-01-31 06:46:11,813 EPOCH 724
2024-01-31 06:46:35,004 [Epoch: 724 Step: 00048500] Batch Recognition Loss:  44.606796 => Gls Tokens per Sec:      403 || Batch Translation Loss: 125.558105 => Txt Tokens per Sec:     1135 || Lr: 0.000050
2024-01-31 06:46:37,191 Epoch 724: Total Training Recognition Loss 2127.48  Total Training Translation Loss 6848.81 
2024-01-31 06:46:37,191 EPOCH 725
2024-01-31 06:47:02,712 Epoch 725: Total Training Recognition Loss 2126.11  Total Training Translation Loss 6848.89 
2024-01-31 06:47:02,712 EPOCH 726
2024-01-31 06:47:14,225 [Epoch: 726 Step: 00048600] Batch Recognition Loss:  37.847870 => Gls Tokens per Sec:      347 || Batch Translation Loss: 116.419662 => Txt Tokens per Sec:      993 || Lr: 0.000050
2024-01-31 06:47:28,323 Epoch 726: Total Training Recognition Loss 2127.25  Total Training Translation Loss 6848.33 
2024-01-31 06:47:28,323 EPOCH 727
2024-01-31 06:47:54,180 [Epoch: 727 Step: 00048700] Batch Recognition Loss:  38.598938 => Gls Tokens per Sec:      355 || Batch Translation Loss: 120.850334 => Txt Tokens per Sec:      996 || Lr: 0.000050
2024-01-31 06:47:57,005 Epoch 727: Total Training Recognition Loss 2129.76  Total Training Translation Loss 6849.48 
2024-01-31 06:47:57,005 EPOCH 728
2024-01-31 06:48:23,736 Epoch 728: Total Training Recognition Loss 2126.26  Total Training Translation Loss 6848.64 
2024-01-31 06:48:23,737 EPOCH 729
2024-01-31 06:48:32,488 [Epoch: 729 Step: 00048800] Batch Recognition Loss:  52.820213 => Gls Tokens per Sec:      439 || Batch Translation Loss: 128.480560 => Txt Tokens per Sec:     1196 || Lr: 0.000050
2024-01-31 06:48:49,460 Epoch 729: Total Training Recognition Loss 2127.57  Total Training Translation Loss 6848.04 
2024-01-31 06:48:49,461 EPOCH 730
2024-01-31 06:49:11,624 [Epoch: 730 Step: 00048900] Batch Recognition Loss:  36.694225 => Gls Tokens per Sec:      407 || Batch Translation Loss: 112.237328 => Txt Tokens per Sec:     1125 || Lr: 0.000050
2024-01-31 06:49:15,127 Epoch 730: Total Training Recognition Loss 2126.11  Total Training Translation Loss 6847.00 
2024-01-31 06:49:15,127 EPOCH 731
2024-01-31 06:49:40,827 Epoch 731: Total Training Recognition Loss 2131.39  Total Training Translation Loss 6848.05 
2024-01-31 06:49:40,828 EPOCH 732
2024-01-31 06:49:49,722 [Epoch: 732 Step: 00049000] Batch Recognition Loss:  37.880417 => Gls Tokens per Sec:      414 || Batch Translation Loss: 102.376587 => Txt Tokens per Sec:     1140 || Lr: 0.000050
2024-01-31 06:50:06,401 Epoch 732: Total Training Recognition Loss 2121.77  Total Training Translation Loss 6848.54 
2024-01-31 06:50:06,401 EPOCH 733
2024-01-31 06:50:28,372 [Epoch: 733 Step: 00049100] Batch Recognition Loss:  22.458340 => Gls Tokens per Sec:      404 || Batch Translation Loss:  80.966286 => Txt Tokens per Sec:     1126 || Lr: 0.000050
2024-01-31 06:50:32,004 Epoch 733: Total Training Recognition Loss 2124.31  Total Training Translation Loss 6847.92 
2024-01-31 06:50:32,004 EPOCH 734
2024-01-31 06:50:57,727 Epoch 734: Total Training Recognition Loss 2129.72  Total Training Translation Loss 6846.48 
2024-01-31 06:50:57,727 EPOCH 735
2024-01-31 06:51:07,677 [Epoch: 735 Step: 00049200] Batch Recognition Loss:  44.392036 => Gls Tokens per Sec:      345 || Batch Translation Loss: 120.541351 => Txt Tokens per Sec:      976 || Lr: 0.000050
2024-01-31 06:51:23,178 Epoch 735: Total Training Recognition Loss 2126.02  Total Training Translation Loss 6850.06 
2024-01-31 06:51:23,178 EPOCH 736
2024-01-31 06:51:43,390 [Epoch: 736 Step: 00049300] Batch Recognition Loss:  36.769630 => Gls Tokens per Sec:      431 || Batch Translation Loss: 108.331436 => Txt Tokens per Sec:     1177 || Lr: 0.000050
2024-01-31 06:51:48,736 Epoch 736: Total Training Recognition Loss 2121.19  Total Training Translation Loss 6847.73 
2024-01-31 06:51:48,736 EPOCH 737
2024-01-31 06:52:14,276 Epoch 737: Total Training Recognition Loss 2129.98  Total Training Translation Loss 6848.96 
2024-01-31 06:52:14,276 EPOCH 738
2024-01-31 06:52:22,829 [Epoch: 738 Step: 00049400] Batch Recognition Loss:  54.325726 => Gls Tokens per Sec:      382 || Batch Translation Loss: 127.173508 => Txt Tokens per Sec:     1030 || Lr: 0.000050
2024-01-31 06:52:39,823 Epoch 738: Total Training Recognition Loss 2128.66  Total Training Translation Loss 6848.59 
2024-01-31 06:52:39,823 EPOCH 739
2024-01-31 06:53:00,263 [Epoch: 739 Step: 00049500] Batch Recognition Loss:  22.869534 => Gls Tokens per Sec:      418 || Batch Translation Loss:  86.159157 => Txt Tokens per Sec:     1145 || Lr: 0.000050
2024-01-31 06:53:05,313 Epoch 739: Total Training Recognition Loss 2128.48  Total Training Translation Loss 6847.50 
2024-01-31 06:53:05,314 EPOCH 740
2024-01-31 06:53:30,869 Epoch 740: Total Training Recognition Loss 2126.33  Total Training Translation Loss 6846.85 
2024-01-31 06:53:30,870 EPOCH 741
2024-01-31 06:53:39,692 [Epoch: 741 Step: 00049600] Batch Recognition Loss:  27.112293 => Gls Tokens per Sec:      363 || Batch Translation Loss: 106.468597 => Txt Tokens per Sec:     1048 || Lr: 0.000050
2024-01-31 06:53:56,346 Epoch 741: Total Training Recognition Loss 2124.51  Total Training Translation Loss 6848.80 
2024-01-31 06:53:56,346 EPOCH 742
2024-01-31 06:54:16,251 [Epoch: 742 Step: 00049700] Batch Recognition Loss:  17.226027 => Gls Tokens per Sec:      426 || Batch Translation Loss:  80.209419 => Txt Tokens per Sec:     1189 || Lr: 0.000050
2024-01-31 06:54:21,877 Epoch 742: Total Training Recognition Loss 2120.57  Total Training Translation Loss 6849.04 
2024-01-31 06:54:21,878 EPOCH 743
2024-01-31 06:54:47,457 Epoch 743: Total Training Recognition Loss 2124.83  Total Training Translation Loss 6848.33 
2024-01-31 06:54:47,458 EPOCH 744
2024-01-31 06:54:56,618 [Epoch: 744 Step: 00049800] Batch Recognition Loss:  43.874474 => Gls Tokens per Sec:      322 || Batch Translation Loss: 131.315170 => Txt Tokens per Sec:      957 || Lr: 0.000050
2024-01-31 06:55:12,727 Epoch 744: Total Training Recognition Loss 2128.75  Total Training Translation Loss 6849.54 
2024-01-31 06:55:12,727 EPOCH 745
2024-01-31 06:55:33,904 [Epoch: 745 Step: 00049900] Batch Recognition Loss:  12.300404 => Gls Tokens per Sec:      389 || Batch Translation Loss:  64.621246 => Txt Tokens per Sec:     1096 || Lr: 0.000050
2024-01-31 06:55:38,205 Epoch 745: Total Training Recognition Loss 2127.49  Total Training Translation Loss 6848.69 
2024-01-31 06:55:38,205 EPOCH 746
2024-01-31 06:56:03,827 Epoch 746: Total Training Recognition Loss 2121.92  Total Training Translation Loss 6849.59 
2024-01-31 06:56:03,827 EPOCH 747
2024-01-31 06:56:10,297 [Epoch: 747 Step: 00050000] Batch Recognition Loss:  23.395115 => Gls Tokens per Sec:      445 || Batch Translation Loss: 101.171997 => Txt Tokens per Sec:     1223 || Lr: 0.000050
2024-01-31 06:56:40,094 Validation result at epoch 747, step    50000: duration: 29.7961s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 679.90265	Translation Loss: 73493.68750	PPL: 1563.24146
	Eval Metric: BLEU
	WER 543.22	(DEL: 4.31,	INS: 454.80,	SUB: 84.11)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.34	ROUGE 0.00
2024-01-31 06:56:40,095 Logging Recognition and Translation Outputs
2024-01-31 06:56:40,095 ========================================================================================================================
2024-01-31 06:56:40,095 Logging Sequence: 59_58.00
2024-01-31 06:56:40,096 	Gloss Reference :	***** ***** * ***** * ***** A B+C+D+E
2024-01-31 06:56:40,096 	Gloss Hypothesis:	<pad> <unk> E <unk> E <unk> E <unk>  
2024-01-31 06:56:40,096 	Gloss Alignment :	I     I     I I     I I     S S      
2024-01-31 06:56:40,096 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:56:40,099 	Text Reference  :	************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* to            fix           the           damage        they          did           not           have          a             lot           of            time         
2024-01-31 06:56:40,099 	Text Hypothesis :	misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 06:56:40,099 	Text Alignment  :	I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 06:56:40,099 ========================================================================================================================
2024-01-31 06:56:40,099 Logging Sequence: 165_2.00
2024-01-31 06:56:40,100 	Gloss Reference :	A *** ***** B+C+D+E          
2024-01-31 06:56:40,100 	Gloss Hypothesis:	A E+C <pad> E+C+E+C+E+C+E+C+E
2024-01-31 06:56:40,100 	Gloss Alignment :	  I   I     S                
2024-01-31 06:56:40,100 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:56:40,103 	Text Reference  :	*** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* many          people        believe       in            superstitions and           think         it            brings        good          luck          and           bad           luck         
2024-01-31 06:56:40,103 	Text Hypothesis :	<s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 06:56:40,103 	Text Alignment  :	I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 06:56:40,103 ========================================================================================================================
2024-01-31 06:56:40,103 Logging Sequence: 58_147.00
2024-01-31 06:56:40,104 	Gloss Reference :	***** * ***** * ***** A B+C+D+E
2024-01-31 06:56:40,104 	Gloss Hypothesis:	<unk> E <unk> B <unk> B <unk>  
2024-01-31 06:56:40,104 	Gloss Alignment :	I     I I     I I     S S      
2024-01-31 06:56:40,104 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:56:40,108 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** the women's cricket team grabbed gold by  beating sri lanka in  the finals what a   historic win
2024-01-31 06:56:40,108 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s>     <s>  <s>     <s>  <s> <s>     <s> <s>   <s> <s> <s>    <s>  <s> <s>      <s>
2024-01-31 06:56:40,108 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S       S       S    S       S    S   S       S   S     S   S   S      S    S   S        S  
2024-01-31 06:56:40,108 ========================================================================================================================
2024-01-31 06:56:40,108 Logging Sequence: 81_139.00
2024-01-31 06:56:40,108 	Gloss Reference :	***** * ***** ********* ***** ******************************* ***** ***************** A     B+C+D+E      
2024-01-31 06:56:40,109 	Gloss Hypothesis:	<unk> D <unk> D+E+D+E+D <unk> E+D+B+D+E+B+D+B+C+E+C+B+D+E+D+E <unk> E+B+E+C+E+B+E+D+C <unk> E+C+E+C+E+B+E
2024-01-31 06:56:40,109 	Gloss Alignment :	I     I I     I         I     I                               I     I                 S     S            
2024-01-31 06:56:40,109 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:56:40,113 	Text Reference  :	*** *** *** *** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* in            2017          the           case          was           filed         first         in            delhi         high          court         by            rhiti         sports        management    on            behalf        of            dhoni        
2024-01-31 06:56:40,113 	Text Hypothesis :	<s> <s> <s> <s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 06:56:40,113 	Text Alignment  :	I   I   I   I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 06:56:40,113 ========================================================================================================================
2024-01-31 06:56:40,113 Logging Sequence: 125_72.00
2024-01-31 06:56:40,114 	Gloss Reference :	***** ***** * ***** ***** ***** *** ***** ******* ***** ***** ***** * ***** ***** ******* ***** * ***** * ***** ***************************** A     B+C+D+E
2024-01-31 06:56:40,114 	Gloss Hypothesis:	<unk> <pad> E <unk> E+B+C <unk> E+B <pad> B+E+B+E <pad> E+B+E <unk> E <pad> <unk> C+E+B+E <pad> E <unk> E <unk> E+B+E+B+E+B+E+B+C+B+C+E+C+B+E <pad> C+E+C+E
2024-01-31 06:56:40,114 	Gloss Alignment :	I     I     I I     I     I     I   I     I       I     I     I     I I     I     I       I     I I     I I     I                             S     S      
2024-01-31 06:56:40,114 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 06:56:40,118 	Text Reference  :	*** *** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** some  said  the   pakistani javelineer had   milicious intentions of    tampering with  the   javelin out   of    jealousy
2024-01-31 06:56:40,118 	Text Hypothesis :	<s> <s> sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha     sabha      sabha sabha     sabha      sabha sabha     sabha sabha sabha   sabha sabha sabha   
2024-01-31 06:56:40,118 	Text Alignment  :	I   I   I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S     S     S         S          S     S         S          S     S         S     S     S       S     S     S       
2024-01-31 06:56:40,118 ========================================================================================================================
2024-01-31 06:56:59,108 Epoch 747: Total Training Recognition Loss 2126.34  Total Training Translation Loss 6849.16 
2024-01-31 06:56:59,108 EPOCH 748
2024-01-31 06:57:19,067 [Epoch: 748 Step: 00050100] Batch Recognition Loss:  23.097824 => Gls Tokens per Sec:      404 || Batch Translation Loss:  94.863808 => Txt Tokens per Sec:     1109 || Lr: 0.000050
2024-01-31 06:57:24,724 Epoch 748: Total Training Recognition Loss 2129.34  Total Training Translation Loss 6847.73 
2024-01-31 06:57:24,724 EPOCH 749
2024-01-31 06:57:50,259 Epoch 749: Total Training Recognition Loss 2124.54  Total Training Translation Loss 6850.43 
2024-01-31 06:57:50,260 EPOCH 750
2024-01-31 06:57:55,645 [Epoch: 750 Step: 00050200] Batch Recognition Loss:  16.508522 => Gls Tokens per Sec:      505 || Batch Translation Loss:  68.884254 => Txt Tokens per Sec:     1361 || Lr: 0.000050
2024-01-31 06:58:15,777 Epoch 750: Total Training Recognition Loss 2130.01  Total Training Translation Loss 6847.78 
2024-01-31 06:58:15,778 EPOCH 751
2024-01-31 06:58:33,906 [Epoch: 751 Step: 00050300] Batch Recognition Loss:  38.688011 => Gls Tokens per Sec:      441 || Batch Translation Loss: 120.845779 => Txt Tokens per Sec:     1220 || Lr: 0.000050
2024-01-31 06:58:41,108 Epoch 751: Total Training Recognition Loss 2130.60  Total Training Translation Loss 6848.67 
2024-01-31 06:58:41,108 EPOCH 752
2024-01-31 06:59:06,748 Epoch 752: Total Training Recognition Loss 2124.05  Total Training Translation Loss 6847.81 
2024-01-31 06:59:06,748 EPOCH 753
2024-01-31 06:59:11,936 [Epoch: 753 Step: 00050400] Batch Recognition Loss:  22.925583 => Gls Tokens per Sec:      494 || Batch Translation Loss:  96.051315 => Txt Tokens per Sec:     1331 || Lr: 0.000050
2024-01-31 06:59:32,372 Epoch 753: Total Training Recognition Loss 2131.65  Total Training Translation Loss 6848.58 
2024-01-31 06:59:32,372 EPOCH 754
2024-01-31 06:59:51,930 [Epoch: 754 Step: 00050500] Batch Recognition Loss:  18.110546 => Gls Tokens per Sec:      401 || Batch Translation Loss:  86.633362 => Txt Tokens per Sec:     1142 || Lr: 0.000050
2024-01-31 06:59:57,974 Epoch 754: Total Training Recognition Loss 2128.47  Total Training Translation Loss 6848.63 
2024-01-31 06:59:57,974 EPOCH 755
2024-01-31 07:00:23,623 Epoch 755: Total Training Recognition Loss 2123.96  Total Training Translation Loss 6850.65 
2024-01-31 07:00:23,624 EPOCH 756
2024-01-31 07:00:28,889 [Epoch: 756 Step: 00050600] Batch Recognition Loss:  38.014290 => Gls Tokens per Sec:      456 || Batch Translation Loss: 118.275253 => Txt Tokens per Sec:     1268 || Lr: 0.000050
2024-01-31 07:00:49,220 Epoch 756: Total Training Recognition Loss 2125.33  Total Training Translation Loss 6848.38 
2024-01-31 07:00:49,221 EPOCH 757
2024-01-31 07:01:07,612 [Epoch: 757 Step: 00050700] Batch Recognition Loss:  23.735859 => Gls Tokens per Sec:      418 || Batch Translation Loss:  97.210632 => Txt Tokens per Sec:     1158 || Lr: 0.000050
2024-01-31 07:01:14,765 Epoch 757: Total Training Recognition Loss 2124.93  Total Training Translation Loss 6847.59 
2024-01-31 07:01:14,765 EPOCH 758
2024-01-31 07:01:40,404 Epoch 758: Total Training Recognition Loss 2128.07  Total Training Translation Loss 6848.96 
2024-01-31 07:01:40,404 EPOCH 759
2024-01-31 07:01:45,525 [Epoch: 759 Step: 00050800] Batch Recognition Loss:  45.435505 => Gls Tokens per Sec:      438 || Batch Translation Loss: 120.886200 => Txt Tokens per Sec:     1220 || Lr: 0.000050
2024-01-31 07:02:05,916 Epoch 759: Total Training Recognition Loss 2124.04  Total Training Translation Loss 6847.53 
2024-01-31 07:02:05,917 EPOCH 760
2024-01-31 07:02:24,148 [Epoch: 760 Step: 00050900] Batch Recognition Loss:  38.448444 => Gls Tokens per Sec:      408 || Batch Translation Loss: 118.017944 => Txt Tokens per Sec:     1104 || Lr: 0.000050
2024-01-31 07:02:31,454 Epoch 760: Total Training Recognition Loss 2130.20  Total Training Translation Loss 6848.41 
2024-01-31 07:02:31,454 EPOCH 761
2024-01-31 07:02:56,855 Epoch 761: Total Training Recognition Loss 2132.34  Total Training Translation Loss 6847.08 
2024-01-31 07:02:56,855 EPOCH 762
2024-01-31 07:03:03,449 [Epoch: 762 Step: 00051000] Batch Recognition Loss:  37.615944 => Gls Tokens per Sec:      316 || Batch Translation Loss:  96.314995 => Txt Tokens per Sec:      926 || Lr: 0.000050
2024-01-31 07:03:22,262 Epoch 762: Total Training Recognition Loss 2125.01  Total Training Translation Loss 6849.86 
2024-01-31 07:03:22,262 EPOCH 763
2024-01-31 07:03:38,511 [Epoch: 763 Step: 00051100] Batch Recognition Loss:  41.421600 => Gls Tokens per Sec:      447 || Batch Translation Loss: 110.743210 => Txt Tokens per Sec:     1207 || Lr: 0.000050
2024-01-31 07:03:47,830 Epoch 763: Total Training Recognition Loss 2124.23  Total Training Translation Loss 6850.09 
2024-01-31 07:03:47,830 EPOCH 764
2024-01-31 07:04:13,315 Epoch 764: Total Training Recognition Loss 2126.29  Total Training Translation Loss 6847.49 
2024-01-31 07:04:13,315 EPOCH 765
2024-01-31 07:04:18,879 [Epoch: 765 Step: 00051200] Batch Recognition Loss:  40.616997 => Gls Tokens per Sec:      329 || Batch Translation Loss: 120.585167 => Txt Tokens per Sec:      998 || Lr: 0.000050
2024-01-31 07:04:38,858 Epoch 765: Total Training Recognition Loss 2126.50  Total Training Translation Loss 6846.56 
2024-01-31 07:04:38,859 EPOCH 766
2024-01-31 07:04:54,252 [Epoch: 766 Step: 00051300] Batch Recognition Loss:  13.783187 => Gls Tokens per Sec:      468 || Batch Translation Loss:  80.031708 => Txt Tokens per Sec:     1289 || Lr: 0.000050
2024-01-31 07:05:04,449 Epoch 766: Total Training Recognition Loss 2124.81  Total Training Translation Loss 6847.90 
2024-01-31 07:05:04,449 EPOCH 767
2024-01-31 07:05:29,995 Epoch 767: Total Training Recognition Loss 2127.90  Total Training Translation Loss 6848.63 
2024-01-31 07:05:29,995 EPOCH 768
2024-01-31 07:05:33,522 [Epoch: 768 Step: 00051400] Batch Recognition Loss:  32.390701 => Gls Tokens per Sec:      499 || Batch Translation Loss:  93.095085 => Txt Tokens per Sec:     1325 || Lr: 0.000050
2024-01-31 07:05:55,653 Epoch 768: Total Training Recognition Loss 2128.24  Total Training Translation Loss 6849.02 
2024-01-31 07:05:55,653 EPOCH 769
2024-01-31 07:06:11,218 [Epoch: 769 Step: 00051500] Batch Recognition Loss:  32.060596 => Gls Tokens per Sec:      452 || Batch Translation Loss:  98.827682 => Txt Tokens per Sec:     1236 || Lr: 0.000050
2024-01-31 07:06:21,203 Epoch 769: Total Training Recognition Loss 2128.89  Total Training Translation Loss 6847.86 
2024-01-31 07:06:21,203 EPOCH 770
2024-01-31 07:06:46,830 Epoch 770: Total Training Recognition Loss 2126.78  Total Training Translation Loss 6847.90 
2024-01-31 07:06:46,831 EPOCH 771
2024-01-31 07:06:50,434 [Epoch: 771 Step: 00051600] Batch Recognition Loss:  39.169849 => Gls Tokens per Sec:      444 || Batch Translation Loss: 127.142395 => Txt Tokens per Sec:     1229 || Lr: 0.000050
2024-01-31 07:07:12,368 Epoch 771: Total Training Recognition Loss 2124.97  Total Training Translation Loss 6849.79 
2024-01-31 07:07:12,368 EPOCH 772
2024-01-31 07:07:29,803 [Epoch: 772 Step: 00051700] Batch Recognition Loss:  30.740192 => Gls Tokens per Sec:      389 || Batch Translation Loss:  98.491150 => Txt Tokens per Sec:     1098 || Lr: 0.000050
2024-01-31 07:07:38,038 Epoch 772: Total Training Recognition Loss 2128.11  Total Training Translation Loss 6847.59 
2024-01-31 07:07:38,038 EPOCH 773
2024-01-31 07:08:03,478 Epoch 773: Total Training Recognition Loss 2125.09  Total Training Translation Loss 6849.47 
2024-01-31 07:08:03,478 EPOCH 774
2024-01-31 07:08:06,556 [Epoch: 774 Step: 00051800] Batch Recognition Loss:  38.008842 => Gls Tokens per Sec:      468 || Batch Translation Loss: 116.426445 => Txt Tokens per Sec:     1263 || Lr: 0.000050
2024-01-31 07:08:29,053 Epoch 774: Total Training Recognition Loss 2124.15  Total Training Translation Loss 6850.78 
2024-01-31 07:08:29,053 EPOCH 775
2024-01-31 07:08:46,146 [Epoch: 775 Step: 00051900] Batch Recognition Loss:  37.118412 => Gls Tokens per Sec:      388 || Batch Translation Loss: 106.406868 => Txt Tokens per Sec:     1094 || Lr: 0.000050
2024-01-31 07:08:54,735 Epoch 775: Total Training Recognition Loss 2126.80  Total Training Translation Loss 6848.76 
2024-01-31 07:08:54,736 EPOCH 776
2024-01-31 07:09:20,253 Epoch 776: Total Training Recognition Loss 2129.55  Total Training Translation Loss 6849.61 
2024-01-31 07:09:20,253 EPOCH 777
2024-01-31 07:09:23,410 [Epoch: 777 Step: 00052000] Batch Recognition Loss:  45.022751 => Gls Tokens per Sec:      406 || Batch Translation Loss: 125.846642 => Txt Tokens per Sec:     1151 || Lr: 0.000050
2024-01-31 07:09:52,580 Validation result at epoch 777, step    52000: duration: 29.1695s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 675.42468	Translation Loss: 73476.42188	PPL: 1560.54358
	Eval Metric: BLEU
	WER 539.97	(DEL: 4.45,	INS: 452.05,	SUB: 83.47)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.44	ROUGE 0.00
2024-01-31 07:09:52,581 Logging Recognition and Translation Outputs
2024-01-31 07:09:52,581 ========================================================================================================================
2024-01-31 07:09:52,582 Logging Sequence: 87_229.00
2024-01-31 07:09:52,582 	Gloss Reference :	***** * ***** * A     B+C+D+E
2024-01-31 07:09:52,582 	Gloss Hypothesis:	<unk> E <unk> E <unk> E      
2024-01-31 07:09:52,582 	Gloss Alignment :	I     I I     I S     S      
2024-01-31 07:09:52,582 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:09:52,584 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** it  was not against dhoni or  kohli
2024-01-31 07:09:52,584 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>     <s>   <s> <s>  
2024-01-31 07:09:52,584 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S   S   S       S     S   S    
2024-01-31 07:09:52,584 ========================================================================================================================
2024-01-31 07:09:52,585 Logging Sequence: 134_153.00
2024-01-31 07:09:52,585 	Gloss Reference :	A B+C+D+E                                                                                        
2024-01-31 07:09:52,585 	Gloss Hypothesis:	C B+C+B+C+E+C+E+B+E+C+B+C+B+C+E+C+B+C+B+E+C+B+E+C+B+C+B+C+B+C+B+C+B+C+B+C+B+C+E+C+B+C+B+E+C+E+B+C
2024-01-31 07:09:52,585 	Gloss Alignment :	S S                                                                                              
2024-01-31 07:09:52,585 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:09:52,589 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** pm  modi in  his interaction said that deaf athletes must fight for their goals and never give up  despite the losses
2024-01-31 07:09:52,590 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s>         <s>  <s>  <s>  <s>      <s>  <s>   <s> <s>   <s>   <s> <s>   <s>  <s> <s>     <s> <s>   
2024-01-31 07:09:52,590 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S    S   S   S           S    S    S    S        S    S     S   S     S     S   S     S    S   S       S   S     
2024-01-31 07:09:52,590 ========================================================================================================================
2024-01-31 07:09:52,590 Logging Sequence: 137_155.00
2024-01-31 07:09:52,590 	Gloss Reference :	* ***** ***** ******* ***** * ***** *** ***** ********* ***** * ***** ***** ***** *********** A     B+C+D+E        
2024-01-31 07:09:52,591 	Gloss Hypothesis:	E <unk> <pad> A+E+A+E <unk> E <unk> E+C <unk> C+A+E+A+E <unk> E <unk> E+C+E <pad> A+C+E+C+E+C <unk> C+E+A+E+C+A+C+E
2024-01-31 07:09:52,591 	Gloss Alignment :	I I     I     I       I     I I     I   I     I         I     I I     I     I     I           S     S              
2024-01-31 07:09:52,591 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:09:52,593 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** an  extremely high tax named as  sin tax will be  applied
2024-01-31 07:09:52,593 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>       <s>  <s> <s>   <s> <s> <s> <s>  <s> <s>    
2024-01-31 07:09:52,593 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S         S    S   S     S   S   S   S    S   S      
2024-01-31 07:09:52,594 ========================================================================================================================
2024-01-31 07:09:52,594 Logging Sequence: 59_18.00
2024-01-31 07:09:52,594 	Gloss Reference :	* ***************************** A     B+C+D+E                                                          
2024-01-31 07:09:52,594 	Gloss Hypothesis:	E D+E+D+E+D+E+D+E+C+E+C+E+C+E+D <unk> E+D+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E+C+E
2024-01-31 07:09:52,594 	Gloss Alignment :	I I                             S     S                                                                
2024-01-31 07:09:52,594 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:09:52,597 	Text Reference  :	*** ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* ************* 27-year-old   jessica       fox           from          australia     won           a             bronze        a             gold          medal         in            canoeing     
2024-01-31 07:09:52,597 	Text Hypothesis :	<s> misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand misunderstand
2024-01-31 07:09:52,597 	Text Alignment  :	I   I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             I             S             S             S             S             S             S             S             S             S             S             S             S             S            
2024-01-31 07:09:52,598 ========================================================================================================================
2024-01-31 07:09:52,598 Logging Sequence: 173_103.00
2024-01-31 07:09:52,598 	Gloss Reference :	***** * ***** A ***** ***** ***** * B+C+D+E
2024-01-31 07:09:52,598 	Gloss Hypothesis:	<unk> A <unk> A <unk> <pad> <unk> C <unk>  
2024-01-31 07:09:52,598 	Gloss Alignment :	I     I I       I     I     I     I S      
2024-01-31 07:09:52,598 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:09:52,600 	Text Reference  :	*** *** *** *** *** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** ******** these    rumours  are      absolutely rubbish 
2024-01-31 07:09:52,600 	Text Hypothesis :	<s> <s> <s> <s> <s> casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas casillas   casillas
2024-01-31 07:09:52,600 	Text Alignment  :	I   I   I   I   I   I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        I        S        S        S        S          S       
2024-01-31 07:09:52,600 ========================================================================================================================
2024-01-31 07:10:15,001 Epoch 777: Total Training Recognition Loss 2123.69  Total Training Translation Loss 6848.40 
2024-01-31 07:10:15,002 EPOCH 778
2024-01-31 07:10:28,573 [Epoch: 778 Step: 00052100] Batch Recognition Loss:  36.609947 => Gls Tokens per Sec:      483 || Batch Translation Loss: 123.181046 => Txt Tokens per Sec:     1343 || Lr: 0.000050
2024-01-31 07:10:40,504 Epoch 778: Total Training Recognition Loss 2121.44  Total Training Translation Loss 6848.07 
2024-01-31 07:10:40,505 EPOCH 779
2024-01-31 07:11:05,954 Epoch 779: Total Training Recognition Loss 2126.17  Total Training Translation Loss 6847.85 
2024-01-31 07:11:05,954 EPOCH 780
2024-01-31 07:11:08,449 [Epoch: 780 Step: 00052200] Batch Recognition Loss:  40.900948 => Gls Tokens per Sec:      449 || Batch Translation Loss: 136.154266 => Txt Tokens per Sec:     1284 || Lr: 0.000050
2024-01-31 07:11:31,451 Epoch 780: Total Training Recognition Loss 2125.79  Total Training Translation Loss 6845.89 
2024-01-31 07:11:31,451 EPOCH 781
2024-01-31 07:11:45,373 [Epoch: 781 Step: 00052300] Batch Recognition Loss:  13.793716 => Gls Tokens per Sec:      460 || Batch Translation Loss:  78.039169 => Txt Tokens per Sec:     1236 || Lr: 0.000050
2024-01-31 07:11:57,040 Epoch 781: Total Training Recognition Loss 2127.69  Total Training Translation Loss 6847.14 
2024-01-31 07:11:57,040 EPOCH 782
2024-01-31 07:12:22,557 Epoch 782: Total Training Recognition Loss 2124.20  Total Training Translation Loss 6847.40 
2024-01-31 07:12:22,557 EPOCH 783
2024-01-31 07:12:24,259 [Epoch: 783 Step: 00052400] Batch Recognition Loss:  28.821331 => Gls Tokens per Sec:      565 || Batch Translation Loss:  88.560966 => Txt Tokens per Sec:     1536 || Lr: 0.000050
2024-01-31 07:12:48,126 Epoch 783: Total Training Recognition Loss 2126.81  Total Training Translation Loss 6849.16 
2024-01-31 07:12:48,126 EPOCH 784
2024-01-31 07:13:03,313 [Epoch: 784 Step: 00052500] Batch Recognition Loss:  30.047922 => Gls Tokens per Sec:      411 || Batch Translation Loss: 103.439697 => Txt Tokens per Sec:     1178 || Lr: 0.000050
2024-01-31 07:13:13,654 Epoch 784: Total Training Recognition Loss 2124.95  Total Training Translation Loss 6846.95 
2024-01-31 07:13:13,654 EPOCH 785
2024-01-31 07:13:39,529 Epoch 785: Total Training Recognition Loss 2129.73  Total Training Translation Loss 6849.16 
2024-01-31 07:13:39,529 EPOCH 786
2024-01-31 07:13:40,826 [Epoch: 786 Step: 00052600] Batch Recognition Loss:  18.644358 => Gls Tokens per Sec:      617 || Batch Translation Loss:  96.626610 => Txt Tokens per Sec:     1610 || Lr: 0.000050
2024-01-31 07:14:05,244 Epoch 786: Total Training Recognition Loss 2128.56  Total Training Translation Loss 6848.17 
2024-01-31 07:14:05,244 EPOCH 787
2024-01-31 07:14:20,586 [Epoch: 787 Step: 00052700] Batch Recognition Loss:  37.321125 => Gls Tokens per Sec:      396 || Batch Translation Loss: 113.198845 => Txt Tokens per Sec:     1131 || Lr: 0.000050
2024-01-31 07:14:30,845 Epoch 787: Total Training Recognition Loss 2125.38  Total Training Translation Loss 6848.97 
2024-01-31 07:14:30,846 EPOCH 788
2024-01-31 07:14:56,314 Epoch 788: Total Training Recognition Loss 2127.38  Total Training Translation Loss 6848.89 
2024-01-31 07:14:56,314 EPOCH 789
2024-01-31 07:14:57,990 [Epoch: 789 Step: 00052800] Batch Recognition Loss:   5.141768 => Gls Tokens per Sec:      329 || Batch Translation Loss:  45.438385 => Txt Tokens per Sec:      743 || Lr: 0.000050
2024-01-31 07:15:21,827 Epoch 789: Total Training Recognition Loss 2126.47  Total Training Translation Loss 6849.21 
2024-01-31 07:15:21,827 EPOCH 790
2024-01-31 07:15:36,284 [Epoch: 790 Step: 00052900] Batch Recognition Loss:  38.333237 => Gls Tokens per Sec:      403 || Batch Translation Loss: 124.739723 => Txt Tokens per Sec:     1106 || Lr: 0.000050
2024-01-31 07:15:47,454 Epoch 790: Total Training Recognition Loss 2128.70  Total Training Translation Loss 6849.10 
2024-01-31 07:15:47,454 EPOCH 791
2024-01-31 07:16:13,041 Epoch 791: Total Training Recognition Loss 2127.41  Total Training Translation Loss 6847.28 
2024-01-31 07:16:13,041 EPOCH 792
2024-01-31 07:16:15,285 [Epoch: 792 Step: 00053000] Batch Recognition Loss:  27.632484 => Gls Tokens per Sec:      214 || Batch Translation Loss:  85.193832 => Txt Tokens per Sec:      683 || Lr: 0.000050
2024-01-31 07:16:38,618 Epoch 792: Total Training Recognition Loss 2125.66  Total Training Translation Loss 6846.03 
2024-01-31 07:16:38,619 EPOCH 793
2024-01-31 07:16:52,493 [Epoch: 793 Step: 00053100] Batch Recognition Loss:  28.251308 => Gls Tokens per Sec:      415 || Batch Translation Loss:  92.808899 => Txt Tokens per Sec:     1155 || Lr: 0.000050
2024-01-31 07:17:04,190 Epoch 793: Total Training Recognition Loss 2127.48  Total Training Translation Loss 6848.35 
2024-01-31 07:17:04,190 EPOCH 794
2024-01-31 07:17:29,734 Epoch 794: Total Training Recognition Loss 2128.40  Total Training Translation Loss 6846.92 
2024-01-31 07:17:29,734 EPOCH 795
2024-01-31 07:17:30,538 [Epoch: 795 Step: 00053200] Batch Recognition Loss:  37.870392 => Gls Tokens per Sec:      399 || Batch Translation Loss: 114.015114 => Txt Tokens per Sec:     1173 || Lr: 0.000050
2024-01-31 07:17:57,086 Epoch 795: Total Training Recognition Loss 2130.96  Total Training Translation Loss 6849.02 
2024-01-31 07:17:57,087 EPOCH 796
2024-01-31 07:18:12,945 [Epoch: 796 Step: 00053300] Batch Recognition Loss:  37.076599 => Gls Tokens per Sec:      347 || Batch Translation Loss: 119.174644 => Txt Tokens per Sec:      990 || Lr: 0.000050
2024-01-31 07:18:25,038 Epoch 796: Total Training Recognition Loss 2126.13  Total Training Translation Loss 6847.62 
2024-01-31 07:18:25,038 EPOCH 797
2024-01-31 07:18:50,606 Epoch 797: Total Training Recognition Loss 2126.78  Total Training Translation Loss 6847.90 
2024-01-31 07:18:50,606 EPOCH 798
2024-01-31 07:18:51,507 [Epoch: 798 Step: 00053400] Batch Recognition Loss:  53.896458 => Gls Tokens per Sec:      178 || Batch Translation Loss: 130.475952 => Txt Tokens per Sec:      632 || Lr: 0.000050
2024-01-31 07:19:16,127 Epoch 798: Total Training Recognition Loss 2123.23  Total Training Translation Loss 6847.38 
2024-01-31 07:19:16,128 EPOCH 799
2024-01-31 07:19:28,871 [Epoch: 799 Step: 00053500] Batch Recognition Loss:  16.273432 => Gls Tokens per Sec:      427 || Batch Translation Loss:  66.232674 => Txt Tokens per Sec:     1174 || Lr: 0.000050
2024-01-31 07:19:41,754 Epoch 799: Total Training Recognition Loss 2128.48  Total Training Translation Loss 6847.60 
2024-01-31 07:19:41,754 EPOCH 800
2024-01-31 07:20:07,335 [Epoch: 800 Step: 00053600] Batch Recognition Loss:  28.471485 => Gls Tokens per Sec:      416 || Batch Translation Loss:  88.240891 => Txt Tokens per Sec:     1154 || Lr: 0.000050
2024-01-31 07:20:07,336 Epoch 800: Total Training Recognition Loss 2127.34  Total Training Translation Loss 6847.65 
2024-01-31 07:20:07,336 EPOCH 801
2024-01-31 07:20:32,813 Epoch 801: Total Training Recognition Loss 2128.09  Total Training Translation Loss 6846.92 
2024-01-31 07:20:32,813 EPOCH 802
2024-01-31 07:20:46,940 [Epoch: 802 Step: 00053700] Batch Recognition Loss:  38.876495 => Gls Tokens per Sec:      367 || Batch Translation Loss: 127.446716 => Txt Tokens per Sec:     1031 || Lr: 0.000050
2024-01-31 07:20:58,678 Epoch 802: Total Training Recognition Loss 2127.72  Total Training Translation Loss 6848.15 
2024-01-31 07:20:58,678 EPOCH 803
2024-01-31 07:21:23,790 [Epoch: 803 Step: 00053800] Batch Recognition Loss:  37.294853 => Gls Tokens per Sec:      417 || Batch Translation Loss: 110.293221 => Txt Tokens per Sec:     1159 || Lr: 0.000050
2024-01-31 07:21:24,068 Epoch 803: Total Training Recognition Loss 2128.22  Total Training Translation Loss 6848.93 
2024-01-31 07:21:24,069 EPOCH 804
2024-01-31 07:21:49,594 Epoch 804: Total Training Recognition Loss 2130.98  Total Training Translation Loss 6849.53 
2024-01-31 07:21:49,595 EPOCH 805
2024-01-31 07:22:04,127 [Epoch: 805 Step: 00053900] Batch Recognition Loss:  60.970417 => Gls Tokens per Sec:      346 || Batch Translation Loss: 135.410599 => Txt Tokens per Sec:      991 || Lr: 0.000050
2024-01-31 07:22:15,126 Epoch 805: Total Training Recognition Loss 2127.73  Total Training Translation Loss 6848.68 
2024-01-31 07:22:15,126 EPOCH 806
2024-01-31 07:22:40,202 [Epoch: 806 Step: 00054000] Batch Recognition Loss:  22.870228 => Gls Tokens per Sec:      411 || Batch Translation Loss:  81.386421 => Txt Tokens per Sec:     1146 || Lr: 0.000050
2024-01-31 07:23:09,718 Validation result at epoch 806, step    54000: duration: 29.5160s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 662.34674	Translation Loss: 73490.85938	PPL: 1562.79919
	Eval Metric: BLEU
	WER 527.82	(DEL: 4.24,	INS: 439.19,	SUB: 84.39)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.50	ROUGE 0.00
2024-01-31 07:23:09,720 Logging Recognition and Translation Outputs
2024-01-31 07:23:09,720 ========================================================================================================================
2024-01-31 07:23:09,720 Logging Sequence: 130_139.00
2024-01-31 07:23:09,721 	Gloss Reference :	***** * ***** ***** ***** *** ***** ***** ***** * ***** *********************** ***** ***** ***** * ***** * ***** *********** ***** *************** A     B+C+D+E        
2024-01-31 07:23:09,721 	Gloss Hypothesis:	<unk> E <pad> E+B+D <pad> E+B <unk> E+B+C <unk> D <unk> E+B+E+B+E+D+E+D+C+B+C+D <unk> B+C+E <unk> E <unk> E <unk> C+B+E+B+C+E <unk> C+E+B+E+C+E+C+E <unk> E+B+E+B+E+B+E+C
2024-01-31 07:23:09,721 	Gloss Alignment :	I     I I     I     I     I   I     I     I     I I     I                       I     I     I     I I     I I     I           I     I               S     S              
2024-01-31 07:23:09,721 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:23:09,727 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** he  shared a   picture of  a   little pouch he  knit for his olympic gold medal with uk  flag on  one side and japanese flag on  the other
2024-01-31 07:23:09,727 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>    <s> <s>     <s> <s> <s>    <s>   <s> <s>  <s> <s> <s>     <s>  <s>   <s>  <s> <s>  <s> <s> <s>  <s> <s>      <s>  <s> <s> <s>  
2024-01-31 07:23:09,727 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   S   S      S   S       S   S   S      S     S   S    S   S   S       S    S     S    S   S    S   S   S    S   S        S    S   S   S    
2024-01-31 07:23:09,727 ========================================================================================================================
2024-01-31 07:23:09,727 Logging Sequence: 148_155.00
2024-01-31 07:23:09,728 	Gloss Reference :	* ********* ***** *** A     B+C+D+E              
2024-01-31 07:23:09,728 	Gloss Hypothesis:	E A+E+B+E+C <unk> C+E <unk> E+B+E+C+E+C+E+C+E+A+E
2024-01-31 07:23:09,728 	Gloss Alignment :	I I         I     I   S     S                    
2024-01-31 07:23:09,728 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:23:09,731 	Text Reference  :	*** *** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** india won  the  match with 263  balls remaining and  without losing any  wicket
2024-01-31 07:23:09,731 	Text Hypothesis :	<s> <s> iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker iker  iker iker iker  iker iker iker  iker      iker iker    iker   iker iker  
2024-01-31 07:23:09,731 	Text Alignment  :	I   I   I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    I    S     S    S    S     S    S    S     S         S    S       S      S    S     
2024-01-31 07:23:09,731 ========================================================================================================================
2024-01-31 07:23:09,731 Logging Sequence: 126_99.00
2024-01-31 07:23:09,731 	Gloss Reference :	A B+C+D+E
2024-01-31 07:23:09,732 	Gloss Hypothesis:	* <unk>  
2024-01-31 07:23:09,732 	Gloss Alignment :	D S      
2024-01-31 07:23:09,732 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:23:09,734 	Text Reference  :	*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** he  dedicated the medal to  sprinter milkha singh
2024-01-31 07:23:09,734 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>       <s> <s>   <s> <s>      <s>    <s>  
2024-01-31 07:23:09,734 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   I   S   S         S   S     S   S        S      S    
2024-01-31 07:23:09,734 ========================================================================================================================
2024-01-31 07:23:09,734 Logging Sequence: 149_77.00
2024-01-31 07:23:09,734 	Gloss Reference :	***** ******* A     B+C+D+E
2024-01-31 07:23:09,735 	Gloss Hypothesis:	<unk> C+D+E+C <unk> C      
2024-01-31 07:23:09,735 	Gloss Alignment :	I     I       S     S      
2024-01-31 07:23:09,735 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:23:09,739 	Text Reference  :	***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** ***** and   arrested danushka for   alleged sexual assault of    a     29    year  old   woman whose name  has   not   been  disclosed
2024-01-31 07:23:09,739 	Text Hypothesis :	sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    sabha    sabha sabha   sabha  sabha   sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha sabha    
2024-01-31 07:23:09,739 	Text Alignment  :	I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     I     S     S        S        S     S       S      S       S     S     S     S     S     S     S     S     S     S     S     S        
2024-01-31 07:23:09,739 ========================================================================================================================
2024-01-31 07:23:09,739 Logging Sequence: 168_15.00
2024-01-31 07:23:09,740 	Gloss Reference :	***** * ***** A ***** *** ***** *** ***** * ***** *** ***** B+C+D+E
2024-01-31 07:23:09,740 	Gloss Hypothesis:	<unk> A <unk> A <unk> E+B <unk> E+B <unk> B <unk> B+E <unk> A      
2024-01-31 07:23:09,740 	Gloss Alignment :	I     I I       I     I   I     I   I     I I     I   I     S      
2024-01-31 07:23:09,740 	--------------------------------------------------------------------------------------------------------------------
2024-01-31 07:23:09,743 	Text Reference  :	*** *** *** *** *** *** *** *** *** ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* ******* when    in      public  the     couple  are     always  approached for     photographys and     autographs
2024-01-31 07:23:09,743 	Text Hypothesis :	<s> <s> <s> <s> <s> <s> <s> <s> <s> nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing    nothing nothing      nothing nothing   
2024-01-31 07:23:09,743 	Text Alignment  :	I   I   I   I   I   I   I   I   I   I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       I       S       S       S       S       S       S       S       S          S       S            S       S         
2024-01-31 07:23:09,743 ========================================================================================================================
2024-01-31 07:23:09,748 Training ended since there were no improvements inthe last learning rate step: 0.000050
2024-01-31 07:23:09,750 Best validation result at step     2000:   0.00 eval_metric.
2024-01-31 07:23:34,211 ------------------------------------------------------------
2024-01-31 07:23:34,211 [DEV] partition [RECOGNITION] experiment [BW]: 1
2024-01-31 07:24:03,564 finished in 29.3538s 
2024-01-31 07:24:03,564 ************************************************************
2024-01-31 07:24:03,564 [DEV] partition [RECOGNITION] results:
	New Best CTC Decode Beam Size: 1
	WER 552.75	(DEL: 4.17,	INS: 464.55,	SUB: 84.04)
2024-01-31 07:24:03,564 ************************************************************
2024-01-31 07:24:03,564 ------------------------------------------------------------
2024-01-31 07:24:03,565 [DEV] partition [RECOGNITION] experiment [BW]: 2
2024-01-31 07:24:36,425 finished in 32.8598s 
2024-01-31 07:24:36,425 ------------------------------------------------------------
2024-01-31 07:24:36,425 [DEV] partition [RECOGNITION] experiment [BW]: 3
2024-01-31 07:25:13,377 finished in 36.9515s 
2024-01-31 07:25:13,377 ------------------------------------------------------------
2024-01-31 07:25:13,378 [DEV] partition [RECOGNITION] experiment [BW]: 4
2024-01-31 07:25:51,507 finished in 38.1298s 
2024-01-31 07:25:51,508 ------------------------------------------------------------
2024-01-31 07:25:51,508 [DEV] partition [RECOGNITION] experiment [BW]: 5
2024-01-31 07:26:30,413 finished in 38.9041s 
2024-01-31 07:26:30,413 ------------------------------------------------------------
2024-01-31 07:26:30,413 [DEV] partition [RECOGNITION] experiment [BW]: 6
2024-01-31 07:27:09,677 finished in 39.2647s 
2024-01-31 07:27:09,677 ------------------------------------------------------------
2024-01-31 07:27:09,678 [DEV] partition [RECOGNITION] experiment [BW]: 7
2024-01-31 07:27:49,289 finished in 39.6106s 
2024-01-31 07:27:49,290 ------------------------------------------------------------
2024-01-31 07:27:49,290 [DEV] partition [RECOGNITION] experiment [BW]: 8
2024-01-31 07:28:29,080 finished in 39.7904s 
2024-01-31 07:28:29,081 ------------------------------------------------------------
2024-01-31 07:28:29,081 [DEV] partition [RECOGNITION] experiment [BW]: 9
2024-01-31 07:29:08,984 finished in 39.9030s 
2024-01-31 07:29:08,985 ------------------------------------------------------------
2024-01-31 07:29:08,985 [DEV] partition [RECOGNITION] experiment [BW]: 10
2024-01-31 07:29:49,092 finished in 40.1070s 
2024-01-31 07:29:49,092 ============================================================
2024-01-31 07:30:18,349 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: -1
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.43	ROUGE 0.01
2024-01-31 07:30:18,349 ------------------------------------------------------------
2024-01-31 09:09:21,587 ************************************************************
2024-01-31 09:09:21,587 [DEV] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 1
	Best Translation Beam Size: 1 and Alpha: -1
	WER 552.75	(DEL: 4.17,	INS: 464.55,	SUB: 84.04)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.43	ROUGE 0.01
2024-01-31 09:09:21,588 ************************************************************
2024-01-31 09:09:51,036 [TEST] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 1
	Best Translation Beam Size: 1 and Alpha: -1
	WER 534.07	(DEL: 4.25,	INS: 444.76,	SUB: 85.06)
	BLEU-4 0.00	(BLEU-1: 0.00,	BLEU-2: 0.00,	BLEU-3: 0.00,	BLEU-4: 0.00)
	CHRF 3.54	ROUGE 0.00
2024-01-31 09:09:51,037 ************************************************************
