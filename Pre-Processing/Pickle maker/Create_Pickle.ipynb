{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d162ada",
   "metadata": {},
   "source": [
    "# **Import all required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8d849-bde6-4b5b-9511-583d502d89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "# import tensorflow_addons as tfa\n",
    "# import keras_tuner\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7, EfficientNetB0 \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras import mixed_precision\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import platform\n",
    "from progress.bar import Bar\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28758cca-200b-402f-8cf4-86dfe4c08f78",
   "metadata": {},
   "source": [
    "# **Enable fp16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f46b74-6982-4840-836f-19f54fe695b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17e323-06f2-4938-8f8b-6d9dbc7cddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25995e90",
   "metadata": {},
   "source": [
    "# **Mention the destination of the files to access:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162b72d-11ab-4035-bb54-c58a390b0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# validation\n",
    "vw_dest = \"Dataset/excels/ISH_News_Business VAL.xlsx\"\n",
    "vo_dest = \"/Dataset/Pickles/excel_dataVal.pickle\"\n",
    "vf_dest = \"Dataset/Final folder for frames\"\n",
    "\n",
    "# test\n",
    "tw_dest = \"Dataset/excels/ISH_News_Business TEST.xlsx\"\n",
    "to_dest = \"/Dataset/Pickles/excel_dataTest.pickle\"\n",
    "tf_dest = \"Dataset/Final folder for frames\"\n",
    "\n",
    "# train\n",
    "w_dest = \"Dataset/excels/ISH_News_Business TRAIN.xlsx\"\n",
    "o_dest = \"/Dataset/Pickles/excel_data.pickle\"\n",
    "f_dest = \"Dataset/Final folder for frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535875b-3733-4340-ace8-19029d5857fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls():\n",
    "    system = platform.system()\n",
    "    if system == 'Windows':\n",
    "        os.system('cls')\n",
    "    elif system == 'Linux':\n",
    "        os.system('clear')\n",
    "    elif system == 'MacOS':\n",
    "        os.system('clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eafff1",
   "metadata": {},
   "source": [
    "# **Initialise the CNN model here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc80e6-90f3-4254-9a40-67042ebca1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe5458",
   "metadata": {},
   "source": [
    "# **Function for extraction of features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96856f6-6a00-4a01-a7a3-a7b9ba39693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features(filename, destination):\n",
    "    input_string = filename\n",
    "    pattern = r'\\d+'\n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        first_match = match.group()\n",
    "        # print(first_match)\n",
    "        # Get file path name\n",
    "        input_folder = os.getcwd()+\"/\"+destination+\"/\"+first_match+\"/\"+input_string\n",
    "        file_paths_frames = [file for file in sorted(os.listdir(input_folder)) if file.endswith(\".jpg\")]\n",
    "\n",
    "        # base_model needs to be initialised first\n",
    "        # x = base_model.output\n",
    "        # x = GlobalAveragePooling2D()(x)\n",
    "        # feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    \n",
    "        features_listofList=[]\n",
    "        for indx, frame_file in enumerate(file_paths_frames):\n",
    "            # Get the file\n",
    "            frame_filename =  input_folder+\"/\" + frame_file\n",
    "            print(\"frame_filename============\", frame_filename,\"\\n\")\n",
    "            image = cv2.imread(frame_filename)\n",
    "                \n",
    "            # Image processing part\n",
    "        \n",
    "            # Define the coordinates of the ROI (top-left and bottom-right)\n",
    "            x1, y1 = 535, 0  # Top-left corner of ROI\n",
    "            x2, y2 = 1385, 1080  # Bottom-right corner of ROI\n",
    "            #210*260\n",
    "            # Crop the image to the specified ROI\n",
    "            image = image[y1:y2, x1:x2]\n",
    "            image = cv2.resize(image, (224, 224))  # Resize to the input size of MobileNet\n",
    "\n",
    "            # Preprocess the image\n",
    "            image = preprocess_input(image)\n",
    "        \n",
    "            # Expand dimensions to match the expected input shape (batch size of 1)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "                \n",
    "            # Extract spatial embedding\n",
    "            spatial_embedding = feature_extractor.predict(image)[0]\n",
    "                \n",
    "            features_listofList.append(spatial_embedding)\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "        return None\n",
    "\n",
    "    # after this, the video must be in the form of features\n",
    "    return torch.tensor(np.array(features_listofList))\n",
    "    #return torch.tensor(features_listofList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa41352",
   "metadata": {},
   "source": [
    "# **Function to create the pickle file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e172c15-2d77-48c7-b475-8894b471d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pickle(workbook_dest, output_dest, frame_dest):\n",
    "    # Load the excel file\n",
    "    workbook = load_workbook(workbook_dest)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Extract data from the Excel file\n",
    "    excel_data = []\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        excel_data.append(row)\n",
    "        # print(excel_data,\"\\n\")\n",
    "        # print(excel_data)list_of_inputs = []\n",
    "    \n",
    "    # Get the features\n",
    "    list_of_inputs = []\n",
    "    \n",
    "    for tmp in excel_data:\n",
    "        features = get_features(str(tmp[0]),frame_dest)\n",
    "        if(features!= None):\n",
    "            data_dict = {}\n",
    "            data_dict['name'] = tmp[0]\n",
    "            data_dict['signer'] = tmp[1]\n",
    "            data_dict['gloss'] = tmp[2]\n",
    "            data_dict['text'] = tmp[3]\n",
    "            data_dict['sign'] = features + 1e-8\n",
    "            #print(data_dict)\n",
    "            #input()\n",
    "            list_of_inputs.append(data_dict)\n",
    "\n",
    "    # print(\"\\nlist_of_input:\\n\")\n",
    "    # print(list_of_inputs)\n",
    "    with gzip.open(os.getcwd() + output_dest,'wb') as f:\n",
    "        pickle.dump(list_of_inputs,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418f4d2",
   "metadata": {},
   "source": [
    "# **Call for training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a3a0d-abd5-455a-a485-58ac1b90fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing pickle\n",
    "create_pickle(tw_dest, to_dest, tf_dest)\n",
    "\n",
    "print(\"Testing pickle Creation Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882db06-bc47-4343-a1e3-47da154df499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation pickle\n",
    "create_pickle(vw_dest, vo_dest, vf_dest)\n",
    "\n",
    "print(\"Validation/dev pickle Creation Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30d5b2-98a0-4b51-8aaf-cfd3bb0f4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training pickle\n",
    "create_pickle(w_dest, o_dest, f_dest)\n",
    "\n",
    "print(\"Training pickle Creation Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc94e7-e87a-4f1a-9a85-bea2eb7944a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
