2024-02-08 13:07:29,849 Hello! This is Joey-NMT.
2024-02-08 13:07:29,858 Total params: 25642504
2024-02-08 13:07:29,859 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2024-02-08 13:07:30,987 cfg.name                           : sign_experiment
2024-02-08 13:07:30,987 cfg.data.data_path                 : ./data/Sports_dataset/7/
2024-02-08 13:07:30,987 cfg.data.version                   : phoenix_2014_trans
2024-02-08 13:07:30,988 cfg.data.sgn                       : sign
2024-02-08 13:07:30,988 cfg.data.txt                       : text
2024-02-08 13:07:30,988 cfg.data.gls                       : gloss
2024-02-08 13:07:30,988 cfg.data.train                     : excel_data.train
2024-02-08 13:07:30,988 cfg.data.dev                       : excel_data.dev
2024-02-08 13:07:30,988 cfg.data.test                      : excel_data.test
2024-02-08 13:07:30,988 cfg.data.feature_size              : 2560
2024-02-08 13:07:30,989 cfg.data.level                     : word
2024-02-08 13:07:30,989 cfg.data.txt_lowercase             : True
2024-02-08 13:07:30,989 cfg.data.max_sent_length           : 500
2024-02-08 13:07:30,989 cfg.data.random_train_subset       : -1
2024-02-08 13:07:30,989 cfg.data.random_dev_subset         : -1
2024-02-08 13:07:30,989 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-02-08 13:07:30,989 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-02-08 13:07:30,989 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2024-02-08 13:07:30,990 cfg.training.reset_best_ckpt       : False
2024-02-08 13:07:30,990 cfg.training.reset_scheduler       : False
2024-02-08 13:07:30,990 cfg.training.reset_optimizer       : False
2024-02-08 13:07:30,990 cfg.training.random_seed           : 42
2024-02-08 13:07:30,990 cfg.training.model_dir             : ./sign_sample_model/fold7/32head/16batch
2024-02-08 13:07:30,990 cfg.training.recognition_loss_weight : 1.0
2024-02-08 13:07:30,990 cfg.training.translation_loss_weight : 1.0
2024-02-08 13:07:30,990 cfg.training.eval_metric           : bleu
2024-02-08 13:07:30,991 cfg.training.optimizer             : adam
2024-02-08 13:07:30,991 cfg.training.learning_rate         : 0.0001
2024-02-08 13:07:30,991 cfg.training.batch_size            : 16
2024-02-08 13:07:30,991 cfg.training.num_valid_log         : 5
2024-02-08 13:07:30,991 cfg.training.epochs                : 50000
2024-02-08 13:07:30,991 cfg.training.early_stopping_metric : eval_metric
2024-02-08 13:07:30,991 cfg.training.batch_type            : sentence
2024-02-08 13:07:30,991 cfg.training.translation_normalization : batch
2024-02-08 13:07:30,992 cfg.training.eval_recognition_beam_size : 1
2024-02-08 13:07:30,992 cfg.training.eval_translation_beam_size : 1
2024-02-08 13:07:30,992 cfg.training.eval_translation_beam_alpha : -1
2024-02-08 13:07:30,992 cfg.training.overwrite             : True
2024-02-08 13:07:30,992 cfg.training.shuffle               : True
2024-02-08 13:07:30,992 cfg.training.use_cuda              : True
2024-02-08 13:07:30,992 cfg.training.translation_max_output_length : 40
2024-02-08 13:07:30,992 cfg.training.keep_last_ckpts       : 1
2024-02-08 13:07:30,993 cfg.training.batch_multiplier      : 1
2024-02-08 13:07:30,993 cfg.training.logging_freq          : 100
2024-02-08 13:07:30,993 cfg.training.validation_freq       : 2000
2024-02-08 13:07:30,993 cfg.training.betas                 : [0.9, 0.998]
2024-02-08 13:07:30,993 cfg.training.scheduling            : plateau
2024-02-08 13:07:30,993 cfg.training.learning_rate_min     : 1e-08
2024-02-08 13:07:30,993 cfg.training.weight_decay          : 0.0001
2024-02-08 13:07:30,993 cfg.training.patience              : 12
2024-02-08 13:07:30,994 cfg.training.decrease_factor       : 0.5
2024-02-08 13:07:30,994 cfg.training.label_smoothing       : 0.0
2024-02-08 13:07:30,994 cfg.model.initializer              : xavier
2024-02-08 13:07:30,994 cfg.model.bias_initializer         : zeros
2024-02-08 13:07:30,994 cfg.model.init_gain                : 1.0
2024-02-08 13:07:30,994 cfg.model.embed_initializer        : xavier
2024-02-08 13:07:30,994 cfg.model.embed_init_gain          : 1.0
2024-02-08 13:07:30,994 cfg.model.tied_softmax             : True
2024-02-08 13:07:30,995 cfg.model.encoder.type             : transformer
2024-02-08 13:07:30,995 cfg.model.encoder.num_layers       : 3
2024-02-08 13:07:30,995 cfg.model.encoder.num_heads        : 32
2024-02-08 13:07:30,995 cfg.model.encoder.embeddings.embedding_dim : 512
2024-02-08 13:07:30,995 cfg.model.encoder.embeddings.scale : False
2024-02-08 13:07:30,995 cfg.model.encoder.embeddings.dropout : 0.1
2024-02-08 13:07:30,995 cfg.model.encoder.embeddings.norm_type : batch
2024-02-08 13:07:30,996 cfg.model.encoder.embeddings.activation_type : softsign
2024-02-08 13:07:30,996 cfg.model.encoder.hidden_size      : 512
2024-02-08 13:07:30,996 cfg.model.encoder.ff_size          : 2048
2024-02-08 13:07:30,996 cfg.model.encoder.dropout          : 0.1
2024-02-08 13:07:30,996 cfg.model.decoder.type             : transformer
2024-02-08 13:07:30,996 cfg.model.decoder.num_layers       : 3
2024-02-08 13:07:30,996 cfg.model.decoder.num_heads        : 32
2024-02-08 13:07:30,996 cfg.model.decoder.embeddings.embedding_dim : 512
2024-02-08 13:07:30,997 cfg.model.decoder.embeddings.scale : False
2024-02-08 13:07:30,997 cfg.model.decoder.embeddings.dropout : 0.1
2024-02-08 13:07:30,997 cfg.model.decoder.embeddings.norm_type : batch
2024-02-08 13:07:30,997 cfg.model.decoder.embeddings.activation_type : softsign
2024-02-08 13:07:30,997 cfg.model.decoder.hidden_size      : 512
2024-02-08 13:07:30,997 cfg.model.decoder.ff_size          : 2048
2024-02-08 13:07:30,997 cfg.model.decoder.dropout          : 0.1
2024-02-08 13:07:30,997 Data set sizes: 
	train 2124,
	valid 708,
	test 708
2024-02-08 13:07:30,998 First training example:
	[GLS] A B C D E
	[TXT] how did she become a champion
2024-02-08 13:07:30,998 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) A (4) B (5) C (6) D (7) E
2024-02-08 13:07:30,998 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) and (6) to (7) in (8) a (9) of
2024-02-08 13:07:30,998 Number of unique glosses (types): 8
2024-02-08 13:07:30,998 Number of unique words (types): 4402
2024-02-08 13:07:30,998 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=32),
	decoder=TransformerDecoder(num_layers=3, num_heads=32),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=2560),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=4402))
2024-02-08 13:07:31,002 EPOCH 1
2024-02-08 13:07:36,965 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   0.905666 => Gls Tokens per Sec:     1342 || Batch Translation Loss: 100.148598 => Txt Tokens per Sec:     3758 || Lr: 0.000100
2024-02-08 13:07:38,760 Epoch   1: Total Training Recognition Loss 265.68  Total Training Translation Loss 12490.13 
2024-02-08 13:07:38,760 EPOCH 2
2024-02-08 13:07:42,444 [Epoch: 002 Step: 00000200] Batch Recognition Loss:   0.655709 => Gls Tokens per Sec:     1455 || Batch Translation Loss:  80.330894 => Txt Tokens per Sec:     4052 || Lr: 0.000100
2024-02-08 13:07:46,178 Epoch   2: Total Training Recognition Loss 97.03  Total Training Translation Loss 11630.19 
2024-02-08 13:07:46,178 EPOCH 3
2024-02-08 13:07:47,950 [Epoch: 003 Step: 00000300] Batch Recognition Loss:   0.454853 => Gls Tokens per Sec:     1536 || Batch Translation Loss:  64.913422 => Txt Tokens per Sec:     4251 || Lr: 0.000100
2024-02-08 13:07:53,543 Epoch   3: Total Training Recognition Loss 68.13  Total Training Translation Loss 11151.14 
2024-02-08 13:07:53,543 EPOCH 4
2024-02-08 13:07:53,605 [Epoch: 004 Step: 00000400] Batch Recognition Loss:   0.430961 => Gls Tokens per Sec:     1312 || Batch Translation Loss:  87.613167 => Txt Tokens per Sec:     3853 || Lr: 0.000100
2024-02-08 13:07:58,915 [Epoch: 004 Step: 00000500] Batch Recognition Loss:   0.174160 => Gls Tokens per Sec:     1506 || Batch Translation Loss:  82.482925 => Txt Tokens per Sec:     4163 || Lr: 0.000100
2024-02-08 13:08:00,580 Epoch   4: Total Training Recognition Loss 42.72  Total Training Translation Loss 10612.26 
2024-02-08 13:08:00,580 EPOCH 5
2024-02-08 13:08:04,508 [Epoch: 005 Step: 00000600] Batch Recognition Loss:   0.130911 => Gls Tokens per Sec:     1385 || Batch Translation Loss:  77.553612 => Txt Tokens per Sec:     3899 || Lr: 0.000100
2024-02-08 13:08:08,110 Epoch   5: Total Training Recognition Loss 37.73  Total Training Translation Loss 10079.92 
2024-02-08 13:08:08,111 EPOCH 6
2024-02-08 13:08:09,931 [Epoch: 006 Step: 00000700] Batch Recognition Loss:   0.062346 => Gls Tokens per Sec:     1539 || Batch Translation Loss:  87.654976 => Txt Tokens per Sec:     4154 || Lr: 0.000100
2024-02-08 13:08:15,670 Epoch   6: Total Training Recognition Loss 19.01  Total Training Translation Loss 9596.05 
2024-02-08 13:08:15,671 EPOCH 7
2024-02-08 13:08:15,772 [Epoch: 007 Step: 00000800] Batch Recognition Loss:   0.017362 => Gls Tokens per Sec:     1600 || Batch Translation Loss:  59.736057 => Txt Tokens per Sec:     4040 || Lr: 0.000100
2024-02-08 13:08:20,843 [Epoch: 007 Step: 00000900] Batch Recognition Loss:   0.117663 => Gls Tokens per Sec:     1577 || Batch Translation Loss:  65.282082 => Txt Tokens per Sec:     4334 || Lr: 0.000100
2024-02-08 13:08:22,769 Epoch   7: Total Training Recognition Loss 15.30  Total Training Translation Loss 9130.31 
2024-02-08 13:08:22,769 EPOCH 8
2024-02-08 13:08:26,489 [Epoch: 008 Step: 00001000] Batch Recognition Loss:   0.046793 => Gls Tokens per Sec:     1484 || Batch Translation Loss:  50.554142 => Txt Tokens per Sec:     4081 || Lr: 0.000100
2024-02-08 13:08:30,203 Epoch   8: Total Training Recognition Loss 13.02  Total Training Translation Loss 8671.56 
2024-02-08 13:08:30,203 EPOCH 9
2024-02-08 13:08:32,231 [Epoch: 009 Step: 00001100] Batch Recognition Loss:   0.287708 => Gls Tokens per Sec:     1421 || Batch Translation Loss:  82.607155 => Txt Tokens per Sec:     3820 || Lr: 0.000100
2024-02-08 13:08:37,826 Epoch   9: Total Training Recognition Loss 10.53  Total Training Translation Loss 8240.51 
2024-02-08 13:08:37,826 EPOCH 10
2024-02-08 13:08:37,967 [Epoch: 010 Step: 00001200] Batch Recognition Loss:   0.075005 => Gls Tokens per Sec:     1714 || Batch Translation Loss:  43.725620 => Txt Tokens per Sec:     4271 || Lr: 0.000100
2024-02-08 13:08:43,276 [Epoch: 010 Step: 00001300] Batch Recognition Loss:   0.045043 => Gls Tokens per Sec:     1507 || Batch Translation Loss:  62.724968 => Txt Tokens per Sec:     4123 || Lr: 0.000100
2024-02-08 13:08:44,957 Epoch  10: Total Training Recognition Loss 9.78  Total Training Translation Loss 7819.53 
2024-02-08 13:08:44,957 EPOCH 11
2024-02-08 13:08:48,683 [Epoch: 011 Step: 00001400] Batch Recognition Loss:   0.022493 => Gls Tokens per Sec:     1503 || Batch Translation Loss:  55.771404 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-08 13:08:52,377 Epoch  11: Total Training Recognition Loss 9.50  Total Training Translation Loss 7384.04 
2024-02-08 13:08:52,378 EPOCH 12
2024-02-08 13:08:54,494 [Epoch: 012 Step: 00001500] Batch Recognition Loss:   0.067870 => Gls Tokens per Sec:     1399 || Batch Translation Loss:  50.721043 => Txt Tokens per Sec:     3887 || Lr: 0.000100
2024-02-08 13:08:59,669 Epoch  12: Total Training Recognition Loss 8.95  Total Training Translation Loss 7000.50 
2024-02-08 13:08:59,669 EPOCH 13
2024-02-08 13:08:59,894 [Epoch: 013 Step: 00001600] Batch Recognition Loss:   0.032241 => Gls Tokens per Sec:     1429 || Batch Translation Loss:  62.026375 => Txt Tokens per Sec:     4585 || Lr: 0.000100
2024-02-08 13:09:05,250 [Epoch: 013 Step: 00001700] Batch Recognition Loss:   0.023936 => Gls Tokens per Sec:     1494 || Batch Translation Loss:  43.995655 => Txt Tokens per Sec:     4087 || Lr: 0.000100
2024-02-08 13:09:06,890 Epoch  13: Total Training Recognition Loss 9.04  Total Training Translation Loss 6576.35 
2024-02-08 13:09:06,890 EPOCH 14
2024-02-08 13:09:10,373 [Epoch: 014 Step: 00001800] Batch Recognition Loss:   0.041191 => Gls Tokens per Sec:     1631 || Batch Translation Loss:  32.518673 => Txt Tokens per Sec:     4491 || Lr: 0.000100
2024-02-08 13:09:13,948 Epoch  14: Total Training Recognition Loss 7.55  Total Training Translation Loss 6162.87 
2024-02-08 13:09:13,949 EPOCH 15
2024-02-08 13:09:16,164 [Epoch: 015 Step: 00001900] Batch Recognition Loss:   0.039102 => Gls Tokens per Sec:     1373 || Batch Translation Loss:  27.397106 => Txt Tokens per Sec:     3879 || Lr: 0.000100
2024-02-08 13:09:21,344 Epoch  15: Total Training Recognition Loss 8.16  Total Training Translation Loss 5781.66 
2024-02-08 13:09:21,344 EPOCH 16
2024-02-08 13:09:21,672 [Epoch: 016 Step: 00002000] Batch Recognition Loss:   0.033931 => Gls Tokens per Sec:     1223 || Batch Translation Loss:  39.151669 => Txt Tokens per Sec:     3342 || Lr: 0.000100
2024-02-08 13:09:32,059 Hooray! New best validation result [eval_metric]!
2024-02-08 13:09:32,060 Saving new checkpoint.
2024-02-08 13:09:32,322 Validation result at epoch  16, step     2000: duration: 10.6489s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.60418	Translation Loss: 59462.84766	PPL: 379.61496
	Eval Metric: BLEU
	WER 6.85	(DEL: 0.00,	INS: 0.00,	SUB: 6.85)
	BLEU-4 0.56	(BLEU-1: 11.09,	BLEU-2: 3.85,	BLEU-3: 1.32,	BLEU-4: 0.56)
	CHRF 13.88	ROUGE 10.18
2024-02-08 13:09:32,324 Logging Recognition and Translation Outputs
2024-02-08 13:09:32,324 ========================================================================================================================
2024-02-08 13:09:32,324 Logging Sequence: 165_414.00
2024-02-08 13:09:32,325 	Gloss Reference :	A B+C+D+E
2024-02-08 13:09:32,325 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:09:32,325 	Gloss Alignment :	         
2024-02-08 13:09:32,325 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:09:32,326 	Text Reference  :	he felt sachin was lucky so   he   always  gave his sweater to give it to the     umpire 
2024-02-08 13:09:32,326 	Text Hypothesis :	he **** ****** *** has   been been brought for  his ******* ** **** ** ** amazing amazing
2024-02-08 13:09:32,327 	Text Alignment  :	   D    D      D   S     S    S    S       S        D       D  D    D  D  S       S      
2024-02-08 13:09:32,327 ========================================================================================================================
2024-02-08 13:09:32,327 Logging Sequence: 169_268.00
2024-02-08 13:09:32,327 	Gloss Reference :	A B+C+D+E
2024-02-08 13:09:32,327 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:09:32,327 	Gloss Alignment :	         
2024-02-08 13:09:32,328 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:09:32,328 	Text Reference  :	shami supports arshdeep and many  fans supported him     as     well 
2024-02-08 13:09:32,328 	Text Hypothesis :	***** the      bcci     is  known as   the       british empire games
2024-02-08 13:09:32,329 	Text Alignment  :	D     S        S        S   S     S    S         S       S      S    
2024-02-08 13:09:32,329 ========================================================================================================================
2024-02-08 13:09:32,329 Logging Sequence: 172_15.00
2024-02-08 13:09:32,329 	Gloss Reference :	A B+C+D+E
2024-02-08 13:09:32,329 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:09:32,329 	Gloss Alignment :	         
2024-02-08 13:09:32,329 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:09:32,331 	Text Reference  :	now in the final match on    28   may 2023 the two teams were up against each other at   the same  venue  
2024-02-08 13:09:32,331 	Text Hypothesis :	*** ** *** ***** ***** after this is  why  the *** ***** **** ** ******* **** most  most of  diego matches
2024-02-08 13:09:32,331 	Text Alignment  :	D   D  D   D     D     S     S    S   S        D   D     D    D  D       D    S     S    S   S     S      
2024-02-08 13:09:32,331 ========================================================================================================================
2024-02-08 13:09:32,331 Logging Sequence: 96_158.00
2024-02-08 13:09:32,332 	Gloss Reference :	A B+C+D+E
2024-02-08 13:09:32,332 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:09:32,332 	Gloss Alignment :	         
2024-02-08 13:09:32,332 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:09:32,333 	Text Reference  :	*** after  this pandya fell on   his knees in  disappointment
2024-02-08 13:09:32,333 	Text Hypothesis :	the couple are  very   very well for their fan following     
2024-02-08 13:09:32,333 	Text Alignment  :	I   S      S    S      S    S    S   S     S   S             
2024-02-08 13:09:32,333 ========================================================================================================================
2024-02-08 13:09:32,333 Logging Sequence: 152_73.00
2024-02-08 13:09:32,334 	Gloss Reference :	A B+C+D+E
2024-02-08 13:09:32,334 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:09:32,334 	Gloss Alignment :	         
2024-02-08 13:09:32,334 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:09:32,335 	Text Reference  :	**** **** ** **** ** eventually he  too      got  out by   shaheen afridi
2024-02-08 13:09:32,335 	Text Hypothesis :	they will be held in mumbai     and pakistan will be  held in      mumbai
2024-02-08 13:09:32,335 	Text Alignment  :	I    I    I  I    I  S          S   S        S    S   S    S       S     
2024-02-08 13:09:32,335 ========================================================================================================================
2024-02-08 13:09:37,991 [Epoch: 016 Step: 00002100] Batch Recognition Loss:   0.050895 => Gls Tokens per Sec:     1411 || Batch Translation Loss:  45.457775 => Txt Tokens per Sec:     3884 || Lr: 0.000100
2024-02-08 13:09:39,551 Epoch  16: Total Training Recognition Loss 7.65  Total Training Translation Loss 5398.06 
2024-02-08 13:09:39,551 EPOCH 17
2024-02-08 13:09:43,334 [Epoch: 017 Step: 00002200] Batch Recognition Loss:   0.014597 => Gls Tokens per Sec:     1523 || Batch Translation Loss:  31.337465 => Txt Tokens per Sec:     4210 || Lr: 0.000100
2024-02-08 13:09:46,755 Epoch  17: Total Training Recognition Loss 7.60  Total Training Translation Loss 5027.95 
2024-02-08 13:09:46,755 EPOCH 18
2024-02-08 13:09:48,873 [Epoch: 018 Step: 00002300] Batch Recognition Loss:   0.051939 => Gls Tokens per Sec:     1474 || Batch Translation Loss:  29.074175 => Txt Tokens per Sec:     4087 || Lr: 0.000100
2024-02-08 13:09:54,308 Epoch  18: Total Training Recognition Loss 7.88  Total Training Translation Loss 4673.04 
2024-02-08 13:09:54,309 EPOCH 19
2024-02-08 13:09:54,591 [Epoch: 019 Step: 00002400] Batch Recognition Loss:   0.037067 => Gls Tokens per Sec:     1714 || Batch Translation Loss:  39.396980 => Txt Tokens per Sec:     4593 || Lr: 0.000100
2024-02-08 13:09:59,799 [Epoch: 019 Step: 00002500] Batch Recognition Loss:   0.025024 => Gls Tokens per Sec:     1536 || Batch Translation Loss:  37.497128 => Txt Tokens per Sec:     4260 || Lr: 0.000100
2024-02-08 13:10:01,292 Epoch  19: Total Training Recognition Loss 7.37  Total Training Translation Loss 4277.78 
2024-02-08 13:10:01,292 EPOCH 20
2024-02-08 13:10:05,490 [Epoch: 020 Step: 00002600] Batch Recognition Loss:   0.087927 => Gls Tokens per Sec:     1391 || Batch Translation Loss:  37.032120 => Txt Tokens per Sec:     3814 || Lr: 0.000100
2024-02-08 13:10:08,728 Epoch  20: Total Training Recognition Loss 6.94  Total Training Translation Loss 3958.39 
2024-02-08 13:10:08,728 EPOCH 21
2024-02-08 13:10:10,830 [Epoch: 021 Step: 00002700] Batch Recognition Loss:   0.022354 => Gls Tokens per Sec:     1524 || Batch Translation Loss:  24.655195 => Txt Tokens per Sec:     4339 || Lr: 0.000100
2024-02-08 13:10:16,106 Epoch  21: Total Training Recognition Loss 7.33  Total Training Translation Loss 3596.51 
2024-02-08 13:10:16,107 EPOCH 22
2024-02-08 13:10:16,425 [Epoch: 022 Step: 00002800] Batch Recognition Loss:   0.074279 => Gls Tokens per Sec:     1761 || Batch Translation Loss:  19.311338 => Txt Tokens per Sec:     4635 || Lr: 0.000100
2024-02-08 13:10:21,919 [Epoch: 022 Step: 00002900] Batch Recognition Loss:   0.043924 => Gls Tokens per Sec:     1452 || Batch Translation Loss:  17.687277 => Txt Tokens per Sec:     4018 || Lr: 0.000100
2024-02-08 13:10:23,427 Epoch  22: Total Training Recognition Loss 6.89  Total Training Translation Loss 3275.39 
2024-02-08 13:10:23,428 EPOCH 23
2024-02-08 13:10:27,416 [Epoch: 023 Step: 00003000] Batch Recognition Loss:   0.097515 => Gls Tokens per Sec:     1485 || Batch Translation Loss:   6.351564 => Txt Tokens per Sec:     4100 || Lr: 0.000100
2024-02-08 13:10:30,734 Epoch  23: Total Training Recognition Loss 7.30  Total Training Translation Loss 2954.51 
2024-02-08 13:10:30,734 EPOCH 24
2024-02-08 13:10:33,141 [Epoch: 024 Step: 00003100] Batch Recognition Loss:   0.012531 => Gls Tokens per Sec:     1363 || Batch Translation Loss:  17.385902 => Txt Tokens per Sec:     3840 || Lr: 0.000100
2024-02-08 13:10:38,278 Epoch  24: Total Training Recognition Loss 6.66  Total Training Translation Loss 2680.72 
2024-02-08 13:10:38,278 EPOCH 25
2024-02-08 13:10:38,816 [Epoch: 025 Step: 00003200] Batch Recognition Loss:   0.020380 => Gls Tokens per Sec:     1194 || Batch Translation Loss:  15.754707 => Txt Tokens per Sec:     3646 || Lr: 0.000100
2024-02-08 13:10:44,340 [Epoch: 025 Step: 00003300] Batch Recognition Loss:   0.026360 => Gls Tokens per Sec:     1448 || Batch Translation Loss:  19.533564 => Txt Tokens per Sec:     3989 || Lr: 0.000100
2024-02-08 13:10:45,783 Epoch  25: Total Training Recognition Loss 7.08  Total Training Translation Loss 2383.74 
2024-02-08 13:10:45,784 EPOCH 26
2024-02-08 13:10:49,764 [Epoch: 026 Step: 00003400] Batch Recognition Loss:   0.112779 => Gls Tokens per Sec:     1508 || Batch Translation Loss:   5.503764 => Txt Tokens per Sec:     4171 || Lr: 0.000100
2024-02-08 13:10:53,006 Epoch  26: Total Training Recognition Loss 6.58  Total Training Translation Loss 2126.54 
2024-02-08 13:10:53,006 EPOCH 27
2024-02-08 13:10:55,156 [Epoch: 027 Step: 00003500] Batch Recognition Loss:   0.096274 => Gls Tokens per Sec:     1563 || Batch Translation Loss:  19.926826 => Txt Tokens per Sec:     4129 || Lr: 0.000100
2024-02-08 13:11:00,587 Epoch  27: Total Training Recognition Loss 6.00  Total Training Translation Loss 1890.02 
2024-02-08 13:11:00,588 EPOCH 28
2024-02-08 13:11:01,169 [Epoch: 028 Step: 00003600] Batch Recognition Loss:   0.048368 => Gls Tokens per Sec:     1242 || Batch Translation Loss:  13.842503 => Txt Tokens per Sec:     3219 || Lr: 0.000100
2024-02-08 13:11:06,356 [Epoch: 028 Step: 00003700] Batch Recognition Loss:   0.026813 => Gls Tokens per Sec:     1542 || Batch Translation Loss:  12.398520 => Txt Tokens per Sec:     4273 || Lr: 0.000100
2024-02-08 13:11:07,655 Epoch  28: Total Training Recognition Loss 6.68  Total Training Translation Loss 1660.51 
2024-02-08 13:11:07,655 EPOCH 29
2024-02-08 13:11:11,771 [Epoch: 029 Step: 00003800] Batch Recognition Loss:   0.027023 => Gls Tokens per Sec:     1478 || Batch Translation Loss:   8.420274 => Txt Tokens per Sec:     4060 || Lr: 0.000100
2024-02-08 13:11:15,055 Epoch  29: Total Training Recognition Loss 6.23  Total Training Translation Loss 1434.68 
2024-02-08 13:11:15,056 EPOCH 30
2024-02-08 13:11:17,209 [Epoch: 030 Step: 00003900] Batch Recognition Loss:   0.008876 => Gls Tokens per Sec:     1598 || Batch Translation Loss:   9.010634 => Txt Tokens per Sec:     4388 || Lr: 0.000100
2024-02-08 13:11:22,387 Epoch  30: Total Training Recognition Loss 5.55  Total Training Translation Loss 1270.01 
2024-02-08 13:11:22,387 EPOCH 31
2024-02-08 13:11:22,968 [Epoch: 031 Step: 00004000] Batch Recognition Loss:   0.023979 => Gls Tokens per Sec:     1379 || Batch Translation Loss:  10.335342 => Txt Tokens per Sec:     3645 || Lr: 0.000100
2024-02-08 13:11:34,242 Hooray! New best validation result [eval_metric]!
2024-02-08 13:11:34,244 Saving new checkpoint.
2024-02-08 13:11:34,514 Validation result at epoch  31, step     4000: duration: 11.5449s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.67530	Translation Loss: 66637.60156	PPL: 777.25867
	Eval Metric: BLEU
	WER 6.21	(DEL: 0.00,	INS: 0.00,	SUB: 6.21)
	BLEU-4 0.90	(BLEU-1: 13.04,	BLEU-2: 4.63,	BLEU-3: 1.79,	BLEU-4: 0.90)
	CHRF 16.97	ROUGE 10.51
2024-02-08 13:11:34,515 Logging Recognition and Translation Outputs
2024-02-08 13:11:34,515 ========================================================================================================================
2024-02-08 13:11:34,515 Logging Sequence: 112_165.00
2024-02-08 13:11:34,515 	Gloss Reference :	A B+C+D+E
2024-02-08 13:11:34,516 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:11:34,516 	Gloss Alignment :	         
2024-02-08 13:11:34,516 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:11:34,517 	Text Reference  :	**** **** ********* the **** *** **** *** ** ***** narendra modi   stadium will be   the  home for     the    ahmedabad-based franchise
2024-02-08 13:11:34,518 	Text Hypothesis :	they were objecting the same but they had to carry on       social media   that they have been planned around their           height   
2024-02-08 13:11:34,518 	Text Alignment  :	I    I    I             I    I   I    I   I  I     S        S      S       S    S    S    S    S       S      S               S        
2024-02-08 13:11:34,518 ========================================================================================================================
2024-02-08 13:11:34,518 Logging Sequence: 176_154.00
2024-02-08 13:11:34,518 	Gloss Reference :	A B+C+D+E
2024-02-08 13:11:34,518 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:11:34,519 	Gloss Alignment :	         
2024-02-08 13:11:34,519 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:11:34,519 	Text Reference  :	*** *** dahiya could potentially bring home india's second gold   medal   
2024-02-08 13:11:34,520 	Text Hypothesis :	she had won    a     silver      medal in   the     2012   london olympics
2024-02-08 13:11:34,520 	Text Alignment  :	I   I   S      S     S           S     S    S       S      S      S       
2024-02-08 13:11:34,520 ========================================================================================================================
2024-02-08 13:11:34,520 Logging Sequence: 94_2.00
2024-02-08 13:11:34,520 	Gloss Reference :	A B+C+D+E
2024-02-08 13:11:34,520 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:11:34,520 	Gloss Alignment :	         
2024-02-08 13:11:34,521 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:11:34,522 	Text Reference  :	the    icc     odi  men' world cup     2023 will   be     hosted  by   india   on 5th     october 2023 
2024-02-08 13:11:34,522 	Text Hypothesis :	indian cricket team is   in    colombo sri  lankan lankan batsmen were playing in colombo sri     lanka
2024-02-08 13:11:34,522 	Text Alignment  :	S      S       S    S    S     S       S    S      S      S       S    S       S  S       S       S    
2024-02-08 13:11:34,522 ========================================================================================================================
2024-02-08 13:11:34,523 Logging Sequence: 165_453.00
2024-02-08 13:11:34,523 	Gloss Reference :	A B+C+D+E
2024-02-08 13:11:34,523 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:11:34,523 	Gloss Alignment :	         
2024-02-08 13:11:34,523 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:11:34,524 	Text Reference  :	icc did not agree to sehwag' decision of        wearing a   numberless jersey    
2024-02-08 13:11:34,524 	Text Hypothesis :	*** he  has been  a  huge    fan      following in      the brand      ambassador
2024-02-08 13:11:34,524 	Text Alignment  :	D   S   S   S     S  S       S        S         S       S   S          S         
2024-02-08 13:11:34,524 ========================================================================================================================
2024-02-08 13:11:34,525 Logging Sequence: 139_46.00
2024-02-08 13:11:34,525 	Gloss Reference :	A B+C+D+E
2024-02-08 13:11:34,525 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:11:34,525 	Gloss Alignment :	         
2024-02-08 13:11:34,525 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:11:34,527 	Text Reference  :	everyone thought it would be a one sided match because  morocco is an  amateur team and       belgium ranks 2nd    in     the    world
2024-02-08 13:11:34,527 	Text Hypothesis :	******** ******* ** ***** ** * *** on    23rd  november 2022    he was known   as   argentina with    the   entire entire entire match
2024-02-08 13:11:34,527 	Text Alignment  :	D        D       D  D     D  D D   S     S     S        S       S  S   S       S    S         S       S     S      S      S      S    
2024-02-08 13:11:34,527 ========================================================================================================================
2024-02-08 13:11:40,006 [Epoch: 031 Step: 00004100] Batch Recognition Loss:   0.089352 => Gls Tokens per Sec:     1457 || Batch Translation Loss:  11.035307 => Txt Tokens per Sec:     4033 || Lr: 0.000100
2024-02-08 13:11:41,263 Epoch  31: Total Training Recognition Loss 5.31  Total Training Translation Loss 1099.32 
2024-02-08 13:11:41,263 EPOCH 32
2024-02-08 13:11:45,701 [Epoch: 032 Step: 00004200] Batch Recognition Loss:   0.076550 => Gls Tokens per Sec:     1388 || Batch Translation Loss:   9.553076 => Txt Tokens per Sec:     3797 || Lr: 0.000100
2024-02-08 13:11:48,737 Epoch  32: Total Training Recognition Loss 4.96  Total Training Translation Loss 962.76 
2024-02-08 13:11:48,737 EPOCH 33
2024-02-08 13:11:50,951 [Epoch: 033 Step: 00004300] Batch Recognition Loss:   0.018557 => Gls Tokens per Sec:     1591 || Batch Translation Loss:   4.415009 => Txt Tokens per Sec:     4307 || Lr: 0.000100
2024-02-08 13:11:56,186 Epoch  33: Total Training Recognition Loss 4.84  Total Training Translation Loss 832.85 
2024-02-08 13:11:56,186 EPOCH 34
2024-02-08 13:11:56,801 [Epoch: 034 Step: 00004400] Batch Recognition Loss:   0.024369 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   6.544117 => Txt Tokens per Sec:     4181 || Lr: 0.000100
2024-02-08 13:12:02,321 [Epoch: 034 Step: 00004500] Batch Recognition Loss:   0.023748 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   6.189412 => Txt Tokens per Sec:     4022 || Lr: 0.000100
2024-02-08 13:12:03,514 Epoch  34: Total Training Recognition Loss 4.56  Total Training Translation Loss 734.23 
2024-02-08 13:12:03,515 EPOCH 35
2024-02-08 13:12:07,731 [Epoch: 035 Step: 00004600] Batch Recognition Loss:   0.083799 => Gls Tokens per Sec:     1480 || Batch Translation Loss:   7.523927 => Txt Tokens per Sec:     4084 || Lr: 0.000100
2024-02-08 13:12:10,620 Epoch  35: Total Training Recognition Loss 4.61  Total Training Translation Loss 647.28 
2024-02-08 13:12:10,620 EPOCH 36
2024-02-08 13:12:12,946 [Epoch: 036 Step: 00004700] Batch Recognition Loss:   0.011147 => Gls Tokens per Sec:     1549 || Batch Translation Loss:   4.958719 => Txt Tokens per Sec:     4139 || Lr: 0.000100
2024-02-08 13:12:18,236 Epoch  36: Total Training Recognition Loss 4.30  Total Training Translation Loss 569.03 
2024-02-08 13:12:18,237 EPOCH 37
2024-02-08 13:12:18,886 [Epoch: 037 Step: 00004800] Batch Recognition Loss:   0.030523 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   5.280664 => Txt Tokens per Sec:     4079 || Lr: 0.000100
2024-02-08 13:12:24,374 [Epoch: 037 Step: 00004900] Batch Recognition Loss:   0.117376 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   5.065679 => Txt Tokens per Sec:     4033 || Lr: 0.000100
2024-02-08 13:12:25,706 Epoch  37: Total Training Recognition Loss 3.86  Total Training Translation Loss 503.10 
2024-02-08 13:12:25,706 EPOCH 38
2024-02-08 13:12:30,078 [Epoch: 038 Step: 00005000] Batch Recognition Loss:   0.013325 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   2.705728 => Txt Tokens per Sec:     3978 || Lr: 0.000100
2024-02-08 13:12:32,916 Epoch  38: Total Training Recognition Loss 4.05  Total Training Translation Loss 463.25 
2024-02-08 13:12:32,916 EPOCH 39
2024-02-08 13:12:35,246 [Epoch: 039 Step: 00005100] Batch Recognition Loss:   0.035562 => Gls Tokens per Sec:     1581 || Batch Translation Loss:   2.965364 => Txt Tokens per Sec:     4205 || Lr: 0.000100
2024-02-08 13:12:40,308 Epoch  39: Total Training Recognition Loss 3.89  Total Training Translation Loss 442.07 
2024-02-08 13:12:40,308 EPOCH 40
2024-02-08 13:12:41,008 [Epoch: 040 Step: 00005200] Batch Recognition Loss:   0.019526 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   2.060647 => Txt Tokens per Sec:     3931 || Lr: 0.000100
2024-02-08 13:12:46,548 [Epoch: 040 Step: 00005300] Batch Recognition Loss:   0.064800 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   1.047823 => Txt Tokens per Sec:     4016 || Lr: 0.000100
2024-02-08 13:12:47,645 Epoch  40: Total Training Recognition Loss 3.83  Total Training Translation Loss 372.47 
2024-02-08 13:12:47,645 EPOCH 41
2024-02-08 13:12:51,813 [Epoch: 041 Step: 00005400] Batch Recognition Loss:   0.024934 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   1.678124 => Txt Tokens per Sec:     4190 || Lr: 0.000100
2024-02-08 13:12:54,705 Epoch  41: Total Training Recognition Loss 3.63  Total Training Translation Loss 333.46 
2024-02-08 13:12:54,706 EPOCH 42
2024-02-08 13:12:57,468 [Epoch: 042 Step: 00005500] Batch Recognition Loss:   0.013325 => Gls Tokens per Sec:     1361 || Batch Translation Loss:   2.666793 => Txt Tokens per Sec:     3618 || Lr: 0.000100
2024-02-08 13:13:02,282 Epoch  42: Total Training Recognition Loss 3.23  Total Training Translation Loss 304.80 
2024-02-08 13:13:02,282 EPOCH 43
2024-02-08 13:13:03,064 [Epoch: 043 Step: 00005600] Batch Recognition Loss:   0.042253 => Gls Tokens per Sec:     1434 || Batch Translation Loss:   2.730907 => Txt Tokens per Sec:     4114 || Lr: 0.000100
2024-02-08 13:13:08,599 [Epoch: 043 Step: 00005700] Batch Recognition Loss:   0.031889 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   1.274524 => Txt Tokens per Sec:     3969 || Lr: 0.000100
2024-02-08 13:13:09,599 Epoch  43: Total Training Recognition Loss 3.12  Total Training Translation Loss 271.39 
2024-02-08 13:13:09,600 EPOCH 44
2024-02-08 13:13:13,588 [Epoch: 044 Step: 00005800] Batch Recognition Loss:   0.008553 => Gls Tokens per Sec:     1625 || Batch Translation Loss:   2.240797 => Txt Tokens per Sec:     4459 || Lr: 0.000100
2024-02-08 13:13:16,582 Epoch  44: Total Training Recognition Loss 3.10  Total Training Translation Loss 270.82 
2024-02-08 13:13:16,582 EPOCH 45
2024-02-08 13:13:19,456 [Epoch: 045 Step: 00005900] Batch Recognition Loss:   0.005049 => Gls Tokens per Sec:     1337 || Batch Translation Loss:   1.643067 => Txt Tokens per Sec:     3776 || Lr: 0.000100
2024-02-08 13:13:24,250 Epoch  45: Total Training Recognition Loss 3.09  Total Training Translation Loss 254.40 
2024-02-08 13:13:24,250 EPOCH 46
2024-02-08 13:13:24,957 [Epoch: 046 Step: 00006000] Batch Recognition Loss:   0.004929 => Gls Tokens per Sec:     1700 || Batch Translation Loss:   3.145338 => Txt Tokens per Sec:     4763 || Lr: 0.000100
2024-02-08 13:13:35,927 Validation result at epoch  46, step     6000: duration: 10.9690s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.23954	Translation Loss: 75033.09375	PPL: 1797.79492
	Eval Metric: BLEU
	WER 6.21	(DEL: 0.00,	INS: 0.00,	SUB: 6.21)
	BLEU-4 0.84	(BLEU-1: 12.90,	BLEU-2: 4.32,	BLEU-3: 1.71,	BLEU-4: 0.84)
	CHRF 17.50	ROUGE 10.26
2024-02-08 13:13:35,928 Logging Recognition and Translation Outputs
2024-02-08 13:13:35,929 ========================================================================================================================
2024-02-08 13:13:35,929 Logging Sequence: 160_153.00
2024-02-08 13:13:35,929 	Gloss Reference :	A B+C+D+E
2024-02-08 13:13:35,929 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:13:35,929 	Gloss Alignment :	  S      
2024-02-08 13:13:35,930 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:13:35,931 	Text Reference  :	i have no hard feelings towards   rohit  sharma  and he will always have   my full support as he is  my   teammate
2024-02-08 13:13:35,931 	Text Hypothesis :	* **** ** **** bcci     president sourav ganguly and ** **** ****** others to step down    as ** odi t20i captain 
2024-02-08 13:13:35,932 	Text Alignment  :	D D    D  D    S        S         S      S           D  D    D      S      S  S    S          D  S   S    S       
2024-02-08 13:13:35,932 ========================================================================================================================
2024-02-08 13:13:35,932 Logging Sequence: 103_253.00
2024-02-08 13:13:35,932 	Gloss Reference :	A B+C+D+E
2024-02-08 13:13:35,932 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:13:35,932 	Gloss Alignment :	         
2024-02-08 13:13:35,932 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:13:35,933 	Text Reference  :	**** ***** ******* *** *** *** ***** ******** canada is 3rd   with 92 medals
2024-02-08 13:13:35,933 	Text Hypothesis :	this upset gambhir has won the first position for    a  total of   6  medals
2024-02-08 13:13:35,933 	Text Alignment  :	I    I     I       I   I   I   I     I        S      S  S     S    S        
2024-02-08 13:13:35,934 ========================================================================================================================
2024-02-08 13:13:35,934 Logging Sequence: 155_25.00
2024-02-08 13:13:35,934 	Gloss Reference :	A B+C+D+E
2024-02-08 13:13:35,934 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:13:35,934 	Gloss Alignment :	         
2024-02-08 13:13:35,934 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:13:35,935 	Text Reference  :	this is because taliban overthrew the  afghan government and    took          over the country
2024-02-08 13:13:35,935 	Text Hypothesis :	i    am so      what    a         huge fan    of         sports personalities for  the matches
2024-02-08 13:13:35,936 	Text Alignment  :	S    S  S       S       S         S    S      S          S      S             S        S      
2024-02-08 13:13:35,936 ========================================================================================================================
2024-02-08 13:13:35,936 Logging Sequence: 81_105.00
2024-02-08 13:13:35,936 	Gloss Reference :	A B+C+D+E
2024-02-08 13:13:35,936 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:13:35,936 	Gloss Alignment :	         
2024-02-08 13:13:35,936 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:13:35,938 	Text Reference  :	*** **** dhoni was tagged in  multiple such posts as he was  the brand ambassador
2024-02-08 13:13:35,938 	Text Hypothesis :	and told him   for the    t20 world    cup  is    up to play the brand ambassador
2024-02-08 13:13:35,938 	Text Alignment  :	I   I    S     S   S      S   S        S    S     S  S  S                        
2024-02-08 13:13:35,938 ========================================================================================================================
2024-02-08 13:13:35,938 Logging Sequence: 105_136.00
2024-02-08 13:13:35,938 	Gloss Reference :	A B+C+D+E
2024-02-08 13:13:35,938 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:13:35,939 	Gloss Alignment :	         
2024-02-08 13:13:35,939 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:13:35,939 	Text Reference  :	** *** **** ** **** *** ***** beating him   once   is  my  biggest dream 
2024-02-08 13:13:35,940 	Text Hypothesis :	as you want to know the image of      their mobile and why was     halted
2024-02-08 13:13:35,940 	Text Alignment  :	I  I   I    I  I    I   I     S       S     S      S   S   S       S     
2024-02-08 13:13:35,940 ========================================================================================================================
2024-02-08 13:13:41,726 [Epoch: 046 Step: 00006100] Batch Recognition Loss:   0.002709 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   1.953916 => Txt Tokens per Sec:     3828 || Lr: 0.000100
2024-02-08 13:13:42,645 Epoch  46: Total Training Recognition Loss 3.23  Total Training Translation Loss 231.51 
2024-02-08 13:13:42,645 EPOCH 47
2024-02-08 13:13:46,814 [Epoch: 047 Step: 00006200] Batch Recognition Loss:   0.016567 => Gls Tokens per Sec:     1574 || Batch Translation Loss:   2.087783 => Txt Tokens per Sec:     4290 || Lr: 0.000100
2024-02-08 13:13:49,788 Epoch  47: Total Training Recognition Loss 3.31  Total Training Translation Loss 228.62 
2024-02-08 13:13:49,788 EPOCH 48
2024-02-08 13:13:52,423 [Epoch: 048 Step: 00006300] Batch Recognition Loss:   0.001881 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   1.626924 => Txt Tokens per Sec:     4107 || Lr: 0.000100
2024-02-08 13:13:57,216 Epoch  48: Total Training Recognition Loss 2.74  Total Training Translation Loss 201.43 
2024-02-08 13:13:57,216 EPOCH 49
2024-02-08 13:13:58,048 [Epoch: 049 Step: 00006400] Batch Recognition Loss:   0.029490 => Gls Tokens per Sec:     1542 || Batch Translation Loss:   0.861567 => Txt Tokens per Sec:     4463 || Lr: 0.000100
2024-02-08 13:14:03,405 [Epoch: 049 Step: 00006500] Batch Recognition Loss:   0.021425 => Gls Tokens per Sec:     1494 || Batch Translation Loss:   1.146782 => Txt Tokens per Sec:     4086 || Lr: 0.000100
2024-02-08 13:14:04,442 Epoch  49: Total Training Recognition Loss 2.55  Total Training Translation Loss 177.93 
2024-02-08 13:14:04,442 EPOCH 50
2024-02-08 13:14:09,441 [Epoch: 050 Step: 00006600] Batch Recognition Loss:   0.028997 => Gls Tokens per Sec:     1329 || Batch Translation Loss:   1.407509 => Txt Tokens per Sec:     3720 || Lr: 0.000100
2024-02-08 13:14:12,073 Epoch  50: Total Training Recognition Loss 2.41  Total Training Translation Loss 172.11 
2024-02-08 13:14:12,073 EPOCH 51
2024-02-08 13:14:14,644 [Epoch: 051 Step: 00006700] Batch Recognition Loss:   0.020972 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   1.600647 => Txt Tokens per Sec:     4280 || Lr: 0.000100
2024-02-08 13:14:19,631 Epoch  51: Total Training Recognition Loss 2.48  Total Training Translation Loss 179.08 
2024-02-08 13:14:19,632 EPOCH 52
2024-02-08 13:14:20,517 [Epoch: 052 Step: 00006800] Batch Recognition Loss:   0.011059 => Gls Tokens per Sec:     1538 || Batch Translation Loss:   1.705976 => Txt Tokens per Sec:     4267 || Lr: 0.000100
2024-02-08 13:14:26,185 [Epoch: 052 Step: 00006900] Batch Recognition Loss:   0.012915 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   1.315951 => Txt Tokens per Sec:     3919 || Lr: 0.000100
2024-02-08 13:14:27,092 Epoch  52: Total Training Recognition Loss 2.34  Total Training Translation Loss 165.06 
2024-02-08 13:14:27,093 EPOCH 53
2024-02-08 13:14:31,664 [Epoch: 053 Step: 00007000] Batch Recognition Loss:   0.006304 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   1.392996 => Txt Tokens per Sec:     4066 || Lr: 0.000100
2024-02-08 13:14:34,357 Epoch  53: Total Training Recognition Loss 2.51  Total Training Translation Loss 152.24 
2024-02-08 13:14:34,357 EPOCH 54
2024-02-08 13:14:37,230 [Epoch: 054 Step: 00007100] Batch Recognition Loss:   0.014460 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   1.123867 => Txt Tokens per Sec:     3989 || Lr: 0.000100
2024-02-08 13:14:41,742 Epoch  54: Total Training Recognition Loss 2.29  Total Training Translation Loss 152.03 
2024-02-08 13:14:41,742 EPOCH 55
2024-02-08 13:14:42,590 [Epoch: 055 Step: 00007200] Batch Recognition Loss:   0.007499 => Gls Tokens per Sec:     1700 || Batch Translation Loss:   0.638661 => Txt Tokens per Sec:     4439 || Lr: 0.000100
2024-02-08 13:14:48,325 [Epoch: 055 Step: 00007300] Batch Recognition Loss:   0.009966 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   1.162497 => Txt Tokens per Sec:     3937 || Lr: 0.000100
2024-02-08 13:14:49,080 Epoch  55: Total Training Recognition Loss 2.23  Total Training Translation Loss 144.10 
2024-02-08 13:14:49,080 EPOCH 56
2024-02-08 13:14:53,620 [Epoch: 056 Step: 00007400] Batch Recognition Loss:   0.012306 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.674756 => Txt Tokens per Sec:     4090 || Lr: 0.000100
2024-02-08 13:14:56,223 Epoch  56: Total Training Recognition Loss 1.91  Total Training Translation Loss 140.63 
2024-02-08 13:14:56,224 EPOCH 57
2024-02-08 13:14:59,155 [Epoch: 057 Step: 00007500] Batch Recognition Loss:   0.015155 => Gls Tokens per Sec:     1420 || Batch Translation Loss:   1.826363 => Txt Tokens per Sec:     3878 || Lr: 0.000100
2024-02-08 13:15:03,945 Epoch  57: Total Training Recognition Loss 2.09  Total Training Translation Loss 138.94 
2024-02-08 13:15:03,945 EPOCH 58
2024-02-08 13:15:04,843 [Epoch: 058 Step: 00007600] Batch Recognition Loss:   0.008336 => Gls Tokens per Sec:     1695 || Batch Translation Loss:   1.180549 => Txt Tokens per Sec:     4695 || Lr: 0.000100
2024-02-08 13:15:10,418 [Epoch: 058 Step: 00007700] Batch Recognition Loss:   0.015186 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.776001 => Txt Tokens per Sec:     3969 || Lr: 0.000100
2024-02-08 13:15:11,249 Epoch  58: Total Training Recognition Loss 2.14  Total Training Translation Loss 130.50 
2024-02-08 13:15:11,249 EPOCH 59
2024-02-08 13:15:15,818 [Epoch: 059 Step: 00007800] Batch Recognition Loss:   0.001509 => Gls Tokens per Sec:     1506 || Batch Translation Loss:   0.707295 => Txt Tokens per Sec:     4178 || Lr: 0.000100
2024-02-08 13:15:18,632 Epoch  59: Total Training Recognition Loss 1.95  Total Training Translation Loss 120.70 
2024-02-08 13:15:18,633 EPOCH 60
2024-02-08 13:15:21,477 [Epoch: 060 Step: 00007900] Batch Recognition Loss:   0.008575 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.499225 => Txt Tokens per Sec:     4142 || Lr: 0.000100
2024-02-08 13:15:25,687 Epoch  60: Total Training Recognition Loss 2.24  Total Training Translation Loss 115.80 
2024-02-08 13:15:25,687 EPOCH 61
2024-02-08 13:15:27,056 [Epoch: 061 Step: 00008000] Batch Recognition Loss:   0.092788 => Gls Tokens per Sec:     1170 || Batch Translation Loss:   1.408222 => Txt Tokens per Sec:     3487 || Lr: 0.000100
2024-02-08 13:15:37,250 Validation result at epoch  61, step     8000: duration: 10.1935s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.46578	Translation Loss: 82008.84375	PPL: 3608.52832
	Eval Metric: BLEU
	WER 5.79	(DEL: 0.00,	INS: 0.00,	SUB: 5.79)
	BLEU-4 0.60	(BLEU-1: 11.46,	BLEU-2: 3.87,	BLEU-3: 1.32,	BLEU-4: 0.60)
	CHRF 17.12	ROUGE 9.95
2024-02-08 13:15:37,251 Logging Recognition and Translation Outputs
2024-02-08 13:15:37,251 ========================================================================================================================
2024-02-08 13:15:37,251 Logging Sequence: 180_236.00
2024-02-08 13:15:37,252 	Gloss Reference :	A B+C+D+E
2024-02-08 13:15:37,252 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:15:37,252 	Gloss Alignment :	         
2024-02-08 13:15:37,252 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:15:37,253 	Text Reference  :	however the  wrestlers returned to      the ****** protest site at   jantar mantar      with     thier demands
2024-02-08 13:15:37,253 	Text Hypothesis :	******* they were      also     outside the report this    and  they were   immediately released her   time   
2024-02-08 13:15:37,253 	Text Alignment  :	D       S    S         S        S           I      S       S    S    S      S           S        S     S      
2024-02-08 13:15:37,254 ========================================================================================================================
2024-02-08 13:15:37,254 Logging Sequence: 111_154.00
2024-02-08 13:15:37,254 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:15:37,254 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:15:37,254 	Gloss Alignment :	  S        
2024-02-08 13:15:37,254 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:15:37,255 	Text Reference  :	** due  to    csk's slow      over   rate dhoni   was fined rs 12 lakh
2024-02-08 13:15:37,255 	Text Hypothesis :	on 10th april 2021  rajasthan royals as   captain was fined rs 12 lakh
2024-02-08 13:15:37,255 	Text Alignment  :	I  S    S     S     S         S      S    S                           
2024-02-08 13:15:37,256 ========================================================================================================================
2024-02-08 13:15:37,256 Logging Sequence: 118_314.00
2024-02-08 13:15:37,256 	Gloss Reference :	A B+C+D+E
2024-02-08 13:15:37,256 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:15:37,256 	Gloss Alignment :	         
2024-02-08 13:15:37,256 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:15:37,257 	Text Reference  :	** wow  even the president had come to   watch
2024-02-08 13:15:37,257 	Text Hypothesis :	so here are  the ********* *** **** same time 
2024-02-08 13:15:37,257 	Text Alignment  :	I  S    S        D         D   D    S    S    
2024-02-08 13:15:37,257 ========================================================================================================================
2024-02-08 13:15:37,257 Logging Sequence: 156_197.00
2024-02-08 13:15:37,257 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:15:37,257 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:15:37,258 	Gloss Alignment :	  S        
2024-02-08 13:15:37,258 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:15:37,259 	Text Reference  :	******* seattle orcas sor   is  owned     by     many investors including satya    nadella microsoft ceo     
2024-02-08 13:15:37,259 	Text Hypothesis :	amazing to      see   these are different states if   they      have      invested in      the       athletes
2024-02-08 13:15:37,259 	Text Alignment  :	I       S       S     S     S   S         S      S    S         S         S        S       S         S       
2024-02-08 13:15:37,259 ========================================================================================================================
2024-02-08 13:15:37,259 Logging Sequence: 183_159.00
2024-02-08 13:15:37,260 	Gloss Reference :	A B+C+D+E
2024-02-08 13:15:37,260 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:15:37,260 	Gloss Alignment :	  S      
2024-02-08 13:15:37,260 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:15:37,261 	Text Reference  :	however an exception to this is virat kohli and his wife anushka sharma  who refuse  to share images of   their daughter
2024-02-08 13:15:37,261 	Text Hypothesis :	******* ** ********* ** **** ** ***** ***** *** *** **** fans    usually the picture of the   virus  will be    applied 
2024-02-08 13:15:37,261 	Text Alignment  :	D       D  D         D  D    D  D     D     D   D   D    S       S       S   S       S  S     S      S    S     S       
2024-02-08 13:15:37,262 ========================================================================================================================
2024-02-08 13:15:43,018 [Epoch: 061 Step: 00008100] Batch Recognition Loss:   0.012546 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.991398 => Txt Tokens per Sec:     3782 || Lr: 0.000100
2024-02-08 13:15:43,717 Epoch  61: Total Training Recognition Loss 2.14  Total Training Translation Loss 121.87 
2024-02-08 13:15:43,717 EPOCH 62
2024-02-08 13:15:48,152 [Epoch: 062 Step: 00008200] Batch Recognition Loss:   0.027587 => Gls Tokens per Sec:     1570 || Batch Translation Loss:   0.937415 => Txt Tokens per Sec:     4269 || Lr: 0.000100
2024-02-08 13:15:50,882 Epoch  62: Total Training Recognition Loss 2.25  Total Training Translation Loss 109.87 
2024-02-08 13:15:50,882 EPOCH 63
2024-02-08 13:15:53,781 [Epoch: 063 Step: 00008300] Batch Recognition Loss:   0.026730 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.660205 => Txt Tokens per Sec:     4122 || Lr: 0.000100
2024-02-08 13:15:58,008 Epoch  63: Total Training Recognition Loss 1.94  Total Training Translation Loss 96.61 
2024-02-08 13:15:58,008 EPOCH 64
2024-02-08 13:15:59,206 [Epoch: 064 Step: 00008400] Batch Recognition Loss:   0.058148 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.834896 => Txt Tokens per Sec:     3974 || Lr: 0.000100
2024-02-08 13:16:05,011 [Epoch: 064 Step: 00008500] Batch Recognition Loss:   0.002967 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   1.119718 => Txt Tokens per Sec:     3807 || Lr: 0.000100
2024-02-08 13:16:05,711 Epoch  64: Total Training Recognition Loss 1.91  Total Training Translation Loss 88.39 
2024-02-08 13:16:05,712 EPOCH 65
2024-02-08 13:16:10,373 [Epoch: 065 Step: 00008600] Batch Recognition Loss:   0.029972 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.445759 => Txt Tokens per Sec:     4135 || Lr: 0.000100
2024-02-08 13:16:12,829 Epoch  65: Total Training Recognition Loss 2.02  Total Training Translation Loss 96.72 
2024-02-08 13:16:12,830 EPOCH 66
2024-02-08 13:16:15,839 [Epoch: 066 Step: 00008700] Batch Recognition Loss:   0.002673 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.654528 => Txt Tokens per Sec:     4035 || Lr: 0.000100
2024-02-08 13:16:20,310 Epoch  66: Total Training Recognition Loss 1.99  Total Training Translation Loss 98.00 
2024-02-08 13:16:20,310 EPOCH 67
2024-02-08 13:16:21,553 [Epoch: 067 Step: 00008800] Batch Recognition Loss:   0.001646 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   0.347029 => Txt Tokens per Sec:     4010 || Lr: 0.000100
2024-02-08 13:16:27,059 [Epoch: 067 Step: 00008900] Batch Recognition Loss:   0.006508 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.470612 => Txt Tokens per Sec:     3987 || Lr: 0.000100
2024-02-08 13:16:27,704 Epoch  67: Total Training Recognition Loss 2.15  Total Training Translation Loss 88.49 
2024-02-08 13:16:27,704 EPOCH 68
2024-02-08 13:16:32,754 [Epoch: 068 Step: 00009000] Batch Recognition Loss:   0.001924 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.623161 => Txt Tokens per Sec:     3853 || Lr: 0.000100
2024-02-08 13:16:35,121 Epoch  68: Total Training Recognition Loss 1.64  Total Training Translation Loss 87.58 
2024-02-08 13:16:35,122 EPOCH 69
2024-02-08 13:16:37,717 [Epoch: 069 Step: 00009100] Batch Recognition Loss:   0.006929 => Gls Tokens per Sec:     1726 || Batch Translation Loss:   0.256164 => Txt Tokens per Sec:     4695 || Lr: 0.000100
2024-02-08 13:16:42,253 Epoch  69: Total Training Recognition Loss 1.71  Total Training Translation Loss 79.80 
2024-02-08 13:16:42,253 EPOCH 70
2024-02-08 13:16:43,681 [Epoch: 070 Step: 00009200] Batch Recognition Loss:   0.007858 => Gls Tokens per Sec:     1289 || Batch Translation Loss:   0.381266 => Txt Tokens per Sec:     3492 || Lr: 0.000100
2024-02-08 13:16:49,071 [Epoch: 070 Step: 00009300] Batch Recognition Loss:   0.022894 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.338679 => Txt Tokens per Sec:     4090 || Lr: 0.000100
2024-02-08 13:16:49,704 Epoch  70: Total Training Recognition Loss 1.95  Total Training Translation Loss 84.22 
2024-02-08 13:16:49,704 EPOCH 71
2024-02-08 13:16:54,640 [Epoch: 071 Step: 00009400] Batch Recognition Loss:   0.003948 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.627664 => Txt Tokens per Sec:     4012 || Lr: 0.000100
2024-02-08 13:16:57,080 Epoch  71: Total Training Recognition Loss 1.56  Total Training Translation Loss 92.25 
2024-02-08 13:16:57,080 EPOCH 72
2024-02-08 13:17:00,099 [Epoch: 072 Step: 00009500] Batch Recognition Loss:   0.011671 => Gls Tokens per Sec:     1511 || Batch Translation Loss:   0.238773 => Txt Tokens per Sec:     4143 || Lr: 0.000100
2024-02-08 13:17:04,329 Epoch  72: Total Training Recognition Loss 1.87  Total Training Translation Loss 88.43 
2024-02-08 13:17:04,330 EPOCH 73
2024-02-08 13:17:05,648 [Epoch: 073 Step: 00009600] Batch Recognition Loss:   0.000867 => Gls Tokens per Sec:     1456 || Batch Translation Loss:   0.433190 => Txt Tokens per Sec:     4082 || Lr: 0.000100
2024-02-08 13:17:11,176 [Epoch: 073 Step: 00009700] Batch Recognition Loss:   0.036470 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.566307 => Txt Tokens per Sec:     3984 || Lr: 0.000100
2024-02-08 13:17:11,668 Epoch  73: Total Training Recognition Loss 1.73  Total Training Translation Loss 83.67 
2024-02-08 13:17:11,668 EPOCH 74
2024-02-08 13:17:16,590 [Epoch: 074 Step: 00009800] Batch Recognition Loss:   0.050869 => Gls Tokens per Sec:     1480 || Batch Translation Loss:   0.799258 => Txt Tokens per Sec:     4078 || Lr: 0.000100
2024-02-08 13:17:18,945 Epoch  74: Total Training Recognition Loss 1.87  Total Training Translation Loss 72.31 
2024-02-08 13:17:18,945 EPOCH 75
2024-02-08 13:17:22,205 [Epoch: 075 Step: 00009900] Batch Recognition Loss:   0.049643 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   1.208637 => Txt Tokens per Sec:     4017 || Lr: 0.000100
2024-02-08 13:17:26,545 Epoch  75: Total Training Recognition Loss 1.76  Total Training Translation Loss 73.37 
2024-02-08 13:17:26,545 EPOCH 76
2024-02-08 13:17:28,160 [Epoch: 076 Step: 00010000] Batch Recognition Loss:   0.004323 => Gls Tokens per Sec:     1239 || Batch Translation Loss:   0.315134 => Txt Tokens per Sec:     3610 || Lr: 0.000100
2024-02-08 13:17:38,817 Validation result at epoch  76, step    10000: duration: 10.6566s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.13198	Translation Loss: 85200.57031	PPL: 4963.39258
	Eval Metric: BLEU
	WER 5.37	(DEL: 0.00,	INS: 0.00,	SUB: 5.37)
	BLEU-4 0.41	(BLEU-1: 11.44,	BLEU-2: 3.66,	BLEU-3: 1.27,	BLEU-4: 0.41)
	CHRF 16.96	ROUGE 9.79
2024-02-08 13:17:38,818 Logging Recognition and Translation Outputs
2024-02-08 13:17:38,818 ========================================================================================================================
2024-02-08 13:17:38,819 Logging Sequence: 123_147.00
2024-02-08 13:17:38,819 	Gloss Reference :	A B+C+D+E
2024-02-08 13:17:38,819 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:17:38,819 	Gloss Alignment :	         
2024-02-08 13:17:38,819 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:17:38,820 	Text Reference  :	the former captain also owns the pontiac firebird trans am car   worth rs 68     lakh      
2024-02-08 13:17:38,820 	Text Hypothesis :	*** ****** ******* **** **** *** ******* ******** ***** ** dhoni has   an ardent bike-lover
2024-02-08 13:17:38,820 	Text Alignment  :	D   D      D       D    D    D   D       D        D     D  S     S     S  S      S         
2024-02-08 13:17:38,820 ========================================================================================================================
2024-02-08 13:17:38,820 Logging Sequence: 58_196.00
2024-02-08 13:17:38,820 	Gloss Reference :	A B+C+D+E
2024-02-08 13:17:38,821 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:17:38,821 	Gloss Alignment :	         
2024-02-08 13:17:38,821 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:17:38,822 	Text Reference  :	the talents and skills of    our athletes  knows no bounds 
2024-02-08 13:17:38,822 	Text Hypothesis :	the ******* *** ****** games are currently held  in england
2024-02-08 13:17:38,822 	Text Alignment  :	    D       D   D      S     S   S         S     S  S      
2024-02-08 13:17:38,822 ========================================================================================================================
2024-02-08 13:17:38,822 Logging Sequence: 168_184.00
2024-02-08 13:17:38,822 	Gloss Reference :	A B+C+D+E
2024-02-08 13:17:38,822 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:17:38,822 	Gloss Alignment :	  S      
2024-02-08 13:17:38,823 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:17:38,824 	Text Reference  :	people say that we may get a true glimpse of vamika  in     february 2022   when she turns 1  year   old  
2024-02-08 13:17:38,824 	Text Hypothesis :	****** *** **** ** *** *** * khan is      an amazing player and      rashid will be  going on social media
2024-02-08 13:17:38,824 	Text Alignment  :	D      D   D    D  D   D   D S    S       S  S       S      S        S      S    S   S     S  S      S    
2024-02-08 13:17:38,825 ========================================================================================================================
2024-02-08 13:17:38,825 Logging Sequence: 87_123.00
2024-02-08 13:17:38,825 	Gloss Reference :	A B+C+D+E
2024-02-08 13:17:38,825 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:17:38,825 	Gloss Alignment :	         
2024-02-08 13:17:38,825 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:17:38,826 	Text Reference  :	he said that he hoped kl rahul   would be fit     for the   upcoming world  cup  
2024-02-08 13:17:38,826 	Text Hypothesis :	** **** **** ** what  an intense game  of gambhir and video on       social media
2024-02-08 13:17:38,826 	Text Alignment  :	D  D    D    D  S     S  S       S     S  S       S   S     S        S      S    
2024-02-08 13:17:38,827 ========================================================================================================================
2024-02-08 13:17:38,827 Logging Sequence: 144_154.00
2024-02-08 13:17:38,827 	Gloss Reference :	A B+C+D+E
2024-02-08 13:17:38,827 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:17:38,827 	Gloss Alignment :	         
2024-02-08 13:17:38,827 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:17:38,828 	Text Reference  :	she also participated in the   rural olympic games  organised in    rajasthan a   few months
2024-02-08 13:17:38,829 	Text Hypothesis :	*** the  final        of their mlc   was     played between   their victory   and sri lanka 
2024-02-08 13:17:38,829 	Text Alignment  :	D   S    S            S  S     S     S       S      S         S     S         S   S   S     
2024-02-08 13:17:38,829 ========================================================================================================================
2024-02-08 13:17:44,462 [Epoch: 076 Step: 00010100] Batch Recognition Loss:   0.002027 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.519987 => Txt Tokens per Sec:     3868 || Lr: 0.000100
2024-02-08 13:17:44,900 Epoch  76: Total Training Recognition Loss 1.30  Total Training Translation Loss 70.18 
2024-02-08 13:17:44,900 EPOCH 77
2024-02-08 13:17:49,784 [Epoch: 077 Step: 00010200] Batch Recognition Loss:   0.064962 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.407748 => Txt Tokens per Sec:     4156 || Lr: 0.000100
2024-02-08 13:17:51,916 Epoch  77: Total Training Recognition Loss 1.57  Total Training Translation Loss 73.31 
2024-02-08 13:17:51,916 EPOCH 78
2024-02-08 13:17:55,408 [Epoch: 078 Step: 00010300] Batch Recognition Loss:   0.160092 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   1.023327 => Txt Tokens per Sec:     3785 || Lr: 0.000100
2024-02-08 13:17:59,550 Epoch  78: Total Training Recognition Loss 1.65  Total Training Translation Loss 71.19 
2024-02-08 13:17:59,551 EPOCH 79
2024-02-08 13:18:00,868 [Epoch: 079 Step: 00010400] Batch Recognition Loss:   0.005596 => Gls Tokens per Sec:     1581 || Batch Translation Loss:   0.624701 => Txt Tokens per Sec:     4423 || Lr: 0.000100
2024-02-08 13:18:06,708 [Epoch: 079 Step: 00010500] Batch Recognition Loss:   0.126011 => Gls Tokens per Sec:     1367 || Batch Translation Loss:   0.545614 => Txt Tokens per Sec:     3806 || Lr: 0.000100
2024-02-08 13:18:07,076 Epoch  79: Total Training Recognition Loss 1.67  Total Training Translation Loss 69.41 
2024-02-08 13:18:07,076 EPOCH 80
2024-02-08 13:18:12,110 [Epoch: 080 Step: 00010600] Batch Recognition Loss:   0.024127 => Gls Tokens per Sec:     1478 || Batch Translation Loss:   0.938861 => Txt Tokens per Sec:     4085 || Lr: 0.000100
2024-02-08 13:18:14,454 Epoch  80: Total Training Recognition Loss 1.62  Total Training Translation Loss 62.20 
2024-02-08 13:18:14,455 EPOCH 81
2024-02-08 13:18:17,427 [Epoch: 081 Step: 00010700] Batch Recognition Loss:   0.003786 => Gls Tokens per Sec:     1616 || Batch Translation Loss:   0.256425 => Txt Tokens per Sec:     4376 || Lr: 0.000100
2024-02-08 13:18:21,392 Epoch  81: Total Training Recognition Loss 1.42  Total Training Translation Loss 62.72 
2024-02-08 13:18:21,393 EPOCH 82
2024-02-08 13:18:22,977 [Epoch: 082 Step: 00010800] Batch Recognition Loss:   0.009216 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.239268 => Txt Tokens per Sec:     3494 || Lr: 0.000100
2024-02-08 13:18:28,725 [Epoch: 082 Step: 00010900] Batch Recognition Loss:   0.005880 => Gls Tokens per Sec:     1389 || Batch Translation Loss:   0.827575 => Txt Tokens per Sec:     3883 || Lr: 0.000100
2024-02-08 13:18:29,052 Epoch  82: Total Training Recognition Loss 1.62  Total Training Translation Loss 72.76 
2024-02-08 13:18:29,052 EPOCH 83
2024-02-08 13:18:33,988 [Epoch: 083 Step: 00011000] Batch Recognition Loss:   0.001157 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.584644 => Txt Tokens per Sec:     4225 || Lr: 0.000100
2024-02-08 13:18:36,159 Epoch  83: Total Training Recognition Loss 1.38  Total Training Translation Loss 70.91 
2024-02-08 13:18:36,159 EPOCH 84
2024-02-08 13:18:39,480 [Epoch: 084 Step: 00011100] Batch Recognition Loss:   0.021870 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.328556 => Txt Tokens per Sec:     4126 || Lr: 0.000100
2024-02-08 13:18:43,394 Epoch  84: Total Training Recognition Loss 1.55  Total Training Translation Loss 54.85 
2024-02-08 13:18:43,395 EPOCH 85
2024-02-08 13:18:44,968 [Epoch: 085 Step: 00011200] Batch Recognition Loss:   0.000674 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.297581 => Txt Tokens per Sec:     4092 || Lr: 0.000100
2024-02-08 13:18:50,785 [Epoch: 085 Step: 00011300] Batch Recognition Loss:   0.115891 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.284902 => Txt Tokens per Sec:     3766 || Lr: 0.000100
2024-02-08 13:18:51,053 Epoch  85: Total Training Recognition Loss 1.24  Total Training Translation Loss 57.09 
2024-02-08 13:18:51,054 EPOCH 86
2024-02-08 13:18:56,561 [Epoch: 086 Step: 00011400] Batch Recognition Loss:   0.006540 => Gls Tokens per Sec:     1380 || Batch Translation Loss:   0.680838 => Txt Tokens per Sec:     3811 || Lr: 0.000100
2024-02-08 13:18:58,538 Epoch  86: Total Training Recognition Loss 1.23  Total Training Translation Loss 58.42 
2024-02-08 13:18:58,538 EPOCH 87
2024-02-08 13:19:01,575 [Epoch: 087 Step: 00011500] Batch Recognition Loss:   0.001482 => Gls Tokens per Sec:     1634 || Batch Translation Loss:   0.239170 => Txt Tokens per Sec:     4582 || Lr: 0.000100
2024-02-08 13:19:05,532 Epoch  87: Total Training Recognition Loss 1.59  Total Training Translation Loss 71.32 
2024-02-08 13:19:05,532 EPOCH 88
2024-02-08 13:19:07,226 [Epoch: 088 Step: 00011600] Batch Recognition Loss:   0.013287 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.355821 => Txt Tokens per Sec:     3730 || Lr: 0.000100
2024-02-08 13:19:12,552 [Epoch: 088 Step: 00011700] Batch Recognition Loss:   0.006866 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.458386 => Txt Tokens per Sec:     4169 || Lr: 0.000100
2024-02-08 13:19:12,778 Epoch  88: Total Training Recognition Loss 1.41  Total Training Translation Loss 66.89 
2024-02-08 13:19:12,778 EPOCH 89
2024-02-08 13:19:18,061 [Epoch: 089 Step: 00011800] Batch Recognition Loss:   0.001591 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.166180 => Txt Tokens per Sec:     4012 || Lr: 0.000100
2024-02-08 13:19:20,045 Epoch  89: Total Training Recognition Loss 1.54  Total Training Translation Loss 59.93 
2024-02-08 13:19:20,045 EPOCH 90
2024-02-08 13:19:23,370 [Epoch: 090 Step: 00011900] Batch Recognition Loss:   0.012697 => Gls Tokens per Sec:     1516 || Batch Translation Loss:   0.383623 => Txt Tokens per Sec:     4199 || Lr: 0.000100
2024-02-08 13:19:27,221 Epoch  90: Total Training Recognition Loss 1.08  Total Training Translation Loss 56.01 
2024-02-08 13:19:27,221 EPOCH 91
2024-02-08 13:19:28,741 [Epoch: 091 Step: 00012000] Batch Recognition Loss:   0.007416 => Gls Tokens per Sec:     1581 || Batch Translation Loss:   0.281402 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-08 13:19:39,867 Validation result at epoch  91, step    12000: duration: 11.1241s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.20881	Translation Loss: 87324.04688	PPL: 6136.06006
	Eval Metric: BLEU
	WER 4.94	(DEL: 0.00,	INS: 0.00,	SUB: 4.94)
	BLEU-4 0.65	(BLEU-1: 11.18,	BLEU-2: 3.56,	BLEU-3: 1.37,	BLEU-4: 0.65)
	CHRF 17.39	ROUGE 9.49
2024-02-08 13:19:39,868 Logging Recognition and Translation Outputs
2024-02-08 13:19:39,868 ========================================================================================================================
2024-02-08 13:19:39,868 Logging Sequence: 168_56.00
2024-02-08 13:19:39,868 	Gloss Reference :	A B+C+D+E
2024-02-08 13:19:39,868 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:19:39,868 	Gloss Alignment :	         
2024-02-08 13:19:39,868 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:19:39,870 	Text Reference  :	fans have been  waiting to ****** ***** see   vamika for  a   long time      
2024-02-08 13:19:39,870 	Text Hypothesis :	**** they don't want    to change their child but    they are very protective
2024-02-08 13:19:39,870 	Text Alignment  :	D    S    S     S          I      I     S     S      S    S   S    S         
2024-02-08 13:19:39,870 ========================================================================================================================
2024-02-08 13:19:39,870 Logging Sequence: 161_74.00
2024-02-08 13:19:39,870 	Gloss Reference :	A B+C+D+E
2024-02-08 13:19:39,870 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:19:39,870 	Gloss Alignment :	         
2024-02-08 13:19:39,871 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:19:39,871 	Text Reference  :	*** ******** *** **** i  am        proud of       the     indian team's achievements
2024-02-08 13:19:39,871 	Text Hypothesis :	the incident was held in australia for   mandhana between india  and    kuwait      
2024-02-08 13:19:39,872 	Text Alignment  :	I   I        I   I    S  S         S     S        S       S      S      S           
2024-02-08 13:19:39,872 ========================================================================================================================
2024-02-08 13:19:39,872 Logging Sequence: 111_83.00
2024-02-08 13:19:39,872 	Gloss Reference :	A B+C+D+E
2024-02-08 13:19:39,872 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:19:39,872 	Gloss Alignment :	         
2024-02-08 13:19:39,872 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:19:39,874 	Text Reference  :	** **** and   the  other 10    team members are fined 25 of    the match fee or rs 6 lakh  
2024-02-08 13:19:39,874 	Text Hypothesis :	on 10th april 2022 deaf  women team ******* was able  to reach the ***** *** ** ** * finals
2024-02-08 13:19:39,874 	Text Alignment  :	I  I    S     S    S     S          D       S   S     S  S         D     D   D  D  D S     
2024-02-08 13:19:39,874 ========================================================================================================================
2024-02-08 13:19:39,874 Logging Sequence: 61_218.00
2024-02-08 13:19:39,874 	Gloss Reference :	A B+C+D+E
2024-02-08 13:19:39,875 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:19:39,875 	Gloss Alignment :	         
2024-02-08 13:19:39,875 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:19:39,876 	Text Reference  :	in   2020    a  woman had said at     the   press    conference
2024-02-08 13:19:39,876 	Text Hypothesis :	they rivalry is seen  the most during india pakistan cricket   
2024-02-08 13:19:39,876 	Text Alignment  :	S    S       S  S     S   S    S      S     S        S         
2024-02-08 13:19:39,876 ========================================================================================================================
2024-02-08 13:19:39,876 Logging Sequence: 94_123.00
2024-02-08 13:19:39,876 	Gloss Reference :	A B+C+D+E
2024-02-08 13:19:39,876 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:19:39,876 	Gloss Alignment :	         
2024-02-08 13:19:39,877 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:19:39,878 	Text Reference  :	the venue narendra modi stadium for the india-pakistan match has      been kept the same people can book  flights etc       
2024-02-08 13:19:39,878 	Text Hypothesis :	*** ***** icc      has  laws    for the finals         of    athletes room for  the **** ****** *** india has     devastated
2024-02-08 13:19:39,878 	Text Alignment  :	D   D     S        S    S               S              S     S        S    S        D    D      D   S     S       S         
2024-02-08 13:19:39,879 ========================================================================================================================
2024-02-08 13:19:45,899 [Epoch: 091 Step: 00012100] Batch Recognition Loss:   0.001299 => Gls Tokens per Sec:     1323 || Batch Translation Loss:   0.306255 => Txt Tokens per Sec:     3733 || Lr: 0.000100
2024-02-08 13:19:46,037 Epoch  91: Total Training Recognition Loss 1.49  Total Training Translation Loss 54.38 
2024-02-08 13:19:46,037 EPOCH 92
2024-02-08 13:19:51,199 [Epoch: 092 Step: 00012200] Batch Recognition Loss:   0.000874 => Gls Tokens per Sec:     1504 || Batch Translation Loss:   0.218672 => Txt Tokens per Sec:     4184 || Lr: 0.000100
2024-02-08 13:19:53,267 Epoch  92: Total Training Recognition Loss 1.56  Total Training Translation Loss 53.44 
2024-02-08 13:19:53,268 EPOCH 93
2024-02-08 13:19:56,861 [Epoch: 093 Step: 00012300] Batch Recognition Loss:   0.009591 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   1.146510 => Txt Tokens per Sec:     3922 || Lr: 0.000100
2024-02-08 13:20:00,561 Epoch  93: Total Training Recognition Loss 1.14  Total Training Translation Loss 49.93 
2024-02-08 13:20:00,561 EPOCH 94
2024-02-08 13:20:02,078 [Epoch: 094 Step: 00012400] Batch Recognition Loss:   0.004012 => Gls Tokens per Sec:     1636 || Batch Translation Loss:   0.282664 => Txt Tokens per Sec:     4486 || Lr: 0.000100
2024-02-08 13:20:07,983 [Epoch: 094 Step: 00012500] Batch Recognition Loss:   0.024007 => Gls Tokens per Sec:     1351 || Batch Translation Loss:   0.342439 => Txt Tokens per Sec:     3756 || Lr: 0.000100
2024-02-08 13:20:08,102 Epoch  94: Total Training Recognition Loss 1.23  Total Training Translation Loss 69.76 
2024-02-08 13:20:08,102 EPOCH 95
2024-02-08 13:20:13,022 [Epoch: 095 Step: 00012600] Batch Recognition Loss:   0.020993 => Gls Tokens per Sec:     1594 || Batch Translation Loss:   0.614361 => Txt Tokens per Sec:     4400 || Lr: 0.000100
2024-02-08 13:20:15,107 Epoch  95: Total Training Recognition Loss 1.38  Total Training Translation Loss 61.00 
2024-02-08 13:20:15,108 EPOCH 96
2024-02-08 13:20:18,774 [Epoch: 096 Step: 00012700] Batch Recognition Loss:   0.002730 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.533607 => Txt Tokens per Sec:     3958 || Lr: 0.000100
2024-02-08 13:20:22,211 Epoch  96: Total Training Recognition Loss 1.22  Total Training Translation Loss 47.73 
2024-02-08 13:20:22,211 EPOCH 97
2024-02-08 13:20:24,105 [Epoch: 097 Step: 00012800] Batch Recognition Loss:   0.001684 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   0.152884 => Txt Tokens per Sec:     3856 || Lr: 0.000100
2024-02-08 13:20:29,748 [Epoch: 097 Step: 00012900] Batch Recognition Loss:   0.016979 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.352363 => Txt Tokens per Sec:     3880 || Lr: 0.000100
2024-02-08 13:20:29,790 Epoch  97: Total Training Recognition Loss 0.94  Total Training Translation Loss 42.53 
2024-02-08 13:20:29,790 EPOCH 98
2024-02-08 13:20:35,108 [Epoch: 098 Step: 00013000] Batch Recognition Loss:   0.000613 => Gls Tokens per Sec:     1490 || Batch Translation Loss:   0.167570 => Txt Tokens per Sec:     4082 || Lr: 0.000100
2024-02-08 13:20:37,035 Epoch  98: Total Training Recognition Loss 1.20  Total Training Translation Loss 53.59 
2024-02-08 13:20:37,035 EPOCH 99
2024-02-08 13:20:40,340 [Epoch: 099 Step: 00013100] Batch Recognition Loss:   0.006574 => Gls Tokens per Sec:     1599 || Batch Translation Loss:   0.173782 => Txt Tokens per Sec:     4383 || Lr: 0.000100
2024-02-08 13:20:43,919 Epoch  99: Total Training Recognition Loss 1.20  Total Training Translation Loss 49.24 
2024-02-08 13:20:43,919 EPOCH 100
2024-02-08 13:20:45,786 [Epoch: 100 Step: 00013200] Batch Recognition Loss:   0.001883 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.328272 => Txt Tokens per Sec:     3882 || Lr: 0.000100
2024-02-08 13:20:51,659 [Epoch: 100 Step: 00013300] Batch Recognition Loss:   0.007463 => Gls Tokens per Sec:     1359 || Batch Translation Loss:   0.507813 => Txt Tokens per Sec:     3770 || Lr: 0.000100
2024-02-08 13:20:51,660 Epoch 100: Total Training Recognition Loss 1.09  Total Training Translation Loss 54.03 
2024-02-08 13:20:51,660 EPOCH 101
2024-02-08 13:20:57,247 [Epoch: 101 Step: 00013400] Batch Recognition Loss:   0.003135 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.113429 => Txt Tokens per Sec:     3956 || Lr: 0.000100
2024-02-08 13:20:59,116 Epoch 101: Total Training Recognition Loss 1.12  Total Training Translation Loss 57.07 
2024-02-08 13:20:59,116 EPOCH 102
2024-02-08 13:21:02,845 [Epoch: 102 Step: 00013500] Batch Recognition Loss:   0.005683 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.308886 => Txt Tokens per Sec:     4010 || Lr: 0.000100
2024-02-08 13:21:06,305 Epoch 102: Total Training Recognition Loss 1.40  Total Training Translation Loss 48.19 
2024-02-08 13:21:06,306 EPOCH 103
2024-02-08 13:21:08,277 [Epoch: 103 Step: 00013600] Batch Recognition Loss:   0.027118 => Gls Tokens per Sec:     1381 || Batch Translation Loss:   0.259160 => Txt Tokens per Sec:     3894 || Lr: 0.000100
2024-02-08 13:21:13,677 Epoch 103: Total Training Recognition Loss 1.29  Total Training Translation Loss 36.63 
2024-02-08 13:21:13,678 EPOCH 104
2024-02-08 13:21:13,736 [Epoch: 104 Step: 00013700] Batch Recognition Loss:   0.000544 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.108321 => Txt Tokens per Sec:     3293 || Lr: 0.000100
2024-02-08 13:21:19,324 [Epoch: 104 Step: 00013800] Batch Recognition Loss:   0.004206 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.307678 => Txt Tokens per Sec:     3960 || Lr: 0.000100
2024-02-08 13:21:21,077 Epoch 104: Total Training Recognition Loss 1.29  Total Training Translation Loss 41.14 
2024-02-08 13:21:21,078 EPOCH 105
2024-02-08 13:21:24,582 [Epoch: 105 Step: 00013900] Batch Recognition Loss:   0.015876 => Gls Tokens per Sec:     1552 || Batch Translation Loss:   0.334841 => Txt Tokens per Sec:     4300 || Lr: 0.000100
2024-02-08 13:21:28,201 Epoch 105: Total Training Recognition Loss 1.28  Total Training Translation Loss 52.55 
2024-02-08 13:21:28,202 EPOCH 106
2024-02-08 13:21:30,160 [Epoch: 106 Step: 00014000] Batch Recognition Loss:   0.004924 => Gls Tokens per Sec:     1431 || Batch Translation Loss:   0.111230 => Txt Tokens per Sec:     4011 || Lr: 0.000100
2024-02-08 13:21:40,963 Validation result at epoch 106, step    14000: duration: 10.8025s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.99798	Translation Loss: 90039.48438	PPL: 8047.81934
	Eval Metric: BLEU
	WER 4.52	(DEL: 0.00,	INS: 0.00,	SUB: 4.52)
	BLEU-4 0.61	(BLEU-1: 11.34,	BLEU-2: 3.35,	BLEU-3: 1.26,	BLEU-4: 0.61)
	CHRF 17.08	ROUGE 9.18
2024-02-08 13:21:40,964 Logging Recognition and Translation Outputs
2024-02-08 13:21:40,964 ========================================================================================================================
2024-02-08 13:21:40,965 Logging Sequence: 177_50.00
2024-02-08 13:21:40,965 	Gloss Reference :	A B+C+D+E
2024-02-08 13:21:40,965 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:21:40,965 	Gloss Alignment :	         
2024-02-08 13:21:40,965 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:21:40,967 	Text Reference  :	***** a     similar reward of    rs    50000  was announced    for    information against his associate ajay   kumar
2024-02-08 13:21:40,967 	Text Hypothesis :	after rana' death   a      delhi court issued a   non-bailable arrest warrant     against *** ********* sushil kumar
2024-02-08 13:21:40,967 	Text Alignment  :	I     S     S       S      S     S     S      S   S            S      S                   D   D         S           
2024-02-08 13:21:40,967 ========================================================================================================================
2024-02-08 13:21:40,967 Logging Sequence: 136_175.00
2024-02-08 13:21:40,967 	Gloss Reference :	A B+C+D+E
2024-02-08 13:21:40,967 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:21:40,967 	Gloss Alignment :	  S      
2024-02-08 13:21:40,968 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:21:40,969 	Text Reference  :	*** *** after 49 years  india' hockey team beat britain and      qualified for the semi-finals
2024-02-08 13:21:40,969 	Text Hypothesis :	she had won   a  bronze medal  at     the  2012 london  olympics in        rio de  janeiro    
2024-02-08 13:21:40,969 	Text Alignment  :	I   I   S     S  S      S      S      S    S    S       S        S         S   S   S          
2024-02-08 13:21:40,969 ========================================================================================================================
2024-02-08 13:21:40,969 Logging Sequence: 126_159.00
2024-02-08 13:21:40,970 	Gloss Reference :	A B+C+D+E
2024-02-08 13:21:40,970 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:21:40,970 	Gloss Alignment :	         
2024-02-08 13:21:40,970 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:21:40,971 	Text Reference  :	despite multiple challenges and injuries you  did  not give up           
2024-02-08 13:21:40,971 	Text Hypothesis :	******* ******** ********** you all      know that a   very disappointing
2024-02-08 13:21:40,971 	Text Alignment  :	D       D        D          S   S        S    S    S   S    S            
2024-02-08 13:21:40,971 ========================================================================================================================
2024-02-08 13:21:40,971 Logging Sequence: 70_88.00
2024-02-08 13:21:40,971 	Gloss Reference :	A B+C+D+E
2024-02-08 13:21:40,971 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:21:40,971 	Gloss Alignment :	         
2024-02-08 13:21:40,972 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:21:40,972 	Text Reference  :	two coca-cola bottles were placed   on the table next to   the      mic 
2024-02-08 13:21:40,972 	Text Hypothesis :	*** ********* ronaldo has  admitted to the ***** **** most football team
2024-02-08 13:21:40,973 	Text Alignment  :	D   D         S       S    S        S      D     D    S    S        S   
2024-02-08 13:21:40,973 ========================================================================================================================
2024-02-08 13:21:40,973 Logging Sequence: 54_201.00
2024-02-08 13:21:40,973 	Gloss Reference :	A B+C+D+E
2024-02-08 13:21:40,973 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:21:40,973 	Gloss Alignment :	         
2024-02-08 13:21:40,973 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:21:40,976 	Text Reference  :	there is  a            huge demand  mostly from non-resident indians nris   who       are excited      to see   the     match and     they have booked the       hotel ******* ***** rooms
2024-02-08 13:21:40,977 	Text Hypothesis :	***** the middle-class fans usually decide at   the          last    moment depending on  availability of match tickets if    tickets are  not  be     available hotel booking would win  
2024-02-08 13:21:40,977 	Text Alignment  :	D     S   S            S    S       S      S    S            S       S      S         S   S            S  S     S       S     S       S    S    S      S               I       I     S    
2024-02-08 13:21:40,977 ========================================================================================================================
2024-02-08 13:21:46,829 Epoch 106: Total Training Recognition Loss 0.90  Total Training Translation Loss 49.27 
2024-02-08 13:21:46,829 EPOCH 107
2024-02-08 13:21:46,922 [Epoch: 107 Step: 00014100] Batch Recognition Loss:   0.006427 => Gls Tokens per Sec:     1739 || Batch Translation Loss:   0.436750 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-08 13:21:52,526 [Epoch: 107 Step: 00014200] Batch Recognition Loss:   0.057529 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   1.061386 => Txt Tokens per Sec:     3934 || Lr: 0.000100
2024-02-08 13:21:54,172 Epoch 107: Total Training Recognition Loss 1.11  Total Training Translation Loss 46.24 
2024-02-08 13:21:54,172 EPOCH 108
2024-02-08 13:21:57,947 [Epoch: 108 Step: 00014300] Batch Recognition Loss:   0.006004 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.201093 => Txt Tokens per Sec:     4107 || Lr: 0.000100
2024-02-08 13:22:01,421 Epoch 108: Total Training Recognition Loss 1.16  Total Training Translation Loss 46.25 
2024-02-08 13:22:01,421 EPOCH 109
2024-02-08 13:22:03,218 [Epoch: 109 Step: 00014400] Batch Recognition Loss:   0.011458 => Gls Tokens per Sec:     1604 || Batch Translation Loss:   0.463274 => Txt Tokens per Sec:     4394 || Lr: 0.000100
2024-02-08 13:22:08,741 Epoch 109: Total Training Recognition Loss 1.09  Total Training Translation Loss 41.67 
2024-02-08 13:22:08,742 EPOCH 110
2024-02-08 13:22:08,877 [Epoch: 110 Step: 00014500] Batch Recognition Loss:   0.002435 => Gls Tokens per Sec:     1791 || Batch Translation Loss:   0.122849 => Txt Tokens per Sec:     4336 || Lr: 0.000100
2024-02-08 13:22:14,255 [Epoch: 110 Step: 00014600] Batch Recognition Loss:   0.003535 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   0.196937 => Txt Tokens per Sec:     4118 || Lr: 0.000100
2024-02-08 13:22:16,006 Epoch 110: Total Training Recognition Loss 1.05  Total Training Translation Loss 37.38 
2024-02-08 13:22:16,007 EPOCH 111
2024-02-08 13:22:19,850 [Epoch: 111 Step: 00014700] Batch Recognition Loss:   0.004897 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.108216 => Txt Tokens per Sec:     3999 || Lr: 0.000100
2024-02-08 13:22:23,265 Epoch 111: Total Training Recognition Loss 1.08  Total Training Translation Loss 47.72 
2024-02-08 13:22:23,265 EPOCH 112
2024-02-08 13:22:25,080 [Epoch: 112 Step: 00014800] Batch Recognition Loss:   0.042154 => Gls Tokens per Sec:     1631 || Batch Translation Loss:   0.183035 => Txt Tokens per Sec:     4479 || Lr: 0.000100
2024-02-08 13:22:30,771 Epoch 112: Total Training Recognition Loss 1.40  Total Training Translation Loss 43.70 
2024-02-08 13:22:30,772 EPOCH 113
2024-02-08 13:22:30,989 [Epoch: 113 Step: 00014900] Batch Recognition Loss:   0.001947 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.108962 => Txt Tokens per Sec:     3977 || Lr: 0.000100
2024-02-08 13:22:36,231 [Epoch: 113 Step: 00015000] Batch Recognition Loss:   0.000653 => Gls Tokens per Sec:     1526 || Batch Translation Loss:   0.258125 => Txt Tokens per Sec:     4217 || Lr: 0.000100
2024-02-08 13:22:37,957 Epoch 113: Total Training Recognition Loss 1.13  Total Training Translation Loss 45.63 
2024-02-08 13:22:37,958 EPOCH 114
2024-02-08 13:22:41,907 [Epoch: 114 Step: 00015100] Batch Recognition Loss:   0.002642 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.342585 => Txt Tokens per Sec:     4003 || Lr: 0.000100
2024-02-08 13:22:45,066 Epoch 114: Total Training Recognition Loss 1.04  Total Training Translation Loss 38.51 
2024-02-08 13:22:45,067 EPOCH 115
2024-02-08 13:22:47,103 [Epoch: 115 Step: 00015200] Batch Recognition Loss:   0.001322 => Gls Tokens per Sec:     1495 || Batch Translation Loss:   0.277618 => Txt Tokens per Sec:     4112 || Lr: 0.000100
2024-02-08 13:22:52,349 Epoch 115: Total Training Recognition Loss 0.99  Total Training Translation Loss 42.79 
2024-02-08 13:22:52,350 EPOCH 116
2024-02-08 13:22:52,624 [Epoch: 116 Step: 00015300] Batch Recognition Loss:   0.002975 => Gls Tokens per Sec:     1460 || Batch Translation Loss:   0.220549 => Txt Tokens per Sec:     4701 || Lr: 0.000100
2024-02-08 13:22:58,183 [Epoch: 116 Step: 00015400] Batch Recognition Loss:   0.000786 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.201532 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-08 13:22:59,660 Epoch 116: Total Training Recognition Loss 1.00  Total Training Translation Loss 44.09 
2024-02-08 13:22:59,660 EPOCH 117
2024-02-08 13:23:03,205 [Epoch: 117 Step: 00015500] Batch Recognition Loss:   0.001717 => Gls Tokens per Sec:     1625 || Batch Translation Loss:   0.200444 => Txt Tokens per Sec:     4470 || Lr: 0.000100
2024-02-08 13:23:06,655 Epoch 117: Total Training Recognition Loss 0.83  Total Training Translation Loss 39.16 
2024-02-08 13:23:06,656 EPOCH 118
2024-02-08 13:23:08,880 [Epoch: 118 Step: 00015600] Batch Recognition Loss:   0.002941 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.411713 => Txt Tokens per Sec:     3977 || Lr: 0.000100
2024-02-08 13:23:14,166 Epoch 118: Total Training Recognition Loss 1.13  Total Training Translation Loss 41.96 
2024-02-08 13:23:14,166 EPOCH 119
2024-02-08 13:23:14,431 [Epoch: 119 Step: 00015700] Batch Recognition Loss:   0.001301 => Gls Tokens per Sec:     1825 || Batch Translation Loss:   0.303045 => Txt Tokens per Sec:     4460 || Lr: 0.000100
2024-02-08 13:23:20,193 [Epoch: 119 Step: 00015800] Batch Recognition Loss:   0.003015 => Gls Tokens per Sec:     1389 || Batch Translation Loss:   0.120365 => Txt Tokens per Sec:     3866 || Lr: 0.000100
2024-02-08 13:23:21,642 Epoch 119: Total Training Recognition Loss 1.07  Total Training Translation Loss 34.42 
2024-02-08 13:23:21,642 EPOCH 120
2024-02-08 13:23:25,709 [Epoch: 120 Step: 00015900] Batch Recognition Loss:   0.009592 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.084605 => Txt Tokens per Sec:     3993 || Lr: 0.000100
2024-02-08 13:23:29,016 Epoch 120: Total Training Recognition Loss 0.92  Total Training Translation Loss 30.72 
2024-02-08 13:23:29,016 EPOCH 121
2024-02-08 13:23:31,134 [Epoch: 121 Step: 00016000] Batch Recognition Loss:   0.006432 => Gls Tokens per Sec:     1511 || Batch Translation Loss:   0.064303 => Txt Tokens per Sec:     4180 || Lr: 0.000100
2024-02-08 13:23:42,328 Validation result at epoch 121, step    16000: duration: 11.1925s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.72533	Translation Loss: 91201.91406	PPL: 9038.60059
	Eval Metric: BLEU
	WER 4.94	(DEL: 0.00,	INS: 0.00,	SUB: 4.94)
	BLEU-4 0.76	(BLEU-1: 11.72,	BLEU-2: 3.76,	BLEU-3: 1.54,	BLEU-4: 0.76)
	CHRF 17.76	ROUGE 9.71
2024-02-08 13:23:42,329 Logging Recognition and Translation Outputs
2024-02-08 13:23:42,329 ========================================================================================================================
2024-02-08 13:23:42,329 Logging Sequence: 163_116.00
2024-02-08 13:23:42,330 	Gloss Reference :	A B+C+D+E
2024-02-08 13:23:42,330 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:23:42,330 	Gloss Alignment :	         
2024-02-08 13:23:42,330 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:23:42,331 	Text Reference  :	people said that  she  looked similar to     virat
2024-02-08 13:23:42,331 	Text Hypothesis :	****** who  would even post   on      social media
2024-02-08 13:23:42,331 	Text Alignment  :	D      S    S     S    S      S       S      S    
2024-02-08 13:23:42,331 ========================================================================================================================
2024-02-08 13:23:42,331 Logging Sequence: 53_161.00
2024-02-08 13:23:42,331 	Gloss Reference :	A B+C+D+E
2024-02-08 13:23:42,331 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:23:42,332 	Gloss Alignment :	  S      
2024-02-08 13:23:42,332 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:23:42,333 	Text Reference  :	********* ********* rashid    has also been urging people to          donate to his rashid khan foundation and   afghanistan cricket association
2024-02-08 13:23:42,333 	Text Hypothesis :	meanwhile sunrisers hyderabad has **** said that   the    rescheduled runs   to *** ****** **** ********** reach the         trent   rockets    
2024-02-08 13:23:42,333 	Text Alignment  :	I         I         S             D    S    S      S      S           S         D   D      D    D          S     S           S       S          
2024-02-08 13:23:42,333 ========================================================================================================================
2024-02-08 13:23:42,334 Logging Sequence: 67_73.00
2024-02-08 13:23:42,334 	Gloss Reference :	A B+C+D+E
2024-02-08 13:23:42,334 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:23:42,334 	Gloss Alignment :	         
2024-02-08 13:23:42,334 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:23:42,335 	Text Reference  :	*** **** *** *** **** ** in   his   tweet he also  said  
2024-02-08 13:23:42,335 	Text Hypothesis :	but this can not want to have their names of their jersey
2024-02-08 13:23:42,335 	Text Alignment  :	I   I    I   I   I    I  S    S     S     S  S     S     
2024-02-08 13:23:42,335 ========================================================================================================================
2024-02-08 13:23:42,335 Logging Sequence: 137_44.00
2024-02-08 13:23:42,335 	Gloss Reference :	A B+C+D+E
2024-02-08 13:23:42,335 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:23:42,336 	Gloss Alignment :	         
2024-02-08 13:23:42,336 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:23:42,337 	Text Reference  :	let me tell you     the    rules that   qatar has announced for  the  fans travelling for     the world cup  
2024-02-08 13:23:42,337 	Text Hypothesis :	*** ** **** anushka sharma and   social media was taking    more than his  father     between the ***** hotel
2024-02-08 13:23:42,338 	Text Alignment  :	D   D  D    S       S      S     S      S     S   S         S    S    S    S          S           D     S    
2024-02-08 13:23:42,338 ========================================================================================================================
2024-02-08 13:23:42,338 Logging Sequence: 99_158.00
2024-02-08 13:23:42,338 	Gloss Reference :	A B+C+D+E
2024-02-08 13:23:42,338 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:23:42,338 	Gloss Alignment :	         
2024-02-08 13:23:42,339 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:23:42,339 	Text Reference  :	the incident occured in   dubai and it     was **** ******* ** extremely shameful
2024-02-08 13:23:42,340 	Text Hypothesis :	*** isn't    that    even since his family was very support of his       support 
2024-02-08 13:23:42,340 	Text Alignment  :	D   S        S       S    S     S   S          I    I       I  S         S       
2024-02-08 13:23:42,340 ========================================================================================================================
2024-02-08 13:23:47,785 Epoch 121: Total Training Recognition Loss 0.73  Total Training Translation Loss 32.19 
2024-02-08 13:23:47,786 EPOCH 122
2024-02-08 13:23:48,149 [Epoch: 122 Step: 00016100] Batch Recognition Loss:   0.001336 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.104566 => Txt Tokens per Sec:     3701 || Lr: 0.000100
2024-02-08 13:23:53,818 [Epoch: 122 Step: 00016200] Batch Recognition Loss:   0.011885 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.111233 => Txt Tokens per Sec:     3933 || Lr: 0.000100
2024-02-08 13:23:55,322 Epoch 122: Total Training Recognition Loss 0.95  Total Training Translation Loss 36.03 
2024-02-08 13:23:55,322 EPOCH 123
2024-02-08 13:23:59,315 [Epoch: 123 Step: 00016300] Batch Recognition Loss:   0.001784 => Gls Tokens per Sec:     1483 || Batch Translation Loss:   0.842671 => Txt Tokens per Sec:     4127 || Lr: 0.000100
2024-02-08 13:24:02,485 Epoch 123: Total Training Recognition Loss 1.02  Total Training Translation Loss 50.83 
2024-02-08 13:24:02,485 EPOCH 124
2024-02-08 13:24:04,597 [Epoch: 124 Step: 00016400] Batch Recognition Loss:   0.004427 => Gls Tokens per Sec:     1554 || Batch Translation Loss:   0.308593 => Txt Tokens per Sec:     4261 || Lr: 0.000100
2024-02-08 13:24:10,037 Epoch 124: Total Training Recognition Loss 1.21  Total Training Translation Loss 51.45 
2024-02-08 13:24:10,038 EPOCH 125
2024-02-08 13:24:10,512 [Epoch: 125 Step: 00016500] Batch Recognition Loss:   0.000847 => Gls Tokens per Sec:     1353 || Batch Translation Loss:   0.513737 => Txt Tokens per Sec:     3685 || Lr: 0.000100
2024-02-08 13:24:16,254 [Epoch: 125 Step: 00016600] Batch Recognition Loss:   0.007734 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.251806 => Txt Tokens per Sec:     3843 || Lr: 0.000100
2024-02-08 13:24:17,698 Epoch 125: Total Training Recognition Loss 0.96  Total Training Translation Loss 46.69 
2024-02-08 13:24:17,699 EPOCH 126
2024-02-08 13:24:21,907 [Epoch: 126 Step: 00016700] Batch Recognition Loss:   0.001814 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.718652 => Txt Tokens per Sec:     3952 || Lr: 0.000100
2024-02-08 13:24:25,194 Epoch 126: Total Training Recognition Loss 0.89  Total Training Translation Loss 35.00 
2024-02-08 13:24:25,194 EPOCH 127
2024-02-08 13:24:27,588 [Epoch: 127 Step: 00016800] Batch Recognition Loss:   0.002377 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.190831 => Txt Tokens per Sec:     3966 || Lr: 0.000100
2024-02-08 13:24:32,586 Epoch 127: Total Training Recognition Loss 0.97  Total Training Translation Loss 33.36 
2024-02-08 13:24:32,587 EPOCH 128
2024-02-08 13:24:32,985 [Epoch: 128 Step: 00016900] Batch Recognition Loss:   0.001017 => Gls Tokens per Sec:     1809 || Batch Translation Loss:   0.127649 => Txt Tokens per Sec:     4030 || Lr: 0.000100
2024-02-08 13:24:38,809 [Epoch: 128 Step: 00017000] Batch Recognition Loss:   0.000596 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.070600 => Txt Tokens per Sec:     3890 || Lr: 0.000100
2024-02-08 13:24:40,304 Epoch 128: Total Training Recognition Loss 0.99  Total Training Translation Loss 28.65 
2024-02-08 13:24:40,304 EPOCH 129
2024-02-08 13:24:44,350 [Epoch: 129 Step: 00017100] Batch Recognition Loss:   0.008180 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.373488 => Txt Tokens per Sec:     4106 || Lr: 0.000100
2024-02-08 13:24:47,554 Epoch 129: Total Training Recognition Loss 0.72  Total Training Translation Loss 31.08 
2024-02-08 13:24:47,554 EPOCH 130
2024-02-08 13:24:49,976 [Epoch: 130 Step: 00017200] Batch Recognition Loss:   0.007317 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.514864 => Txt Tokens per Sec:     4007 || Lr: 0.000100
2024-02-08 13:24:54,877 Epoch 130: Total Training Recognition Loss 0.89  Total Training Translation Loss 33.61 
2024-02-08 13:24:54,877 EPOCH 131
2024-02-08 13:24:55,416 [Epoch: 131 Step: 00017300] Batch Recognition Loss:   0.012828 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.246008 => Txt Tokens per Sec:     4149 || Lr: 0.000100
2024-02-08 13:25:00,825 [Epoch: 131 Step: 00017400] Batch Recognition Loss:   0.011624 => Gls Tokens per Sec:     1479 || Batch Translation Loss:   0.083166 => Txt Tokens per Sec:     4080 || Lr: 0.000100
2024-02-08 13:25:02,232 Epoch 131: Total Training Recognition Loss 0.69  Total Training Translation Loss 29.37 
2024-02-08 13:25:02,232 EPOCH 132
2024-02-08 13:25:06,172 [Epoch: 132 Step: 00017500] Batch Recognition Loss:   0.033559 => Gls Tokens per Sec:     1564 || Batch Translation Loss:   0.569010 => Txt Tokens per Sec:     4280 || Lr: 0.000100
2024-02-08 13:25:09,185 Epoch 132: Total Training Recognition Loss 0.72  Total Training Translation Loss 42.24 
2024-02-08 13:25:09,185 EPOCH 133
2024-02-08 13:25:11,382 [Epoch: 133 Step: 00017600] Batch Recognition Loss:   0.001445 => Gls Tokens per Sec:     1603 || Batch Translation Loss:   0.226789 => Txt Tokens per Sec:     4576 || Lr: 0.000100
2024-02-08 13:25:15,981 Epoch 133: Total Training Recognition Loss 0.93  Total Training Translation Loss 43.58 
2024-02-08 13:25:15,981 EPOCH 134
2024-02-08 13:25:16,609 [Epoch: 134 Step: 00017700] Batch Recognition Loss:   0.004119 => Gls Tokens per Sec:     1406 || Batch Translation Loss:   0.169590 => Txt Tokens per Sec:     4003 || Lr: 0.000100
2024-02-08 13:25:21,610 [Epoch: 134 Step: 00017800] Batch Recognition Loss:   0.018500 => Gls Tokens per Sec:     1596 || Batch Translation Loss:   0.355973 => Txt Tokens per Sec:     4400 || Lr: 0.000100
2024-02-08 13:25:22,854 Epoch 134: Total Training Recognition Loss 0.64  Total Training Translation Loss 36.52 
2024-02-08 13:25:22,855 EPOCH 135
2024-02-08 13:25:27,182 [Epoch: 135 Step: 00017900] Batch Recognition Loss:   0.000332 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   0.566239 => Txt Tokens per Sec:     3993 || Lr: 0.000100
2024-02-08 13:25:30,084 Epoch 135: Total Training Recognition Loss 0.75  Total Training Translation Loss 41.20 
2024-02-08 13:25:30,084 EPOCH 136
2024-02-08 13:25:32,419 [Epoch: 136 Step: 00018000] Batch Recognition Loss:   0.007281 => Gls Tokens per Sec:     1543 || Batch Translation Loss:   0.175598 => Txt Tokens per Sec:     4261 || Lr: 0.000100
2024-02-08 13:25:43,320 Validation result at epoch 136, step    18000: duration: 10.9003s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.85440	Translation Loss: 91452.40625	PPL: 9267.59570
	Eval Metric: BLEU
	WER 4.38	(DEL: 0.00,	INS: 0.00,	SUB: 4.38)
	BLEU-4 0.00	(BLEU-1: 11.19,	BLEU-2: 3.39,	BLEU-3: 1.05,	BLEU-4: 0.00)
	CHRF 17.35	ROUGE 9.25
2024-02-08 13:25:43,321 Logging Recognition and Translation Outputs
2024-02-08 13:25:43,321 ========================================================================================================================
2024-02-08 13:25:43,321 Logging Sequence: 179_309.00
2024-02-08 13:25:43,321 	Gloss Reference :	A B+C+D+E
2024-02-08 13:25:43,321 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:25:43,321 	Gloss Alignment :	         
2024-02-08 13:25:43,321 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:25:43,322 	Text Reference  :	before the ioa could send the notice wfi has asked phogat to explain her *** **** ** indiscipline
2024-02-08 13:25:43,323 	Text Hypothesis :	****** *** *** ***** **** *** if     she was not   travel to see     her ban will be extended    
2024-02-08 13:25:43,323 	Text Alignment  :	D      D   D   D     D    D   S      S   S   S     S         S           I   I    I  S           
2024-02-08 13:25:43,323 ========================================================================================================================
2024-02-08 13:25:43,323 Logging Sequence: 156_35.00
2024-02-08 13:25:43,323 	Gloss Reference :	A B+C+D+E
2024-02-08 13:25:43,323 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:25:43,323 	Gloss Alignment :	         
2024-02-08 13:25:43,324 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:25:43,325 	Text Reference  :	***** the first   season of mlc    began on  13th    july 2023 and ended on 30th july 2023 with six   teams      
2024-02-08 13:25:43,326 	Text Hypothesis :	after 2   players for    5  months they  got married in   2010 and ***** ** are  sold for  its  tough competition
2024-02-08 13:25:43,326 	Text Alignment  :	I     S   S       S      S  S      S     S   S       S    S        D     D  S    S    S    S    S     S          
2024-02-08 13:25:43,326 ========================================================================================================================
2024-02-08 13:25:43,326 Logging Sequence: 129_45.00
2024-02-08 13:25:43,326 	Gloss Reference :	A B+C+D+E
2024-02-08 13:25:43,326 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:25:43,326 	Gloss Alignment :	         
2024-02-08 13:25:43,327 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:25:43,328 	Text Reference  :	suga then  announced that    from 5    july onwards japan will be in   a  state of    emergency
2024-02-08 13:25:43,328 	Text Hypothesis :	the  tokyo olympics  started in   2020 but  will    have  to   be held at the   covid pandemic 
2024-02-08 13:25:43,328 	Text Alignment  :	S    S     S         S       S    S    S    S       S     S       S    S  S     S     S        
2024-02-08 13:25:43,328 ========================================================================================================================
2024-02-08 13:25:43,328 Logging Sequence: 56_17.00
2024-02-08 13:25:43,329 	Gloss Reference :	A B+C+D+E
2024-02-08 13:25:43,329 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:25:43,329 	Gloss Alignment :	         
2024-02-08 13:25:43,329 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:25:43,330 	Text Reference  :	*** ***** ******* it    was held at mumbai's wankhede stadium
2024-02-08 13:25:43,330 	Text Hypothesis :	the match started after a   lot  of them     as       well   
2024-02-08 13:25:43,330 	Text Alignment  :	I   I     I       S     S   S    S  S        S        S      
2024-02-08 13:25:43,330 ========================================================================================================================
2024-02-08 13:25:43,330 Logging Sequence: 152_73.00
2024-02-08 13:25:43,330 	Gloss Reference :	A B+C+D+E
2024-02-08 13:25:43,330 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:25:43,331 	Gloss Alignment :	         
2024-02-08 13:25:43,331 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:25:43,331 	Text Reference  :	**** ****** eventually he  too     got  out   by          shaheen afridi
2024-02-08 13:25:43,331 	Text Hypothesis :	even social media      was buzzing with match predictions and     memes 
2024-02-08 13:25:43,331 	Text Alignment  :	I    I      S          S   S       S    S     S           S       S     
2024-02-08 13:25:43,332 ========================================================================================================================
2024-02-08 13:25:48,471 Epoch 136: Total Training Recognition Loss 0.84  Total Training Translation Loss 32.23 
2024-02-08 13:25:48,472 EPOCH 137
2024-02-08 13:25:49,193 [Epoch: 137 Step: 00018100] Batch Recognition Loss:   0.004111 => Gls Tokens per Sec:     1333 || Batch Translation Loss:   0.462885 => Txt Tokens per Sec:     3679 || Lr: 0.000100
2024-02-08 13:25:54,708 [Epoch: 137 Step: 00018200] Batch Recognition Loss:   0.001157 => Gls Tokens per Sec:     1451 || Batch Translation Loss:   0.189284 => Txt Tokens per Sec:     4032 || Lr: 0.000100
2024-02-08 13:25:55,909 Epoch 137: Total Training Recognition Loss 0.80  Total Training Translation Loss 32.82 
2024-02-08 13:25:55,909 EPOCH 138
2024-02-08 13:26:00,356 [Epoch: 138 Step: 00018300] Batch Recognition Loss:   0.001154 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.173252 => Txt Tokens per Sec:     3853 || Lr: 0.000100
2024-02-08 13:26:03,293 Epoch 138: Total Training Recognition Loss 1.04  Total Training Translation Loss 28.55 
2024-02-08 13:26:03,293 EPOCH 139
2024-02-08 13:26:05,750 [Epoch: 139 Step: 00018400] Batch Recognition Loss:   0.000817 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.214437 => Txt Tokens per Sec:     4262 || Lr: 0.000100
2024-02-08 13:26:10,519 Epoch 139: Total Training Recognition Loss 0.68  Total Training Translation Loss 30.21 
2024-02-08 13:26:10,520 EPOCH 140
2024-02-08 13:26:11,146 [Epoch: 140 Step: 00018500] Batch Recognition Loss:   0.021515 => Gls Tokens per Sec:     1661 || Batch Translation Loss:   0.421303 => Txt Tokens per Sec:     4612 || Lr: 0.000100
2024-02-08 13:26:16,701 [Epoch: 140 Step: 00018600] Batch Recognition Loss:   0.003384 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.484289 => Txt Tokens per Sec:     4021 || Lr: 0.000100
2024-02-08 13:26:18,033 Epoch 140: Total Training Recognition Loss 0.97  Total Training Translation Loss 33.43 
2024-02-08 13:26:18,034 EPOCH 141
2024-02-08 13:26:22,326 [Epoch: 141 Step: 00018700] Batch Recognition Loss:   0.000957 => Gls Tokens per Sec:     1492 || Batch Translation Loss:   0.224188 => Txt Tokens per Sec:     4108 || Lr: 0.000100
2024-02-08 13:26:25,246 Epoch 141: Total Training Recognition Loss 0.52  Total Training Translation Loss 42.90 
2024-02-08 13:26:25,246 EPOCH 142
2024-02-08 13:26:27,606 [Epoch: 142 Step: 00018800] Batch Recognition Loss:   0.007924 => Gls Tokens per Sec:     1595 || Batch Translation Loss:   0.197421 => Txt Tokens per Sec:     4480 || Lr: 0.000100
2024-02-08 13:26:31,969 Epoch 142: Total Training Recognition Loss 1.01  Total Training Translation Loss 45.60 
2024-02-08 13:26:31,969 EPOCH 143
2024-02-08 13:26:32,641 [Epoch: 143 Step: 00018900] Batch Recognition Loss:   0.005379 => Gls Tokens per Sec:     1669 || Batch Translation Loss:   0.062095 => Txt Tokens per Sec:     4429 || Lr: 0.000100
2024-02-08 13:26:38,248 [Epoch: 143 Step: 00019000] Batch Recognition Loss:   0.002107 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.191387 => Txt Tokens per Sec:     3952 || Lr: 0.000100
2024-02-08 13:26:39,381 Epoch 143: Total Training Recognition Loss 0.61  Total Training Translation Loss 35.33 
2024-02-08 13:26:39,381 EPOCH 144
2024-02-08 13:26:43,602 [Epoch: 144 Step: 00019100] Batch Recognition Loss:   0.009141 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   0.163995 => Txt Tokens per Sec:     4254 || Lr: 0.000100
2024-02-08 13:26:46,591 Epoch 144: Total Training Recognition Loss 0.65  Total Training Translation Loss 35.43 
2024-02-08 13:26:46,592 EPOCH 145
2024-02-08 13:26:49,159 [Epoch: 145 Step: 00019200] Batch Recognition Loss:   0.008095 => Gls Tokens per Sec:     1497 || Batch Translation Loss:   0.112994 => Txt Tokens per Sec:     4192 || Lr: 0.000100
2024-02-08 13:26:53,591 Epoch 145: Total Training Recognition Loss 0.61  Total Training Translation Loss 28.28 
2024-02-08 13:26:53,591 EPOCH 146
2024-02-08 13:26:54,468 [Epoch: 146 Step: 00019300] Batch Recognition Loss:   0.010477 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.077574 => Txt Tokens per Sec:     3477 || Lr: 0.000100
2024-02-08 13:27:00,352 [Epoch: 146 Step: 00019400] Batch Recognition Loss:   0.000676 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.239450 => Txt Tokens per Sec:     3810 || Lr: 0.000100
2024-02-08 13:27:01,348 Epoch 146: Total Training Recognition Loss 0.63  Total Training Translation Loss 23.42 
2024-02-08 13:27:01,348 EPOCH 147
2024-02-08 13:27:05,724 [Epoch: 147 Step: 00019500] Batch Recognition Loss:   0.011550 => Gls Tokens per Sec:     1500 || Batch Translation Loss:   0.596155 => Txt Tokens per Sec:     4163 || Lr: 0.000100
2024-02-08 13:27:08,423 Epoch 147: Total Training Recognition Loss 0.63  Total Training Translation Loss 28.41 
2024-02-08 13:27:08,423 EPOCH 148
2024-02-08 13:27:10,908 [Epoch: 148 Step: 00019600] Batch Recognition Loss:   0.000475 => Gls Tokens per Sec:     1578 || Batch Translation Loss:   0.151386 => Txt Tokens per Sec:     4414 || Lr: 0.000100
2024-02-08 13:27:15,618 Epoch 148: Total Training Recognition Loss 0.59  Total Training Translation Loss 31.37 
2024-02-08 13:27:15,619 EPOCH 149
2024-02-08 13:27:16,445 [Epoch: 149 Step: 00019700] Batch Recognition Loss:   0.001263 => Gls Tokens per Sec:     1552 || Batch Translation Loss:   0.106637 => Txt Tokens per Sec:     4452 || Lr: 0.000100
2024-02-08 13:27:21,882 [Epoch: 149 Step: 00019800] Batch Recognition Loss:   0.002513 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.155850 => Txt Tokens per Sec:     4019 || Lr: 0.000100
2024-02-08 13:27:22,937 Epoch 149: Total Training Recognition Loss 0.88  Total Training Translation Loss 30.89 
2024-02-08 13:27:22,937 EPOCH 150
2024-02-08 13:27:27,782 [Epoch: 150 Step: 00019900] Batch Recognition Loss:   0.000875 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.168710 => Txt Tokens per Sec:     3716 || Lr: 0.000100
2024-02-08 13:27:30,459 Epoch 150: Total Training Recognition Loss 1.21  Total Training Translation Loss 28.84 
2024-02-08 13:27:30,459 EPOCH 151
2024-02-08 13:27:32,889 [Epoch: 151 Step: 00020000] Batch Recognition Loss:   0.000325 => Gls Tokens per Sec:     1647 || Batch Translation Loss:   0.259193 => Txt Tokens per Sec:     4624 || Lr: 0.000100
2024-02-08 13:27:43,604 Validation result at epoch 151, step    20000: duration: 10.7145s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.38330	Translation Loss: 93203.25781	PPL: 11038.61133
	Eval Metric: BLEU
	WER 4.73	(DEL: 0.00,	INS: 0.00,	SUB: 4.73)
	BLEU-4 0.50	(BLEU-1: 10.36,	BLEU-2: 3.19,	BLEU-3: 1.13,	BLEU-4: 0.50)
	CHRF 16.30	ROUGE 9.14
2024-02-08 13:27:43,605 Logging Recognition and Translation Outputs
2024-02-08 13:27:43,605 ========================================================================================================================
2024-02-08 13:27:43,605 Logging Sequence: 120_7.00
2024-02-08 13:27:43,606 	Gloss Reference :	A B+C+D+E
2024-02-08 13:27:43,606 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:27:43,606 	Gloss Alignment :	         
2024-02-08 13:27:43,606 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:27:43,607 	Text Reference  :	** he          had    tested positive for    covid-19 on     may    19  
2024-02-08 13:27:43,607 	Text Hypothesis :	on questioning people about  the      murder the      police learnt that
2024-02-08 13:27:43,607 	Text Alignment  :	I  S           S      S      S        S      S        S      S      S   
2024-02-08 13:27:43,607 ========================================================================================================================
2024-02-08 13:27:43,607 Logging Sequence: 148_186.00
2024-02-08 13:27:43,607 	Gloss Reference :	A B+C+D+E
2024-02-08 13:27:43,607 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:27:43,608 	Gloss Alignment :	         
2024-02-08 13:27:43,608 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:27:43,609 	Text Reference  :	siraj also took four wickets in  1         over  thus       becoming the   record-holder for   most wickets in an    over in   odis
2024-02-08 13:27:43,609 	Text Hypothesis :	***** **** **** **** ******* the badminton world federation of       india is            being held every   2  years of   both more
2024-02-08 13:27:43,610 	Text Alignment  :	D     D    D    D    D       S   S         S     S          S        S     S             S     S    S       S  S     S    S    S   
2024-02-08 13:27:43,610 ========================================================================================================================
2024-02-08 13:27:43,610 Logging Sequence: 67_73.00
2024-02-08 13:27:43,610 	Gloss Reference :	A B+C+D+E
2024-02-08 13:27:43,610 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:27:43,610 	Gloss Alignment :	         
2024-02-08 13:27:43,610 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:27:43,611 	Text Reference  :	*** ****** in  his tweet he  also  said
2024-02-08 13:27:43,611 	Text Hypothesis :	she really let me  tell  you about it  
2024-02-08 13:27:43,611 	Text Alignment  :	I   I      S   S   S     S   S     S   
2024-02-08 13:27:43,611 ========================================================================================================================
2024-02-08 13:27:43,611 Logging Sequence: 164_526.00
2024-02-08 13:27:43,611 	Gloss Reference :	A B+C+D+E
2024-02-08 13:27:43,612 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:27:43,612 	Gloss Alignment :	         
2024-02-08 13:27:43,612 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:27:43,613 	Text Reference  :	*** you   are  aware that viacom18 bought the broadcast    rights *** of  ipl       
2024-02-08 13:27:43,613 	Text Hypothesis :	the first ball ended in   a        lot    of  broadcasting rights for the tournament
2024-02-08 13:27:43,613 	Text Alignment  :	I   S     S    S     S    S        S      S   S                   I   S   S         
2024-02-08 13:27:43,613 ========================================================================================================================
2024-02-08 13:27:43,613 Logging Sequence: 108_28.00
2024-02-08 13:27:43,613 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:27:43,614 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:27:43,614 	Gloss Alignment :	  S        
2024-02-08 13:27:43,614 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:27:43,615 	Text Reference  :	the 10 teams bought 204 players including 67      foreign players after spending a  total of     rs 55170 crore   
2024-02-08 13:27:43,615 	Text Hypothesis :	the ** ***** ****** *** ******* ipl       matches will    be      held  only     in pune  mumbai at 25    capacity
2024-02-08 13:27:43,615 	Text Alignment  :	    D  D     D      D   D       S         S       S       S       S     S        S  S     S      S  S     S       
2024-02-08 13:27:43,616 ========================================================================================================================
2024-02-08 13:27:48,506 Epoch 151: Total Training Recognition Loss 0.62  Total Training Translation Loss 29.82 
2024-02-08 13:27:48,507 EPOCH 152
2024-02-08 13:27:49,510 [Epoch: 152 Step: 00020100] Batch Recognition Loss:   0.001510 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.090646 => Txt Tokens per Sec:     3971 || Lr: 0.000100
2024-02-08 13:27:54,717 [Epoch: 152 Step: 00020200] Batch Recognition Loss:   0.000351 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   0.385409 => Txt Tokens per Sec:     4194 || Lr: 0.000100
2024-02-08 13:27:55,662 Epoch 152: Total Training Recognition Loss 0.81  Total Training Translation Loss 40.67 
2024-02-08 13:27:55,662 EPOCH 153
2024-02-08 13:28:00,575 [Epoch: 153 Step: 00020300] Batch Recognition Loss:   0.000661 => Gls Tokens per Sec:     1368 || Batch Translation Loss:   0.202304 => Txt Tokens per Sec:     3771 || Lr: 0.000100
2024-02-08 13:28:03,143 Epoch 153: Total Training Recognition Loss 0.65  Total Training Translation Loss 35.55 
2024-02-08 13:28:03,143 EPOCH 154
2024-02-08 13:28:05,548 [Epoch: 154 Step: 00020400] Batch Recognition Loss:   0.000519 => Gls Tokens per Sec:     1697 || Batch Translation Loss:   0.169693 => Txt Tokens per Sec:     4709 || Lr: 0.000100
2024-02-08 13:28:10,187 Epoch 154: Total Training Recognition Loss 0.56  Total Training Translation Loss 30.47 
2024-02-08 13:28:10,188 EPOCH 155
2024-02-08 13:28:11,209 [Epoch: 155 Step: 00020500] Batch Recognition Loss:   0.004185 => Gls Tokens per Sec:     1412 || Batch Translation Loss:   0.043244 => Txt Tokens per Sec:     3882 || Lr: 0.000100
2024-02-08 13:28:16,664 [Epoch: 155 Step: 00020600] Batch Recognition Loss:   0.003613 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.236167 => Txt Tokens per Sec:     4066 || Lr: 0.000100
2024-02-08 13:28:17,654 Epoch 155: Total Training Recognition Loss 0.51  Total Training Translation Loss 28.07 
2024-02-08 13:28:17,654 EPOCH 156
2024-02-08 13:28:22,327 [Epoch: 156 Step: 00020700] Batch Recognition Loss:   0.031692 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.838195 => Txt Tokens per Sec:     3992 || Lr: 0.000100
2024-02-08 13:28:24,974 Epoch 156: Total Training Recognition Loss 0.76  Total Training Translation Loss 31.15 
2024-02-08 13:28:24,974 EPOCH 157
2024-02-08 13:28:27,891 [Epoch: 157 Step: 00020800] Batch Recognition Loss:   0.000407 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.105858 => Txt Tokens per Sec:     4111 || Lr: 0.000100
2024-02-08 13:28:32,217 Epoch 157: Total Training Recognition Loss 0.67  Total Training Translation Loss 34.35 
2024-02-08 13:28:32,217 EPOCH 158
2024-02-08 13:28:33,129 [Epoch: 158 Step: 00020900] Batch Recognition Loss:   0.004711 => Gls Tokens per Sec:     1668 || Batch Translation Loss:   0.095395 => Txt Tokens per Sec:     4553 || Lr: 0.000100
2024-02-08 13:28:38,778 [Epoch: 158 Step: 00021000] Batch Recognition Loss:   0.002481 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.118422 => Txt Tokens per Sec:     3921 || Lr: 0.000100
2024-02-08 13:28:39,611 Epoch 158: Total Training Recognition Loss 0.75  Total Training Translation Loss 33.41 
2024-02-08 13:28:39,611 EPOCH 159
2024-02-08 13:28:44,189 [Epoch: 159 Step: 00021100] Batch Recognition Loss:   0.005952 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.069328 => Txt Tokens per Sec:     4241 || Lr: 0.000100
2024-02-08 13:28:46,587 Epoch 159: Total Training Recognition Loss 0.80  Total Training Translation Loss 21.17 
2024-02-08 13:28:46,588 EPOCH 160
2024-02-08 13:28:49,734 [Epoch: 160 Step: 00021200] Batch Recognition Loss:   0.001537 => Gls Tokens per Sec:     1349 || Batch Translation Loss:   1.002618 => Txt Tokens per Sec:     3726 || Lr: 0.000100
2024-02-08 13:28:54,161 Epoch 160: Total Training Recognition Loss 0.62  Total Training Translation Loss 34.96 
2024-02-08 13:28:54,161 EPOCH 161
2024-02-08 13:28:55,172 [Epoch: 161 Step: 00021300] Batch Recognition Loss:   0.000724 => Gls Tokens per Sec:     1584 || Batch Translation Loss:   0.198404 => Txt Tokens per Sec:     4249 || Lr: 0.000100
2024-02-08 13:29:00,930 [Epoch: 161 Step: 00021400] Batch Recognition Loss:   0.007121 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.375808 => Txt Tokens per Sec:     3887 || Lr: 0.000100
2024-02-08 13:29:01,615 Epoch 161: Total Training Recognition Loss 0.81  Total Training Translation Loss 35.81 
2024-02-08 13:29:01,615 EPOCH 162
2024-02-08 13:29:06,306 [Epoch: 162 Step: 00021500] Batch Recognition Loss:   0.006962 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.082019 => Txt Tokens per Sec:     4096 || Lr: 0.000100
2024-02-08 13:29:08,631 Epoch 162: Total Training Recognition Loss 0.74  Total Training Translation Loss 36.25 
2024-02-08 13:29:08,632 EPOCH 163
2024-02-08 13:29:11,322 [Epoch: 163 Step: 00021600] Batch Recognition Loss:   0.000294 => Gls Tokens per Sec:     1606 || Batch Translation Loss:   0.152268 => Txt Tokens per Sec:     4681 || Lr: 0.000100
2024-02-08 13:29:14,903 Epoch 163: Total Training Recognition Loss 0.75  Total Training Translation Loss 29.05 
2024-02-08 13:29:14,903 EPOCH 164
2024-02-08 13:29:15,895 [Epoch: 164 Step: 00021700] Batch Recognition Loss:   0.000472 => Gls Tokens per Sec:     1695 || Batch Translation Loss:   0.382574 => Txt Tokens per Sec:     4623 || Lr: 0.000100
2024-02-08 13:29:21,828 [Epoch: 164 Step: 00021800] Batch Recognition Loss:   0.001277 => Gls Tokens per Sec:     1345 || Batch Translation Loss:   0.092522 => Txt Tokens per Sec:     3746 || Lr: 0.000100
2024-02-08 13:29:22,494 Epoch 164: Total Training Recognition Loss 0.58  Total Training Translation Loss 23.53 
2024-02-08 13:29:22,494 EPOCH 165
2024-02-08 13:29:27,406 [Epoch: 165 Step: 00021900] Batch Recognition Loss:   0.000455 => Gls Tokens per Sec:     1434 || Batch Translation Loss:   0.095739 => Txt Tokens per Sec:     3953 || Lr: 0.000100
2024-02-08 13:29:29,932 Epoch 165: Total Training Recognition Loss 0.84  Total Training Translation Loss 20.02 
2024-02-08 13:29:29,932 EPOCH 166
2024-02-08 13:29:32,929 [Epoch: 166 Step: 00022000] Batch Recognition Loss:   0.000800 => Gls Tokens per Sec:     1468 || Batch Translation Loss:   0.134264 => Txt Tokens per Sec:     4029 || Lr: 0.000100
2024-02-08 13:29:43,959 Validation result at epoch 166, step    22000: duration: 11.0296s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.46466	Translation Loss: 93196.78906	PPL: 11031.48633
	Eval Metric: BLEU
	WER 4.45	(DEL: 0.00,	INS: 0.00,	SUB: 4.45)
	BLEU-4 0.77	(BLEU-1: 11.33,	BLEU-2: 3.65,	BLEU-3: 1.45,	BLEU-4: 0.77)
	CHRF 17.51	ROUGE 9.55
2024-02-08 13:29:43,960 Logging Recognition and Translation Outputs
2024-02-08 13:29:43,961 ========================================================================================================================
2024-02-08 13:29:43,961 Logging Sequence: 179_2.00
2024-02-08 13:29:43,961 	Gloss Reference :	A B+C+D+E    
2024-02-08 13:29:43,961 	Gloss Hypothesis:	A B+C+D+E+D+E
2024-02-08 13:29:43,961 	Gloss Alignment :	  S          
2024-02-08 13:29:43,961 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:29:43,962 	Text Reference  :	vinesh phogat is   a         well known   wrestler
2024-02-08 13:29:43,962 	Text Hypothesis :	the    duo    then travelled to   various winners 
2024-02-08 13:29:43,962 	Text Alignment  :	S      S      S    S         S    S       S       
2024-02-08 13:29:43,962 ========================================================================================================================
2024-02-08 13:29:43,962 Logging Sequence: 55_124.00
2024-02-08 13:29:43,962 	Gloss Reference :	A B+C+D+E
2024-02-08 13:29:43,963 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:29:43,963 	Gloss Alignment :	         
2024-02-08 13:29:43,963 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:29:43,964 	Text Reference  :	** *** * next to  him       with   the    patel jersey   was           ajaz patel
2024-02-08 13:29:43,964 	Text Hypothesis :	it was a huge fan following hardik pandya and   netizens congratulated the  tv   
2024-02-08 13:29:43,964 	Text Alignment  :	I  I   I S    S   S         S      S      S     S        S             S    S    
2024-02-08 13:29:43,964 ========================================================================================================================
2024-02-08 13:29:43,964 Logging Sequence: 148_105.00
2024-02-08 13:29:43,964 	Gloss Reference :	A B+C+D+E
2024-02-08 13:29:43,965 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:29:43,965 	Gloss Alignment :	         
2024-02-08 13:29:43,965 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:29:43,966 	Text Reference  :	later with amazing bowling by hardik pandya and kuldeep yadav sri lanka were     all out in   just   50    runs
2024-02-08 13:29:43,966 	Text Hypothesis :	***** **** ******* ******* ** ****** ****** the first   time  the most  followed the 6th over yuvraj singh said
2024-02-08 13:29:43,966 	Text Alignment  :	D     D    D       D       D  D      D      S   S       S     S   S     S        S   S   S    S      S     S   
2024-02-08 13:29:43,967 ========================================================================================================================
2024-02-08 13:29:43,967 Logging Sequence: 125_165.00
2024-02-08 13:29:43,967 	Gloss Reference :	A B+C+D+E
2024-02-08 13:29:43,967 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:29:43,967 	Gloss Alignment :	         
2024-02-08 13:29:43,967 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:29:43,968 	Text Reference  :	please do not target nadeem we speak to  each other and share   a   good bond   
2024-02-08 13:29:43,968 	Text Hypothesis :	****** ** *** ****** ****** ** ***** but that time  pat cummins for all  rounder
2024-02-08 13:29:43,968 	Text Alignment  :	D      D  D   D      D      D  D     S   S    S     S   S       S   S    S      
2024-02-08 13:29:43,968 ========================================================================================================================
2024-02-08 13:29:43,969 Logging Sequence: 77_52.00
2024-02-08 13:29:43,969 	Gloss Reference :	A B+C+D+E
2024-02-08 13:29:43,969 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:29:43,969 	Gloss Alignment :	         
2024-02-08 13:29:43,969 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:29:43,971 	Text Reference  :	kane williamson held down    the fort for hyderabad by   scoring     66  runs and ended the match in    a   tie  
2024-02-08 13:29:43,971 	Text Hypothesis :	**** ********** **** however the **** *** first     time afghanistan was set  to  help  he  still final and sixes
2024-02-08 13:29:43,971 	Text Alignment  :	D    D          D    S           D    D   S         S    S           S   S    S   S     S   S     S     S   S    
2024-02-08 13:29:43,971 ========================================================================================================================
2024-02-08 13:29:48,291 Epoch 166: Total Training Recognition Loss 0.40  Total Training Translation Loss 22.98 
2024-02-08 13:29:48,291 EPOCH 167
2024-02-08 13:29:49,655 [Epoch: 167 Step: 00022100] Batch Recognition Loss:   0.000530 => Gls Tokens per Sec:     1292 || Batch Translation Loss:   0.187099 => Txt Tokens per Sec:     3743 || Lr: 0.000100
2024-02-08 13:29:55,334 [Epoch: 167 Step: 00022200] Batch Recognition Loss:   0.000909 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.162898 => Txt Tokens per Sec:     3868 || Lr: 0.000100
2024-02-08 13:29:55,867 Epoch 167: Total Training Recognition Loss 0.48  Total Training Translation Loss 23.80 
2024-02-08 13:29:55,868 EPOCH 168
2024-02-08 13:30:00,344 [Epoch: 168 Step: 00022300] Batch Recognition Loss:   0.002222 => Gls Tokens per Sec:     1591 || Batch Translation Loss:   0.103693 => Txt Tokens per Sec:     4425 || Lr: 0.000100
2024-02-08 13:30:02,805 Epoch 168: Total Training Recognition Loss 0.79  Total Training Translation Loss 22.51 
2024-02-08 13:30:02,806 EPOCH 169
2024-02-08 13:30:05,814 [Epoch: 169 Step: 00022400] Batch Recognition Loss:   0.000421 => Gls Tokens per Sec:     1490 || Batch Translation Loss:   0.229001 => Txt Tokens per Sec:     4248 || Lr: 0.000100
2024-02-08 13:30:09,840 Epoch 169: Total Training Recognition Loss 0.62  Total Training Translation Loss 30.43 
2024-02-08 13:30:09,841 EPOCH 170
2024-02-08 13:30:11,237 [Epoch: 170 Step: 00022500] Batch Recognition Loss:   0.007584 => Gls Tokens per Sec:     1320 || Batch Translation Loss:   0.437102 => Txt Tokens per Sec:     3577 || Lr: 0.000100
2024-02-08 13:30:16,913 [Epoch: 170 Step: 00022600] Batch Recognition Loss:   0.044553 => Gls Tokens per Sec:     1406 || Batch Translation Loss:   0.385981 => Txt Tokens per Sec:     3910 || Lr: 0.000100
2024-02-08 13:30:17,422 Epoch 170: Total Training Recognition Loss 0.54  Total Training Translation Loss 40.42 
2024-02-08 13:30:17,423 EPOCH 171
2024-02-08 13:30:22,584 [Epoch: 171 Step: 00022700] Batch Recognition Loss:   0.001122 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.170462 => Txt Tokens per Sec:     3870 || Lr: 0.000100
2024-02-08 13:30:24,919 Epoch 171: Total Training Recognition Loss 0.71  Total Training Translation Loss 46.43 
2024-02-08 13:30:24,920 EPOCH 172
2024-02-08 13:30:27,736 [Epoch: 172 Step: 00022800] Batch Recognition Loss:   0.001065 => Gls Tokens per Sec:     1620 || Batch Translation Loss:   0.237408 => Txt Tokens per Sec:     4491 || Lr: 0.000100
2024-02-08 13:30:31,840 Epoch 172: Total Training Recognition Loss 0.48  Total Training Translation Loss 25.03 
2024-02-08 13:30:31,841 EPOCH 173
2024-02-08 13:30:33,269 [Epoch: 173 Step: 00022900] Batch Recognition Loss:   0.006649 => Gls Tokens per Sec:     1346 || Batch Translation Loss:   0.113181 => Txt Tokens per Sec:     3845 || Lr: 0.000100
2024-02-08 13:30:38,896 [Epoch: 173 Step: 00023000] Batch Recognition Loss:   0.002972 => Gls Tokens per Sec:     1418 || Batch Translation Loss:   0.213074 => Txt Tokens per Sec:     3882 || Lr: 0.000100
2024-02-08 13:30:39,433 Epoch 173: Total Training Recognition Loss 0.66  Total Training Translation Loss 21.46 
2024-02-08 13:30:39,433 EPOCH 174
2024-02-08 13:30:44,488 [Epoch: 174 Step: 00023100] Batch Recognition Loss:   0.000397 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.811819 => Txt Tokens per Sec:     3989 || Lr: 0.000100
2024-02-08 13:30:46,954 Epoch 174: Total Training Recognition Loss 0.52  Total Training Translation Loss 24.85 
2024-02-08 13:30:46,954 EPOCH 175
2024-02-08 13:30:49,791 [Epoch: 175 Step: 00023200] Batch Recognition Loss:   0.004840 => Gls Tokens per Sec:     1636 || Batch Translation Loss:   0.108179 => Txt Tokens per Sec:     4418 || Lr: 0.000100
2024-02-08 13:30:54,115 Epoch 175: Total Training Recognition Loss 0.41  Total Training Translation Loss 26.62 
2024-02-08 13:30:54,115 EPOCH 176
2024-02-08 13:30:55,380 [Epoch: 176 Step: 00023300] Batch Recognition Loss:   0.000411 => Gls Tokens per Sec:     1582 || Batch Translation Loss:   0.119696 => Txt Tokens per Sec:     4496 || Lr: 0.000100
2024-02-08 13:31:00,924 [Epoch: 176 Step: 00023400] Batch Recognition Loss:   0.002890 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.070665 => Txt Tokens per Sec:     3944 || Lr: 0.000100
2024-02-08 13:31:01,380 Epoch 176: Total Training Recognition Loss 0.52  Total Training Translation Loss 21.69 
2024-02-08 13:31:01,381 EPOCH 177
2024-02-08 13:31:06,724 [Epoch: 177 Step: 00023500] Batch Recognition Loss:   0.000441 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.053166 => Txt Tokens per Sec:     3834 || Lr: 0.000100
2024-02-08 13:31:08,994 Epoch 177: Total Training Recognition Loss 0.75  Total Training Translation Loss 16.77 
2024-02-08 13:31:08,994 EPOCH 178
2024-02-08 13:31:12,096 [Epoch: 178 Step: 00023600] Batch Recognition Loss:   0.000474 => Gls Tokens per Sec:     1523 || Batch Translation Loss:   0.143014 => Txt Tokens per Sec:     4228 || Lr: 0.000100
2024-02-08 13:31:16,509 Epoch 178: Total Training Recognition Loss 0.56  Total Training Translation Loss 16.59 
2024-02-08 13:31:16,509 EPOCH 179
2024-02-08 13:31:17,852 [Epoch: 179 Step: 00023700] Batch Recognition Loss:   0.027519 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.098789 => Txt Tokens per Sec:     4146 || Lr: 0.000100
2024-02-08 13:31:23,295 [Epoch: 179 Step: 00023800] Batch Recognition Loss:   0.000863 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.085402 => Txt Tokens per Sec:     4089 || Lr: 0.000100
2024-02-08 13:31:23,693 Epoch 179: Total Training Recognition Loss 0.69  Total Training Translation Loss 21.00 
2024-02-08 13:31:23,694 EPOCH 180
2024-02-08 13:31:29,156 [Epoch: 180 Step: 00023900] Batch Recognition Loss:   0.002150 => Gls Tokens per Sec:     1362 || Batch Translation Loss:   0.161194 => Txt Tokens per Sec:     3781 || Lr: 0.000100
2024-02-08 13:31:31,539 Epoch 180: Total Training Recognition Loss 0.43  Total Training Translation Loss 34.21 
2024-02-08 13:31:31,540 EPOCH 181
2024-02-08 13:31:34,880 [Epoch: 181 Step: 00024000] Batch Recognition Loss:   0.000896 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.160034 => Txt Tokens per Sec:     4035 || Lr: 0.000100
2024-02-08 13:31:45,563 Validation result at epoch 181, step    24000: duration: 10.6820s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.84828	Translation Loss: 92944.82812	PPL: 10757.32715
	Eval Metric: BLEU
	WER 4.87	(DEL: 0.00,	INS: 0.00,	SUB: 4.87)
	BLEU-4 0.42	(BLEU-1: 9.97,	BLEU-2: 3.09,	BLEU-3: 1.03,	BLEU-4: 0.42)
	CHRF 16.72	ROUGE 8.66
2024-02-08 13:31:45,565 Logging Recognition and Translation Outputs
2024-02-08 13:31:45,565 ========================================================================================================================
2024-02-08 13:31:45,565 Logging Sequence: 171_2.00
2024-02-08 13:31:45,565 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:31:45,565 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:31:45,565 	Gloss Alignment :	  S        
2024-02-08 13:31:45,565 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:31:45,567 	Text Reference  :	as you might all know that the        ipl  is    about  to end  the finals are        on *** 28th may   
2024-02-08 13:31:45,567 	Text Hypothesis :	** *** ***** in  2011 2020 cricketers when india scored 35 runs in  26     deliveries on his left unsold
2024-02-08 13:31:45,567 	Text Alignment  :	D  D   D     S   S    S    S          S    S     S      S  S    S   S      S             I   S    S     
2024-02-08 13:31:45,567 ========================================================================================================================
2024-02-08 13:31:45,568 Logging Sequence: 119_33.00
2024-02-08 13:31:45,568 	Gloss Reference :	A B+C+D+E
2024-02-08 13:31:45,568 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:31:45,568 	Gloss Alignment :	         
2024-02-08 13:31:45,568 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:31:45,569 	Text Reference  :	he **** ********* *** *** wanted to    gift *** *** ****** ** 35 people wow wonderful
2024-02-08 13:31:45,569 	Text Hypothesis :	he then qualified for his wife   their gift for his father as he has    a   gift     
2024-02-08 13:31:45,569 	Text Alignment  :	   I    I         I   I   S      S          I   I   I      I  S  S      S   S        
2024-02-08 13:31:45,569 ========================================================================================================================
2024-02-08 13:31:45,570 Logging Sequence: 158_131.00
2024-02-08 13:31:45,570 	Gloss Reference :	A B+C+D+E
2024-02-08 13:31:45,570 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:31:45,570 	Gloss Alignment :	         
2024-02-08 13:31:45,570 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:31:45,571 	Text Reference  :	on 10th april 2023 there was a match between rcb     and     lsg in  bengaluru     
2024-02-08 13:31:45,571 	Text Hypothesis :	** **** ***** bcci kohli was * ***** ******* gambhir playing one day internationals
2024-02-08 13:31:45,571 	Text Alignment  :	D  D    D     S    S         D D     D       S       S       S   S   S             
2024-02-08 13:31:45,571 ========================================================================================================================
2024-02-08 13:31:45,571 Logging Sequence: 164_412.00
2024-02-08 13:31:45,571 	Gloss Reference :	A B+C+D+E
2024-02-08 13:31:45,572 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:31:45,572 	Gloss Alignment :	         
2024-02-08 13:31:45,572 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:31:45,574 	Text Reference  :	if  you   divide these     two figures you will be      shocked to know that each ball's   worth is      rs     50  lakhs    
2024-02-08 13:31:45,574 	Text Hypothesis :	the match was    presented the rights  of  ipl  matches yet     to **** **** **** complete the   various rights for marketing
2024-02-08 13:31:45,574 	Text Alignment  :	S   S     S      S         S   S       S   S    S       S          D    D    D    S        S     S       S      S   S        
2024-02-08 13:31:45,574 ========================================================================================================================
2024-02-08 13:31:45,574 Logging Sequence: 159_112.00
2024-02-08 13:31:45,575 	Gloss Reference :	A B+C+D+E    
2024-02-08 13:31:45,575 	Gloss Hypothesis:	A B+C+D+E+D+E
2024-02-08 13:31:45,575 	Gloss Alignment :	  S          
2024-02-08 13:31:45,575 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:31:45,576 	Text Reference  :	kohli had revealed that before the tournament he did not touch his bat  for a   month   yes 1    month  
2024-02-08 13:31:45,576 	Text Hypothesis :	***** *** you      all  know   the ********** ** *** *** ***** *** list of  ipl matches in  t20i captain
2024-02-08 13:31:45,576 	Text Alignment  :	D     D   S        S    S          D          D  D   D   D     D   S    S   S   S       S   S    S      
2024-02-08 13:31:45,577 ========================================================================================================================
2024-02-08 13:31:49,651 Epoch 181: Total Training Recognition Loss 1.05  Total Training Translation Loss 36.56 
2024-02-08 13:31:49,651 EPOCH 182
2024-02-08 13:31:51,382 [Epoch: 182 Step: 00024100] Batch Recognition Loss:   0.000838 => Gls Tokens per Sec:     1248 || Batch Translation Loss:   0.164148 => Txt Tokens per Sec:     3681 || Lr: 0.000100
2024-02-08 13:31:56,755 [Epoch: 182 Step: 00024200] Batch Recognition Loss:   0.006966 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.070189 => Txt Tokens per Sec:     4031 || Lr: 0.000100
2024-02-08 13:31:57,091 Epoch 182: Total Training Recognition Loss 0.61  Total Training Translation Loss 26.52 
2024-02-08 13:31:57,091 EPOCH 183
2024-02-08 13:32:02,499 [Epoch: 183 Step: 00024300] Batch Recognition Loss:   0.006293 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   0.142127 => Txt Tokens per Sec:     3823 || Lr: 0.000100
2024-02-08 13:32:04,801 Epoch 183: Total Training Recognition Loss 0.83  Total Training Translation Loss 33.48 
2024-02-08 13:32:04,801 EPOCH 184
2024-02-08 13:32:07,878 [Epoch: 184 Step: 00024400] Batch Recognition Loss:   0.004679 => Gls Tokens per Sec:     1586 || Batch Translation Loss:   0.102491 => Txt Tokens per Sec:     4437 || Lr: 0.000100
2024-02-08 13:32:11,924 Epoch 184: Total Training Recognition Loss 0.73  Total Training Translation Loss 28.07 
2024-02-08 13:32:11,925 EPOCH 185
2024-02-08 13:32:13,367 [Epoch: 185 Step: 00024500] Batch Recognition Loss:   0.005598 => Gls Tokens per Sec:     1554 || Batch Translation Loss:   0.063528 => Txt Tokens per Sec:     4075 || Lr: 0.000100
2024-02-08 13:32:19,096 [Epoch: 185 Step: 00024600] Batch Recognition Loss:   0.002944 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.146917 => Txt Tokens per Sec:     3921 || Lr: 0.000100
2024-02-08 13:32:19,412 Epoch 185: Total Training Recognition Loss 0.46  Total Training Translation Loss 23.98 
2024-02-08 13:32:19,412 EPOCH 186
2024-02-08 13:32:24,700 [Epoch: 186 Step: 00024700] Batch Recognition Loss:   0.001820 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.400954 => Txt Tokens per Sec:     3936 || Lr: 0.000100
2024-02-08 13:32:26,867 Epoch 186: Total Training Recognition Loss 0.54  Total Training Translation Loss 32.39 
2024-02-08 13:32:26,867 EPOCH 187
2024-02-08 13:32:30,204 [Epoch: 187 Step: 00024800] Batch Recognition Loss:   0.001730 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.121914 => Txt Tokens per Sec:     3991 || Lr: 0.000100
2024-02-08 13:32:34,241 Epoch 187: Total Training Recognition Loss 0.84  Total Training Translation Loss 27.39 
2024-02-08 13:32:34,242 EPOCH 188
2024-02-08 13:32:35,770 [Epoch: 188 Step: 00024900] Batch Recognition Loss:   0.001593 => Gls Tokens per Sec:     1519 || Batch Translation Loss:   0.058778 => Txt Tokens per Sec:     4110 || Lr: 0.000100
2024-02-08 13:32:41,563 [Epoch: 188 Step: 00025000] Batch Recognition Loss:   0.021875 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.100687 => Txt Tokens per Sec:     3806 || Lr: 0.000100
2024-02-08 13:32:41,796 Epoch 188: Total Training Recognition Loss 0.74  Total Training Translation Loss 25.61 
2024-02-08 13:32:41,797 EPOCH 189
2024-02-08 13:32:47,268 [Epoch: 189 Step: 00025100] Batch Recognition Loss:   0.011639 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.098742 => Txt Tokens per Sec:     3874 || Lr: 0.000100
2024-02-08 13:32:49,294 Epoch 189: Total Training Recognition Loss 0.54  Total Training Translation Loss 24.12 
2024-02-08 13:32:49,294 EPOCH 190
2024-02-08 13:32:52,787 [Epoch: 190 Step: 00025200] Batch Recognition Loss:   0.002052 => Gls Tokens per Sec:     1443 || Batch Translation Loss:   0.061181 => Txt Tokens per Sec:     4059 || Lr: 0.000100
2024-02-08 13:32:56,673 Epoch 190: Total Training Recognition Loss 0.55  Total Training Translation Loss 22.22 
2024-02-08 13:32:56,673 EPOCH 191
2024-02-08 13:32:58,281 [Epoch: 191 Step: 00025300] Batch Recognition Loss:   0.001485 => Gls Tokens per Sec:     1493 || Batch Translation Loss:   0.061673 => Txt Tokens per Sec:     4236 || Lr: 0.000100
2024-02-08 13:33:04,096 [Epoch: 191 Step: 00025400] Batch Recognition Loss:   0.000576 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.199808 => Txt Tokens per Sec:     3801 || Lr: 0.000100
2024-02-08 13:33:04,233 Epoch 191: Total Training Recognition Loss 0.38  Total Training Translation Loss 21.90 
2024-02-08 13:33:04,234 EPOCH 192
2024-02-08 13:33:09,757 [Epoch: 192 Step: 00025500] Batch Recognition Loss:   0.002167 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.083159 => Txt Tokens per Sec:     3892 || Lr: 0.000100
2024-02-08 13:33:11,967 Epoch 192: Total Training Recognition Loss 0.41  Total Training Translation Loss 27.31 
2024-02-08 13:33:11,967 EPOCH 193
2024-02-08 13:33:15,258 [Epoch: 193 Step: 00025600] Batch Recognition Loss:   0.000854 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   0.236958 => Txt Tokens per Sec:     4240 || Lr: 0.000100
2024-02-08 13:33:19,133 Epoch 193: Total Training Recognition Loss 0.49  Total Training Translation Loss 25.52 
2024-02-08 13:33:19,133 EPOCH 194
2024-02-08 13:33:21,038 [Epoch: 194 Step: 00025700] Batch Recognition Loss:   0.000261 => Gls Tokens per Sec:     1304 || Batch Translation Loss:   0.083362 => Txt Tokens per Sec:     3552 || Lr: 0.000100
2024-02-08 13:33:26,627 [Epoch: 194 Step: 00025800] Batch Recognition Loss:   0.015759 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.046993 => Txt Tokens per Sec:     3990 || Lr: 0.000100
2024-02-08 13:33:26,719 Epoch 194: Total Training Recognition Loss 0.53  Total Training Translation Loss 26.63 
2024-02-08 13:33:26,720 EPOCH 195
2024-02-08 13:33:32,196 [Epoch: 195 Step: 00025900] Batch Recognition Loss:   0.013362 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.076994 => Txt Tokens per Sec:     3966 || Lr: 0.000100
2024-02-08 13:33:34,188 Epoch 195: Total Training Recognition Loss 0.70  Total Training Translation Loss 20.89 
2024-02-08 13:33:34,188 EPOCH 196
2024-02-08 13:33:38,029 [Epoch: 196 Step: 00026000] Batch Recognition Loss:   0.000608 => Gls Tokens per Sec:     1354 || Batch Translation Loss:   0.313212 => Txt Tokens per Sec:     3859 || Lr: 0.000100
2024-02-08 13:33:48,985 Validation result at epoch 196, step    26000: duration: 10.9546s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.54710	Translation Loss: 94426.23438	PPL: 12472.80469
	Eval Metric: BLEU
	WER 4.24	(DEL: 0.00,	INS: 0.00,	SUB: 4.24)
	BLEU-4 0.49	(BLEU-1: 10.80,	BLEU-2: 3.16,	BLEU-3: 1.12,	BLEU-4: 0.49)
	CHRF 17.00	ROUGE 9.18
2024-02-08 13:33:48,986 Logging Recognition and Translation Outputs
2024-02-08 13:33:48,986 ========================================================================================================================
2024-02-08 13:33:48,986 Logging Sequence: 166_243.00
2024-02-08 13:33:48,986 	Gloss Reference :	A B+C+D+E
2024-02-08 13:33:48,986 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:33:48,987 	Gloss Alignment :	  S      
2024-02-08 13:33:48,987 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:33:48,988 	Text Reference  :	*** ********* *********** ********* *** ***** ** icc     worked with members boards like bcci pcb   cricket australia etc 
2024-02-08 13:33:48,988 	Text Hypothesis :	the broadcast advertisers ticketing etc would be decided by     the  board   of     the  2    teams playing the       test
2024-02-08 13:33:48,988 	Text Alignment  :	I   I         I           I         I   I     I  S       S      S    S       S      S    S    S     S       S         S   
2024-02-08 13:33:48,988 ========================================================================================================================
2024-02-08 13:33:48,989 Logging Sequence: 59_152.00
2024-02-08 13:33:48,989 	Gloss Reference :	A B+C+D+E
2024-02-08 13:33:48,989 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:33:48,989 	Gloss Alignment :	         
2024-02-08 13:33:48,989 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:33:48,990 	Text Reference  :	the organisers encouraged athletes to    use the condoms      in    their home countries
2024-02-08 13:33:48,990 	Text Hypothesis :	in  2010       he         took     place as  the commonwealth games so    keep watching 
2024-02-08 13:33:48,990 	Text Alignment  :	S   S          S          S        S     S       S            S     S     S    S        
2024-02-08 13:33:48,990 ========================================================================================================================
2024-02-08 13:33:48,991 Logging Sequence: 145_52.00
2024-02-08 13:33:48,991 	Gloss Reference :	A B+C+D+E
2024-02-08 13:33:48,991 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:33:48,991 	Gloss Alignment :	         
2024-02-08 13:33:48,991 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:33:48,992 	Text Reference  :	her    name was   dropped despite having qualified as  she was the only female athlete
2024-02-08 13:33:48,992 	Text Hypothesis :	before the  start of      chennai super  kings     csk has won the **** ****** world  
2024-02-08 13:33:48,992 	Text Alignment  :	S      S    S     S       S       S      S         S   S   S       D    D      S      
2024-02-08 13:33:48,993 ========================================================================================================================
2024-02-08 13:33:48,993 Logging Sequence: 172_163.00
2024-02-08 13:33:48,993 	Gloss Reference :	A B+C+D+E
2024-02-08 13:33:48,993 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:33:48,993 	Gloss Alignment :	         
2024-02-08 13:33:48,993 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:33:48,994 	Text Reference  :	** if  the match starts anywhere between 730 pm     to 935 pm a full 20-over match can be played  
2024-02-08 13:33:48,995 	Text Hypothesis :	as per the ***** rules  if       hou     had failed to *** ** * **** ******* ***** *** be refunded
2024-02-08 13:33:48,995 	Text Alignment  :	I  S       D     S      S        S       S   S         D   D  D D    D       D     D      S       
2024-02-08 13:33:48,995 ========================================================================================================================
2024-02-08 13:33:48,995 Logging Sequence: 150_20.00
2024-02-08 13:33:48,995 	Gloss Reference :	A B+C+D+E
2024-02-08 13:33:48,995 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:33:48,995 	Gloss Alignment :	         
2024-02-08 13:33:48,995 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:33:48,996 	Text Reference  :	after   a   tough match india won the saff championship 2023 title  
2024-02-08 13:33:48,996 	Text Hypothesis :	however the one   thing has   won the **** indian       team members
2024-02-08 13:33:48,996 	Text Alignment  :	S       S   S     S     S             D    S            S    S      
2024-02-08 13:33:48,997 ========================================================================================================================
2024-02-08 13:33:52,685 Epoch 196: Total Training Recognition Loss 0.43  Total Training Translation Loss 20.54 
2024-02-08 13:33:52,685 EPOCH 197
2024-02-08 13:33:54,460 [Epoch: 197 Step: 00026100] Batch Recognition Loss:   0.001205 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.215495 => Txt Tokens per Sec:     4089 || Lr: 0.000100
2024-02-08 13:34:00,058 [Epoch: 197 Step: 00026200] Batch Recognition Loss:   0.012492 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.073124 => Txt Tokens per Sec:     3911 || Lr: 0.000100
2024-02-08 13:34:00,123 Epoch 197: Total Training Recognition Loss 0.66  Total Training Translation Loss 31.19 
2024-02-08 13:34:00,123 EPOCH 198
2024-02-08 13:34:05,527 [Epoch: 198 Step: 00026300] Batch Recognition Loss:   0.001148 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   0.168768 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-08 13:34:07,507 Epoch 198: Total Training Recognition Loss 0.81  Total Training Translation Loss 28.14 
2024-02-08 13:34:07,508 EPOCH 199
2024-02-08 13:34:11,214 [Epoch: 199 Step: 00026400] Batch Recognition Loss:   0.000850 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.237897 => Txt Tokens per Sec:     3988 || Lr: 0.000100
2024-02-08 13:34:14,980 Epoch 199: Total Training Recognition Loss 0.53  Total Training Translation Loss 21.80 
2024-02-08 13:34:14,981 EPOCH 200
2024-02-08 13:34:16,646 [Epoch: 200 Step: 00026500] Batch Recognition Loss:   0.002359 => Gls Tokens per Sec:     1586 || Batch Translation Loss:   0.181406 => Txt Tokens per Sec:     4336 || Lr: 0.000100
2024-02-08 13:34:22,340 [Epoch: 200 Step: 00026600] Batch Recognition Loss:   0.002503 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.152549 => Txt Tokens per Sec:     3893 || Lr: 0.000100
2024-02-08 13:34:22,340 Epoch 200: Total Training Recognition Loss 0.48  Total Training Translation Loss 25.58 
2024-02-08 13:34:22,341 EPOCH 201
2024-02-08 13:34:28,140 [Epoch: 201 Step: 00026700] Batch Recognition Loss:   0.020365 => Gls Tokens per Sec:     1380 || Batch Translation Loss:   0.166988 => Txt Tokens per Sec:     3802 || Lr: 0.000100
2024-02-08 13:34:30,085 Epoch 201: Total Training Recognition Loss 0.44  Total Training Translation Loss 29.10 
2024-02-08 13:34:30,085 EPOCH 202
2024-02-08 13:34:33,828 [Epoch: 202 Step: 00026800] Batch Recognition Loss:   0.000616 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.075227 => Txt Tokens per Sec:     3957 || Lr: 0.000100
2024-02-08 13:34:37,415 Epoch 202: Total Training Recognition Loss 0.46  Total Training Translation Loss 18.98 
2024-02-08 13:34:37,415 EPOCH 203
2024-02-08 13:34:39,274 [Epoch: 203 Step: 00026900] Batch Recognition Loss:   0.003031 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.187730 => Txt Tokens per Sec:     3932 || Lr: 0.000100
2024-02-08 13:34:45,178 Epoch 203: Total Training Recognition Loss 0.44  Total Training Translation Loss 17.69 
2024-02-08 13:34:45,178 EPOCH 204
2024-02-08 13:34:45,251 [Epoch: 204 Step: 00027000] Batch Recognition Loss:   0.006356 => Gls Tokens per Sec:     1127 || Batch Translation Loss:   0.134366 => Txt Tokens per Sec:     3817 || Lr: 0.000100
2024-02-08 13:34:50,882 [Epoch: 204 Step: 00027100] Batch Recognition Loss:   0.000614 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.076725 => Txt Tokens per Sec:     3951 || Lr: 0.000100
2024-02-08 13:34:52,714 Epoch 204: Total Training Recognition Loss 0.65  Total Training Translation Loss 22.07 
2024-02-08 13:34:52,715 EPOCH 205
2024-02-08 13:34:56,199 [Epoch: 205 Step: 00027200] Batch Recognition Loss:   0.000376 => Gls Tokens per Sec:     1562 || Batch Translation Loss:   0.114227 => Txt Tokens per Sec:     4256 || Lr: 0.000100
2024-02-08 13:35:00,072 Epoch 205: Total Training Recognition Loss 0.50  Total Training Translation Loss 20.09 
2024-02-08 13:35:00,073 EPOCH 206
2024-02-08 13:35:01,825 [Epoch: 206 Step: 00027300] Batch Recognition Loss:   0.003539 => Gls Tokens per Sec:     1600 || Batch Translation Loss:   0.526535 => Txt Tokens per Sec:     4275 || Lr: 0.000100
2024-02-08 13:35:07,462 Epoch 206: Total Training Recognition Loss 0.33  Total Training Translation Loss 24.92 
2024-02-08 13:35:07,463 EPOCH 207
2024-02-08 13:35:07,570 [Epoch: 207 Step: 00027400] Batch Recognition Loss:   0.013092 => Gls Tokens per Sec:     1495 || Batch Translation Loss:   0.025344 => Txt Tokens per Sec:     2907 || Lr: 0.000100
2024-02-08 13:35:13,040 [Epoch: 207 Step: 00027500] Batch Recognition Loss:   0.021106 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.104591 => Txt Tokens per Sec:     4068 || Lr: 0.000100
2024-02-08 13:35:14,685 Epoch 207: Total Training Recognition Loss 0.58  Total Training Translation Loss 31.65 
2024-02-08 13:35:14,686 EPOCH 208
2024-02-08 13:35:18,309 [Epoch: 208 Step: 00027600] Batch Recognition Loss:   0.001703 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.164730 => Txt Tokens per Sec:     4171 || Lr: 0.000100
2024-02-08 13:35:21,840 Epoch 208: Total Training Recognition Loss 0.55  Total Training Translation Loss 29.87 
2024-02-08 13:35:21,840 EPOCH 209
2024-02-08 13:35:23,797 [Epoch: 209 Step: 00027700] Batch Recognition Loss:   0.000510 => Gls Tokens per Sec:     1473 || Batch Translation Loss:   0.064930 => Txt Tokens per Sec:     4133 || Lr: 0.000100
2024-02-08 13:35:29,235 Epoch 209: Total Training Recognition Loss 0.68  Total Training Translation Loss 29.44 
2024-02-08 13:35:29,235 EPOCH 210
2024-02-08 13:35:29,373 [Epoch: 210 Step: 00027800] Batch Recognition Loss:   0.001885 => Gls Tokens per Sec:     1752 || Batch Translation Loss:   0.100273 => Txt Tokens per Sec:     4314 || Lr: 0.000100
2024-02-08 13:35:34,841 [Epoch: 210 Step: 00027900] Batch Recognition Loss:   0.000230 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.076136 => Txt Tokens per Sec:     4081 || Lr: 0.000100
2024-02-08 13:35:36,528 Epoch 210: Total Training Recognition Loss 0.58  Total Training Translation Loss 22.03 
2024-02-08 13:35:36,528 EPOCH 211
2024-02-08 13:35:40,372 [Epoch: 211 Step: 00028000] Batch Recognition Loss:   0.002268 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.057622 => Txt Tokens per Sec:     3978 || Lr: 0.000100
2024-02-08 13:35:51,333 Validation result at epoch 211, step    28000: duration: 10.9595s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.68292	Translation Loss: 93456.27344	PPL: 11321.12793
	Eval Metric: BLEU
	WER 4.66	(DEL: 0.00,	INS: 0.00,	SUB: 4.66)
	BLEU-4 0.45	(BLEU-1: 10.31,	BLEU-2: 2.94,	BLEU-3: 1.00,	BLEU-4: 0.45)
	CHRF 16.84	ROUGE 9.01
2024-02-08 13:35:51,334 Logging Recognition and Translation Outputs
2024-02-08 13:35:51,334 ========================================================================================================================
2024-02-08 13:35:51,334 Logging Sequence: 156_288.00
2024-02-08 13:35:51,334 	Gloss Reference :	A B+C+D+E
2024-02-08 13:35:51,334 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:35:51,335 	Gloss Alignment :	  S      
2024-02-08 13:35:51,335 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:35:51,336 	Text Reference  :	***** pooran led the team to victory miny became winners of  the     1st season
2024-02-08 13:35:51,336 	Text Hypothesis :	india had    won the **** ** ******* **** ****** toss    and elected to  bat   
2024-02-08 13:35:51,336 	Text Alignment  :	I     S      S       D    D  D       D    D      S       S   S       S   S     
2024-02-08 13:35:51,336 ========================================================================================================================
2024-02-08 13:35:51,336 Logging Sequence: 98_135.00
2024-02-08 13:35:51,336 	Gloss Reference :	A B+C+D+E
2024-02-08 13:35:51,336 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:35:51,337 	Gloss Alignment :	         
2024-02-08 13:35:51,337 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:35:51,337 	Text Reference  :	however due to  the rise in   coronavirus cases the tournament was shifted
2024-02-08 13:35:51,338 	Text Hypothesis :	******* *** and it  was  very proud       for   the ********** *** series 
2024-02-08 13:35:51,338 	Text Alignment  :	D       D   S   S   S    S    S           S         D          D   S      
2024-02-08 13:35:51,338 ========================================================================================================================
2024-02-08 13:35:51,338 Logging Sequence: 161_47.00
2024-02-08 13:35:51,338 	Gloss Reference :	A B+C+D+E
2024-02-08 13:35:51,338 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:35:51,338 	Gloss Alignment :	         
2024-02-08 13:35:51,338 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:35:51,340 	Text Reference  :	** *** he requested confidentiality as     he  was  planning to   make an official announcement
2024-02-08 13:35:51,340 	Text Hypothesis :	it was a  few       minutes         before the game and      then goes on social   media       
2024-02-08 13:35:51,340 	Text Alignment  :	I  I   S  S         S               S      S   S    S        S    S    S  S        S           
2024-02-08 13:35:51,340 ========================================================================================================================
2024-02-08 13:35:51,340 Logging Sequence: 131_159.00
2024-02-08 13:35:51,340 	Gloss Reference :	A B+C+D+E
2024-02-08 13:35:51,340 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:35:51,340 	Gloss Alignment :	  S      
2024-02-08 13:35:51,341 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:35:51,342 	Text Reference  :	chanu also met biren singh following the  meeting singh   described chanu   as our      nation' pride   
2024-02-08 13:35:51,342 	Text Hypothesis :	we    also *** ***** ***** ********* have to      nongpok kakching  village in manipur' imphal  district
2024-02-08 13:35:51,342 	Text Alignment  :	S          D   D     D     D         S    S       S       S         S       S  S        S       S       
2024-02-08 13:35:51,342 ========================================================================================================================
2024-02-08 13:35:51,342 Logging Sequence: 137_167.00
2024-02-08 13:35:51,342 	Gloss Reference :	A B+C+D+E
2024-02-08 13:35:51,342 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:35:51,342 	Gloss Alignment :	         
2024-02-08 13:35:51,343 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:35:51,344 	Text Reference  :	however after 630 pm there will be  certain fan     zones where  beer   will be **** available and  nowhere else
2024-02-08 13:35:51,344 	Text Hypothesis :	******* ***** *** ** 3     if   the indian  skipper rohit sharma yuvraj will be held on        12th january 2022
2024-02-08 13:35:51,344 	Text Alignment  :	D       D     D   D  S     S    S   S       S       S     S      S              I    S         S    S       S   
2024-02-08 13:35:51,345 ========================================================================================================================
2024-02-08 13:35:54,947 Epoch 211: Total Training Recognition Loss 0.64  Total Training Translation Loss 21.25 
2024-02-08 13:35:54,948 EPOCH 212
2024-02-08 13:35:56,953 [Epoch: 212 Step: 00028100] Batch Recognition Loss:   0.000802 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.052111 => Txt Tokens per Sec:     4082 || Lr: 0.000100
2024-02-08 13:36:02,364 Epoch 212: Total Training Recognition Loss 0.53  Total Training Translation Loss 19.10 
2024-02-08 13:36:02,365 EPOCH 213
2024-02-08 13:36:02,587 [Epoch: 213 Step: 00028200] Batch Recognition Loss:   0.002273 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.595716 => Txt Tokens per Sec:     4153 || Lr: 0.000100
2024-02-08 13:36:08,243 [Epoch: 213 Step: 00028300] Batch Recognition Loss:   0.001186 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.095266 => Txt Tokens per Sec:     3914 || Lr: 0.000100
2024-02-08 13:36:09,961 Epoch 213: Total Training Recognition Loss 0.74  Total Training Translation Loss 21.37 
2024-02-08 13:36:09,961 EPOCH 214
2024-02-08 13:36:14,136 [Epoch: 214 Step: 00028400] Batch Recognition Loss:   0.004628 => Gls Tokens per Sec:     1361 || Batch Translation Loss:   0.161001 => Txt Tokens per Sec:     3792 || Lr: 0.000100
2024-02-08 13:36:17,542 Epoch 214: Total Training Recognition Loss 0.71  Total Training Translation Loss 17.33 
2024-02-08 13:36:17,542 EPOCH 215
2024-02-08 13:36:19,395 [Epoch: 215 Step: 00028500] Batch Recognition Loss:   0.003514 => Gls Tokens per Sec:     1641 || Batch Translation Loss:   0.039136 => Txt Tokens per Sec:     4362 || Lr: 0.000100
2024-02-08 13:36:24,649 Epoch 215: Total Training Recognition Loss 0.49  Total Training Translation Loss 15.28 
2024-02-08 13:36:24,649 EPOCH 216
2024-02-08 13:36:24,908 [Epoch: 216 Step: 00028600] Batch Recognition Loss:   0.000598 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.047002 => Txt Tokens per Sec:     4450 || Lr: 0.000100
2024-02-08 13:36:30,849 [Epoch: 216 Step: 00028700] Batch Recognition Loss:   0.001982 => Gls Tokens per Sec:     1346 || Batch Translation Loss:   0.286819 => Txt Tokens per Sec:     3695 || Lr: 0.000100
2024-02-08 13:36:32,504 Epoch 216: Total Training Recognition Loss 0.86  Total Training Translation Loss 25.64 
2024-02-08 13:36:32,505 EPOCH 217
2024-02-08 13:36:36,591 [Epoch: 217 Step: 00028800] Batch Recognition Loss:   0.008845 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.336679 => Txt Tokens per Sec:     3973 || Lr: 0.000100
2024-02-08 13:36:40,062 Epoch 217: Total Training Recognition Loss 0.55  Total Training Translation Loss 32.91 
2024-02-08 13:36:40,062 EPOCH 218
2024-02-08 13:36:42,313 [Epoch: 218 Step: 00028900] Batch Recognition Loss:   0.010336 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.130726 => Txt Tokens per Sec:     3899 || Lr: 0.000100
2024-02-08 13:36:47,396 Epoch 218: Total Training Recognition Loss 0.62  Total Training Translation Loss 28.33 
2024-02-08 13:36:47,397 EPOCH 219
2024-02-08 13:36:47,677 [Epoch: 219 Step: 00029000] Batch Recognition Loss:   0.001940 => Gls Tokens per Sec:     1720 || Batch Translation Loss:   0.836607 => Txt Tokens per Sec:     4724 || Lr: 0.000100
2024-02-08 13:36:53,318 [Epoch: 219 Step: 00029100] Batch Recognition Loss:   0.000434 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.264208 => Txt Tokens per Sec:     3899 || Lr: 0.000100
2024-02-08 13:36:54,870 Epoch 219: Total Training Recognition Loss 0.45  Total Training Translation Loss 20.08 
2024-02-08 13:36:54,870 EPOCH 220
2024-02-08 13:36:58,924 [Epoch: 220 Step: 00029200] Batch Recognition Loss:   0.000544 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.122029 => Txt Tokens per Sec:     3886 || Lr: 0.000100
2024-02-08 13:37:02,281 Epoch 220: Total Training Recognition Loss 0.77  Total Training Translation Loss 15.55 
2024-02-08 13:37:02,281 EPOCH 221
2024-02-08 13:37:04,450 [Epoch: 221 Step: 00029300] Batch Recognition Loss:   0.046856 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.035005 => Txt Tokens per Sec:     4060 || Lr: 0.000100
2024-02-08 13:37:09,823 Epoch 221: Total Training Recognition Loss 0.54  Total Training Translation Loss 15.31 
2024-02-08 13:37:09,823 EPOCH 222
2024-02-08 13:37:10,209 [Epoch: 222 Step: 00029400] Batch Recognition Loss:   0.000142 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.045645 => Txt Tokens per Sec:     3969 || Lr: 0.000100
2024-02-08 13:37:15,891 [Epoch: 222 Step: 00029500] Batch Recognition Loss:   0.000302 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.051471 => Txt Tokens per Sec:     3895 || Lr: 0.000100
2024-02-08 13:37:17,319 Epoch 222: Total Training Recognition Loss 0.49  Total Training Translation Loss 23.32 
2024-02-08 13:37:17,319 EPOCH 223
2024-02-08 13:37:21,203 [Epoch: 223 Step: 00029600] Batch Recognition Loss:   0.002204 => Gls Tokens per Sec:     1525 || Batch Translation Loss:   0.239862 => Txt Tokens per Sec:     4147 || Lr: 0.000100
2024-02-08 13:37:24,411 Epoch 223: Total Training Recognition Loss 0.51  Total Training Translation Loss 19.59 
2024-02-08 13:37:24,412 EPOCH 224
2024-02-08 13:37:26,745 [Epoch: 224 Step: 00029700] Batch Recognition Loss:   0.000844 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.064286 => Txt Tokens per Sec:     3934 || Lr: 0.000100
2024-02-08 13:37:31,555 Epoch 224: Total Training Recognition Loss 0.44  Total Training Translation Loss 19.58 
2024-02-08 13:37:31,556 EPOCH 225
2024-02-08 13:37:31,915 [Epoch: 225 Step: 00029800] Batch Recognition Loss:   0.000481 => Gls Tokens per Sec:     1791 || Batch Translation Loss:   0.109525 => Txt Tokens per Sec:     5191 || Lr: 0.000100
2024-02-08 13:37:37,674 [Epoch: 225 Step: 00029900] Batch Recognition Loss:   0.001487 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.556110 => Txt Tokens per Sec:     3810 || Lr: 0.000100
2024-02-08 13:37:39,016 Epoch 225: Total Training Recognition Loss 0.32  Total Training Translation Loss 19.63 
2024-02-08 13:37:39,016 EPOCH 226
2024-02-08 13:37:42,874 [Epoch: 226 Step: 00030000] Batch Recognition Loss:   0.003173 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   0.061715 => Txt Tokens per Sec:     4345 || Lr: 0.000100
2024-02-08 13:37:54,055 Validation result at epoch 226, step    30000: duration: 11.1812s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 7.65807	Translation Loss: 94322.59375	PPL: 12344.35059
	Eval Metric: BLEU
	WER 4.31	(DEL: 0.00,	INS: 0.00,	SUB: 4.31)
	BLEU-4 0.44	(BLEU-1: 10.22,	BLEU-2: 2.93,	BLEU-3: 0.96,	BLEU-4: 0.44)
	CHRF 17.10	ROUGE 8.66
2024-02-08 13:37:54,056 Logging Recognition and Translation Outputs
2024-02-08 13:37:54,056 ========================================================================================================================
2024-02-08 13:37:54,057 Logging Sequence: 146_102.00
2024-02-08 13:37:54,057 	Gloss Reference :	A B+C+D+E
2024-02-08 13:37:54,057 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:37:54,057 	Gloss Alignment :	         
2024-02-08 13:37:54,057 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:37:54,059 	Text Reference  :	famous indian champion players like kidambi     srikanth and      ashwini ponappa  have tested positive for coronavirus
2024-02-08 13:37:54,059 	Text Hypothesis :	****** ****** rohit    sharma  a    accompanied by       mohammed shami   fielding with a      caption  at  home       
2024-02-08 13:37:54,059 	Text Alignment  :	D      D      S        S       S    S           S        S        S       S        S    S      S        S   S          
2024-02-08 13:37:54,059 ========================================================================================================================
2024-02-08 13:37:54,059 Logging Sequence: 53_178.00
2024-02-08 13:37:54,059 	Gloss Reference :	A B+C+D+E
2024-02-08 13:37:54,059 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:37:54,059 	Gloss Alignment :	         
2024-02-08 13:37:54,060 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:37:54,061 	Text Reference  :	***** the money would help   all  those affected by       the  humanitarian crisis in  afghanistan
2024-02-08 13:37:54,061 	Text Hypothesis :	after the ***** match people will play  against  pakistan such a            huge   fan following  
2024-02-08 13:37:54,061 	Text Alignment  :	I         D     S     S      S    S     S        S        S    S            S      S   S          
2024-02-08 13:37:54,061 ========================================================================================================================
2024-02-08 13:37:54,061 Logging Sequence: 129_200.00
2024-02-08 13:37:54,062 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:37:54,062 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:37:54,062 	Gloss Alignment :	  S        
2024-02-08 13:37:54,062 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:37:54,063 	Text Reference  :	*** ****** the   ioc    would lose  about  4  billion if   the olympics were   to  be       cancelled
2024-02-08 13:37:54,063 	Text Hypothesis :	now fouaad mirza became the   first indian to reach   some of  aerated  drinks and venomous abuses   
2024-02-08 13:37:54,064 	Text Alignment  :	I   I      S     S      S     S     S      S  S       S    S   S        S      S   S        S        
2024-02-08 13:37:54,064 ========================================================================================================================
2024-02-08 13:37:54,064 Logging Sequence: 77_2.00
2024-02-08 13:37:54,064 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:37:54,064 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:37:54,064 	Gloss Alignment :	  S        
2024-02-08 13:37:54,064 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:37:54,066 	Text Reference  :	on    25th april     the           ipl match between    sunrisers hyderabad and   delhi capitals ended in a   tie    
2024-02-08 13:37:54,066 	Text Hypothesis :	india is   currently participating in  the   tournament against   sri       lanka while playing  out   of the taliban
2024-02-08 13:37:54,066 	Text Alignment  :	S     S    S         S             S   S     S          S         S         S     S     S        S     S  S   S      
2024-02-08 13:37:54,066 ========================================================================================================================
2024-02-08 13:37:54,066 Logging Sequence: 119_170.00
2024-02-08 13:37:54,067 	Gloss Reference :	A B+C+D+E
2024-02-08 13:37:54,067 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:37:54,067 	Gloss Alignment :	         
2024-02-08 13:37:54,067 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:37:54,068 	Text Reference  :	they said  it was    a  proud   moment messi is    a   big   hearted man
2024-02-08 13:37:54,068 	Text Hypothesis :	**** about 3  months of winning the    fifa  world cup messi met     ben
2024-02-08 13:37:54,068 	Text Alignment  :	D    S     S  S      S  S       S      S     S     S   S     S       S  
2024-02-08 13:37:54,068 ========================================================================================================================
2024-02-08 13:37:57,485 Epoch 226: Total Training Recognition Loss 0.40  Total Training Translation Loss 16.39 
2024-02-08 13:37:57,485 EPOCH 227
2024-02-08 13:37:59,729 [Epoch: 227 Step: 00030100] Batch Recognition Loss:   0.001246 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.032206 => Txt Tokens per Sec:     4198 || Lr: 0.000050
2024-02-08 13:38:04,370 Epoch 227: Total Training Recognition Loss 0.26  Total Training Translation Loss 8.37 
2024-02-08 13:38:04,370 EPOCH 228
2024-02-08 13:38:04,810 [Epoch: 228 Step: 00030200] Batch Recognition Loss:   0.000255 => Gls Tokens per Sec:     1640 || Batch Translation Loss:   0.030048 => Txt Tokens per Sec:     4522 || Lr: 0.000050
2024-02-08 13:38:10,656 [Epoch: 228 Step: 00030300] Batch Recognition Loss:   0.000549 => Gls Tokens per Sec:     1368 || Batch Translation Loss:   0.017663 => Txt Tokens per Sec:     3770 || Lr: 0.000050
2024-02-08 13:38:12,125 Epoch 228: Total Training Recognition Loss 0.27  Total Training Translation Loss 5.24 
2024-02-08 13:38:12,125 EPOCH 229
2024-02-08 13:38:16,476 [Epoch: 229 Step: 00030400] Batch Recognition Loss:   0.000496 => Gls Tokens per Sec:     1398 || Batch Translation Loss:   0.047325 => Txt Tokens per Sec:     3880 || Lr: 0.000050
2024-02-08 13:38:19,681 Epoch 229: Total Training Recognition Loss 0.35  Total Training Translation Loss 4.20 
2024-02-08 13:38:19,681 EPOCH 230
2024-02-08 13:38:21,996 [Epoch: 230 Step: 00030500] Batch Recognition Loss:   0.009954 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.011675 => Txt Tokens per Sec:     4098 || Lr: 0.000050
2024-02-08 13:38:27,111 Epoch 230: Total Training Recognition Loss 0.21  Total Training Translation Loss 3.95 
2024-02-08 13:38:27,111 EPOCH 231
2024-02-08 13:38:27,640 [Epoch: 231 Step: 00030600] Batch Recognition Loss:   0.000608 => Gls Tokens per Sec:     1517 || Batch Translation Loss:   0.030592 => Txt Tokens per Sec:     4417 || Lr: 0.000050
2024-02-08 13:38:33,098 [Epoch: 231 Step: 00030700] Batch Recognition Loss:   0.000144 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   0.016607 => Txt Tokens per Sec:     4050 || Lr: 0.000050
2024-02-08 13:38:34,362 Epoch 231: Total Training Recognition Loss 0.28  Total Training Translation Loss 4.37 
2024-02-08 13:38:34,362 EPOCH 232
2024-02-08 13:38:38,299 [Epoch: 232 Step: 00030800] Batch Recognition Loss:   0.000214 => Gls Tokens per Sec:     1565 || Batch Translation Loss:   0.026221 => Txt Tokens per Sec:     4402 || Lr: 0.000050
2024-02-08 13:38:40,864 Epoch 232: Total Training Recognition Loss 0.44  Total Training Translation Loss 5.24 
2024-02-08 13:38:40,865 EPOCH 233
2024-02-08 13:38:42,857 [Epoch: 233 Step: 00030900] Batch Recognition Loss:   0.001399 => Gls Tokens per Sec:     1767 || Batch Translation Loss:   0.025199 => Txt Tokens per Sec:     4868 || Lr: 0.000050
2024-02-08 13:38:47,767 Epoch 233: Total Training Recognition Loss 0.28  Total Training Translation Loss 3.96 
2024-02-08 13:38:47,768 EPOCH 234
2024-02-08 13:38:48,336 [Epoch: 234 Step: 00031000] Batch Recognition Loss:   0.007387 => Gls Tokens per Sec:     1552 || Batch Translation Loss:   0.009975 => Txt Tokens per Sec:     4146 || Lr: 0.000050
2024-02-08 13:38:53,727 [Epoch: 234 Step: 00031100] Batch Recognition Loss:   0.000172 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.015027 => Txt Tokens per Sec:     4110 || Lr: 0.000050
2024-02-08 13:38:55,136 Epoch 234: Total Training Recognition Loss 0.22  Total Training Translation Loss 5.27 
2024-02-08 13:38:55,137 EPOCH 235
2024-02-08 13:38:59,791 [Epoch: 235 Step: 00031200] Batch Recognition Loss:   0.003804 => Gls Tokens per Sec:     1341 || Batch Translation Loss:   0.013166 => Txt Tokens per Sec:     3801 || Lr: 0.000050
2024-02-08 13:39:02,759 Epoch 235: Total Training Recognition Loss 0.18  Total Training Translation Loss 4.51 
2024-02-08 13:39:02,759 EPOCH 236
2024-02-08 13:39:04,983 [Epoch: 236 Step: 00031300] Batch Recognition Loss:   0.000687 => Gls Tokens per Sec:     1619 || Batch Translation Loss:   0.019849 => Txt Tokens per Sec:     4662 || Lr: 0.000050
2024-02-08 13:39:09,110 Epoch 236: Total Training Recognition Loss 0.15  Total Training Translation Loss 6.59 
2024-02-08 13:39:09,111 EPOCH 237
2024-02-08 13:39:09,657 [Epoch: 237 Step: 00031400] Batch Recognition Loss:   0.006976 => Gls Tokens per Sec:     1759 || Batch Translation Loss:   0.006448 => Txt Tokens per Sec:     4805 || Lr: 0.000050
2024-02-08 13:39:15,312 [Epoch: 237 Step: 00031500] Batch Recognition Loss:   0.000372 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.038629 => Txt Tokens per Sec:     3894 || Lr: 0.000050
2024-02-08 13:39:16,623 Epoch 237: Total Training Recognition Loss 0.25  Total Training Translation Loss 9.99 
2024-02-08 13:39:16,623 EPOCH 238
2024-02-08 13:39:20,621 [Epoch: 238 Step: 00031600] Batch Recognition Loss:   0.000350 => Gls Tokens per Sec:     1581 || Batch Translation Loss:   0.104881 => Txt Tokens per Sec:     4350 || Lr: 0.000050
2024-02-08 13:39:23,759 Epoch 238: Total Training Recognition Loss 0.30  Total Training Translation Loss 10.26 
2024-02-08 13:39:23,760 EPOCH 239
2024-02-08 13:39:26,199 [Epoch: 239 Step: 00031700] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.029104 => Txt Tokens per Sec:     4174 || Lr: 0.000050
2024-02-08 13:39:30,783 Epoch 239: Total Training Recognition Loss 0.36  Total Training Translation Loss 7.11 
2024-02-08 13:39:30,783 EPOCH 240
2024-02-08 13:39:31,605 [Epoch: 240 Step: 00031800] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1269 || Batch Translation Loss:   0.022870 => Txt Tokens per Sec:     3386 || Lr: 0.000050
2024-02-08 13:39:37,251 [Epoch: 240 Step: 00031900] Batch Recognition Loss:   0.002667 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.227411 => Txt Tokens per Sec:     3919 || Lr: 0.000050
2024-02-08 13:39:38,259 Epoch 240: Total Training Recognition Loss 0.22  Total Training Translation Loss 9.52 
2024-02-08 13:39:38,259 EPOCH 241
2024-02-08 13:39:42,265 [Epoch: 241 Step: 00032000] Batch Recognition Loss:   0.006518 => Gls Tokens per Sec:     1598 || Batch Translation Loss:   0.016053 => Txt Tokens per Sec:     4340 || Lr: 0.000050
2024-02-08 13:39:53,128 Validation result at epoch 241, step    32000: duration: 10.8631s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.60586	Translation Loss: 94054.10156	PPL: 12017.70703
	Eval Metric: BLEU
	WER 4.24	(DEL: 0.00,	INS: 0.00,	SUB: 4.24)
	BLEU-4 0.52	(BLEU-1: 11.41,	BLEU-2: 3.52,	BLEU-3: 1.20,	BLEU-4: 0.52)
	CHRF 17.06	ROUGE 9.41
2024-02-08 13:39:53,129 Logging Recognition and Translation Outputs
2024-02-08 13:39:53,129 ========================================================================================================================
2024-02-08 13:39:53,129 Logging Sequence: 162_133.00
2024-02-08 13:39:53,130 	Gloss Reference :	A B+C+D+E
2024-02-08 13:39:53,130 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:39:53,130 	Gloss Alignment :	         
2024-02-08 13:39:53,130 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:39:53,131 	Text Reference  :	they also sent rape threats to       his    9-month old daughter
2024-02-08 13:39:53,131 	Text Hypothesis :	**** pm   modi and  pm      albanese handed over    the team    
2024-02-08 13:39:53,131 	Text Alignment  :	D    S    S    S    S       S        S      S       S   S       
2024-02-08 13:39:53,131 ========================================================================================================================
2024-02-08 13:39:53,131 Logging Sequence: 134_236.00
2024-02-08 13:39:53,131 	Gloss Reference :	A B+C+D+E
2024-02-08 13:39:53,131 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:39:53,132 	Gloss Alignment :	         
2024-02-08 13:39:53,132 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:39:53,133 	Text Reference  :	** **** after the     interaction modi tweeted the   images  and   captioned it saying
2024-02-08 13:39:53,133 	Text Hypothesis :	pm modi even  chatted with        5    time    medal winning women will      be hanged
2024-02-08 13:39:53,133 	Text Alignment  :	I  I    S     S       S           S    S       S     S       S     S         S  S     
2024-02-08 13:39:53,133 ========================================================================================================================
2024-02-08 13:39:53,133 Logging Sequence: 145_52.00
2024-02-08 13:39:53,133 	Gloss Reference :	A B+C+D+E
2024-02-08 13:39:53,133 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:39:53,134 	Gloss Alignment :	         
2024-02-08 13:39:53,134 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:39:53,135 	Text Reference  :	her       name was  dropped despite having qualified as  she   was the only female athlete  
2024-02-08 13:39:53,135 	Text Hypothesis :	yesterday on   23rd may     2023    in     the       ipl there was a   huge fan    following
2024-02-08 13:39:53,135 	Text Alignment  :	S         S    S    S       S       S      S         S   S         S   S    S      S        
2024-02-08 13:39:53,135 ========================================================================================================================
2024-02-08 13:39:53,135 Logging Sequence: 175_40.00
2024-02-08 13:39:53,136 	Gloss Reference :	A B+C+D+E
2024-02-08 13:39:53,136 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:39:53,136 	Gloss Alignment :	         
2024-02-08 13:39:53,136 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:39:53,137 	Text Reference  :	***** *** *** **** * soumyadeep and   shreya bagged three   medals each    including a  silver medal each 
2024-02-08 13:39:53,138 	Text Hypothesis :	india did not have a t20        world cup    match  between 1st    october 2023      in the    same  place
2024-02-08 13:39:53,138 	Text Alignment  :	I     I   I   I    I S          S     S      S      S       S      S       S         S  S      S     S    
2024-02-08 13:39:53,138 ========================================================================================================================
2024-02-08 13:39:53,138 Logging Sequence: 156_51.00
2024-02-08 13:39:53,138 	Gloss Reference :	A B+C+D+E
2024-02-08 13:39:53,138 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:39:53,138 	Gloss Alignment :	         
2024-02-08 13:39:53,138 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:39:53,139 	Text Reference  :	the selection of  the players was similar to    that of   ipl 
2024-02-08 13:39:53,139 	Text Hypothesis :	*** in        ipl we  have    kkr and     video was  very soon
2024-02-08 13:39:53,139 	Text Alignment  :	D   S         S   S   S       S   S       S     S    S    S   
2024-02-08 13:39:53,140 ========================================================================================================================
2024-02-08 13:39:56,182 Epoch 241: Total Training Recognition Loss 0.29  Total Training Translation Loss 8.00 
2024-02-08 13:39:56,182 EPOCH 242
2024-02-08 13:39:58,786 [Epoch: 242 Step: 00032100] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.020874 => Txt Tokens per Sec:     4123 || Lr: 0.000050
2024-02-08 13:40:03,616 Epoch 242: Total Training Recognition Loss 0.22  Total Training Translation Loss 7.04 
2024-02-08 13:40:03,616 EPOCH 243
2024-02-08 13:40:04,331 [Epoch: 243 Step: 00032200] Batch Recognition Loss:   0.000309 => Gls Tokens per Sec:     1569 || Batch Translation Loss:   0.015928 => Txt Tokens per Sec:     4364 || Lr: 0.000050
2024-02-08 13:40:10,151 [Epoch: 243 Step: 00032300] Batch Recognition Loss:   0.000446 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.045436 => Txt Tokens per Sec:     3836 || Lr: 0.000050
2024-02-08 13:40:11,164 Epoch 243: Total Training Recognition Loss 0.24  Total Training Translation Loss 7.44 
2024-02-08 13:40:11,164 EPOCH 244
2024-02-08 13:40:15,409 [Epoch: 244 Step: 00032400] Batch Recognition Loss:   0.000284 => Gls Tokens per Sec:     1527 || Batch Translation Loss:   0.037663 => Txt Tokens per Sec:     4157 || Lr: 0.000050
2024-02-08 13:40:18,330 Epoch 244: Total Training Recognition Loss 0.18  Total Training Translation Loss 7.54 
2024-02-08 13:40:18,330 EPOCH 245
2024-02-08 13:40:20,963 [Epoch: 245 Step: 00032500] Batch Recognition Loss:   0.000248 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.027276 => Txt Tokens per Sec:     3970 || Lr: 0.000050
2024-02-08 13:40:25,460 Epoch 245: Total Training Recognition Loss 0.15  Total Training Translation Loss 6.02 
2024-02-08 13:40:25,460 EPOCH 246
2024-02-08 13:40:26,244 [Epoch: 246 Step: 00032600] Batch Recognition Loss:   0.002604 => Gls Tokens per Sec:     1534 || Batch Translation Loss:   0.021141 => Txt Tokens per Sec:     4171 || Lr: 0.000050
2024-02-08 13:40:31,375 [Epoch: 246 Step: 00032700] Batch Recognition Loss:   0.000224 => Gls Tokens per Sec:     1559 || Batch Translation Loss:   0.024256 => Txt Tokens per Sec:     4336 || Lr: 0.000050
2024-02-08 13:40:32,387 Epoch 246: Total Training Recognition Loss 0.19  Total Training Translation Loss 5.66 
2024-02-08 13:40:32,387 EPOCH 247
2024-02-08 13:40:36,872 [Epoch: 247 Step: 00032800] Batch Recognition Loss:   0.000287 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.009770 => Txt Tokens per Sec:     4087 || Lr: 0.000050
2024-02-08 13:40:39,407 Epoch 247: Total Training Recognition Loss 0.29  Total Training Translation Loss 6.37 
2024-02-08 13:40:39,407 EPOCH 248
2024-02-08 13:40:42,293 [Epoch: 248 Step: 00032900] Batch Recognition Loss:   0.002946 => Gls Tokens per Sec:     1358 || Batch Translation Loss:   0.037818 => Txt Tokens per Sec:     3777 || Lr: 0.000050
2024-02-08 13:40:46,760 Epoch 248: Total Training Recognition Loss 0.15  Total Training Translation Loss 6.92 
2024-02-08 13:40:46,760 EPOCH 249
2024-02-08 13:40:47,446 [Epoch: 249 Step: 00033000] Batch Recognition Loss:   0.016952 => Gls Tokens per Sec:     1870 || Batch Translation Loss:   0.009319 => Txt Tokens per Sec:     4824 || Lr: 0.000050
2024-02-08 13:40:52,899 [Epoch: 249 Step: 00033100] Batch Recognition Loss:   0.000146 => Gls Tokens per Sec:     1464 || Batch Translation Loss:   0.020259 => Txt Tokens per Sec:     4097 || Lr: 0.000050
2024-02-08 13:40:53,835 Epoch 249: Total Training Recognition Loss 0.16  Total Training Translation Loss 7.38 
2024-02-08 13:40:53,835 EPOCH 250
2024-02-08 13:40:58,089 [Epoch: 250 Step: 00033200] Batch Recognition Loss:   0.000242 => Gls Tokens per Sec:     1561 || Batch Translation Loss:   0.035488 => Txt Tokens per Sec:     4372 || Lr: 0.000050
2024-02-08 13:41:00,876 Epoch 250: Total Training Recognition Loss 0.21  Total Training Translation Loss 7.92 
2024-02-08 13:41:00,876 EPOCH 251
2024-02-08 13:41:03,551 [Epoch: 251 Step: 00033300] Batch Recognition Loss:   0.000276 => Gls Tokens per Sec:     1496 || Batch Translation Loss:   0.023317 => Txt Tokens per Sec:     3946 || Lr: 0.000050
2024-02-08 13:41:08,136 Epoch 251: Total Training Recognition Loss 0.24  Total Training Translation Loss 6.14 
2024-02-08 13:41:08,136 EPOCH 252
2024-02-08 13:41:08,933 [Epoch: 252 Step: 00033400] Batch Recognition Loss:   0.000486 => Gls Tokens per Sec:     1708 || Batch Translation Loss:   0.026519 => Txt Tokens per Sec:     4534 || Lr: 0.000050
2024-02-08 13:41:14,432 [Epoch: 252 Step: 00033500] Batch Recognition Loss:   0.000522 => Gls Tokens per Sec:     1451 || Batch Translation Loss:   0.023900 => Txt Tokens per Sec:     4039 || Lr: 0.000050
2024-02-08 13:41:15,352 Epoch 252: Total Training Recognition Loss 0.09  Total Training Translation Loss 5.56 
2024-02-08 13:41:15,352 EPOCH 253
2024-02-08 13:41:19,583 [Epoch: 253 Step: 00033600] Batch Recognition Loss:   0.003410 => Gls Tokens per Sec:     1589 || Batch Translation Loss:   0.026217 => Txt Tokens per Sec:     4361 || Lr: 0.000050
2024-02-08 13:41:22,153 Epoch 253: Total Training Recognition Loss 0.12  Total Training Translation Loss 6.10 
2024-02-08 13:41:22,153 EPOCH 254
2024-02-08 13:41:24,958 [Epoch: 254 Step: 00033700] Batch Recognition Loss:   0.000380 => Gls Tokens per Sec:     1456 || Batch Translation Loss:   0.014126 => Txt Tokens per Sec:     4091 || Lr: 0.000050
2024-02-08 13:41:29,348 Epoch 254: Total Training Recognition Loss 0.26  Total Training Translation Loss 4.63 
2024-02-08 13:41:29,349 EPOCH 255
2024-02-08 13:41:30,301 [Epoch: 255 Step: 00033800] Batch Recognition Loss:   0.000403 => Gls Tokens per Sec:     1515 || Batch Translation Loss:   0.010380 => Txt Tokens per Sec:     4248 || Lr: 0.000050
2024-02-08 13:41:35,688 [Epoch: 255 Step: 00033900] Batch Recognition Loss:   0.000319 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.012989 => Txt Tokens per Sec:     4112 || Lr: 0.000050
2024-02-08 13:41:36,471 Epoch 255: Total Training Recognition Loss 0.23  Total Training Translation Loss 4.70 
2024-02-08 13:41:36,471 EPOCH 256
2024-02-08 13:41:40,599 [Epoch: 256 Step: 00034000] Batch Recognition Loss:   0.001660 => Gls Tokens per Sec:     1648 || Batch Translation Loss:   0.013072 => Txt Tokens per Sec:     4483 || Lr: 0.000050
2024-02-08 13:41:51,519 Validation result at epoch 256, step    34000: duration: 10.9199s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.76804	Translation Loss: 92661.48438	PPL: 10457.15918
	Eval Metric: BLEU
	WER 4.10	(DEL: 0.00,	INS: 0.00,	SUB: 4.10)
	BLEU-4 0.00	(BLEU-1: 10.38,	BLEU-2: 3.09,	BLEU-3: 1.03,	BLEU-4: 0.00)
	CHRF 16.80	ROUGE 8.80
2024-02-08 13:41:51,520 Logging Recognition and Translation Outputs
2024-02-08 13:41:51,520 ========================================================================================================================
2024-02-08 13:41:51,521 Logging Sequence: 171_158.00
2024-02-08 13:41:51,521 	Gloss Reference :	A B+C+D+E
2024-02-08 13:41:51,521 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:41:51,521 	Gloss Alignment :	         
2024-02-08 13:41:51,521 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:41:51,522 	Text Reference  :	with speculations of dhoni being banned are spreading many say     that it    is  unlikely to    happen   
2024-02-08 13:41:51,522 	Text Hypothesis :	**** ************ ** ***** ***** ****** *** ********* **** however the  venue saw heavy    rains yesterday
2024-02-08 13:41:51,522 	Text Alignment  :	D    D            D  D     D     D      D   D         D    S       S    S     S   S        S     S        
2024-02-08 13:41:51,522 ========================================================================================================================
2024-02-08 13:41:51,522 Logging Sequence: 108_235.00
2024-02-08 13:41:51,523 	Gloss Reference :	A B+C+D+E
2024-02-08 13:41:51,523 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:41:51,523 	Gloss Alignment :	         
2024-02-08 13:41:51,523 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:41:51,525 	Text Reference  :	****** he   was  taken to   the ****** ********* **** hospital and it was reported that he is not   in any     danger
2024-02-08 13:41:51,525 	Text Hypothesis :	people were very happy that the player practices very hard     and it was ******** **** ** ** proud of india's win   
2024-02-08 13:41:51,525 	Text Alignment  :	I      S    S    S     S        I      I         I    S                   D        D    D  D  S     S  S       S     
2024-02-08 13:41:51,525 ========================================================================================================================
2024-02-08 13:41:51,525 Logging Sequence: 153_206.00
2024-02-08 13:41:51,526 	Gloss Reference :	A B+C+D+E
2024-02-08 13:41:51,526 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:41:51,526 	Gloss Alignment :	         
2024-02-08 13:41:51,526 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:41:51,527 	Text Reference  :	*** **** ***** *** **** now on  13th november  everyone is    hoping pakistan rewrites history
2024-02-08 13:41:51,527 	Text Hypothesis :	the 2022 final was held in  the same melbourne stadium  where the    1992     world    cup    
2024-02-08 13:41:51,527 	Text Alignment  :	I   I    I     I   I    S   S   S    S         S        S     S      S        S        S      
2024-02-08 13:41:51,527 ========================================================================================================================
2024-02-08 13:41:51,528 Logging Sequence: 87_202.00
2024-02-08 13:41:51,528 	Gloss Reference :	A B+C+D+E
2024-02-08 13:41:51,528 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:41:51,528 	Gloss Alignment :	         
2024-02-08 13:41:51,528 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:41:51,529 	Text Reference  :	*** **** ******** ** *** ** *** ** i  love  our          players and i         love my     country
2024-02-08 13:41:51,529 	Text Hypothesis :	the vast majority of the of the 56 of india participated in      the followers on   social media  
2024-02-08 13:41:51,529 	Text Alignment  :	I   I    I        I  I   I  I   I  S  S     S            S       S   S         S    S      S      
2024-02-08 13:41:51,530 ========================================================================================================================
2024-02-08 13:41:51,530 Logging Sequence: 84_2.00
2024-02-08 13:41:51,530 	Gloss Reference :	A B+C+D+E
2024-02-08 13:41:51,530 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:41:51,530 	Gloss Alignment :	         
2024-02-08 13:41:51,530 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:41:51,532 	Text Reference  :	the 2022 fifa football world  cup     is going on   in   qatar from 20th november 2022 to **** 18th december 2022   
2024-02-08 13:41:51,532 	Text Hypothesis :	*** **** bcci chief    sourav ganguly on 28th  june said that  she  does not      want to wait for  the      auction
2024-02-08 13:41:51,533 	Text Alignment  :	D   D    S    S        S      S       S  S     S    S    S     S    S    S        S       I    S    S        S      
2024-02-08 13:41:51,533 ========================================================================================================================
2024-02-08 13:41:54,512 Epoch 256: Total Training Recognition Loss 0.23  Total Training Translation Loss 4.29 
2024-02-08 13:41:54,513 EPOCH 257
2024-02-08 13:41:57,302 [Epoch: 257 Step: 00034100] Batch Recognition Loss:   0.000677 => Gls Tokens per Sec:     1492 || Batch Translation Loss:   0.018601 => Txt Tokens per Sec:     4035 || Lr: 0.000050
2024-02-08 13:42:01,629 Epoch 257: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.08 
2024-02-08 13:42:01,629 EPOCH 258
2024-02-08 13:42:02,716 [Epoch: 258 Step: 00034200] Batch Recognition Loss:   0.000081 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.010611 => Txt Tokens per Sec:     3657 || Lr: 0.000050
2024-02-08 13:42:08,395 [Epoch: 258 Step: 00034300] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.021191 => Txt Tokens per Sec:     3924 || Lr: 0.000050
2024-02-08 13:42:09,150 Epoch 258: Total Training Recognition Loss 0.10  Total Training Translation Loss 5.12 
2024-02-08 13:42:09,150 EPOCH 259
2024-02-08 13:42:13,769 [Epoch: 259 Step: 00034400] Batch Recognition Loss:   0.000257 => Gls Tokens per Sec:     1490 || Batch Translation Loss:   0.032958 => Txt Tokens per Sec:     4154 || Lr: 0.000050
2024-02-08 13:42:16,359 Epoch 259: Total Training Recognition Loss 0.17  Total Training Translation Loss 6.68 
2024-02-08 13:42:16,359 EPOCH 260
2024-02-08 13:42:18,996 [Epoch: 260 Step: 00034500] Batch Recognition Loss:   0.000483 => Gls Tokens per Sec:     1608 || Batch Translation Loss:   0.047460 => Txt Tokens per Sec:     4502 || Lr: 0.000050
2024-02-08 13:42:23,355 Epoch 260: Total Training Recognition Loss 0.22  Total Training Translation Loss 13.39 
2024-02-08 13:42:23,355 EPOCH 261
2024-02-08 13:42:24,440 [Epoch: 261 Step: 00034600] Batch Recognition Loss:   0.000547 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.032071 => Txt Tokens per Sec:     3873 || Lr: 0.000050
2024-02-08 13:42:29,746 [Epoch: 261 Step: 00034700] Batch Recognition Loss:   0.000177 => Gls Tokens per Sec:     1508 || Batch Translation Loss:   0.015986 => Txt Tokens per Sec:     4194 || Lr: 0.000050
2024-02-08 13:42:30,411 Epoch 261: Total Training Recognition Loss 0.22  Total Training Translation Loss 7.37 
2024-02-08 13:42:30,411 EPOCH 262
2024-02-08 13:42:35,230 [Epoch: 262 Step: 00034800] Batch Recognition Loss:   0.001167 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.012936 => Txt Tokens per Sec:     3984 || Lr: 0.000050
2024-02-08 13:42:37,932 Epoch 262: Total Training Recognition Loss 0.18  Total Training Translation Loss 7.68 
2024-02-08 13:42:37,933 EPOCH 263
2024-02-08 13:42:40,846 [Epoch: 263 Step: 00034900] Batch Recognition Loss:   0.000531 => Gls Tokens per Sec:     1483 || Batch Translation Loss:   0.035052 => Txt Tokens per Sec:     4243 || Lr: 0.000050
2024-02-08 13:42:44,893 Epoch 263: Total Training Recognition Loss 0.32  Total Training Translation Loss 5.77 
2024-02-08 13:42:44,894 EPOCH 264
2024-02-08 13:42:46,067 [Epoch: 264 Step: 00035000] Batch Recognition Loss:   0.000545 => Gls Tokens per Sec:     1434 || Batch Translation Loss:   0.017745 => Txt Tokens per Sec:     3897 || Lr: 0.000050
2024-02-08 13:42:51,570 [Epoch: 264 Step: 00035100] Batch Recognition Loss:   0.014337 => Gls Tokens per Sec:     1450 || Batch Translation Loss:   0.019212 => Txt Tokens per Sec:     4024 || Lr: 0.000050
2024-02-08 13:42:52,264 Epoch 264: Total Training Recognition Loss 0.52  Total Training Translation Loss 5.53 
2024-02-08 13:42:52,265 EPOCH 265
2024-02-08 13:42:57,165 [Epoch: 265 Step: 00035200] Batch Recognition Loss:   0.000442 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.020567 => Txt Tokens per Sec:     4000 || Lr: 0.000050
2024-02-08 13:42:59,759 Epoch 265: Total Training Recognition Loss 0.46  Total Training Translation Loss 5.27 
2024-02-08 13:42:59,759 EPOCH 266
2024-02-08 13:43:02,610 [Epoch: 266 Step: 00035300] Batch Recognition Loss:   0.000248 => Gls Tokens per Sec:     1544 || Batch Translation Loss:   0.013766 => Txt Tokens per Sec:     4329 || Lr: 0.000050
2024-02-08 13:43:07,042 Epoch 266: Total Training Recognition Loss 0.19  Total Training Translation Loss 6.17 
2024-02-08 13:43:07,043 EPOCH 267
2024-02-08 13:43:08,267 [Epoch: 267 Step: 00035400] Batch Recognition Loss:   0.000410 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.029024 => Txt Tokens per Sec:     4279 || Lr: 0.000050
2024-02-08 13:43:13,257 [Epoch: 267 Step: 00035500] Batch Recognition Loss:   0.002102 => Gls Tokens per Sec:     1600 || Batch Translation Loss:   0.838122 => Txt Tokens per Sec:     4309 || Lr: 0.000050
2024-02-08 13:43:13,941 Epoch 267: Total Training Recognition Loss 0.20  Total Training Translation Loss 7.10 
2024-02-08 13:43:13,942 EPOCH 268
2024-02-08 13:43:18,932 [Epoch: 268 Step: 00035600] Batch Recognition Loss:   0.000216 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.023400 => Txt Tokens per Sec:     3992 || Lr: 0.000050
2024-02-08 13:43:21,345 Epoch 268: Total Training Recognition Loss 0.18  Total Training Translation Loss 5.12 
2024-02-08 13:43:21,345 EPOCH 269
2024-02-08 13:43:24,391 [Epoch: 269 Step: 00035700] Batch Recognition Loss:   0.000189 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.017386 => Txt Tokens per Sec:     4052 || Lr: 0.000050
2024-02-08 13:43:28,766 Epoch 269: Total Training Recognition Loss 0.15  Total Training Translation Loss 3.75 
2024-02-08 13:43:28,766 EPOCH 270
2024-02-08 13:43:29,964 [Epoch: 270 Step: 00035800] Batch Recognition Loss:   0.000285 => Gls Tokens per Sec:     1537 || Batch Translation Loss:   0.021357 => Txt Tokens per Sec:     4431 || Lr: 0.000050
2024-02-08 13:43:35,657 [Epoch: 270 Step: 00035900] Batch Recognition Loss:   0.001125 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.041138 => Txt Tokens per Sec:     3857 || Lr: 0.000050
2024-02-08 13:43:36,164 Epoch 270: Total Training Recognition Loss 0.13  Total Training Translation Loss 5.26 
2024-02-08 13:43:36,164 EPOCH 271
2024-02-08 13:43:40,998 [Epoch: 271 Step: 00036000] Batch Recognition Loss:   0.000252 => Gls Tokens per Sec:     1490 || Batch Translation Loss:   0.015534 => Txt Tokens per Sec:     4150 || Lr: 0.000050
2024-02-08 13:43:52,063 Validation result at epoch 271, step    36000: duration: 11.0650s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.21384	Translation Loss: 92594.63281	PPL: 10387.57324
	Eval Metric: BLEU
	WER 3.95	(DEL: 0.00,	INS: 0.00,	SUB: 3.95)
	BLEU-4 0.36	(BLEU-1: 10.56,	BLEU-2: 3.04,	BLEU-3: 1.06,	BLEU-4: 0.36)
	CHRF 16.62	ROUGE 9.11
2024-02-08 13:43:52,064 Logging Recognition and Translation Outputs
2024-02-08 13:43:52,064 ========================================================================================================================
2024-02-08 13:43:52,064 Logging Sequence: 153_36.00
2024-02-08 13:43:52,065 	Gloss Reference :	A B+C+D+E
2024-02-08 13:43:52,065 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:43:52,065 	Gloss Alignment :	         
2024-02-08 13:43:52,065 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:43:52,066 	Text Reference  :	india made a    good  score   of    1686 in       20    overs 
2024-02-08 13:43:52,066 	Text Hypothesis :	in    the  same match between india and  pakistan south africa
2024-02-08 13:43:52,066 	Text Alignment  :	S     S    S    S     S       S     S    S        S     S     
2024-02-08 13:43:52,066 ========================================================================================================================
2024-02-08 13:43:52,066 Logging Sequence: 163_30.00
2024-02-08 13:43:52,066 	Gloss Reference :	A B+C+D+E
2024-02-08 13:43:52,067 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:43:52,067 	Gloss Alignment :	         
2024-02-08 13:43:52,067 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:43:52,068 	Text Reference  :	*** *** ********** ******* ***** ***** they never permitted    anyone to reveal her  face   
2024-02-08 13:43:52,068 	Text Hypothesis :	for the post-match meeting virat kohli made an    announcement and    it was    very private
2024-02-08 13:43:52,068 	Text Alignment  :	I   I   I          I       I     I     S    S     S            S      S  S      S    S      
2024-02-08 13:43:52,068 ========================================================================================================================
2024-02-08 13:43:52,068 Logging Sequence: 167_60.00
2024-02-08 13:43:52,068 	Gloss Reference :	A B+C+D+E
2024-02-08 13:43:52,068 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:43:52,069 	Gloss Alignment :	         
2024-02-08 13:43:52,069 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:43:52,070 	Text Reference  :	camel  flu spreads   rapidly when one comes in  close contact with the  infected  
2024-02-08 13:43:52,070 	Text Hypothesis :	people are desparate to      see  the child but the   couple  are  very protective
2024-02-08 13:43:52,070 	Text Alignment  :	S      S   S         S       S    S   S     S   S     S       S    S    S         
2024-02-08 13:43:52,070 ========================================================================================================================
2024-02-08 13:43:52,070 Logging Sequence: 84_35.00
2024-02-08 13:43:52,070 	Gloss Reference :	A B+C+D+E
2024-02-08 13:43:52,071 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:43:52,071 	Gloss Alignment :	         
2024-02-08 13:43:52,071 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:43:52,071 	Text Reference  :	here is the reason why they covered their mouth
2024-02-08 13:43:52,071 	Text Hypothesis :	**** ** *** ****** *** let  me      tell  you  
2024-02-08 13:43:52,071 	Text Alignment  :	D    D  D   D      D   S    S       S     S    
2024-02-08 13:43:52,071 ========================================================================================================================
2024-02-08 13:43:52,072 Logging Sequence: 96_2.00
2024-02-08 13:43:52,072 	Gloss Reference :	A B+C+D+E    
2024-02-08 13:43:52,072 	Gloss Hypothesis:	A B+C+D+E+D+E
2024-02-08 13:43:52,072 	Gloss Alignment :	  S          
2024-02-08 13:43:52,072 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:43:52,074 	Text Reference  :	the world is preparing for the      t20     world cup scheduled to  start from 16th october **** this year     
2024-02-08 13:43:52,074 	Text Hypothesis :	the ***** ** ********* icc under-19 cricket world cup ********* was held  on   23rd october 2022 in   bengaluru
2024-02-08 13:43:52,074 	Text Alignment  :	    D     D  D         S   S        S                 D         S   S     S    S            I    S    S        
2024-02-08 13:43:52,074 ========================================================================================================================
2024-02-08 13:43:54,498 Epoch 271: Total Training Recognition Loss 0.15  Total Training Translation Loss 8.37 
2024-02-08 13:43:54,499 EPOCH 272
2024-02-08 13:43:57,425 [Epoch: 272 Step: 00036100] Batch Recognition Loss:   0.000612 => Gls Tokens per Sec:     1559 || Batch Translation Loss:   0.032493 => Txt Tokens per Sec:     4204 || Lr: 0.000050
2024-02-08 13:44:01,882 Epoch 272: Total Training Recognition Loss 0.21  Total Training Translation Loss 11.05 
2024-02-08 13:44:01,883 EPOCH 273
2024-02-08 13:44:03,229 [Epoch: 273 Step: 00036200] Batch Recognition Loss:   0.000832 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.022883 => Txt Tokens per Sec:     3688 || Lr: 0.000050
2024-02-08 13:44:08,689 [Epoch: 273 Step: 00036300] Batch Recognition Loss:   0.000813 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.030343 => Txt Tokens per Sec:     4084 || Lr: 0.000050
2024-02-08 13:44:09,281 Epoch 273: Total Training Recognition Loss 0.19  Total Training Translation Loss 9.35 
2024-02-08 13:44:09,282 EPOCH 274
2024-02-08 13:44:14,578 [Epoch: 274 Step: 00036400] Batch Recognition Loss:   0.000243 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.018400 => Txt Tokens per Sec:     3822 || Lr: 0.000050
2024-02-08 13:44:16,847 Epoch 274: Total Training Recognition Loss 0.16  Total Training Translation Loss 7.69 
2024-02-08 13:44:16,848 EPOCH 275
2024-02-08 13:44:20,168 [Epoch: 275 Step: 00036500] Batch Recognition Loss:   0.000376 => Gls Tokens per Sec:     1398 || Batch Translation Loss:   0.019086 => Txt Tokens per Sec:     3933 || Lr: 0.000050
2024-02-08 13:44:23,799 Epoch 275: Total Training Recognition Loss 0.16  Total Training Translation Loss 4.35 
2024-02-08 13:44:23,799 EPOCH 276
2024-02-08 13:44:25,236 [Epoch: 276 Step: 00036600] Batch Recognition Loss:   0.000155 => Gls Tokens per Sec:     1394 || Batch Translation Loss:   0.024533 => Txt Tokens per Sec:     3800 || Lr: 0.000050
2024-02-08 13:44:30,660 [Epoch: 276 Step: 00036700] Batch Recognition Loss:   0.002789 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.037618 => Txt Tokens per Sec:     4098 || Lr: 0.000050
2024-02-08 13:44:31,086 Epoch 276: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.64 
2024-02-08 13:44:31,086 EPOCH 277
2024-02-08 13:44:36,024 [Epoch: 277 Step: 00036800] Batch Recognition Loss:   0.000224 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.024231 => Txt Tokens per Sec:     4071 || Lr: 0.000050
2024-02-08 13:44:38,379 Epoch 277: Total Training Recognition Loss 0.09  Total Training Translation Loss 5.06 
2024-02-08 13:44:38,379 EPOCH 278
2024-02-08 13:44:41,783 [Epoch: 278 Step: 00036900] Batch Recognition Loss:   0.000139 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.020039 => Txt Tokens per Sec:     3683 || Lr: 0.000050
2024-02-08 13:44:45,907 Epoch 278: Total Training Recognition Loss 0.11  Total Training Translation Loss 7.96 
2024-02-08 13:44:45,907 EPOCH 279
2024-02-08 13:44:47,279 [Epoch: 279 Step: 00037000] Batch Recognition Loss:   0.000169 => Gls Tokens per Sec:     1517 || Batch Translation Loss:   0.021918 => Txt Tokens per Sec:     4401 || Lr: 0.000050
2024-02-08 13:44:52,389 [Epoch: 279 Step: 00037100] Batch Recognition Loss:   0.000301 => Gls Tokens per Sec:     1562 || Batch Translation Loss:   0.125831 => Txt Tokens per Sec:     4293 || Lr: 0.000050
2024-02-08 13:44:52,695 Epoch 279: Total Training Recognition Loss 0.16  Total Training Translation Loss 8.43 
2024-02-08 13:44:52,695 EPOCH 280
2024-02-08 13:44:58,057 [Epoch: 280 Step: 00037200] Batch Recognition Loss:   0.000213 => Gls Tokens per Sec:     1388 || Batch Translation Loss:   0.045715 => Txt Tokens per Sec:     3851 || Lr: 0.000050
2024-02-08 13:45:00,290 Epoch 280: Total Training Recognition Loss 0.09  Total Training Translation Loss 7.92 
2024-02-08 13:45:00,290 EPOCH 281
2024-02-08 13:45:03,532 [Epoch: 281 Step: 00037300] Batch Recognition Loss:   0.000339 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.036379 => Txt Tokens per Sec:     4144 || Lr: 0.000050
2024-02-08 13:45:07,691 Epoch 281: Total Training Recognition Loss 0.15  Total Training Translation Loss 7.33 
2024-02-08 13:45:07,691 EPOCH 282
2024-02-08 13:45:09,232 [Epoch: 282 Step: 00037400] Batch Recognition Loss:   0.001325 => Gls Tokens per Sec:     1403 || Batch Translation Loss:   0.042303 => Txt Tokens per Sec:     3962 || Lr: 0.000050
2024-02-08 13:45:14,151 [Epoch: 282 Step: 00037500] Batch Recognition Loss:   0.000421 => Gls Tokens per Sec:     1622 || Batch Translation Loss:   0.017654 => Txt Tokens per Sec:     4478 || Lr: 0.000050
2024-02-08 13:45:14,433 Epoch 282: Total Training Recognition Loss 0.12  Total Training Translation Loss 5.69 
2024-02-08 13:45:14,433 EPOCH 283
2024-02-08 13:45:19,630 [Epoch: 283 Step: 00037600] Batch Recognition Loss:   0.002789 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.022093 => Txt Tokens per Sec:     3975 || Lr: 0.000050
2024-02-08 13:45:21,731 Epoch 283: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.50 
2024-02-08 13:45:21,731 EPOCH 284
2024-02-08 13:45:24,882 [Epoch: 284 Step: 00037700] Batch Recognition Loss:   0.000605 => Gls Tokens per Sec:     1549 || Batch Translation Loss:   0.024773 => Txt Tokens per Sec:     4394 || Lr: 0.000050
2024-02-08 13:45:28,834 Epoch 284: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.35 
2024-02-08 13:45:28,834 EPOCH 285
2024-02-08 13:45:30,289 [Epoch: 285 Step: 00037800] Batch Recognition Loss:   0.000330 => Gls Tokens per Sec:     1542 || Batch Translation Loss:   0.044868 => Txt Tokens per Sec:     4120 || Lr: 0.000050
2024-02-08 13:45:35,762 [Epoch: 285 Step: 00037900] Batch Recognition Loss:   0.000221 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.039209 => Txt Tokens per Sec:     4075 || Lr: 0.000050
2024-02-08 13:45:36,104 Epoch 285: Total Training Recognition Loss 0.09  Total Training Translation Loss 6.76 
2024-02-08 13:45:36,104 EPOCH 286
2024-02-08 13:45:41,331 [Epoch: 286 Step: 00038000] Batch Recognition Loss:   0.000289 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.102262 => Txt Tokens per Sec:     4069 || Lr: 0.000050
2024-02-08 13:45:53,387 Validation result at epoch 286, step    38000: duration: 12.0562s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.93627	Translation Loss: 91640.64844	PPL: 9443.49121
	Eval Metric: BLEU
	WER 3.74	(DEL: 0.00,	INS: 0.00,	SUB: 3.74)
	BLEU-4 0.71	(BLEU-1: 10.68,	BLEU-2: 3.44,	BLEU-3: 1.37,	BLEU-4: 0.71)
	CHRF 16.98	ROUGE 9.14
2024-02-08 13:45:53,388 Logging Recognition and Translation Outputs
2024-02-08 13:45:53,388 ========================================================================================================================
2024-02-08 13:45:53,388 Logging Sequence: 59_152.00
2024-02-08 13:45:53,388 	Gloss Reference :	A B+C+D+E
2024-02-08 13:45:53,388 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:45:53,388 	Gloss Alignment :	         
2024-02-08 13:45:53,388 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:45:53,389 	Text Reference  :	the organisers encouraged athletes to   use the condoms      in     their home countries  
2024-02-08 13:45:53,390 	Text Hypothesis :	*** well       let        me       tell you the broadcasting rights for   the  coronavirus
2024-02-08 13:45:53,390 	Text Alignment  :	D   S          S          S        S    S       S            S      S     S    S          
2024-02-08 13:45:53,390 ========================================================================================================================
2024-02-08 13:45:53,390 Logging Sequence: 155_78.00
2024-02-08 13:45:53,390 	Gloss Reference :	A B+C+D+E
2024-02-08 13:45:53,390 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:45:53,391 	Gloss Alignment :	         
2024-02-08 13:45:53,391 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:45:53,392 	Text Reference  :	it was difficult for icc to disqualify the afghan team at the last    minute  so       they    included them        as  per     the schedule
2024-02-08 13:45:53,392 	Text Hypothesis :	** *** ********* *** *** ** ********** *** ****** **** ** the taliban swiftly regained control of       afghanistan was through the loss    
2024-02-08 13:45:53,392 	Text Alignment  :	D  D   D         D   D   D  D          D   D      D    D      S       S       S        S       S        S           S   S           S       
2024-02-08 13:45:53,392 ========================================================================================================================
2024-02-08 13:45:53,393 Logging Sequence: 102_147.00
2024-02-08 13:45:53,393 	Gloss Reference :	A B+C+D+E
2024-02-08 13:45:53,393 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:45:53,393 	Gloss Alignment :	         
2024-02-08 13:45:53,393 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:45:53,396 	Text Reference  :	despite the muscle cramps this  young boy lifted  such a  huge weight and made the ******* country proud by    securing a      gold medal
2024-02-08 13:45:53,396 	Text Hypothesis :	******* *** ****** a      total of    22  matches will be held in     uae with the penalty shoot   out   while italy    scored 1    lakh 
2024-02-08 13:45:53,396 	Text Alignment  :	D       D   D      S      S     S     S   S       S    S  S    S      S   S        I       S       S     S     S        S      S    S    
2024-02-08 13:45:53,396 ========================================================================================================================
2024-02-08 13:45:53,396 Logging Sequence: 105_2.00
2024-02-08 13:45:53,396 	Gloss Reference :	A B+C+D+E
2024-02-08 13:45:53,396 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:45:53,396 	Gloss Alignment :	  S      
2024-02-08 13:45:53,397 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:45:53,398 	Text Reference  :	*** ***** ** the ***** **** airthings    masters tournament is      an    online chess tournament
2024-02-08 13:45:53,398 	Text Hypothesis :	the final of the world test championship was     held       between india and    new   zealand   
2024-02-08 13:45:53,398 	Text Alignment  :	I   I     I      I     I    S            S       S          S       S     S      S     S         
2024-02-08 13:45:53,398 ========================================================================================================================
2024-02-08 13:45:53,398 Logging Sequence: 96_31.00
2024-02-08 13:45:53,398 	Gloss Reference :	A B+C+D+E
2024-02-08 13:45:53,398 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:45:53,398 	Gloss Alignment :	         
2024-02-08 13:45:53,399 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:45:53,399 	Text Reference  :	and then 2 teams   will go   on    to  play    the final 
2024-02-08 13:45:53,399 	Text Hypothesis :	*** **** * however a    very happy and secured a   wicket
2024-02-08 13:45:53,399 	Text Alignment  :	D   D    D S       S    S    S     S   S       S   S     
2024-02-08 13:45:53,400 ========================================================================================================================
2024-02-08 13:45:55,485 Epoch 286: Total Training Recognition Loss 0.13  Total Training Translation Loss 7.14 
2024-02-08 13:45:55,486 EPOCH 287
2024-02-08 13:45:58,779 [Epoch: 287 Step: 00038100] Batch Recognition Loss:   0.000395 => Gls Tokens per Sec:     1506 || Batch Translation Loss:   0.120262 => Txt Tokens per Sec:     4190 || Lr: 0.000050
2024-02-08 13:46:02,857 Epoch 287: Total Training Recognition Loss 0.18  Total Training Translation Loss 9.35 
2024-02-08 13:46:02,857 EPOCH 288
2024-02-08 13:46:04,397 [Epoch: 288 Step: 00038200] Batch Recognition Loss:   0.000817 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.042680 => Txt Tokens per Sec:     4313 || Lr: 0.000050
2024-02-08 13:46:09,890 [Epoch: 288 Step: 00038300] Batch Recognition Loss:   0.001583 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.048662 => Txt Tokens per Sec:     4006 || Lr: 0.000050
2024-02-08 13:46:10,112 Epoch 288: Total Training Recognition Loss 0.14  Total Training Translation Loss 9.09 
2024-02-08 13:46:10,112 EPOCH 289
2024-02-08 13:46:15,574 [Epoch: 289 Step: 00038400] Batch Recognition Loss:   0.001076 => Gls Tokens per Sec:     1406 || Batch Translation Loss:   0.033565 => Txt Tokens per Sec:     3888 || Lr: 0.000050
2024-02-08 13:46:17,493 Epoch 289: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.88 
2024-02-08 13:46:17,493 EPOCH 290
2024-02-08 13:46:21,013 [Epoch: 290 Step: 00038500] Batch Recognition Loss:   0.000191 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.022457 => Txt Tokens per Sec:     3940 || Lr: 0.000050
2024-02-08 13:46:24,996 Epoch 290: Total Training Recognition Loss 0.15  Total Training Translation Loss 8.10 
2024-02-08 13:46:24,997 EPOCH 291
2024-02-08 13:46:26,654 [Epoch: 291 Step: 00038600] Batch Recognition Loss:   0.000271 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.041922 => Txt Tokens per Sec:     3965 || Lr: 0.000050
2024-02-08 13:46:31,623 [Epoch: 291 Step: 00038700] Batch Recognition Loss:   0.000318 => Gls Tokens per Sec:     1606 || Batch Translation Loss:   0.029322 => Txt Tokens per Sec:     4435 || Lr: 0.000050
2024-02-08 13:46:31,784 Epoch 291: Total Training Recognition Loss 0.17  Total Training Translation Loss 8.78 
2024-02-08 13:46:31,784 EPOCH 292
2024-02-08 13:46:37,219 [Epoch: 292 Step: 00038800] Batch Recognition Loss:   0.001204 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.036898 => Txt Tokens per Sec:     3937 || Lr: 0.000050
2024-02-08 13:46:39,276 Epoch 292: Total Training Recognition Loss 0.14  Total Training Translation Loss 7.35 
2024-02-08 13:46:39,276 EPOCH 293
2024-02-08 13:46:42,416 [Epoch: 293 Step: 00038900] Batch Recognition Loss:   0.001455 => Gls Tokens per Sec:     1631 || Batch Translation Loss:   0.034995 => Txt Tokens per Sec:     4553 || Lr: 0.000050
2024-02-08 13:46:46,308 Epoch 293: Total Training Recognition Loss 0.16  Total Training Translation Loss 8.80 
2024-02-08 13:46:46,308 EPOCH 294
2024-02-08 13:46:48,144 [Epoch: 294 Step: 00039000] Batch Recognition Loss:   0.000216 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   0.027989 => Txt Tokens per Sec:     3839 || Lr: 0.000050
2024-02-08 13:46:53,464 [Epoch: 294 Step: 00039100] Batch Recognition Loss:   0.001746 => Gls Tokens per Sec:     1500 || Batch Translation Loss:   0.010611 => Txt Tokens per Sec:     4121 || Lr: 0.000050
2024-02-08 13:46:53,570 Epoch 294: Total Training Recognition Loss 0.12  Total Training Translation Loss 7.03 
2024-02-08 13:46:53,571 EPOCH 295
2024-02-08 13:46:58,842 [Epoch: 295 Step: 00039200] Batch Recognition Loss:   0.000736 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   0.019047 => Txt Tokens per Sec:     4120 || Lr: 0.000050
2024-02-08 13:47:01,012 Epoch 295: Total Training Recognition Loss 0.12  Total Training Translation Loss 7.16 
2024-02-08 13:47:01,013 EPOCH 296
2024-02-08 13:47:04,751 [Epoch: 296 Step: 00039300] Batch Recognition Loss:   0.000236 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   0.014082 => Txt Tokens per Sec:     3835 || Lr: 0.000050
2024-02-08 13:47:08,683 Epoch 296: Total Training Recognition Loss 0.21  Total Training Translation Loss 5.81 
2024-02-08 13:47:08,683 EPOCH 297
2024-02-08 13:47:10,282 [Epoch: 297 Step: 00039400] Batch Recognition Loss:   0.000675 => Gls Tokens per Sec:     1602 || Batch Translation Loss:   0.030826 => Txt Tokens per Sec:     4262 || Lr: 0.000050
2024-02-08 13:47:15,976 [Epoch: 297 Step: 00039500] Batch Recognition Loss:   0.000344 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.140118 => Txt Tokens per Sec:     3930 || Lr: 0.000050
2024-02-08 13:47:16,034 Epoch 297: Total Training Recognition Loss 0.21  Total Training Translation Loss 6.93 
2024-02-08 13:47:16,034 EPOCH 298
2024-02-08 13:47:21,435 [Epoch: 298 Step: 00039600] Batch Recognition Loss:   0.001023 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.032671 => Txt Tokens per Sec:     4028 || Lr: 0.000050
2024-02-08 13:47:23,328 Epoch 298: Total Training Recognition Loss 0.22  Total Training Translation Loss 3.44 
2024-02-08 13:47:23,328 EPOCH 299
2024-02-08 13:47:27,126 [Epoch: 299 Step: 00039700] Batch Recognition Loss:   0.000908 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   0.033853 => Txt Tokens per Sec:     3934 || Lr: 0.000050
2024-02-08 13:47:30,909 Epoch 299: Total Training Recognition Loss 0.09  Total Training Translation Loss 8.42 
2024-02-08 13:47:30,909 EPOCH 300
2024-02-08 13:47:32,735 [Epoch: 300 Step: 00039800] Batch Recognition Loss:   0.000437 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.030789 => Txt Tokens per Sec:     4111 || Lr: 0.000050
2024-02-08 13:47:37,940 [Epoch: 300 Step: 00039900] Batch Recognition Loss:   0.000464 => Gls Tokens per Sec:     1533 || Batch Translation Loss:   0.040345 => Txt Tokens per Sec:     4203 || Lr: 0.000050
2024-02-08 13:47:37,941 Epoch 300: Total Training Recognition Loss 0.10  Total Training Translation Loss 6.64 
2024-02-08 13:47:37,941 EPOCH 301
2024-02-08 13:47:43,256 [Epoch: 301 Step: 00040000] Batch Recognition Loss:   0.000448 => Gls Tokens per Sec:     1505 || Batch Translation Loss:   0.116771 => Txt Tokens per Sec:     4177 || Lr: 0.000050
2024-02-08 13:47:54,126 Validation result at epoch 301, step    40000: duration: 10.8703s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.31522	Translation Loss: 92226.41406	PPL: 10012.47363
	Eval Metric: BLEU
	WER 3.81	(DEL: 0.00,	INS: 0.00,	SUB: 3.81)
	BLEU-4 0.49	(BLEU-1: 11.08,	BLEU-2: 3.52,	BLEU-3: 1.28,	BLEU-4: 0.49)
	CHRF 16.90	ROUGE 9.80
2024-02-08 13:47:54,127 Logging Recognition and Translation Outputs
2024-02-08 13:47:54,127 ========================================================================================================================
2024-02-08 13:47:54,127 Logging Sequence: 86_84.00
2024-02-08 13:47:54,128 	Gloss Reference :	A B+C+D+E
2024-02-08 13:47:54,128 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:47:54,128 	Gloss Alignment :	         
2024-02-08 13:47:54,128 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:47:54,129 	Text Reference  :	amassing 8933 runs which included 21  centuries with    a   highest score of      201 not out 
2024-02-08 13:47:54,129 	Text Hypothesis :	******** **** **** he    played   194 odi       matches and took    293   wickets due to  1983
2024-02-08 13:47:54,129 	Text Alignment  :	D        D    D    S     S        S   S         S       S   S       S     S       S   S   S   
2024-02-08 13:47:54,130 ========================================================================================================================
2024-02-08 13:47:54,130 Logging Sequence: 179_110.00
2024-02-08 13:47:54,130 	Gloss Reference :	A B+C+D+E    
2024-02-08 13:47:54,130 	Gloss Hypothesis:	A B+C+D+E+D+E
2024-02-08 13:47:54,130 	Gloss Alignment :	  S          
2024-02-08 13:47:54,130 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:47:54,131 	Text Reference  :	*** *** ** phogat refused to  stay      in  the same room with other indian female wrestlers
2024-02-08 13:47:54,132 	Text Hypothesis :	the ban is a      holiday wfi collected for the wfi  and  that she   is     the    stumps   
2024-02-08 13:47:54,132 	Text Alignment  :	I   I   I  S      S       S   S         S       S    S    S    S     S      S      S        
2024-02-08 13:47:54,132 ========================================================================================================================
2024-02-08 13:47:54,132 Logging Sequence: 102_2.00
2024-02-08 13:47:54,132 	Gloss Reference :	A B+C+D+E
2024-02-08 13:47:54,132 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:47:54,132 	Gloss Alignment :	         
2024-02-08 13:47:54,132 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:47:54,133 	Text Reference  :	commonwealth games are among the world's most recognised gaming championships after   the     olympics
2024-02-08 13:47:54,133 	Text Hypothesis :	************ ***** *** ***** in  3       days india      and    bangladesh    women's cricket team    
2024-02-08 13:47:54,134 	Text Alignment  :	D            D     D   D     S   S       S    S          S      S             S       S       S       
2024-02-08 13:47:54,134 ========================================================================================================================
2024-02-08 13:47:54,134 Logging Sequence: 60_195.00
2024-02-08 13:47:54,134 	Gloss Reference :	A B+C+D+E
2024-02-08 13:47:54,134 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:47:54,134 	Gloss Alignment :	         
2024-02-08 13:47:54,134 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:47:54,135 	Text Reference  :	** people loved to      watch his   aggressive expressions and     his bowling
2024-02-08 13:47:54,135 	Text Hypothesis :	in his    142   matches for   india chhetri    has         slammed 92  goals  
2024-02-08 13:47:54,135 	Text Alignment  :	I  S      S     S       S     S     S          S           S       S   S      
2024-02-08 13:47:54,135 ========================================================================================================================
2024-02-08 13:47:54,136 Logging Sequence: 70_200.00
2024-02-08 13:47:54,136 	Gloss Reference :	A B+C+D+E
2024-02-08 13:47:54,136 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:47:54,136 	Gloss Alignment :	         
2024-02-08 13:47:54,136 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:47:54,136 	Text Reference  :	showing ronaldo whole-heartedly endorsing the ***** brand **********
2024-02-08 13:47:54,137 	Text Hypothesis :	******* ******* *************** in        the state brand ambassador
2024-02-08 13:47:54,137 	Text Alignment  :	D       D       D               S             I           I         
2024-02-08 13:47:54,137 ========================================================================================================================
2024-02-08 13:47:56,159 Epoch 301: Total Training Recognition Loss 0.13  Total Training Translation Loss 9.16 
2024-02-08 13:47:56,159 EPOCH 302
2024-02-08 13:47:59,984 [Epoch: 302 Step: 00040100] Batch Recognition Loss:   0.000171 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.025797 => Txt Tokens per Sec:     3844 || Lr: 0.000050
2024-02-08 13:48:03,632 Epoch 302: Total Training Recognition Loss 0.08  Total Training Translation Loss 5.66 
2024-02-08 13:48:03,633 EPOCH 303
2024-02-08 13:48:05,253 [Epoch: 303 Step: 00040200] Batch Recognition Loss:   0.000317 => Gls Tokens per Sec:     1679 || Batch Translation Loss:   0.045549 => Txt Tokens per Sec:     4707 || Lr: 0.000050
2024-02-08 13:48:10,675 Epoch 303: Total Training Recognition Loss 0.13  Total Training Translation Loss 7.17 
2024-02-08 13:48:10,675 EPOCH 304
2024-02-08 13:48:10,732 [Epoch: 304 Step: 00040300] Batch Recognition Loss:   0.000293 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.026895 => Txt Tokens per Sec:     4428 || Lr: 0.000050
2024-02-08 13:48:15,659 [Epoch: 304 Step: 00040400] Batch Recognition Loss:   0.000254 => Gls Tokens per Sec:     1624 || Batch Translation Loss:   0.148767 => Txt Tokens per Sec:     4482 || Lr: 0.000050
2024-02-08 13:48:17,538 Epoch 304: Total Training Recognition Loss 0.16  Total Training Translation Loss 8.18 
2024-02-08 13:48:17,539 EPOCH 305
2024-02-08 13:48:21,436 [Epoch: 305 Step: 00040500] Batch Recognition Loss:   0.000341 => Gls Tokens per Sec:     1396 || Batch Translation Loss:   0.018493 => Txt Tokens per Sec:     3923 || Lr: 0.000050
2024-02-08 13:48:25,155 Epoch 305: Total Training Recognition Loss 0.21  Total Training Translation Loss 4.32 
2024-02-08 13:48:25,156 EPOCH 306
2024-02-08 13:48:27,093 [Epoch: 306 Step: 00040600] Batch Recognition Loss:   0.000294 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.023659 => Txt Tokens per Sec:     3809 || Lr: 0.000050
2024-02-08 13:48:32,556 Epoch 306: Total Training Recognition Loss 0.11  Total Training Translation Loss 7.10 
2024-02-08 13:48:32,556 EPOCH 307
2024-02-08 13:48:32,693 [Epoch: 307 Step: 00040700] Batch Recognition Loss:   0.000808 => Gls Tokens per Sec:     1185 || Batch Translation Loss:   0.016051 => Txt Tokens per Sec:     3363 || Lr: 0.000050
2024-02-08 13:48:38,163 [Epoch: 307 Step: 00040800] Batch Recognition Loss:   0.000323 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.027140 => Txt Tokens per Sec:     4026 || Lr: 0.000050
2024-02-08 13:48:39,760 Epoch 307: Total Training Recognition Loss 0.11  Total Training Translation Loss 5.67 
2024-02-08 13:48:39,761 EPOCH 308
2024-02-08 13:48:43,507 [Epoch: 308 Step: 00040900] Batch Recognition Loss:   0.000180 => Gls Tokens per Sec:     1474 || Batch Translation Loss:   0.061621 => Txt Tokens per Sec:     4079 || Lr: 0.000050
2024-02-08 13:48:47,404 Epoch 308: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.53 
2024-02-08 13:48:47,405 EPOCH 309
2024-02-08 13:48:49,482 [Epoch: 309 Step: 00041000] Batch Recognition Loss:   0.002155 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.032035 => Txt Tokens per Sec:     3875 || Lr: 0.000050
2024-02-08 13:48:54,719 Epoch 309: Total Training Recognition Loss 0.22  Total Training Translation Loss 3.64 
2024-02-08 13:48:54,720 EPOCH 310
2024-02-08 13:48:54,897 [Epoch: 310 Step: 00041100] Batch Recognition Loss:   0.000286 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.019496 => Txt Tokens per Sec:     3983 || Lr: 0.000050
2024-02-08 13:49:00,458 [Epoch: 310 Step: 00041200] Batch Recognition Loss:   0.000156 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.022948 => Txt Tokens per Sec:     3966 || Lr: 0.000050
2024-02-08 13:49:02,065 Epoch 310: Total Training Recognition Loss 0.11  Total Training Translation Loss 5.12 
2024-02-08 13:49:02,065 EPOCH 311
2024-02-08 13:49:05,462 [Epoch: 311 Step: 00041300] Batch Recognition Loss:   0.007613 => Gls Tokens per Sec:     1650 || Batch Translation Loss:   0.081303 => Txt Tokens per Sec:     4495 || Lr: 0.000050
2024-02-08 13:49:09,122 Epoch 311: Total Training Recognition Loss 0.20  Total Training Translation Loss 11.56 
2024-02-08 13:49:09,122 EPOCH 312
2024-02-08 13:49:11,221 [Epoch: 312 Step: 00041400] Batch Recognition Loss:   0.001063 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.109667 => Txt Tokens per Sec:     3889 || Lr: 0.000050
2024-02-08 13:49:16,369 Epoch 312: Total Training Recognition Loss 0.15  Total Training Translation Loss 9.26 
2024-02-08 13:49:16,369 EPOCH 313
2024-02-08 13:49:16,604 [Epoch: 313 Step: 00041500] Batch Recognition Loss:   0.000423 => Gls Tokens per Sec:     1368 || Batch Translation Loss:   0.193406 => Txt Tokens per Sec:     4085 || Lr: 0.000050
2024-02-08 13:49:22,021 [Epoch: 313 Step: 00041600] Batch Recognition Loss:   0.000209 => Gls Tokens per Sec:     1478 || Batch Translation Loss:   0.023609 => Txt Tokens per Sec:     4061 || Lr: 0.000050
2024-02-08 13:49:23,754 Epoch 313: Total Training Recognition Loss 0.11  Total Training Translation Loss 7.56 
2024-02-08 13:49:23,754 EPOCH 314
2024-02-08 13:49:27,294 [Epoch: 314 Step: 00041700] Batch Recognition Loss:   0.000266 => Gls Tokens per Sec:     1605 || Batch Translation Loss:   0.024633 => Txt Tokens per Sec:     4424 || Lr: 0.000050
2024-02-08 13:49:30,863 Epoch 314: Total Training Recognition Loss 0.19  Total Training Translation Loss 6.98 
2024-02-08 13:49:30,864 EPOCH 315
2024-02-08 13:49:32,888 [Epoch: 315 Step: 00041800] Batch Recognition Loss:   0.000242 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.105030 => Txt Tokens per Sec:     4321 || Lr: 0.000050
2024-02-08 13:49:38,045 Epoch 315: Total Training Recognition Loss 0.12  Total Training Translation Loss 5.23 
2024-02-08 13:49:38,046 EPOCH 316
2024-02-08 13:49:38,339 [Epoch: 316 Step: 00041900] Batch Recognition Loss:   0.000204 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.017212 => Txt Tokens per Sec:     3612 || Lr: 0.000050
2024-02-08 13:49:43,897 [Epoch: 316 Step: 00042000] Batch Recognition Loss:   0.000787 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.026768 => Txt Tokens per Sec:     3973 || Lr: 0.000050
2024-02-08 13:49:54,813 Validation result at epoch 316, step    42000: duration: 10.9162s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.06617	Translation Loss: 91442.53125	PPL: 9258.46094
	Eval Metric: BLEU
	WER 3.18	(DEL: 0.00,	INS: 0.00,	SUB: 3.18)
	BLEU-4 0.61	(BLEU-1: 10.99,	BLEU-2: 3.65,	BLEU-3: 1.34,	BLEU-4: 0.61)
	CHRF 16.97	ROUGE 9.53
2024-02-08 13:49:54,814 Logging Recognition and Translation Outputs
2024-02-08 13:49:54,814 ========================================================================================================================
2024-02-08 13:49:54,814 Logging Sequence: 154_94.00
2024-02-08 13:49:54,814 	Gloss Reference :	A B+C+D+E
2024-02-08 13:49:54,815 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:49:54,815 	Gloss Alignment :	         
2024-02-08 13:49:54,815 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:49:54,816 	Text Reference  :	the ipl  will also be held in uae from september 19          to   october 15  
2024-02-08 13:49:54,816 	Text Hypothesis :	but they will now  be **** ** *** **** ********* quarantined till 13th    june
2024-02-08 13:49:54,816 	Text Alignment  :	S   S         S       D    D  D   D    D         S           S    S       S   
2024-02-08 13:49:54,816 ========================================================================================================================
2024-02-08 13:49:54,816 Logging Sequence: 118_2.00
2024-02-08 13:49:54,816 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:49:54,817 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:49:54,817 	Gloss Alignment :	  S        
2024-02-08 13:49:54,817 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:49:54,817 	Text Reference  :	yesterday was a very exciting day      people  across the   world were watching
2024-02-08 13:49:54,818 	Text Hypothesis :	********* *** * **** ******** everyone thought that   india and   deaf love    
2024-02-08 13:49:54,818 	Text Alignment  :	D         D   D D    D        S        S       S      S     S     S    S       
2024-02-08 13:49:54,818 ========================================================================================================================
2024-02-08 13:49:54,818 Logging Sequence: 165_453.00
2024-02-08 13:49:54,818 	Gloss Reference :	A B+C+D+E
2024-02-08 13:49:54,818 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:49:54,818 	Gloss Alignment :	         
2024-02-08 13:49:54,818 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:49:54,819 	Text Reference  :	** icc did not  agree to sehwag' decision of wearing a   numberless jersey
2024-02-08 13:49:54,819 	Text Hypothesis :	he has a   very sad   to ******* ******** ** ******* see his        wife  
2024-02-08 13:49:54,819 	Text Alignment  :	I  S   S   S    S        D       D        D  D       S   S          S     
2024-02-08 13:49:54,820 ========================================================================================================================
2024-02-08 13:49:54,820 Logging Sequence: 126_163.00
2024-02-08 13:49:54,820 	Gloss Reference :	A B+C+D+E
2024-02-08 13:49:54,820 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:49:54,820 	Gloss Alignment :	         
2024-02-08 13:49:54,820 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:49:54,821 	Text Reference  :	your  hard   work  has helped secure a    medal at     the tokyo olympics
2024-02-08 13:49:54,821 	Text Hypothesis :	since stokes broke his family and    very calm  during the ***** olympics
2024-02-08 13:49:54,821 	Text Alignment  :	S     S      S     S   S      S      S    S     S          D             
2024-02-08 13:49:54,821 ========================================================================================================================
2024-02-08 13:49:54,822 Logging Sequence: 84_2.00
2024-02-08 13:49:54,822 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:49:54,822 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:49:54,822 	Gloss Alignment :	  S        
2024-02-08 13:49:54,822 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:49:54,823 	Text Reference  :	the 2022 fifa      football world cup   is   going   on in qatar from 20th november 2022 to 18th december 2022 
2024-02-08 13:49:54,823 	Text Hypothesis :	*** **** cricketer and      hazel keech were married on ** ***** **** **** ******** **** ** **** social   media
2024-02-08 13:49:54,824 	Text Alignment  :	D   D    S         S        S     S     S    S          D  D     D    D    D        D    D  D    S        S    
2024-02-08 13:49:54,824 ========================================================================================================================
2024-02-08 13:49:56,391 Epoch 316: Total Training Recognition Loss 0.19  Total Training Translation Loss 5.40 
2024-02-08 13:49:56,391 EPOCH 317
2024-02-08 13:50:00,700 [Epoch: 317 Step: 00042100] Batch Recognition Loss:   0.000220 => Gls Tokens per Sec:     1337 || Batch Translation Loss:   0.021706 => Txt Tokens per Sec:     3756 || Lr: 0.000050
2024-02-08 13:50:03,889 Epoch 317: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.41 
2024-02-08 13:50:03,889 EPOCH 318
2024-02-08 13:50:05,959 [Epoch: 318 Step: 00042200] Batch Recognition Loss:   0.000182 => Gls Tokens per Sec:     1508 || Batch Translation Loss:   0.073869 => Txt Tokens per Sec:     4118 || Lr: 0.000050
2024-02-08 13:50:11,495 Epoch 318: Total Training Recognition Loss 0.15  Total Training Translation Loss 5.13 
2024-02-08 13:50:11,496 EPOCH 319
2024-02-08 13:50:11,826 [Epoch: 319 Step: 00042300] Batch Recognition Loss:   0.001154 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.021564 => Txt Tokens per Sec:     4377 || Lr: 0.000050
2024-02-08 13:50:16,827 [Epoch: 319 Step: 00042400] Batch Recognition Loss:   0.000204 => Gls Tokens per Sec:     1600 || Batch Translation Loss:   0.020538 => Txt Tokens per Sec:     4384 || Lr: 0.000050
2024-02-08 13:50:18,366 Epoch 319: Total Training Recognition Loss 0.19  Total Training Translation Loss 7.08 
2024-02-08 13:50:18,366 EPOCH 320
2024-02-08 13:50:22,562 [Epoch: 320 Step: 00042500] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1392 || Batch Translation Loss:   0.030349 => Txt Tokens per Sec:     3807 || Lr: 0.000050
2024-02-08 13:50:26,004 Epoch 320: Total Training Recognition Loss 0.19  Total Training Translation Loss 5.62 
2024-02-08 13:50:26,004 EPOCH 321
2024-02-08 13:50:28,426 [Epoch: 321 Step: 00042600] Batch Recognition Loss:   0.011007 => Gls Tokens per Sec:     1322 || Batch Translation Loss:   0.040613 => Txt Tokens per Sec:     3760 || Lr: 0.000050
2024-02-08 13:50:33,465 Epoch 321: Total Training Recognition Loss 0.14  Total Training Translation Loss 5.53 
2024-02-08 13:50:33,465 EPOCH 322
2024-02-08 13:50:33,813 [Epoch: 322 Step: 00042700] Batch Recognition Loss:   0.000096 => Gls Tokens per Sec:     1614 || Batch Translation Loss:   0.013649 => Txt Tokens per Sec:     4582 || Lr: 0.000050
2024-02-08 13:50:39,340 [Epoch: 322 Step: 00042800] Batch Recognition Loss:   0.000216 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.035773 => Txt Tokens per Sec:     4003 || Lr: 0.000050
2024-02-08 13:50:40,719 Epoch 322: Total Training Recognition Loss 0.23  Total Training Translation Loss 6.10 
2024-02-08 13:50:40,719 EPOCH 323
2024-02-08 13:50:44,943 [Epoch: 323 Step: 00042900] Batch Recognition Loss:   0.001869 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.040001 => Txt Tokens per Sec:     3934 || Lr: 0.000050
2024-02-08 13:50:48,380 Epoch 323: Total Training Recognition Loss 0.08  Total Training Translation Loss 12.84 
2024-02-08 13:50:48,380 EPOCH 324
2024-02-08 13:50:50,718 [Epoch: 324 Step: 00043000] Batch Recognition Loss:   0.000186 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.023780 => Txt Tokens per Sec:     3823 || Lr: 0.000050
2024-02-08 13:50:55,879 Epoch 324: Total Training Recognition Loss 0.16  Total Training Translation Loss 13.26 
2024-02-08 13:50:55,880 EPOCH 325
2024-02-08 13:50:56,302 [Epoch: 325 Step: 00043100] Batch Recognition Loss:   0.001223 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.121079 => Txt Tokens per Sec:     4531 || Lr: 0.000050
2024-02-08 13:51:01,905 [Epoch: 325 Step: 00043200] Batch Recognition Loss:   0.000405 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.027212 => Txt Tokens per Sec:     3955 || Lr: 0.000050
2024-02-08 13:51:03,183 Epoch 325: Total Training Recognition Loss 0.13  Total Training Translation Loss 5.22 
2024-02-08 13:51:03,183 EPOCH 326
2024-02-08 13:51:07,426 [Epoch: 326 Step: 00043300] Batch Recognition Loss:   0.000494 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.013571 => Txt Tokens per Sec:     3938 || Lr: 0.000050
2024-02-08 13:51:10,723 Epoch 326: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.24 
2024-02-08 13:51:10,723 EPOCH 327
2024-02-08 13:51:13,070 [Epoch: 327 Step: 00043400] Batch Recognition Loss:   0.000258 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   0.022794 => Txt Tokens per Sec:     3739 || Lr: 0.000050
2024-02-08 13:51:18,301 Epoch 327: Total Training Recognition Loss 0.15  Total Training Translation Loss 5.84 
2024-02-08 13:51:18,302 EPOCH 328
2024-02-08 13:51:18,750 [Epoch: 328 Step: 00043500] Batch Recognition Loss:   0.000243 => Gls Tokens per Sec:     1612 || Batch Translation Loss:   0.047424 => Txt Tokens per Sec:     4606 || Lr: 0.000050
2024-02-08 13:51:24,223 [Epoch: 328 Step: 00043600] Batch Recognition Loss:   0.000222 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.104008 => Txt Tokens per Sec:     4026 || Lr: 0.000050
2024-02-08 13:51:25,694 Epoch 328: Total Training Recognition Loss 0.08  Total Training Translation Loss 7.76 
2024-02-08 13:51:25,695 EPOCH 329
2024-02-08 13:51:29,869 [Epoch: 329 Step: 00043700] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.027792 => Txt Tokens per Sec:     4040 || Lr: 0.000050
2024-02-08 13:51:33,303 Epoch 329: Total Training Recognition Loss 0.17  Total Training Translation Loss 6.12 
2024-02-08 13:51:33,304 EPOCH 330
2024-02-08 13:51:35,684 [Epoch: 330 Step: 00043800] Batch Recognition Loss:   0.000708 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.078613 => Txt Tokens per Sec:     3952 || Lr: 0.000050
2024-02-08 13:51:42,152 Epoch 330: Total Training Recognition Loss 0.19  Total Training Translation Loss 5.85 
2024-02-08 13:51:42,153 EPOCH 331
2024-02-08 13:51:42,752 [Epoch: 331 Step: 00043900] Batch Recognition Loss:   0.000117 => Gls Tokens per Sec:     1341 || Batch Translation Loss:   0.008912 => Txt Tokens per Sec:     3320 || Lr: 0.000050
2024-02-08 13:51:49,147 [Epoch: 331 Step: 00044000] Batch Recognition Loss:   0.000261 => Gls Tokens per Sec:     1251 || Batch Translation Loss:   0.019133 => Txt Tokens per Sec:     3502 || Lr: 0.000050
2024-02-08 13:52:01,398 Validation result at epoch 331, step    44000: duration: 12.2494s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.05813	Translation Loss: 90728.05469	PPL: 8620.77832
	Eval Metric: BLEU
	WER 2.97	(DEL: 0.00,	INS: 0.00,	SUB: 2.97)
	BLEU-4 0.50	(BLEU-1: 10.23,	BLEU-2: 3.11,	BLEU-3: 1.14,	BLEU-4: 0.50)
	CHRF 17.01	ROUGE 8.83
2024-02-08 13:52:01,399 Logging Recognition and Translation Outputs
2024-02-08 13:52:01,399 ========================================================================================================================
2024-02-08 13:52:01,399 Logging Sequence: 57_104.00
2024-02-08 13:52:01,400 	Gloss Reference :	A B+C+D+E
2024-02-08 13:52:01,400 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:52:01,400 	Gloss Alignment :	         
2024-02-08 13:52:01,400 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:52:01,402 	Text Reference  :	the next day kohli and kl rahul continued from where they  had left and displayed amazing batting performance without losing their wickets  
2024-02-08 13:52:01,402 	Text Hypothesis :	*** **** *** ***** *** ** soon  after     that the   score of  odi  and pakistan  were    also    faced       a       huge   fan   following
2024-02-08 13:52:01,402 	Text Alignment  :	D   D    D   D     D   D  S     S         S    S     S     S   S        S         S       S       S           S       S      S     S        
2024-02-08 13:52:01,402 ========================================================================================================================
2024-02-08 13:52:01,403 Logging Sequence: 136_64.00
2024-02-08 13:52:01,403 	Gloss Reference :	A B+C+D+E
2024-02-08 13:52:01,403 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:52:01,403 	Gloss Alignment :	         
2024-02-08 13:52:01,403 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:52:01,404 	Text Reference  :	**** in all     she         has won     2   medals
2024-02-08 13:52:01,404 	Text Hypothesis :	this is because allegations are ruining his first 
2024-02-08 13:52:01,404 	Text Alignment  :	I    S  S       S           S   S       S   S     
2024-02-08 13:52:01,404 ========================================================================================================================
2024-02-08 13:52:01,404 Logging Sequence: 54_123.00
2024-02-08 13:52:01,405 	Gloss Reference :	A B+C+D+E
2024-02-08 13:52:01,405 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:52:01,405 	Gloss Alignment :	         
2024-02-08 13:52:01,405 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:52:01,406 	Text Reference  :	*** * **** vips   sponsors international cricket groups have already booked their hotel rooms
2024-02-08 13:52:01,406 	Text Hypothesis :	but i know people love     to            see     this   is   because of     the   same  room 
2024-02-08 13:52:01,406 	Text Alignment  :	I   I I    S      S        S             S       S      S    S       S      S     S     S    
2024-02-08 13:52:01,406 ========================================================================================================================
2024-02-08 13:52:01,406 Logging Sequence: 168_115.00
2024-02-08 13:52:01,407 	Gloss Reference :	A B+C+D+E
2024-02-08 13:52:01,407 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:52:01,407 	Gloss Alignment :	         
2024-02-08 13:52:01,407 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:52:01,408 	Text Reference  :	* ***** ****** **** ***** ** this  has sparked   a  major discussion on social media
2024-02-08 13:52:01,408 	Text Hypothesis :	4 rahul dravid were glued to their fan following in the   field      oh 5      time 
2024-02-08 13:52:01,408 	Text Alignment  :	I I     I      I    I     I  S     S   S         S  S     S          S  S      S    
2024-02-08 13:52:01,408 ========================================================================================================================
2024-02-08 13:52:01,409 Logging Sequence: 121_132.00
2024-02-08 13:52:01,409 	Gloss Reference :	A B+C+D+E
2024-02-08 13:52:01,409 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:52:01,409 	Gloss Alignment :	         
2024-02-08 13:52:01,409 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:52:01,410 	Text Reference  :	which is why they     will be retesting her   to check if she consumed any stamina enhancing drugs  
2024-02-08 13:52:01,410 	Text Hypothesis :	***** ** the olympics will be ********* given to ***** ** *** ******** *** ******* ********* mirabai
2024-02-08 13:52:01,410 	Text Alignment  :	D     D  S   S                D         S        D     D  D   D        D   D       D         S      
2024-02-08 13:52:01,411 ========================================================================================================================
2024-02-08 13:52:02,882 Epoch 331: Total Training Recognition Loss 0.14  Total Training Translation Loss 4.84 
2024-02-08 13:52:02,882 EPOCH 332
2024-02-08 13:52:07,612 [Epoch: 332 Step: 00044100] Batch Recognition Loss:   0.000310 => Gls Tokens per Sec:     1303 || Batch Translation Loss:   0.009447 => Txt Tokens per Sec:     3608 || Lr: 0.000050
2024-02-08 13:52:10,881 Epoch 332: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.23 
2024-02-08 13:52:10,882 EPOCH 333
2024-02-08 13:52:13,704 [Epoch: 333 Step: 00044200] Batch Recognition Loss:   0.000524 => Gls Tokens per Sec:     1248 || Batch Translation Loss:   0.014380 => Txt Tokens per Sec:     3471 || Lr: 0.000050
2024-02-08 13:52:19,197 Epoch 333: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.97 
2024-02-08 13:52:19,197 EPOCH 334
2024-02-08 13:52:19,839 [Epoch: 334 Step: 00044300] Batch Recognition Loss:   0.001085 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.005262 => Txt Tokens per Sec:     3650 || Lr: 0.000050
2024-02-08 13:52:25,748 [Epoch: 334 Step: 00044400] Batch Recognition Loss:   0.000206 => Gls Tokens per Sec:     1354 || Batch Translation Loss:   0.035103 => Txt Tokens per Sec:     3741 || Lr: 0.000050
2024-02-08 13:52:27,137 Epoch 334: Total Training Recognition Loss 0.11  Total Training Translation Loss 4.95 
2024-02-08 13:52:27,138 EPOCH 335
2024-02-08 13:52:31,766 [Epoch: 335 Step: 00044500] Batch Recognition Loss:   0.000204 => Gls Tokens per Sec:     1348 || Batch Translation Loss:   0.007037 => Txt Tokens per Sec:     3735 || Lr: 0.000050
2024-02-08 13:52:35,023 Epoch 335: Total Training Recognition Loss 0.09  Total Training Translation Loss 7.59 
2024-02-08 13:52:35,024 EPOCH 336
2024-02-08 13:52:37,554 [Epoch: 336 Step: 00044600] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.019626 => Txt Tokens per Sec:     4091 || Lr: 0.000050
2024-02-08 13:52:42,724 Epoch 336: Total Training Recognition Loss 0.18  Total Training Translation Loss 8.47 
2024-02-08 13:52:42,724 EPOCH 337
2024-02-08 13:52:43,474 [Epoch: 337 Step: 00044700] Batch Recognition Loss:   0.000257 => Gls Tokens per Sec:     1283 || Batch Translation Loss:   0.060796 => Txt Tokens per Sec:     3569 || Lr: 0.000050
2024-02-08 13:52:49,288 [Epoch: 337 Step: 00044800] Batch Recognition Loss:   0.000253 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.032897 => Txt Tokens per Sec:     3749 || Lr: 0.000050
2024-02-08 13:52:50,568 Epoch 337: Total Training Recognition Loss 0.17  Total Training Translation Loss 11.02 
2024-02-08 13:52:50,569 EPOCH 338
2024-02-08 13:52:55,413 [Epoch: 338 Step: 00044900] Batch Recognition Loss:   0.000539 => Gls Tokens per Sec:     1305 || Batch Translation Loss:   0.018012 => Txt Tokens per Sec:     3659 || Lr: 0.000050
2024-02-08 13:52:58,480 Epoch 338: Total Training Recognition Loss 0.11  Total Training Translation Loss 11.23 
2024-02-08 13:52:58,481 EPOCH 339
2024-02-08 13:53:01,162 [Epoch: 339 Step: 00045000] Batch Recognition Loss:   0.004571 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.014918 => Txt Tokens per Sec:     3867 || Lr: 0.000050
2024-02-08 13:53:06,157 Epoch 339: Total Training Recognition Loss 0.19  Total Training Translation Loss 6.20 
2024-02-08 13:53:06,158 EPOCH 340
2024-02-08 13:53:06,889 [Epoch: 340 Step: 00045100] Batch Recognition Loss:   0.000237 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.014862 => Txt Tokens per Sec:     3799 || Lr: 0.000050
2024-02-08 13:53:12,934 [Epoch: 340 Step: 00045200] Batch Recognition Loss:   0.000323 => Gls Tokens per Sec:     1320 || Batch Translation Loss:   0.020735 => Txt Tokens per Sec:     3623 || Lr: 0.000050
2024-02-08 13:53:14,304 Epoch 340: Total Training Recognition Loss 0.09  Total Training Translation Loss 6.22 
2024-02-08 13:53:14,304 EPOCH 341
2024-02-08 13:53:19,357 [Epoch: 341 Step: 00045300] Batch Recognition Loss:   0.000543 => Gls Tokens per Sec:     1267 || Batch Translation Loss:   0.033081 => Txt Tokens per Sec:     3543 || Lr: 0.000050
2024-02-08 13:53:22,819 Epoch 341: Total Training Recognition Loss 0.10  Total Training Translation Loss 8.94 
2024-02-08 13:53:22,820 EPOCH 342
2024-02-08 13:53:25,438 [Epoch: 342 Step: 00045400] Batch Recognition Loss:   0.000241 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.023097 => Txt Tokens per Sec:     3974 || Lr: 0.000050
2024-02-08 13:53:30,473 Epoch 342: Total Training Recognition Loss 0.12  Total Training Translation Loss 10.86 
2024-02-08 13:53:30,474 EPOCH 343
2024-02-08 13:53:31,215 [Epoch: 343 Step: 00045500] Batch Recognition Loss:   0.000249 => Gls Tokens per Sec:     1516 || Batch Translation Loss:   0.028609 => Txt Tokens per Sec:     4253 || Lr: 0.000050
2024-02-08 13:53:37,124 [Epoch: 343 Step: 00045600] Batch Recognition Loss:   0.000262 => Gls Tokens per Sec:     1354 || Batch Translation Loss:   0.033596 => Txt Tokens per Sec:     3740 || Lr: 0.000050
2024-02-08 13:53:38,191 Epoch 343: Total Training Recognition Loss 0.22  Total Training Translation Loss 7.09 
2024-02-08 13:53:38,191 EPOCH 344
2024-02-08 13:53:42,701 [Epoch: 344 Step: 00045700] Batch Recognition Loss:   0.000238 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.019897 => Txt Tokens per Sec:     3892 || Lr: 0.000050
2024-02-08 13:53:45,869 Epoch 344: Total Training Recognition Loss 0.15  Total Training Translation Loss 4.18 
2024-02-08 13:53:45,869 EPOCH 345
2024-02-08 13:53:48,688 [Epoch: 345 Step: 00045800] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1363 || Batch Translation Loss:   0.175811 => Txt Tokens per Sec:     3773 || Lr: 0.000050
2024-02-08 13:53:53,568 Epoch 345: Total Training Recognition Loss 0.07  Total Training Translation Loss 6.76 
2024-02-08 13:53:53,569 EPOCH 346
2024-02-08 13:53:54,278 [Epoch: 346 Step: 00045900] Batch Recognition Loss:   0.002885 => Gls Tokens per Sec:     1696 || Batch Translation Loss:   0.182336 => Txt Tokens per Sec:     4607 || Lr: 0.000050
2024-02-08 13:54:00,031 [Epoch: 346 Step: 00046000] Batch Recognition Loss:   0.000790 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.018163 => Txt Tokens per Sec:     3856 || Lr: 0.000050
2024-02-08 13:54:14,993 Validation result at epoch 346, step    46000: duration: 14.9608s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.44919	Translation Loss: 90168.47656	PPL: 8152.17920
	Eval Metric: BLEU
	WER 3.53	(DEL: 0.00,	INS: 0.00,	SUB: 3.53)
	BLEU-4 0.51	(BLEU-1: 11.28,	BLEU-2: 3.64,	BLEU-3: 1.33,	BLEU-4: 0.51)
	CHRF 17.39	ROUGE 9.46
2024-02-08 13:54:14,995 Logging Recognition and Translation Outputs
2024-02-08 13:54:14,995 ========================================================================================================================
2024-02-08 13:54:14,995 Logging Sequence: 87_207.00
2024-02-08 13:54:14,996 	Gloss Reference :	A B+C+D+E
2024-02-08 13:54:14,996 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:54:14,996 	Gloss Alignment :	         
2024-02-08 13:54:14,997 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:54:14,998 	Text Reference  :	there were 2-3  pakistanis who were speaking anti-india things and things on    kashmir
2024-02-08 13:54:14,998 	Text Hypothesis :	***** what will bcci       do  with your     medals     since  his games  candy crush  
2024-02-08 13:54:14,999 	Text Alignment  :	D     S    S    S          S   S    S        S          S      S   S      S     S      
2024-02-08 13:54:14,999 ========================================================================================================================
2024-02-08 13:54:14,999 Logging Sequence: 67_73.00
2024-02-08 13:54:14,999 	Gloss Reference :	A B+C+D+E
2024-02-08 13:54:15,000 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:54:15,000 	Gloss Alignment :	         
2024-02-08 13:54:15,000 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:54:15,001 	Text Reference  :	in his tweet    he      also  said
2024-02-08 13:54:15,001 	Text Hypothesis :	** icc under-19 cricket world cup 
2024-02-08 13:54:15,001 	Text Alignment  :	D  S   S        S       S     S   
2024-02-08 13:54:15,001 ========================================================================================================================
2024-02-08 13:54:15,002 Logging Sequence: 172_267.00
2024-02-08 13:54:15,002 	Gloss Reference :	A B+C+D+E
2024-02-08 13:54:15,003 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:54:15,003 	Gloss Alignment :	         
2024-02-08 13:54:15,003 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:54:15,004 	Text Reference  :	**** ** *** such provisions have been made     
2024-02-08 13:54:15,004 	Text Hypothesis :	this is why the  bcci       had  17   statement
2024-02-08 13:54:15,004 	Text Alignment  :	I    I  I   S    S          S    S    S        
2024-02-08 13:54:15,005 ========================================================================================================================
2024-02-08 13:54:15,005 Logging Sequence: 144_23.00
2024-02-08 13:54:15,005 	Gloss Reference :	A B+C+D+E
2024-02-08 13:54:15,006 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:54:15,006 	Gloss Alignment :	         
2024-02-08 13:54:15,006 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:54:15,008 	Text Reference  :	***** the girl is 14-year-old mumal mehar and she is         from kanasar village   of   barmer in        rajasthan
2024-02-08 13:54:15,009 	Text Hypothesis :	since the **** ** *********** ***** start of  the tournament on   23rd    september till 29th   september 2023     
2024-02-08 13:54:15,009 	Text Alignment  :	I         D    D  D           D     S     S   S   S          S    S       S         S    S      S         S        
2024-02-08 13:54:15,009 ========================================================================================================================
2024-02-08 13:54:15,009 Logging Sequence: 133_202.00
2024-02-08 13:54:15,010 	Gloss Reference :	A B+C+D+E
2024-02-08 13:54:15,010 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:54:15,010 	Gloss Alignment :	         
2024-02-08 13:54:15,010 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:54:15,012 	Text Reference  :	australia has already qualified for       the   final      if  india wins    it will face australia
2024-02-08 13:54:15,012 	Text Hypothesis :	********* *** ******* ********* similarly smith introduced his team  members to the  pm   amazing  
2024-02-08 13:54:15,012 	Text Alignment  :	D         D   D       D         S         S     S          S   S     S       S  S    S    S        
2024-02-08 13:54:15,012 ========================================================================================================================
2024-02-08 13:54:16,698 Epoch 346: Total Training Recognition Loss 0.10  Total Training Translation Loss 6.71 
2024-02-08 13:54:16,699 EPOCH 347
2024-02-08 13:54:23,540 [Epoch: 347 Step: 00046100] Batch Recognition Loss:   0.000188 => Gls Tokens per Sec:      959 || Batch Translation Loss:   0.080152 => Txt Tokens per Sec:     2660 || Lr: 0.000050
2024-02-08 13:54:27,642 Epoch 347: Total Training Recognition Loss 0.09  Total Training Translation Loss 7.12 
2024-02-08 13:54:27,643 EPOCH 348
2024-02-08 13:54:31,667 [Epoch: 348 Step: 00046200] Batch Recognition Loss:   0.000399 => Gls Tokens per Sec:      975 || Batch Translation Loss:   0.031050 => Txt Tokens per Sec:     2632 || Lr: 0.000050
2024-02-08 13:54:37,007 Epoch 348: Total Training Recognition Loss 0.12  Total Training Translation Loss 8.43 
2024-02-08 13:54:37,008 EPOCH 349
2024-02-08 13:54:38,166 [Epoch: 349 Step: 00046300] Batch Recognition Loss:   0.000508 => Gls Tokens per Sec:     1107 || Batch Translation Loss:   0.034060 => Txt Tokens per Sec:     3179 || Lr: 0.000050
2024-02-08 13:54:43,835 [Epoch: 349 Step: 00046400] Batch Recognition Loss:   0.000237 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.017809 => Txt Tokens per Sec:     3859 || Lr: 0.000050
2024-02-08 13:54:44,868 Epoch 349: Total Training Recognition Loss 0.09  Total Training Translation Loss 9.31 
2024-02-08 13:54:44,868 EPOCH 350
2024-02-08 13:54:49,574 [Epoch: 350 Step: 00046500] Batch Recognition Loss:   0.000442 => Gls Tokens per Sec:     1412 || Batch Translation Loss:   0.058460 => Txt Tokens per Sec:     3879 || Lr: 0.000050
2024-02-08 13:54:52,359 Epoch 350: Total Training Recognition Loss 0.08  Total Training Translation Loss 6.08 
2024-02-08 13:54:52,359 EPOCH 351
2024-02-08 13:54:54,757 [Epoch: 351 Step: 00046600] Batch Recognition Loss:   0.000413 => Gls Tokens per Sec:     1670 || Batch Translation Loss:   0.037713 => Txt Tokens per Sec:     4338 || Lr: 0.000050
2024-02-08 13:55:00,063 Epoch 351: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.61 
2024-02-08 13:55:00,064 EPOCH 352
2024-02-08 13:55:01,009 [Epoch: 352 Step: 00046700] Batch Recognition Loss:   0.000201 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.009378 => Txt Tokens per Sec:     3924 || Lr: 0.000050
2024-02-08 13:55:07,186 [Epoch: 352 Step: 00046800] Batch Recognition Loss:   0.000335 => Gls Tokens per Sec:     1292 || Batch Translation Loss:   0.020630 => Txt Tokens per Sec:     3588 || Lr: 0.000050
2024-02-08 13:55:08,167 Epoch 352: Total Training Recognition Loss 0.12  Total Training Translation Loss 3.42 
2024-02-08 13:55:08,168 EPOCH 353
2024-02-08 13:55:12,946 [Epoch: 353 Step: 00046900] Batch Recognition Loss:   0.000156 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.008800 => Txt Tokens per Sec:     3928 || Lr: 0.000050
2024-02-08 13:55:15,636 Epoch 353: Total Training Recognition Loss 0.08  Total Training Translation Loss 2.97 
2024-02-08 13:55:15,636 EPOCH 354
2024-02-08 13:55:18,869 [Epoch: 354 Step: 00047000] Batch Recognition Loss:   0.000454 => Gls Tokens per Sec:     1263 || Batch Translation Loss:   0.046252 => Txt Tokens per Sec:     3477 || Lr: 0.000050
2024-02-08 13:55:23,477 Epoch 354: Total Training Recognition Loss 0.13  Total Training Translation Loss 5.83 
2024-02-08 13:55:23,477 EPOCH 355
2024-02-08 13:55:24,473 [Epoch: 355 Step: 00047100] Batch Recognition Loss:   0.000874 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.056730 => Txt Tokens per Sec:     3763 || Lr: 0.000050
2024-02-08 13:55:30,538 [Epoch: 355 Step: 00047200] Batch Recognition Loss:   0.000510 => Gls Tokens per Sec:     1316 || Batch Translation Loss:   0.043143 => Txt Tokens per Sec:     3724 || Lr: 0.000050
2024-02-08 13:55:31,275 Epoch 355: Total Training Recognition Loss 0.11  Total Training Translation Loss 16.27 
2024-02-08 13:55:31,276 EPOCH 356
2024-02-08 13:55:35,888 [Epoch: 356 Step: 00047300] Batch Recognition Loss:   0.000197 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.024469 => Txt Tokens per Sec:     4111 || Lr: 0.000050
2024-02-08 13:55:38,808 Epoch 356: Total Training Recognition Loss 0.10  Total Training Translation Loss 7.89 
2024-02-08 13:55:38,809 EPOCH 357
2024-02-08 13:55:41,802 [Epoch: 357 Step: 00047400] Batch Recognition Loss:   0.006284 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.030163 => Txt Tokens per Sec:     3770 || Lr: 0.000050
2024-02-08 13:55:46,371 Epoch 357: Total Training Recognition Loss 0.07  Total Training Translation Loss 6.88 
2024-02-08 13:55:46,371 EPOCH 358
2024-02-08 13:55:47,404 [Epoch: 358 Step: 00047500] Batch Recognition Loss:   0.005738 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.005315 => Txt Tokens per Sec:     3735 || Lr: 0.000050
2024-02-08 13:55:53,358 [Epoch: 358 Step: 00047600] Batch Recognition Loss:   0.000351 => Gls Tokens per Sec:     1340 || Batch Translation Loss:   0.022980 => Txt Tokens per Sec:     3805 || Lr: 0.000050
2024-02-08 13:55:54,132 Epoch 358: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.88 
2024-02-08 13:55:54,132 EPOCH 359
2024-02-08 13:55:58,628 [Epoch: 359 Step: 00047700] Batch Recognition Loss:   0.000286 => Gls Tokens per Sec:     1531 || Batch Translation Loss:   0.030416 => Txt Tokens per Sec:     4214 || Lr: 0.000050
2024-02-08 13:56:01,353 Epoch 359: Total Training Recognition Loss 0.14  Total Training Translation Loss 5.38 
2024-02-08 13:56:01,353 EPOCH 360
2024-02-08 13:56:04,238 [Epoch: 360 Step: 00047800] Batch Recognition Loss:   0.000122 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.023480 => Txt Tokens per Sec:     4074 || Lr: 0.000050
2024-02-08 13:56:09,059 Epoch 360: Total Training Recognition Loss 0.21  Total Training Translation Loss 4.79 
2024-02-08 13:56:09,059 EPOCH 361
2024-02-08 13:56:10,227 [Epoch: 361 Step: 00047900] Batch Recognition Loss:   0.000444 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.011391 => Txt Tokens per Sec:     3547 || Lr: 0.000050
2024-02-08 13:56:15,969 [Epoch: 361 Step: 00048000] Batch Recognition Loss:   0.000345 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.016960 => Txt Tokens per Sec:     3927 || Lr: 0.000050
2024-02-08 13:56:27,536 Validation result at epoch 361, step    48000: duration: 11.5670s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.05626	Translation Loss: 91368.46094	PPL: 9190.21387
	Eval Metric: BLEU
	WER 3.53	(DEL: 0.00,	INS: 0.00,	SUB: 3.53)
	BLEU-4 0.85	(BLEU-1: 11.02,	BLEU-2: 3.59,	BLEU-3: 1.60,	BLEU-4: 0.85)
	CHRF 16.98	ROUGE 9.72
2024-02-08 13:56:27,537 Logging Recognition and Translation Outputs
2024-02-08 13:56:27,537 ========================================================================================================================
2024-02-08 13:56:27,537 Logging Sequence: 96_93.00
2024-02-08 13:56:27,537 	Gloss Reference :	A B+C+D+E
2024-02-08 13:56:27,538 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:56:27,538 	Gloss Alignment :	         
2024-02-08 13:56:27,538 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:56:27,539 	Text Reference  :	bhuvneshwar kumar took 4   wickets and hardik  pandya took 3 wickets wonderful
2024-02-08 13:56:27,539 	Text Hypothesis :	*********** ***** **** now the     own cricket team   took * a       wicket   
2024-02-08 13:56:27,539 	Text Alignment  :	D           D     D    S   S       S   S       S           D S       S        
2024-02-08 13:56:27,539 ========================================================================================================================
2024-02-08 13:56:27,539 Logging Sequence: 144_2.00
2024-02-08 13:56:27,540 	Gloss Reference :	A B+C+D+E    
2024-02-08 13:56:27,540 	Gloss Hypothesis:	A B+C+D+E+D+E
2024-02-08 13:56:27,540 	Gloss Alignment :	  S          
2024-02-08 13:56:27,540 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:56:27,541 	Text Reference  :	a girl      posted a  video  of herself playing cricket on a village farm on social media the     video      has        gone      viral  
2024-02-08 13:56:27,541 	Text Hypothesis :	* moroccans living in cities of ******* ******* ******* ** * ******* **** ** ****** ***** belgium netherland celebrated morocco's victory
2024-02-08 13:56:27,542 	Text Alignment  :	D S         S      S  S         D       D       D       D  D D       D    D  D      D     S       S          S          S         S      
2024-02-08 13:56:27,542 ========================================================================================================================
2024-02-08 13:56:27,542 Logging Sequence: 178_83.00
2024-02-08 13:56:27,542 	Gloss Reference :	A B+C+D+E
2024-02-08 13:56:27,543 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:56:27,543 	Gloss Alignment :	         
2024-02-08 13:56:27,543 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:56:27,544 	Text Reference  :	and the police still haven't apprehended the   wrestler
2024-02-08 13:56:27,544 	Text Hypothesis :	and the couple were  very    particular  about it      
2024-02-08 13:56:27,544 	Text Alignment  :	        S      S     S       S           S     S       
2024-02-08 13:56:27,544 ========================================================================================================================
2024-02-08 13:56:27,544 Logging Sequence: 169_214.00
2024-02-08 13:56:27,545 	Gloss Reference :	A B+C+D+E
2024-02-08 13:56:27,545 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:56:27,545 	Gloss Alignment :	         
2024-02-08 13:56:27,545 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:56:27,547 	Text Reference  :	virat kohli said that though arshdeep dropped the catch he   is still a ******** ************ strong  part of  the     indian team 
2024-02-08 13:56:27,547 	Text Hypothesis :	***** ***** **** the  car    was      told    to  pay   this is ***** a talented wicketkeeper captain old  and medical be     added
2024-02-08 13:56:27,547 	Text Alignment  :	D     D     D    S    S      S        S       S   S     S       D       I        I            S       S    S   S       S      S    
2024-02-08 13:56:27,547 ========================================================================================================================
2024-02-08 13:56:27,547 Logging Sequence: 147_202.00
2024-02-08 13:56:27,548 	Gloss Reference :	A B+C+D+E
2024-02-08 13:56:27,548 	Gloss Hypothesis:	A B+C+D  
2024-02-08 13:56:27,548 	Gloss Alignment :	  S      
2024-02-08 13:56:27,548 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:56:27,550 	Text Reference  :	were impressed that she   took      the difficult decision to      withdraw from  the   olympics and focus on her mental   health
2024-02-08 13:56:27,550 	Text Hypothesis :	**** earlier   the  board organised the test      series   against each     other celeb parents  and ***** ** *** venomous abuses
2024-02-08 13:56:27,550 	Text Alignment  :	D    S         S    S     S             S         S        S       S        S     S     S            D     D  D   S        S     
2024-02-08 13:56:27,550 ========================================================================================================================
2024-02-08 13:56:28,219 Epoch 361: Total Training Recognition Loss 0.09  Total Training Translation Loss 3.60 
2024-02-08 13:56:28,219 EPOCH 362
2024-02-08 13:56:33,223 [Epoch: 362 Step: 00048100] Batch Recognition Loss:   0.000255 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   0.025866 => Txt Tokens per Sec:     3847 || Lr: 0.000050
2024-02-08 13:56:36,100 Epoch 362: Total Training Recognition Loss 0.12  Total Training Translation Loss 6.00 
2024-02-08 13:56:36,101 EPOCH 363
2024-02-08 13:56:39,436 [Epoch: 363 Step: 00048200] Batch Recognition Loss:   0.000336 => Gls Tokens per Sec:     1296 || Batch Translation Loss:   0.019994 => Txt Tokens per Sec:     3636 || Lr: 0.000050
2024-02-08 13:56:44,286 Epoch 363: Total Training Recognition Loss 0.12  Total Training Translation Loss 9.12 
2024-02-08 13:56:44,286 EPOCH 364
2024-02-08 13:56:45,425 [Epoch: 364 Step: 00048300] Batch Recognition Loss:   0.000174 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.015572 => Txt Tokens per Sec:     4180 || Lr: 0.000050
2024-02-08 13:56:51,405 [Epoch: 364 Step: 00048400] Batch Recognition Loss:   0.000239 => Gls Tokens per Sec:     1334 || Batch Translation Loss:   0.039097 => Txt Tokens per Sec:     3650 || Lr: 0.000050
2024-02-08 13:56:52,053 Epoch 364: Total Training Recognition Loss 0.09  Total Training Translation Loss 10.04 
2024-02-08 13:56:52,053 EPOCH 365
2024-02-08 13:56:56,953 [Epoch: 365 Step: 00048500] Batch Recognition Loss:   0.000146 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   1.304635 => Txt Tokens per Sec:     4023 || Lr: 0.000050
2024-02-08 13:56:59,295 Epoch 365: Total Training Recognition Loss 0.18  Total Training Translation Loss 10.35 
2024-02-08 13:56:59,296 EPOCH 366
2024-02-08 13:57:02,355 [Epoch: 366 Step: 00048600] Batch Recognition Loss:   0.000256 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.019390 => Txt Tokens per Sec:     3949 || Lr: 0.000050
2024-02-08 13:57:07,400 Epoch 366: Total Training Recognition Loss 0.12  Total Training Translation Loss 9.01 
2024-02-08 13:57:07,400 EPOCH 367
2024-02-08 13:57:08,673 [Epoch: 367 Step: 00048700] Batch Recognition Loss:   0.000231 => Gls Tokens per Sec:     1385 || Batch Translation Loss:   0.041038 => Txt Tokens per Sec:     3755 || Lr: 0.000050
2024-02-08 13:57:14,521 [Epoch: 367 Step: 00048800] Batch Recognition Loss:   0.000448 => Gls Tokens per Sec:     1365 || Batch Translation Loss:   0.027587 => Txt Tokens per Sec:     3798 || Lr: 0.000050
2024-02-08 13:57:15,180 Epoch 367: Total Training Recognition Loss 0.11  Total Training Translation Loss 6.88 
2024-02-08 13:57:15,181 EPOCH 368
2024-02-08 13:57:20,274 [Epoch: 368 Step: 00048900] Batch Recognition Loss:   0.000172 => Gls Tokens per Sec:     1398 || Batch Translation Loss:   0.014533 => Txt Tokens per Sec:     3858 || Lr: 0.000050
2024-02-08 13:57:22,907 Epoch 368: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.93 
2024-02-08 13:57:22,908 EPOCH 369
2024-02-08 13:57:26,431 [Epoch: 369 Step: 00049000] Batch Recognition Loss:   0.000303 => Gls Tokens per Sec:     1272 || Batch Translation Loss:   0.023190 => Txt Tokens per Sec:     3537 || Lr: 0.000050
2024-02-08 13:57:30,883 Epoch 369: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.89 
2024-02-08 13:57:30,883 EPOCH 370
2024-02-08 13:57:32,354 [Epoch: 370 Step: 00049100] Batch Recognition Loss:   0.000432 => Gls Tokens per Sec:     1252 || Batch Translation Loss:   0.020999 => Txt Tokens per Sec:     3616 || Lr: 0.000050
2024-02-08 13:57:38,263 [Epoch: 370 Step: 00049200] Batch Recognition Loss:   0.000221 => Gls Tokens per Sec:     1354 || Batch Translation Loss:   0.024265 => Txt Tokens per Sec:     3731 || Lr: 0.000050
2024-02-08 13:57:38,869 Epoch 370: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.97 
2024-02-08 13:57:38,869 EPOCH 371
2024-02-08 13:57:43,998 [Epoch: 371 Step: 00049300] Batch Recognition Loss:   0.000304 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.053105 => Txt Tokens per Sec:     3894 || Lr: 0.000050
2024-02-08 13:57:46,536 Epoch 371: Total Training Recognition Loss 0.23  Total Training Translation Loss 12.12 
2024-02-08 13:57:46,536 EPOCH 372
2024-02-08 13:57:49,832 [Epoch: 372 Step: 00049400] Batch Recognition Loss:   0.000466 => Gls Tokens per Sec:     1385 || Batch Translation Loss:   0.599464 => Txt Tokens per Sec:     3812 || Lr: 0.000050
2024-02-08 13:57:54,463 Epoch 372: Total Training Recognition Loss 0.12  Total Training Translation Loss 11.06 
2024-02-08 13:57:54,464 EPOCH 373
2024-02-08 13:57:55,874 [Epoch: 373 Step: 00049500] Batch Recognition Loss:   0.001640 => Gls Tokens per Sec:     1362 || Batch Translation Loss:   0.044032 => Txt Tokens per Sec:     3749 || Lr: 0.000050
2024-02-08 13:58:01,581 [Epoch: 373 Step: 00049600] Batch Recognition Loss:   0.000699 => Gls Tokens per Sec:     1398 || Batch Translation Loss:   0.061461 => Txt Tokens per Sec:     3876 || Lr: 0.000050
2024-02-08 13:58:02,053 Epoch 373: Total Training Recognition Loss 0.14  Total Training Translation Loss 7.43 
2024-02-08 13:58:02,054 EPOCH 374
2024-02-08 13:58:07,125 [Epoch: 374 Step: 00049700] Batch Recognition Loss:   0.001781 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.022241 => Txt Tokens per Sec:     3994 || Lr: 0.000050
2024-02-08 13:58:09,573 Epoch 374: Total Training Recognition Loss 0.14  Total Training Translation Loss 7.00 
2024-02-08 13:58:09,573 EPOCH 375
2024-02-08 13:58:12,939 [Epoch: 375 Step: 00049800] Batch Recognition Loss:   0.000333 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.010216 => Txt Tokens per Sec:     3855 || Lr: 0.000050
2024-02-08 13:58:17,440 Epoch 375: Total Training Recognition Loss 0.11  Total Training Translation Loss 4.39 
2024-02-08 13:58:17,441 EPOCH 376
2024-02-08 13:58:18,897 [Epoch: 376 Step: 00049900] Batch Recognition Loss:   0.000193 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.010830 => Txt Tokens per Sec:     3597 || Lr: 0.000050
2024-02-08 13:58:24,957 [Epoch: 376 Step: 00050000] Batch Recognition Loss:   0.000465 => Gls Tokens per Sec:     1317 || Batch Translation Loss:   0.026805 => Txt Tokens per Sec:     3698 || Lr: 0.000050
2024-02-08 13:58:40,159 Validation result at epoch 376, step    50000: duration: 15.2002s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.27305	Translation Loss: 89925.65625	PPL: 7956.83643
	Eval Metric: BLEU
	WER 4.03	(DEL: 0.00,	INS: 0.00,	SUB: 4.03)
	BLEU-4 0.77	(BLEU-1: 11.20,	BLEU-2: 3.79,	BLEU-3: 1.59,	BLEU-4: 0.77)
	CHRF 17.06	ROUGE 9.45
2024-02-08 13:58:40,160 Logging Recognition and Translation Outputs
2024-02-08 13:58:40,160 ========================================================================================================================
2024-02-08 13:58:40,160 Logging Sequence: 178_157.00
2024-02-08 13:58:40,161 	Gloss Reference :	A B+C+D+E
2024-02-08 13:58:40,161 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:58:40,161 	Gloss Alignment :	         
2024-02-08 13:58:40,161 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:58:40,161 	Text Reference  :	this is why sushil kumar will have to    be arrested
2024-02-08 13:58:40,162 	Text Hypothesis :	**** ** *** and    that  was  very proud of him     
2024-02-08 13:58:40,162 	Text Alignment  :	D    D  D   S      S     S    S    S     S  S       
2024-02-08 13:58:40,162 ========================================================================================================================
2024-02-08 13:58:40,162 Logging Sequence: 118_111.00
2024-02-08 13:58:40,162 	Gloss Reference :	A B+C+D+E
2024-02-08 13:58:40,162 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:58:40,162 	Gloss Alignment :	         
2024-02-08 13:58:40,162 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:58:40,163 	Text Reference  :	and  people encourage him   have hope  for the next world cup  
2024-02-08 13:58:40,164 	Text Hypothesis :	here is     the       first time india won the **** ***** match
2024-02-08 13:58:40,164 	Text Alignment  :	S    S      S         S     S    S     S       D    D     S    
2024-02-08 13:58:40,164 ========================================================================================================================
2024-02-08 13:58:40,164 Logging Sequence: 148_2.00
2024-02-08 13:58:40,164 	Gloss Reference :	A B+C+D+E  
2024-02-08 13:58:40,164 	Gloss Hypothesis:	A B+C+D+E+D
2024-02-08 13:58:40,164 	Gloss Alignment :	  S        
2024-02-08 13:58:40,164 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:58:40,165 	Text Reference  :	the final of the asia cup   2023 cricket tournament was played between india and sri lanka on   17th september 2023
2024-02-08 13:58:40,165 	Text Hypothesis :	*** ***** ** the **** first time hardik  pandya     was ****** ******* ***** *** *** ***** held in   t20i      runs
2024-02-08 13:58:40,165 	Text Alignment  :	D   D     D      D    S     S    S       S              D      D       D     D   D   D     S    S    S         S   
2024-02-08 13:58:40,166 ========================================================================================================================
2024-02-08 13:58:40,166 Logging Sequence: 83_129.00
2024-02-08 13:58:40,166 	Gloss Reference :	A B+C+D+E
2024-02-08 13:58:40,166 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:58:40,166 	Gloss Alignment :	         
2024-02-08 13:58:40,166 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:58:40,167 	Text Reference  :	** ** later the  denmark football association tweeted
2024-02-08 13:58:40,167 	Text Hypothesis :	he is a     very proud   of       euro        2020   
2024-02-08 13:58:40,167 	Text Alignment  :	I  I  S     S    S       S        S           S      
2024-02-08 13:58:40,167 ========================================================================================================================
2024-02-08 13:58:40,167 Logging Sequence: 99_158.00
2024-02-08 13:58:40,168 	Gloss Reference :	A B+C+D+E
2024-02-08 13:58:40,168 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 13:58:40,168 	Gloss Alignment :	         
2024-02-08 13:58:40,168 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 13:58:40,169 	Text Reference  :	** *** **** ***** ** the  incident occured  in dubai and    it     was extremely shameful
2024-02-08 13:58:40,169 	Text Hypothesis :	he was then moved to play against  pakistan in ***** sports rather you call      it      
2024-02-08 13:58:40,169 	Text Alignment  :	I  I   I    I     I  S    S        S           D     S      S      S   S         S       
2024-02-08 13:58:40,169 ========================================================================================================================
2024-02-08 13:58:40,984 Epoch 376: Total Training Recognition Loss 0.17  Total Training Translation Loss 4.02 
2024-02-08 13:58:40,984 EPOCH 377
2024-02-08 13:58:50,091 [Epoch: 377 Step: 00050100] Batch Recognition Loss:   0.000561 => Gls Tokens per Sec:      808 || Batch Translation Loss:   0.032990 => Txt Tokens per Sec:     2233 || Lr: 0.000050
2024-02-08 13:58:54,109 Epoch 377: Total Training Recognition Loss 0.11  Total Training Translation Loss 5.63 
2024-02-08 13:58:54,110 EPOCH 378
2024-02-08 13:58:59,717 [Epoch: 378 Step: 00050200] Batch Recognition Loss:   0.000222 => Gls Tokens per Sec:      842 || Batch Translation Loss:   0.023392 => Txt Tokens per Sec:     2294 || Lr: 0.000050
2024-02-08 13:59:07,219 Epoch 378: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.91 
2024-02-08 13:59:07,220 EPOCH 379
2024-02-08 13:59:09,906 [Epoch: 379 Step: 00050300] Batch Recognition Loss:   0.000344 => Gls Tokens per Sec:      775 || Batch Translation Loss:   0.021692 => Txt Tokens per Sec:     2268 || Lr: 0.000050
2024-02-08 13:59:19,716 [Epoch: 379 Step: 00050400] Batch Recognition Loss:   0.000786 => Gls Tokens per Sec:      814 || Batch Translation Loss:   0.058153 => Txt Tokens per Sec:     2221 || Lr: 0.000050
2024-02-08 13:59:20,358 Epoch 379: Total Training Recognition Loss 0.08  Total Training Translation Loss 7.79 
2024-02-08 13:59:20,358 EPOCH 380
2024-02-08 13:59:29,566 [Epoch: 380 Step: 00050500] Batch Recognition Loss:   0.000505 => Gls Tokens per Sec:      808 || Batch Translation Loss:   0.085183 => Txt Tokens per Sec:     2226 || Lr: 0.000050
2024-02-08 13:59:33,646 Epoch 380: Total Training Recognition Loss 0.17  Total Training Translation Loss 9.38 
2024-02-08 13:59:33,647 EPOCH 381
2024-02-08 13:59:39,856 [Epoch: 381 Step: 00050600] Batch Recognition Loss:   0.000252 => Gls Tokens per Sec:      773 || Batch Translation Loss:   0.046499 => Txt Tokens per Sec:     2168 || Lr: 0.000050
2024-02-08 13:59:46,798 Epoch 381: Total Training Recognition Loss 0.13  Total Training Translation Loss 7.52 
2024-02-08 13:59:46,799 EPOCH 382
2024-02-08 13:59:49,385 [Epoch: 382 Step: 00050700] Batch Recognition Loss:   0.002175 => Gls Tokens per Sec:      836 || Batch Translation Loss:   0.033888 => Txt Tokens per Sec:     2338 || Lr: 0.000050
2024-02-08 13:59:59,177 [Epoch: 382 Step: 00050800] Batch Recognition Loss:   0.000856 => Gls Tokens per Sec:      817 || Batch Translation Loss:   0.068081 => Txt Tokens per Sec:     2252 || Lr: 0.000050
2024-02-08 13:59:59,856 Epoch 382: Total Training Recognition Loss 0.13  Total Training Translation Loss 7.70 
2024-02-08 13:59:59,856 EPOCH 383
2024-02-08 14:00:09,041 [Epoch: 383 Step: 00050900] Batch Recognition Loss:   0.000467 => Gls Tokens per Sec:      819 || Batch Translation Loss:   0.037449 => Txt Tokens per Sec:     2290 || Lr: 0.000050
2024-02-08 14:00:12,803 Epoch 383: Total Training Recognition Loss 0.11  Total Training Translation Loss 10.64 
2024-02-08 14:00:12,803 EPOCH 384
2024-02-08 14:00:18,778 [Epoch: 384 Step: 00051000] Batch Recognition Loss:   0.000239 => Gls Tokens per Sec:      817 || Batch Translation Loss:   0.019376 => Txt Tokens per Sec:     2257 || Lr: 0.000050
2024-02-08 14:00:23,509 Epoch 384: Total Training Recognition Loss 0.12  Total Training Translation Loss 5.14 
2024-02-08 14:00:23,509 EPOCH 385
2024-02-08 14:00:24,914 [Epoch: 385 Step: 00051100] Batch Recognition Loss:   0.000221 => Gls Tokens per Sec:     1595 || Batch Translation Loss:   0.038949 => Txt Tokens per Sec:     4246 || Lr: 0.000050
2024-02-08 14:00:30,493 [Epoch: 385 Step: 00051200] Batch Recognition Loss:   0.000567 => Gls Tokens per Sec:     1431 || Batch Translation Loss:   0.038128 => Txt Tokens per Sec:     3992 || Lr: 0.000050
2024-02-08 14:00:30,862 Epoch 385: Total Training Recognition Loss 0.09  Total Training Translation Loss 5.17 
2024-02-08 14:00:30,863 EPOCH 386
2024-02-08 14:00:36,148 [Epoch: 386 Step: 00051300] Batch Recognition Loss:   0.000413 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.020444 => Txt Tokens per Sec:     3997 || Lr: 0.000050
2024-02-08 14:00:38,293 Epoch 386: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.79 
2024-02-08 14:00:38,293 EPOCH 387
2024-02-08 14:00:41,674 [Epoch: 387 Step: 00051400] Batch Recognition Loss:   0.001108 => Gls Tokens per Sec:     1468 || Batch Translation Loss:   0.034891 => Txt Tokens per Sec:     4005 || Lr: 0.000050
2024-02-08 14:00:45,767 Epoch 387: Total Training Recognition Loss 0.14  Total Training Translation Loss 3.30 
2024-02-08 14:00:45,767 EPOCH 388
2024-02-08 14:00:47,277 [Epoch: 388 Step: 00051500] Batch Recognition Loss:   0.000100 => Gls Tokens per Sec:     1537 || Batch Translation Loss:   0.010196 => Txt Tokens per Sec:     4256 || Lr: 0.000050
2024-02-08 14:00:53,161 [Epoch: 388 Step: 00051600] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.029994 => Txt Tokens per Sec:     3744 || Lr: 0.000050
2024-02-08 14:00:53,374 Epoch 388: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.24 
2024-02-08 14:00:53,374 EPOCH 389
2024-02-08 14:00:58,364 [Epoch: 389 Step: 00051700] Batch Recognition Loss:   0.000190 => Gls Tokens per Sec:     1540 || Batch Translation Loss:   0.039002 => Txt Tokens per Sec:     4209 || Lr: 0.000050
2024-02-08 14:01:00,635 Epoch 389: Total Training Recognition Loss 0.15  Total Training Translation Loss 9.90 
2024-02-08 14:01:00,635 EPOCH 390
2024-02-08 14:01:04,117 [Epoch: 390 Step: 00051800] Batch Recognition Loss:   0.000227 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.049594 => Txt Tokens per Sec:     3864 || Lr: 0.000050
2024-02-08 14:01:08,248 Epoch 390: Total Training Recognition Loss 0.08  Total Training Translation Loss 8.89 
2024-02-08 14:01:08,248 EPOCH 391
2024-02-08 14:01:09,686 [Epoch: 391 Step: 00051900] Batch Recognition Loss:   0.000664 => Gls Tokens per Sec:     1670 || Batch Translation Loss:   0.018134 => Txt Tokens per Sec:     4484 || Lr: 0.000050
2024-02-08 14:01:15,717 [Epoch: 391 Step: 00052000] Batch Recognition Loss:   0.000461 => Gls Tokens per Sec:     1323 || Batch Translation Loss:   0.109415 => Txt Tokens per Sec:     3714 || Lr: 0.000050
2024-02-08 14:01:26,832 Validation result at epoch 391, step    52000: duration: 11.1150s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.67766	Translation Loss: 90945.58594	PPL: 8810.13672
	Eval Metric: BLEU
	WER 4.17	(DEL: 0.00,	INS: 0.00,	SUB: 4.17)
	BLEU-4 0.48	(BLEU-1: 10.37,	BLEU-2: 3.15,	BLEU-3: 1.08,	BLEU-4: 0.48)
	CHRF 17.09	ROUGE 8.95
2024-02-08 14:01:26,833 Logging Recognition and Translation Outputs
2024-02-08 14:01:26,833 ========================================================================================================================
2024-02-08 14:01:26,833 Logging Sequence: 59_101.00
2024-02-08 14:01:26,833 	Gloss Reference :	A B+C+D+E
2024-02-08 14:01:26,834 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:01:26,834 	Gloss Alignment :	         
2024-02-08 14:01:26,834 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:01:26,836 	Text Reference  :	did you see  the video fox said she     won       her     medals because of  a condom and is  very happy
2024-02-08 14:01:26,836 	Text Hypothesis :	*** in  june the ***** *** most strange statement against sri    lanka   for a look   at  the 4th  over 
2024-02-08 14:01:26,836 	Text Alignment  :	D   S   S        D     D   S    S       S         S       S      S       S     S      S   S   S    S    
2024-02-08 14:01:26,836 ========================================================================================================================
2024-02-08 14:01:26,836 Logging Sequence: 103_112.00
2024-02-08 14:01:26,836 	Gloss Reference :	A B+C+D+E
2024-02-08 14:01:26,836 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:01:26,836 	Gloss Alignment :	         
2024-02-08 14:01:26,837 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:01:26,837 	Text Reference  :	you are aware that earlier the britishers had colonized a     lot  of     countries in      the    world
2024-02-08 14:01:26,838 	Text Hypothesis :	*** *** ***** **** ******* the ********** *** ********* games were called their     british empire games
2024-02-08 14:01:26,838 	Text Alignment  :	D   D   D     D    D           D          D   D         S     S    S      S         S       S      S    
2024-02-08 14:01:26,838 ========================================================================================================================
2024-02-08 14:01:26,838 Logging Sequence: 143_11.00
2024-02-08 14:01:26,838 	Gloss Reference :	A B+C+D+E
2024-02-08 14:01:26,838 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:01:26,838 	Gloss Alignment :	         
2024-02-08 14:01:26,839 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:01:26,840 	Text Reference  :	ronaldo has also become the first person to have  500      million followers on  instagram  he  is    the       most loved      footballer
2024-02-08 14:01:26,840 	Text Hypothesis :	******* *** **** ****** the ***** ****** ** other football team    about     the tournament and found ronaldo's name definitely pops      
2024-02-08 14:01:26,840 	Text Alignment  :	D       D   D    D          D     D      D  S     S        S       S         S   S          S   S     S         S    S          S         
2024-02-08 14:01:26,840 ========================================================================================================================
2024-02-08 14:01:26,841 Logging Sequence: 183_23.00
2024-02-08 14:01:26,841 	Gloss Reference :	A B+C+D+E
2024-02-08 14:01:26,841 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:01:26,841 	Gloss Alignment :	         
2024-02-08 14:01:26,841 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:01:26,843 	Text Reference  :	however everybody has been   waiting for  them to    announce the **** *** name   of      the *** child
2024-02-08 14:01:26,843 	Text Hypothesis :	and     scored    a   report said    that the  hotel with     the mind was played between the and it   
2024-02-08 14:01:26,843 	Text Alignment  :	S       S         S   S      S       S    S    S     S            I    I   S      S           I   S    
2024-02-08 14:01:26,843 ========================================================================================================================
2024-02-08 14:01:26,843 Logging Sequence: 169_165.00
2024-02-08 14:01:26,843 	Gloss Reference :	A B+C+D+E
2024-02-08 14:01:26,843 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:01:26,843 	Gloss Alignment :	         
2024-02-08 14:01:26,844 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:01:26,845 	Text Reference  :	the ***** indian  government was ********** ** outraged by   the  incident and      these changes were   undone by  wikipedia
2024-02-08 14:01:26,845 	Text Hypothesis :	the men's cricket team       was devastated as they     were sent to       complete the   british empire and    the ball     
2024-02-08 14:01:26,845 	Text Alignment  :	    I     S       S              I          I  S        S    S    S        S        S     S       S      S      S   S        
2024-02-08 14:01:26,845 ========================================================================================================================
2024-02-08 14:01:26,985 Epoch 391: Total Training Recognition Loss 0.07  Total Training Translation Loss 6.37 
2024-02-08 14:01:26,985 EPOCH 392
2024-02-08 14:01:32,718 [Epoch: 392 Step: 00052100] Batch Recognition Loss:   0.000607 => Gls Tokens per Sec:     1354 || Batch Translation Loss:   0.024300 => Txt Tokens per Sec:     3792 || Lr: 0.000050
2024-02-08 14:01:34,729 Epoch 392: Total Training Recognition Loss 0.12  Total Training Translation Loss 7.66 
2024-02-08 14:01:34,730 EPOCH 393
2024-02-08 14:01:38,279 [Epoch: 393 Step: 00052200] Batch Recognition Loss:   0.000233 => Gls Tokens per Sec:     1443 || Batch Translation Loss:   0.016235 => Txt Tokens per Sec:     4046 || Lr: 0.000050
2024-02-08 14:01:42,252 Epoch 393: Total Training Recognition Loss 0.11  Total Training Translation Loss 7.68 
2024-02-08 14:01:42,253 EPOCH 394
2024-02-08 14:01:44,054 [Epoch: 394 Step: 00052300] Batch Recognition Loss:   0.000215 => Gls Tokens per Sec:     1377 || Batch Translation Loss:   0.030829 => Txt Tokens per Sec:     3768 || Lr: 0.000050
2024-02-08 14:01:49,953 [Epoch: 394 Step: 00052400] Batch Recognition Loss:   0.000704 => Gls Tokens per Sec:     1353 || Batch Translation Loss:   0.026053 => Txt Tokens per Sec:     3737 || Lr: 0.000050
2024-02-08 14:01:50,074 Epoch 394: Total Training Recognition Loss 0.13  Total Training Translation Loss 10.15 
2024-02-08 14:01:50,074 EPOCH 395
2024-02-08 14:01:55,613 [Epoch: 395 Step: 00052500] Batch Recognition Loss:   0.000998 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.049264 => Txt Tokens per Sec:     3897 || Lr: 0.000050
2024-02-08 14:01:57,761 Epoch 395: Total Training Recognition Loss 0.16  Total Training Translation Loss 12.39 
2024-02-08 14:01:57,762 EPOCH 396
2024-02-08 14:02:01,457 [Epoch: 396 Step: 00052600] Batch Recognition Loss:   0.003955 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.023038 => Txt Tokens per Sec:     3894 || Lr: 0.000050
2024-02-08 14:02:05,336 Epoch 396: Total Training Recognition Loss 0.14  Total Training Translation Loss 8.30 
2024-02-08 14:02:05,336 EPOCH 397
2024-02-08 14:02:06,997 [Epoch: 397 Step: 00052700] Batch Recognition Loss:   0.000641 => Gls Tokens per Sec:     1542 || Batch Translation Loss:   0.046157 => Txt Tokens per Sec:     4297 || Lr: 0.000050
2024-02-08 14:02:13,014 [Epoch: 397 Step: 00052800] Batch Recognition Loss:   0.000421 => Gls Tokens per Sec:     1330 || Batch Translation Loss:   0.030542 => Txt Tokens per Sec:     3665 || Lr: 0.000050
2024-02-08 14:02:13,117 Epoch 397: Total Training Recognition Loss 0.20  Total Training Translation Loss 4.78 
2024-02-08 14:02:13,118 EPOCH 398
2024-02-08 14:02:18,686 [Epoch: 398 Step: 00052900] Batch Recognition Loss:   0.002183 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.016841 => Txt Tokens per Sec:     3950 || Lr: 0.000050
2024-02-08 14:02:20,602 Epoch 398: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.06 
2024-02-08 14:02:20,602 EPOCH 399
2024-02-08 14:02:24,017 [Epoch: 399 Step: 00053000] Batch Recognition Loss:   0.000175 => Gls Tokens per Sec:     1546 || Batch Translation Loss:   0.011109 => Txt Tokens per Sec:     4197 || Lr: 0.000050
2024-02-08 14:02:28,012 Epoch 399: Total Training Recognition Loss 0.07  Total Training Translation Loss 4.83 
2024-02-08 14:02:28,013 EPOCH 400
2024-02-08 14:02:29,984 [Epoch: 400 Step: 00053100] Batch Recognition Loss:   0.000496 => Gls Tokens per Sec:     1340 || Batch Translation Loss:   0.016613 => Txt Tokens per Sec:     3831 || Lr: 0.000050
2024-02-08 14:02:36,060 [Epoch: 400 Step: 00053200] Batch Recognition Loss:   0.000580 => Gls Tokens per Sec:     1313 || Batch Translation Loss:   0.025783 => Txt Tokens per Sec:     3594 || Lr: 0.000050
2024-02-08 14:02:36,060 Epoch 400: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.92 
2024-02-08 14:02:36,060 EPOCH 401
2024-02-08 14:02:46,153 [Epoch: 401 Step: 00053300] Batch Recognition Loss:   0.000266 => Gls Tokens per Sec:      793 || Batch Translation Loss:   0.138513 => Txt Tokens per Sec:     2196 || Lr: 0.000050
2024-02-08 14:02:49,658 Epoch 401: Total Training Recognition Loss 0.09  Total Training Translation Loss 6.35 
2024-02-08 14:02:49,659 EPOCH 402
2024-02-08 14:02:56,477 [Epoch: 402 Step: 00053400] Batch Recognition Loss:   0.002260 => Gls Tokens per Sec:      786 || Batch Translation Loss:   0.254009 => Txt Tokens per Sec:     2184 || Lr: 0.000050
2024-02-08 14:03:03,454 Epoch 402: Total Training Recognition Loss 0.16  Total Training Translation Loss 6.18 
2024-02-08 14:03:03,455 EPOCH 403
2024-02-08 14:03:07,068 [Epoch: 403 Step: 00053500] Batch Recognition Loss:   0.000268 => Gls Tokens per Sec:      753 || Batch Translation Loss:   0.054298 => Txt Tokens per Sec:     2070 || Lr: 0.000050
2024-02-08 14:03:17,388 Epoch 403: Total Training Recognition Loss 0.11  Total Training Translation Loss 6.05 
2024-02-08 14:03:17,389 EPOCH 404
2024-02-08 14:03:17,518 [Epoch: 404 Step: 00053600] Batch Recognition Loss:   0.000737 => Gls Tokens per Sec:      624 || Batch Translation Loss:   0.148861 => Txt Tokens per Sec:     2272 || Lr: 0.000050
2024-02-08 14:03:27,930 [Epoch: 404 Step: 00053700] Batch Recognition Loss:   0.001014 => Gls Tokens per Sec:      768 || Batch Translation Loss:   0.031019 => Txt Tokens per Sec:     2120 || Lr: 0.000050
2024-02-08 14:03:31,191 Epoch 404: Total Training Recognition Loss 0.11  Total Training Translation Loss 6.09 
2024-02-08 14:03:31,191 EPOCH 405
2024-02-08 14:03:37,904 [Epoch: 405 Step: 00053800] Batch Recognition Loss:   0.000516 => Gls Tokens per Sec:      810 || Batch Translation Loss:   0.016390 => Txt Tokens per Sec:     2259 || Lr: 0.000050
2024-02-08 14:03:44,698 Epoch 405: Total Training Recognition Loss 0.07  Total Training Translation Loss 4.25 
2024-02-08 14:03:44,699 EPOCH 406
2024-02-08 14:03:47,996 [Epoch: 406 Step: 00053900] Batch Recognition Loss:   0.002718 => Gls Tokens per Sec:      850 || Batch Translation Loss:   0.038715 => Txt Tokens per Sec:     2277 || Lr: 0.000050
2024-02-08 14:03:58,555 Epoch 406: Total Training Recognition Loss 0.15  Total Training Translation Loss 5.40 
2024-02-08 14:03:58,555 EPOCH 407
2024-02-08 14:03:58,764 [Epoch: 407 Step: 00054000] Batch Recognition Loss:   0.000223 => Gls Tokens per Sec:      776 || Batch Translation Loss:   0.014483 => Txt Tokens per Sec:     1999 || Lr: 0.000050
2024-02-08 14:04:17,056 Validation result at epoch 407, step    54000: duration: 18.2911s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 5.79307	Translation Loss: 89250.80469	PPL: 7438.19092
	Eval Metric: BLEU
	WER 3.39	(DEL: 0.00,	INS: 0.00,	SUB: 3.39)
	BLEU-4 0.65	(BLEU-1: 11.56,	BLEU-2: 3.63,	BLEU-3: 1.36,	BLEU-4: 0.65)
	CHRF 17.32	ROUGE 9.68
2024-02-08 14:04:17,057 Logging Recognition and Translation Outputs
2024-02-08 14:04:17,057 ========================================================================================================================
2024-02-08 14:04:17,057 Logging Sequence: 166_243.00
2024-02-08 14:04:17,058 	Gloss Reference :	A B+C+D+E
2024-02-08 14:04:17,058 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:04:17,058 	Gloss Alignment :	         
2024-02-08 14:04:17,058 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:04:17,059 	Text Reference  :	*** ********* *********** ********* *** ***** ** icc     worked with members boards like bcci pcb   cricket australia etc 
2024-02-08 14:04:17,059 	Text Hypothesis :	the broadcast advertisers ticketing etc would be decided by     the  board   of     the  2    teams playing the       test
2024-02-08 14:04:17,059 	Text Alignment  :	I   I         I           I         I   I     I  S       S      S    S       S      S    S    S     S       S         S   
2024-02-08 14:04:17,060 ========================================================================================================================
2024-02-08 14:04:17,060 Logging Sequence: 179_409.00
2024-02-08 14:04:17,060 	Gloss Reference :	A B+C+D+E
2024-02-08 14:04:17,060 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:04:17,060 	Gloss Alignment :	         
2024-02-08 14:04:17,060 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:04:17,061 	Text Reference  :	the passport  was  at    the       wfi      office in  delhi
2024-02-08 14:04:17,061 	Text Hypothesis :	*** meanwhile some funny incidents happened during the match
2024-02-08 14:04:17,061 	Text Alignment  :	D   S         S    S     S         S        S      S   S    
2024-02-08 14:04:17,061 ========================================================================================================================
2024-02-08 14:04:17,061 Logging Sequence: 81_407.00
2024-02-08 14:04:17,062 	Gloss Reference :	A B+C+D+E
2024-02-08 14:04:17,062 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:04:17,062 	Gloss Alignment :	         
2024-02-08 14:04:17,062 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:04:17,064 	Text Reference  :	the government company -   national buildings construction corporation and  they will complete them     in a   time-bound manner  
2024-02-08 14:04:17,064 	Text Hypothesis :	the ********** company was not      able      to           harbhajan   said it   will be       focussed by the delhi      capitals
2024-02-08 14:04:17,064 	Text Alignment  :	    D                  S   S        S         S            S           S    S         S        S        S  S   S          S       
2024-02-08 14:04:17,064 ========================================================================================================================
2024-02-08 14:04:17,064 Logging Sequence: 96_31.00
2024-02-08 14:04:17,064 	Gloss Reference :	A B+C+D+E
2024-02-08 14:04:17,064 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:04:17,065 	Gloss Alignment :	         
2024-02-08 14:04:17,065 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:04:17,065 	Text Reference  :	and then 2     teams will go  on    to  play the     final
2024-02-08 14:04:17,066 	Text Hypothesis :	*** **** india had   won  the match for 15th october 2023 
2024-02-08 14:04:17,066 	Text Alignment  :	D   D    S     S     S    S   S     S   S    S       S    
2024-02-08 14:04:17,066 ========================================================================================================================
2024-02-08 14:04:17,066 Logging Sequence: 160_87.00
2024-02-08 14:04:17,066 	Gloss Reference :	A B+C+D+E
2024-02-08 14:04:17,066 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:04:17,066 	Gloss Alignment :	         
2024-02-08 14:04:17,066 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:04:17,067 	Text Reference  :	********* ******** ** ********** kohli held  a   press conference and said
2024-02-08 14:04:17,067 	Text Hypothesis :	currently everyone to understand that  india was done  in         the usa 
2024-02-08 14:04:17,067 	Text Alignment  :	I         I        I  I          S     S     S   S     S          S   S   
2024-02-08 14:04:17,067 ========================================================================================================================
2024-02-08 14:04:27,431 [Epoch: 407 Step: 00054100] Batch Recognition Loss:   0.000223 => Gls Tokens per Sec:      771 || Batch Translation Loss:   0.063237 => Txt Tokens per Sec:     2147 || Lr: 0.000050
2024-02-08 14:04:30,729 Epoch 407: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.73 
2024-02-08 14:04:30,730 EPOCH 408
2024-02-08 14:04:37,617 [Epoch: 408 Step: 00054200] Batch Recognition Loss:   0.000142 => Gls Tokens per Sec:      802 || Batch Translation Loss:   0.014872 => Txt Tokens per Sec:     2219 || Lr: 0.000050
2024-02-08 14:04:44,433 Epoch 408: Total Training Recognition Loss 0.12  Total Training Translation Loss 9.43 
2024-02-08 14:04:44,434 EPOCH 409
2024-02-08 14:04:47,843 [Epoch: 409 Step: 00054300] Batch Recognition Loss:   0.000213 => Gls Tokens per Sec:      845 || Batch Translation Loss:   0.048023 => Txt Tokens per Sec:     2294 || Lr: 0.000050
2024-02-08 14:04:58,113 Epoch 409: Total Training Recognition Loss 0.11  Total Training Translation Loss 7.92 
2024-02-08 14:04:58,114 EPOCH 410
2024-02-08 14:04:58,463 [Epoch: 410 Step: 00054400] Batch Recognition Loss:   0.000251 => Gls Tokens per Sec:      690 || Batch Translation Loss:   0.037719 => Txt Tokens per Sec:     2225 || Lr: 0.000050
2024-02-08 14:05:08,753 [Epoch: 410 Step: 00054500] Batch Recognition Loss:   0.000315 => Gls Tokens per Sec:      777 || Batch Translation Loss:   0.088560 => Txt Tokens per Sec:     2129 || Lr: 0.000050
2024-02-08 14:05:11,863 Epoch 410: Total Training Recognition Loss 0.08  Total Training Translation Loss 7.07 
2024-02-08 14:05:11,864 EPOCH 411
2024-02-08 14:05:18,952 [Epoch: 411 Step: 00054600] Batch Recognition Loss:   0.001879 => Gls Tokens per Sec:      790 || Batch Translation Loss:   0.653306 => Txt Tokens per Sec:     2157 || Lr: 0.000050
2024-02-08 14:05:25,587 Epoch 411: Total Training Recognition Loss 0.10  Total Training Translation Loss 7.25 
2024-02-08 14:05:25,588 EPOCH 412
2024-02-08 14:05:29,039 [Epoch: 412 Step: 00054700] Batch Recognition Loss:   0.000173 => Gls Tokens per Sec:      858 || Batch Translation Loss:   0.020483 => Txt Tokens per Sec:     2363 || Lr: 0.000050
2024-02-08 14:05:39,169 Epoch 412: Total Training Recognition Loss 0.09  Total Training Translation Loss 8.47 
2024-02-08 14:05:39,170 EPOCH 413
2024-02-08 14:05:39,499 [Epoch: 413 Step: 00054800] Batch Recognition Loss:   0.000257 => Gls Tokens per Sec:      976 || Batch Translation Loss:   0.132181 => Txt Tokens per Sec:     2541 || Lr: 0.000050
2024-02-08 14:05:49,909 [Epoch: 413 Step: 00054900] Batch Recognition Loss:   0.000357 => Gls Tokens per Sec:      769 || Batch Translation Loss:   0.032951 => Txt Tokens per Sec:     2123 || Lr: 0.000050
2024-02-08 14:05:53,069 Epoch 413: Total Training Recognition Loss 0.07  Total Training Translation Loss 8.21 
2024-02-08 14:05:53,069 EPOCH 414
2024-02-08 14:06:00,328 [Epoch: 414 Step: 00055000] Batch Recognition Loss:   0.000557 => Gls Tokens per Sec:      783 || Batch Translation Loss:   0.034054 => Txt Tokens per Sec:     2194 || Lr: 0.000050
2024-02-08 14:06:06,736 Epoch 414: Total Training Recognition Loss 0.07  Total Training Translation Loss 7.21 
2024-02-08 14:06:06,737 EPOCH 415
2024-02-08 14:06:10,133 [Epoch: 415 Step: 00055100] Batch Recognition Loss:   0.000154 => Gls Tokens per Sec:      895 || Batch Translation Loss:   0.116314 => Txt Tokens per Sec:     2399 || Lr: 0.000050
2024-02-08 14:06:20,280 Epoch 415: Total Training Recognition Loss 0.10  Total Training Translation Loss 7.48 
2024-02-08 14:06:20,281 EPOCH 416
2024-02-08 14:06:20,721 [Epoch: 416 Step: 00055200] Batch Recognition Loss:   0.000998 => Gls Tokens per Sec:      911 || Batch Translation Loss:   0.026478 => Txt Tokens per Sec:     2438 || Lr: 0.000050
2024-02-08 14:06:31,107 [Epoch: 416 Step: 00055300] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:      768 || Batch Translation Loss:   0.073097 => Txt Tokens per Sec:     2132 || Lr: 0.000050
2024-02-08 14:06:34,032 Epoch 416: Total Training Recognition Loss 0.17  Total Training Translation Loss 8.43 
2024-02-08 14:06:34,033 EPOCH 417
2024-02-08 14:06:41,278 [Epoch: 417 Step: 00055400] Batch Recognition Loss:   0.000367 => Gls Tokens per Sec:      795 || Batch Translation Loss:   0.020822 => Txt Tokens per Sec:     2217 || Lr: 0.000050
2024-02-08 14:06:47,595 Epoch 417: Total Training Recognition Loss 0.17  Total Training Translation Loss 5.16 
2024-02-08 14:06:47,595 EPOCH 418
2024-02-08 14:06:51,399 [Epoch: 418 Step: 00055500] Batch Recognition Loss:   0.000436 => Gls Tokens per Sec:      820 || Batch Translation Loss:   0.091524 => Txt Tokens per Sec:     2287 || Lr: 0.000050
2024-02-08 14:07:01,139 Epoch 418: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.49 
2024-02-08 14:07:01,139 EPOCH 419
2024-02-08 14:07:01,785 [Epoch: 419 Step: 00055600] Batch Recognition Loss:   0.001535 => Gls Tokens per Sec:      745 || Batch Translation Loss:   0.027716 => Txt Tokens per Sec:     2113 || Lr: 0.000050
2024-02-08 14:07:11,969 [Epoch: 419 Step: 00055700] Batch Recognition Loss:   0.000158 => Gls Tokens per Sec:      786 || Batch Translation Loss:   0.016623 => Txt Tokens per Sec:     2173 || Lr: 0.000050
2024-02-08 14:07:14,933 Epoch 419: Total Training Recognition Loss 0.13  Total Training Translation Loss 6.77 
2024-02-08 14:07:14,934 EPOCH 420
2024-02-08 14:07:22,069 [Epoch: 420 Step: 00055800] Batch Recognition Loss:   0.000260 => Gls Tokens per Sec:      819 || Batch Translation Loss:   0.197564 => Txt Tokens per Sec:     2258 || Lr: 0.000050
2024-02-08 14:07:28,610 Epoch 420: Total Training Recognition Loss 0.25  Total Training Translation Loss 9.52 
2024-02-08 14:07:28,610 EPOCH 421
2024-02-08 14:07:32,552 [Epoch: 421 Step: 00055900] Batch Recognition Loss:   0.000456 => Gls Tokens per Sec:      812 || Batch Translation Loss:   0.020926 => Txt Tokens per Sec:     2201 || Lr: 0.000050
2024-02-08 14:07:42,080 Epoch 421: Total Training Recognition Loss 0.16  Total Training Translation Loss 5.09 
2024-02-08 14:07:42,080 EPOCH 422
2024-02-08 14:07:42,850 [Epoch: 422 Step: 00056000] Batch Recognition Loss:   0.000264 => Gls Tokens per Sec:      728 || Batch Translation Loss:   0.024911 => Txt Tokens per Sec:     2164 || Lr: 0.000050
2024-02-08 14:08:00,361 Validation result at epoch 422, step    56000: duration: 17.5100s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 6.34038	Translation Loss: 89711.23438	PPL: 7788.24609
	Eval Metric: BLEU
	WER 4.24	(DEL: 0.00,	INS: 0.00,	SUB: 4.24)
	BLEU-4 0.68	(BLEU-1: 10.77,	BLEU-2: 3.47,	BLEU-3: 1.35,	BLEU-4: 0.68)
	CHRF 16.97	ROUGE 9.35
2024-02-08 14:08:00,363 Logging Recognition and Translation Outputs
2024-02-08 14:08:00,363 ========================================================================================================================
2024-02-08 14:08:00,363 Logging Sequence: 177_167.00
2024-02-08 14:08:00,363 	Gloss Reference :	A B+C+D+E
2024-02-08 14:08:00,363 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:08:00,363 	Gloss Alignment :	         
2024-02-08 14:08:00,364 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:08:00,365 	Text Reference  :	*** ********** this    is  because sushil   wanted  to  establish his  fear   to   ensure no one       would oppose him    
2024-02-08 14:08:00,365 	Text Hypothesis :	who graciously accepts one and     politely returns the wfi       kept saying that will   be available for   the    matches
2024-02-08 14:08:00,366 	Text Alignment  :	I   I          S       S   S       S        S       S   S         S    S      S    S      S  S         S     S      S      
2024-02-08 14:08:00,366 ========================================================================================================================
2024-02-08 14:08:00,366 Logging Sequence: 127_140.00
2024-02-08 14:08:00,366 	Gloss Reference :	A B+C+D+E
2024-02-08 14:08:00,366 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:08:00,366 	Gloss Alignment :	         
2024-02-08 14:08:00,367 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:08:00,368 	Text Reference  :	this  is  india' 3rd  medal in the world athletics championships he    is very talented and his performance is   highly  impressive
2024-02-08 14:08:00,368 	Text Hypothesis :	india now hotel  room rates in *** ***** ********* ************* india is **** ******** *** *** *********** 15th october 2023      
2024-02-08 14:08:00,368 	Text Alignment  :	S     S   S      S    S        D   D     D         D             S        D    D        D   D   D           S    S       S         
2024-02-08 14:08:00,368 ========================================================================================================================
2024-02-08 14:08:00,368 Logging Sequence: 126_200.00
2024-02-08 14:08:00,369 	Gloss Reference :	A B+C+D+E
2024-02-08 14:08:00,369 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:08:00,369 	Gloss Alignment :	         
2024-02-08 14:08:00,369 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:08:00,370 	Text Reference  :	let me tell you about them
2024-02-08 14:08:00,370 	Text Hypothesis :	let me tell you about it  
2024-02-08 14:08:00,370 	Text Alignment  :	                      S   
2024-02-08 14:08:00,370 ========================================================================================================================
2024-02-08 14:08:00,370 Logging Sequence: 104_119.00
2024-02-08 14:08:00,370 	Gloss Reference :	A B+C+D+E
2024-02-08 14:08:00,370 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:08:00,370 	Gloss Alignment :	         
2024-02-08 14:08:00,371 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:08:00,372 	Text Reference  :	famous chess players like viswanathan anand and     praggnanandhaa's coach r   b   ramesh congratulated him   for    his     impressive performance
2024-02-08 14:08:00,372 	Text Hypothesis :	****** ***** ******* **** *********** the   women's team             too   had won a      young         young player without the        world      
2024-02-08 14:08:00,372 	Text Alignment  :	D      D     D       D    D           S     S       S                S     S   S   S      S             S     S      S       S          S          
2024-02-08 14:08:00,372 ========================================================================================================================
2024-02-08 14:08:00,373 Logging Sequence: 172_267.00
2024-02-08 14:08:00,373 	Gloss Reference :	A B+C+D+E
2024-02-08 14:08:00,373 	Gloss Hypothesis:	A B+C+D+E
2024-02-08 14:08:00,373 	Gloss Alignment :	         
2024-02-08 14:08:00,373 	--------------------------------------------------------------------------------------------------------------------
2024-02-08 14:08:00,374 	Text Reference  :	**** ** *** *** **** such provisions have      been made 
2024-02-08 14:08:00,374 	Text Hypothesis :	this is why the bcci had  a          statement on   there
2024-02-08 14:08:00,374 	Text Alignment  :	I    I  I   I   I    S    S          S         S    S    
2024-02-08 14:08:00,374 ========================================================================================================================
2024-02-08 14:08:00,378 Training ended since there were no improvements inthe last learning rate step: 0.000050
2024-02-08 14:08:00,379 Best validation result at step     4000:   0.90 eval_metric.
2024-02-08 14:08:34,140 ------------------------------------------------------------
2024-02-08 14:08:34,140 [DEV] partition [RECOGNITION] experiment [BW]: 1
2024-02-08 14:08:52,386 finished in 18.2457s 
2024-02-08 14:08:52,386 ************************************************************
2024-02-08 14:08:52,386 [DEV] partition [RECOGNITION] results:
	New Best CTC Decode Beam Size: 1
	WER 6.21	(DEL: 0.00,	INS: 0.00,	SUB: 6.21)
2024-02-08 14:08:52,387 ************************************************************
2024-02-08 14:08:52,387 ------------------------------------------------------------
2024-02-08 14:08:52,387 [DEV] partition [RECOGNITION] experiment [BW]: 2
2024-02-08 14:09:10,572 finished in 18.1855s 
2024-02-08 14:09:10,573 ************************************************************
2024-02-08 14:09:10,573 [DEV] partition [RECOGNITION] results:
	New Best CTC Decode Beam Size: 2
	WER 6.00	(DEL: 0.00,	INS: 0.00,	SUB: 6.00)
2024-02-08 14:09:10,573 ************************************************************
2024-02-08 14:09:10,573 ------------------------------------------------------------
2024-02-08 14:09:10,573 [DEV] partition [RECOGNITION] experiment [BW]: 3
2024-02-08 14:09:28,847 finished in 18.2742s 
2024-02-08 14:09:28,848 ------------------------------------------------------------
2024-02-08 14:09:28,848 [DEV] partition [RECOGNITION] experiment [BW]: 4
2024-02-08 14:09:47,356 finished in 18.5072s 
2024-02-08 14:09:47,356 ------------------------------------------------------------
2024-02-08 14:09:47,356 [DEV] partition [RECOGNITION] experiment [BW]: 5
2024-02-08 14:10:05,643 finished in 18.2865s 
2024-02-08 14:10:05,644 ------------------------------------------------------------
2024-02-08 14:10:05,644 [DEV] partition [RECOGNITION] experiment [BW]: 6
2024-02-08 14:10:23,802 finished in 18.1580s 
2024-02-08 14:10:23,803 ------------------------------------------------------------
2024-02-08 14:10:23,803 [DEV] partition [RECOGNITION] experiment [BW]: 7
2024-02-08 14:10:42,076 finished in 18.2724s 
2024-02-08 14:10:42,076 ------------------------------------------------------------
2024-02-08 14:10:42,076 [DEV] partition [RECOGNITION] experiment [BW]: 8
2024-02-08 14:11:00,358 finished in 18.2814s 
2024-02-08 14:11:00,358 ------------------------------------------------------------
2024-02-08 14:11:00,358 [DEV] partition [RECOGNITION] experiment [BW]: 9
2024-02-08 14:11:18,608 finished in 18.2500s 
2024-02-08 14:11:18,608 ------------------------------------------------------------
2024-02-08 14:11:18,608 [DEV] partition [RECOGNITION] experiment [BW]: 10
2024-02-08 14:11:36,976 finished in 18.3685s 
2024-02-08 14:11:36,976 ============================================================
2024-02-08 14:11:55,160 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: -1
	BLEU-4 0.90	(BLEU-1: 13.04,	BLEU-2: 4.63,	BLEU-3: 1.79,	BLEU-4: 0.90)
	CHRF 16.97	ROUGE 10.51
2024-02-08 14:11:55,161 ------------------------------------------------------------
2024-02-08 14:13:18,387 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 2 and Alpha: -1
	BLEU-4 0.93	(BLEU-1: 11.44,	BLEU-2: 4.12,	BLEU-3: 1.78,	BLEU-4: 0.93)
	CHRF 16.22	ROUGE 9.63
2024-02-08 14:13:18,388 ------------------------------------------------------------
2024-02-08 14:13:48,225 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 2 and Alpha: 1
	BLEU-4 0.93	(BLEU-1: 11.64,	BLEU-2: 4.22,	BLEU-3: 1.81,	BLEU-4: 0.93)
	CHRF 16.26	ROUGE 9.61
2024-02-08 14:13:48,225 ------------------------------------------------------------
2024-02-08 14:14:07,486 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 2 and Alpha: 2
	BLEU-4 0.96	(BLEU-1: 11.92,	BLEU-2: 4.27,	BLEU-3: 1.82,	BLEU-4: 0.96)
	CHRF 16.30	ROUGE 9.54
2024-02-08 14:14:07,486 ------------------------------------------------------------
2024-02-08 14:14:26,905 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 2 and Alpha: 3
	BLEU-4 0.96	(BLEU-1: 11.98,	BLEU-2: 4.31,	BLEU-3: 1.83,	BLEU-4: 0.96)
	CHRF 16.31	ROUGE 9.52
2024-02-08 14:14:26,906 ------------------------------------------------------------
2024-02-08 14:16:14,856 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 3 and Alpha: 2
	BLEU-4 1.05	(BLEU-1: 11.65,	BLEU-2: 4.38,	BLEU-3: 1.98,	BLEU-4: 1.05)
	CHRF 16.14	ROUGE 9.57
2024-02-08 14:16:14,857 ------------------------------------------------------------
2024-02-08 14:16:54,675 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 3 and Alpha: 4
	BLEU-4 1.05	(BLEU-1: 11.81,	BLEU-2: 4.42,	BLEU-3: 1.99,	BLEU-4: 1.05)
	CHRF 16.18	ROUGE 9.55
2024-02-08 14:16:54,676 ------------------------------------------------------------
2024-02-08 14:40:38,330 ************************************************************
2024-02-08 14:40:38,330 [DEV] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 2
	Best Translation Beam Size: 3 and Alpha: 4
	WER 6.00	(DEL: 0.00,	INS: 0.00,	SUB: 6.00)
	BLEU-4 1.05	(BLEU-1: 11.81,	BLEU-2: 4.42,	BLEU-3: 1.99,	BLEU-4: 1.05)
	CHRF 16.18	ROUGE 9.55
2024-02-08 14:40:38,331 ************************************************************
2024-02-08 14:40:53,065 [TEST] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 2
	Best Translation Beam Size: 3 and Alpha: 4
	WER 4.17	(DEL: 0.00,	INS: 0.00,	SUB: 4.17)
	BLEU-4 0.81	(BLEU-1: 11.35,	BLEU-2: 3.91,	BLEU-3: 1.65,	BLEU-4: 0.81)
	CHRF 16.08	ROUGE 9.35
2024-02-08 14:40:53,065 ************************************************************
