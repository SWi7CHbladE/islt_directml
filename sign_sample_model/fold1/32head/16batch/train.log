2024-02-03 03:50:17,907 Hello! This is Joey-NMT.
2024-02-03 03:50:17,923 Total params: 25618440
2024-02-03 03:50:17,924 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'gloss_output_layer.bias', 'gloss_output_layer.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2024-02-03 03:50:19,133 cfg.name                           : sign_experiment
2024-02-03 03:50:19,133 cfg.data.data_path                 : ./data/Sports_dataset/1/
2024-02-03 03:50:19,133 cfg.data.version                   : phoenix_2014_trans
2024-02-03 03:50:19,134 cfg.data.sgn                       : sign
2024-02-03 03:50:19,134 cfg.data.txt                       : text
2024-02-03 03:50:19,134 cfg.data.gls                       : gloss
2024-02-03 03:50:19,134 cfg.data.train                     : excel_data.train
2024-02-03 03:50:19,134 cfg.data.dev                       : excel_data.dev
2024-02-03 03:50:19,134 cfg.data.test                      : excel_data.test
2024-02-03 03:50:19,134 cfg.data.feature_size              : 2560
2024-02-03 03:50:19,135 cfg.data.level                     : word
2024-02-03 03:50:19,135 cfg.data.txt_lowercase             : True
2024-02-03 03:50:19,135 cfg.data.max_sent_length           : 500
2024-02-03 03:50:19,135 cfg.data.random_train_subset       : -1
2024-02-03 03:50:19,135 cfg.data.random_dev_subset         : -1
2024-02-03 03:50:19,135 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-02-03 03:50:19,135 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2024-02-03 03:50:19,135 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2024-02-03 03:50:19,136 cfg.training.reset_best_ckpt       : False
2024-02-03 03:50:19,136 cfg.training.reset_scheduler       : False
2024-02-03 03:50:19,136 cfg.training.reset_optimizer       : False
2024-02-03 03:50:19,136 cfg.training.random_seed           : 42
2024-02-03 03:50:19,136 cfg.training.model_dir             : ./sign_sample_model/fold1/32head/16batch
2024-02-03 03:50:19,136 cfg.training.recognition_loss_weight : 1.0
2024-02-03 03:50:19,136 cfg.training.translation_loss_weight : 1.0
2024-02-03 03:50:19,137 cfg.training.eval_metric           : bleu
2024-02-03 03:50:19,137 cfg.training.optimizer             : adam
2024-02-03 03:50:19,137 cfg.training.learning_rate         : 0.0001
2024-02-03 03:50:19,137 cfg.training.batch_size            : 16
2024-02-03 03:50:19,137 cfg.training.num_valid_log         : 5
2024-02-03 03:50:19,137 cfg.training.epochs                : 50000
2024-02-03 03:50:19,137 cfg.training.early_stopping_metric : eval_metric
2024-02-03 03:50:19,137 cfg.training.batch_type            : sentence
2024-02-03 03:50:19,138 cfg.training.translation_normalization : batch
2024-02-03 03:50:19,138 cfg.training.eval_recognition_beam_size : 1
2024-02-03 03:50:19,138 cfg.training.eval_translation_beam_size : 1
2024-02-03 03:50:19,138 cfg.training.eval_translation_beam_alpha : -1
2024-02-03 03:50:19,138 cfg.training.overwrite             : True
2024-02-03 03:50:19,138 cfg.training.shuffle               : True
2024-02-03 03:50:19,138 cfg.training.use_cuda              : True
2024-02-03 03:50:19,138 cfg.training.translation_max_output_length : 40
2024-02-03 03:50:19,139 cfg.training.keep_last_ckpts       : 1
2024-02-03 03:50:19,139 cfg.training.batch_multiplier      : 1
2024-02-03 03:50:19,139 cfg.training.logging_freq          : 100
2024-02-03 03:50:19,139 cfg.training.validation_freq       : 2000
2024-02-03 03:50:19,139 cfg.training.betas                 : [0.9, 0.998]
2024-02-03 03:50:19,139 cfg.training.scheduling            : plateau
2024-02-03 03:50:19,139 cfg.training.learning_rate_min     : 1e-08
2024-02-03 03:50:19,139 cfg.training.weight_decay          : 0.0001
2024-02-03 03:50:19,139 cfg.training.patience              : 12
2024-02-03 03:50:19,140 cfg.training.decrease_factor       : 0.5
2024-02-03 03:50:19,140 cfg.training.label_smoothing       : 0.0
2024-02-03 03:50:19,140 cfg.model.initializer              : xavier
2024-02-03 03:50:19,140 cfg.model.bias_initializer         : zeros
2024-02-03 03:50:19,140 cfg.model.init_gain                : 1.0
2024-02-03 03:50:19,140 cfg.model.embed_initializer        : xavier
2024-02-03 03:50:19,140 cfg.model.embed_init_gain          : 1.0
2024-02-03 03:50:19,140 cfg.model.tied_softmax             : True
2024-02-03 03:50:19,141 cfg.model.encoder.type             : transformer
2024-02-03 03:50:19,141 cfg.model.encoder.num_layers       : 3
2024-02-03 03:50:19,141 cfg.model.encoder.num_heads        : 32
2024-02-03 03:50:19,141 cfg.model.encoder.embeddings.embedding_dim : 512
2024-02-03 03:50:19,141 cfg.model.encoder.embeddings.scale : False
2024-02-03 03:50:19,141 cfg.model.encoder.embeddings.dropout : 0.1
2024-02-03 03:50:19,141 cfg.model.encoder.embeddings.norm_type : batch
2024-02-03 03:50:19,141 cfg.model.encoder.embeddings.activation_type : softsign
2024-02-03 03:50:19,142 cfg.model.encoder.hidden_size      : 512
2024-02-03 03:50:19,142 cfg.model.encoder.ff_size          : 2048
2024-02-03 03:50:19,142 cfg.model.encoder.dropout          : 0.1
2024-02-03 03:50:19,142 cfg.model.decoder.type             : transformer
2024-02-03 03:50:19,142 cfg.model.decoder.num_layers       : 3
2024-02-03 03:50:19,142 cfg.model.decoder.num_heads        : 32
2024-02-03 03:50:19,142 cfg.model.decoder.embeddings.embedding_dim : 512
2024-02-03 03:50:19,142 cfg.model.decoder.embeddings.scale : False
2024-02-03 03:50:19,142 cfg.model.decoder.embeddings.dropout : 0.1
2024-02-03 03:50:19,143 cfg.model.decoder.embeddings.norm_type : batch
2024-02-03 03:50:19,143 cfg.model.decoder.embeddings.activation_type : softsign
2024-02-03 03:50:19,143 cfg.model.decoder.hidden_size      : 512
2024-02-03 03:50:19,143 cfg.model.decoder.ff_size          : 2048
2024-02-03 03:50:19,143 cfg.model.decoder.dropout          : 0.1
2024-02-03 03:50:19,143 Data set sizes: 
	train 2126,
	valid 707,
	test 708
2024-02-03 03:50:19,143 First training example:
	[GLS] A B C D E
	[TXT] another problem is that because of ipl and t20 world cup many players may not be available for the matches
2024-02-03 03:50:19,144 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) A (4) B (5) C (6) D (7) E
2024-02-03 03:50:19,144 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) to (6) and (7) in (8) a (9) of
2024-02-03 03:50:19,144 Number of unique glosses (types): 8
2024-02-03 03:50:19,144 Number of unique words (types): 4355
2024-02-03 03:50:19,144 SignModel(
	encoder=TransformerEncoder(num_layers=3, num_heads=32),
	decoder=TransformerDecoder(num_layers=3, num_heads=32),
	sgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=2560),
	txt_embed=Embeddings(embedding_dim=512, vocab_size=4355))
2024-02-03 03:50:19,155 EPOCH 1
2024-02-03 03:50:25,058 [Epoch: 001 Step: 00000100] Batch Recognition Loss:   2.308783 => Gls Tokens per Sec:     1355 || Batch Translation Loss:  74.312836 => Txt Tokens per Sec:     3790 || Lr: 0.000100
2024-02-03 03:50:26,915 Epoch   1: Total Training Recognition Loss 529.31  Total Training Translation Loss 12520.76 
2024-02-03 03:50:26,915 EPOCH 2
2024-02-03 03:50:30,704 [Epoch: 002 Step: 00000200] Batch Recognition Loss:   2.146464 => Gls Tokens per Sec:     1415 || Batch Translation Loss:  78.580765 => Txt Tokens per Sec:     3983 || Lr: 0.000100
2024-02-03 03:50:34,542 Epoch   2: Total Training Recognition Loss 275.06  Total Training Translation Loss 11700.92 
2024-02-03 03:50:34,542 EPOCH 3
2024-02-03 03:50:36,461 [Epoch: 003 Step: 00000300] Batch Recognition Loss:   0.959704 => Gls Tokens per Sec:     1419 || Batch Translation Loss:  69.009903 => Txt Tokens per Sec:     3981 || Lr: 0.000100
2024-02-03 03:50:42,230 Epoch   3: Total Training Recognition Loss 166.55  Total Training Translation Loss 11293.94 
2024-02-03 03:50:42,230 EPOCH 4
2024-02-03 03:50:42,308 [Epoch: 004 Step: 00000400] Batch Recognition Loss:   0.666638 => Gls Tokens per Sec:     1039 || Batch Translation Loss:  90.959793 => Txt Tokens per Sec:     3221 || Lr: 0.000100
2024-02-03 03:50:47,614 [Epoch: 004 Step: 00000500] Batch Recognition Loss:   0.133374 => Gls Tokens per Sec:     1508 || Batch Translation Loss:  66.114105 => Txt Tokens per Sec:     4184 || Lr: 0.000100
2024-02-03 03:50:49,314 Epoch   4: Total Training Recognition Loss 91.86  Total Training Translation Loss 10741.83 
2024-02-03 03:50:49,314 EPOCH 5
2024-02-03 03:50:52,927 [Epoch: 005 Step: 00000600] Batch Recognition Loss:   0.585382 => Gls Tokens per Sec:     1506 || Batch Translation Loss:  74.243324 => Txt Tokens per Sec:     4230 || Lr: 0.000100
2024-02-03 03:50:56,625 Epoch   5: Total Training Recognition Loss 66.01  Total Training Translation Loss 10217.85 
2024-02-03 03:50:56,625 EPOCH 6
2024-02-03 03:50:58,537 [Epoch: 006 Step: 00000700] Batch Recognition Loss:   0.023441 => Gls Tokens per Sec:     1466 || Batch Translation Loss:  65.456398 => Txt Tokens per Sec:     3970 || Lr: 0.000100
2024-02-03 03:51:04,007 Epoch   6: Total Training Recognition Loss 50.47  Total Training Translation Loss 9731.91 
2024-02-03 03:51:04,007 EPOCH 7
2024-02-03 03:51:04,116 [Epoch: 007 Step: 00000800] Batch Recognition Loss:   0.273046 => Gls Tokens per Sec:     1481 || Batch Translation Loss:  50.269619 => Txt Tokens per Sec:     4176 || Lr: 0.000100
2024-02-03 03:51:09,804 [Epoch: 007 Step: 00000900] Batch Recognition Loss:   0.035248 => Gls Tokens per Sec:     1406 || Batch Translation Loss:  73.459366 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-03 03:51:11,508 Epoch   7: Total Training Recognition Loss 36.30  Total Training Translation Loss 9242.49 
2024-02-03 03:51:11,508 EPOCH 8
2024-02-03 03:51:15,030 [Epoch: 008 Step: 00001000] Batch Recognition Loss:   0.124247 => Gls Tokens per Sec:     1568 || Batch Translation Loss:  52.901939 => Txt Tokens per Sec:     4266 || Lr: 0.000100
2024-02-03 03:51:18,873 Epoch   8: Total Training Recognition Loss 30.24  Total Training Translation Loss 8800.43 
2024-02-03 03:51:18,873 EPOCH 9
2024-02-03 03:51:20,745 [Epoch: 009 Step: 00001100] Batch Recognition Loss:   0.016807 => Gls Tokens per Sec:     1539 || Batch Translation Loss:  51.769588 => Txt Tokens per Sec:     4233 || Lr: 0.000100
2024-02-03 03:51:26,404 Epoch   9: Total Training Recognition Loss 28.67  Total Training Translation Loss 8375.90 
2024-02-03 03:51:26,405 EPOCH 10
2024-02-03 03:51:26,566 [Epoch: 010 Step: 00001200] Batch Recognition Loss:   0.088801 => Gls Tokens per Sec:     1497 || Batch Translation Loss:  35.606567 => Txt Tokens per Sec:     4036 || Lr: 0.000100
2024-02-03 03:51:31,599 [Epoch: 010 Step: 00001300] Batch Recognition Loss:   0.096318 => Gls Tokens per Sec:     1590 || Batch Translation Loss:  54.584084 => Txt Tokens per Sec:     4427 || Lr: 0.000100
2024-02-03 03:51:33,489 Epoch  10: Total Training Recognition Loss 22.23  Total Training Translation Loss 7962.53 
2024-02-03 03:51:33,490 EPOCH 11
2024-02-03 03:51:37,198 [Epoch: 011 Step: 00001400] Batch Recognition Loss:   0.389987 => Gls Tokens per Sec:     1511 || Batch Translation Loss:  59.032639 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-03 03:51:40,868 Epoch  11: Total Training Recognition Loss 19.92  Total Training Translation Loss 7538.21 
2024-02-03 03:51:40,868 EPOCH 12
2024-02-03 03:51:43,068 [Epoch: 012 Step: 00001500] Batch Recognition Loss:   0.041607 => Gls Tokens per Sec:     1346 || Batch Translation Loss:  48.473625 => Txt Tokens per Sec:     3659 || Lr: 0.000100
2024-02-03 03:51:48,725 Epoch  12: Total Training Recognition Loss 17.83  Total Training Translation Loss 7139.95 
2024-02-03 03:51:48,725 EPOCH 13
2024-02-03 03:51:48,907 [Epoch: 013 Step: 00001600] Batch Recognition Loss:   0.077440 => Gls Tokens per Sec:     1768 || Batch Translation Loss:  51.975346 => Txt Tokens per Sec:     4680 || Lr: 0.000100
2024-02-03 03:51:54,618 [Epoch: 013 Step: 00001700] Batch Recognition Loss:   0.021519 => Gls Tokens per Sec:     1401 || Batch Translation Loss:  41.797359 => Txt Tokens per Sec:     3876 || Lr: 0.000100
2024-02-03 03:51:56,205 Epoch  13: Total Training Recognition Loss 16.84  Total Training Translation Loss 6740.57 
2024-02-03 03:51:56,205 EPOCH 14
2024-02-03 03:51:59,744 [Epoch: 014 Step: 00001800] Batch Recognition Loss:   0.181905 => Gls Tokens per Sec:     1605 || Batch Translation Loss:  29.849140 => Txt Tokens per Sec:     4422 || Lr: 0.000100
2024-02-03 03:52:03,469 Epoch  14: Total Training Recognition Loss 16.30  Total Training Translation Loss 6360.90 
2024-02-03 03:52:03,470 EPOCH 15
2024-02-03 03:52:05,718 [Epoch: 015 Step: 00001900] Batch Recognition Loss:   0.020799 => Gls Tokens per Sec:     1353 || Batch Translation Loss:  41.583908 => Txt Tokens per Sec:     3835 || Lr: 0.000100
2024-02-03 03:52:11,160 Epoch  15: Total Training Recognition Loss 16.43  Total Training Translation Loss 5986.78 
2024-02-03 03:52:11,160 EPOCH 16
2024-02-03 03:52:11,424 [Epoch: 016 Step: 00002000] Batch Recognition Loss:   0.123933 => Gls Tokens per Sec:     1521 || Batch Translation Loss:  25.429995 => Txt Tokens per Sec:     4259 || Lr: 0.000100
2024-02-03 03:52:22,965 Hooray! New best validation result [eval_metric]!
2024-02-03 03:52:22,966 Saving new checkpoint.
2024-02-03 03:52:23,261 Validation result at epoch  16, step     2000: duration: 11.8364s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.85081	Translation Loss: 56558.52344	PPL: 355.80368
	Eval Metric: BLEU
	WER 7.28	(DEL: 0.14,	INS: 0.00,	SUB: 7.14)
	BLEU-4 0.00	(BLEU-1: 12.43,	BLEU-2: 4.32,	BLEU-3: 1.39,	BLEU-4: 0.00)
	CHRF 16.00	ROUGE 11.23
2024-02-03 03:52:23,263 Logging Recognition and Translation Outputs
2024-02-03 03:52:23,263 ========================================================================================================================
2024-02-03 03:52:23,263 Logging Sequence: 143_161.00
2024-02-03 03:52:23,264 	Gloss Reference :	A B+C+D+E
2024-02-03 03:52:23,264 	Gloss Hypothesis:	A B+C+E  
2024-02-03 03:52:23,264 	Gloss Alignment :	  S      
2024-02-03 03:52:23,264 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:52:23,265 	Text Reference  :	there is  no    response from them as  yet 
2024-02-03 03:52:23,265 	Text Hypothesis :	***** the match was      held in   the same
2024-02-03 03:52:23,265 	Text Alignment  :	D     S   S     S        S    S    S   S   
2024-02-03 03:52:23,265 ========================================================================================================================
2024-02-03 03:52:23,265 Logging Sequence: 63_21.00
2024-02-03 03:52:23,266 	Gloss Reference :	A B+C+D+E
2024-02-03 03:52:23,266 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:52:23,266 	Gloss Alignment :	         
2024-02-03 03:52:23,266 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:52:23,267 	Text Reference  :	however the **** ** **** ***** teams will    be announced only on   25th october 2021      
2024-02-03 03:52:23,267 	Text Hypothesis :	******* the team is very happy and   captain to the       ipl  team is   very    protective
2024-02-03 03:52:23,267 	Text Alignment  :	D           I    I  I    I     S     S       S  S         S    S    S    S       S         
2024-02-03 03:52:23,267 ========================================================================================================================
2024-02-03 03:52:23,268 Logging Sequence: 122_147.00
2024-02-03 03:52:23,268 	Gloss Reference :	A B+C+D+E
2024-02-03 03:52:23,268 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:52:23,268 	Gloss Alignment :	         
2024-02-03 03:52:23,268 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:52:23,269 	Text Reference  :	chanu had  been working as  a *** ** tickets inspector in the indian railways 
2024-02-03 03:52:23,269 	Text Hypothesis :	she   said that she     was a lot of winning as        a  lot of     instagram
2024-02-03 03:52:23,270 	Text Alignment  :	S     S    S    S       S     I   I  S       S         S  S   S      S        
2024-02-03 03:52:23,270 ========================================================================================================================
2024-02-03 03:52:23,270 Logging Sequence: 87_196.00
2024-02-03 03:52:23,270 	Gloss Reference :	A B+C+D+E
2024-02-03 03:52:23,270 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:52:23,270 	Gloss Alignment :	         
2024-02-03 03:52:23,271 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:52:23,271 	Text Reference  :	******* my  expression was not * ***** ** against dhoni or     kohli
2024-02-03 03:52:23,271 	Text Hypothesis :	however the video      was not a video of video   on    social media
2024-02-03 03:52:23,272 	Text Alignment  :	I       S   S                  I I     I  S       S     S      S    
2024-02-03 03:52:23,272 ========================================================================================================================
2024-02-03 03:52:23,272 Logging Sequence: 114_153.00
2024-02-03 03:52:23,272 	Gloss Reference :	A B+C+D+E
2024-02-03 03:52:23,272 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:52:23,272 	Gloss Alignment :	         
2024-02-03 03:52:23,272 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:52:23,274 	Text Reference  :	******* another big football news is     that the ****** *** *** *** ** ** **** copa america final
2024-02-03 03:52:23,274 	Text Hypothesis :	however a       lot of       the  reason for  the reason was not not to be held on   social  media
2024-02-03 03:52:23,274 	Text Alignment  :	I       S       S   S        S    S      S        I      I   I   I   I  I  I    S    S       S    
2024-02-03 03:52:23,274 ========================================================================================================================
2024-02-03 03:52:28,842 [Epoch: 016 Step: 00002100] Batch Recognition Loss:   0.129313 => Gls Tokens per Sec:     1433 || Batch Translation Loss:  41.661831 => Txt Tokens per Sec:     3993 || Lr: 0.000100
2024-02-03 03:52:30,350 Epoch  16: Total Training Recognition Loss 14.84  Total Training Translation Loss 5615.51 
2024-02-03 03:52:30,350 EPOCH 17
2024-02-03 03:52:34,097 [Epoch: 017 Step: 00002200] Batch Recognition Loss:   0.028243 => Gls Tokens per Sec:     1538 || Batch Translation Loss:  35.135498 => Txt Tokens per Sec:     4294 || Lr: 0.000100
2024-02-03 03:52:37,483 Epoch  17: Total Training Recognition Loss 14.56  Total Training Translation Loss 5239.31 
2024-02-03 03:52:37,484 EPOCH 18
2024-02-03 03:52:39,658 [Epoch: 018 Step: 00002300] Batch Recognition Loss:   0.041298 => Gls Tokens per Sec:     1436 || Batch Translation Loss:  29.873781 => Txt Tokens per Sec:     4007 || Lr: 0.000100
2024-02-03 03:52:45,123 Epoch  18: Total Training Recognition Loss 14.87  Total Training Translation Loss 4924.70 
2024-02-03 03:52:45,124 EPOCH 19
2024-02-03 03:52:45,410 [Epoch: 019 Step: 00002400] Batch Recognition Loss:   0.079336 => Gls Tokens per Sec:     1684 || Batch Translation Loss:  43.931393 => Txt Tokens per Sec:     4558 || Lr: 0.000100
2024-02-03 03:52:51,277 [Epoch: 019 Step: 00002500] Batch Recognition Loss:   0.099261 => Gls Tokens per Sec:     1364 || Batch Translation Loss:  40.641113 => Txt Tokens per Sec:     3805 || Lr: 0.000100
2024-02-03 03:52:52,798 Epoch  19: Total Training Recognition Loss 14.18  Total Training Translation Loss 4531.93 
2024-02-03 03:52:52,798 EPOCH 20
2024-02-03 03:52:56,805 [Epoch: 020 Step: 00002600] Batch Recognition Loss:   0.080527 => Gls Tokens per Sec:     1458 || Batch Translation Loss:  41.617981 => Txt Tokens per Sec:     4011 || Lr: 0.000100
2024-02-03 03:53:00,230 Epoch  20: Total Training Recognition Loss 13.39  Total Training Translation Loss 4196.11 
2024-02-03 03:53:00,231 EPOCH 21
2024-02-03 03:53:02,596 [Epoch: 021 Step: 00002700] Batch Recognition Loss:   0.016040 => Gls Tokens per Sec:     1354 || Batch Translation Loss:  25.405052 => Txt Tokens per Sec:     3860 || Lr: 0.000100
2024-02-03 03:53:07,854 Epoch  21: Total Training Recognition Loss 13.44  Total Training Translation Loss 3821.63 
2024-02-03 03:53:07,855 EPOCH 22
2024-02-03 03:53:08,171 [Epoch: 022 Step: 00002800] Batch Recognition Loss:   0.043907 => Gls Tokens per Sec:     1772 || Batch Translation Loss:  19.935125 => Txt Tokens per Sec:     4437 || Lr: 0.000100
2024-02-03 03:53:13,227 [Epoch: 022 Step: 00002900] Batch Recognition Loss:   0.166864 => Gls Tokens per Sec:     1581 || Batch Translation Loss:  13.826159 => Txt Tokens per Sec:     4421 || Lr: 0.000100
2024-02-03 03:53:14,447 Epoch  22: Total Training Recognition Loss 13.30  Total Training Translation Loss 3497.29 
2024-02-03 03:53:14,447 EPOCH 23
2024-02-03 03:53:18,193 [Epoch: 023 Step: 00003000] Batch Recognition Loss:   0.335547 => Gls Tokens per Sec:     1581 || Batch Translation Loss:   7.980148 => Txt Tokens per Sec:     4361 || Lr: 0.000100
2024-02-03 03:53:21,279 Epoch  23: Total Training Recognition Loss 13.48  Total Training Translation Loss 3186.18 
2024-02-03 03:53:21,280 EPOCH 24
2024-02-03 03:53:23,528 [Epoch: 024 Step: 00003100] Batch Recognition Loss:   0.029673 => Gls Tokens per Sec:     1460 || Batch Translation Loss:  19.394800 => Txt Tokens per Sec:     4031 || Lr: 0.000100
2024-02-03 03:53:28,886 Epoch  24: Total Training Recognition Loss 12.58  Total Training Translation Loss 2886.44 
2024-02-03 03:53:28,887 EPOCH 25
2024-02-03 03:53:29,329 [Epoch: 025 Step: 00003200] Batch Recognition Loss:   0.047880 => Gls Tokens per Sec:     1451 || Batch Translation Loss:  16.965063 => Txt Tokens per Sec:     3993 || Lr: 0.000100
2024-02-03 03:53:34,861 [Epoch: 025 Step: 00003300] Batch Recognition Loss:   0.036828 => Gls Tokens per Sec:     1445 || Batch Translation Loss:  15.264715 => Txt Tokens per Sec:     4034 || Lr: 0.000100
2024-02-03 03:53:36,126 Epoch  25: Total Training Recognition Loss 12.13  Total Training Translation Loss 2600.93 
2024-02-03 03:53:36,126 EPOCH 26
2024-02-03 03:53:40,037 [Epoch: 026 Step: 00003400] Batch Recognition Loss:   0.286469 => Gls Tokens per Sec:     1535 || Batch Translation Loss:   4.584691 => Txt Tokens per Sec:     4208 || Lr: 0.000100
2024-02-03 03:53:43,281 Epoch  26: Total Training Recognition Loss 12.21  Total Training Translation Loss 2316.89 
2024-02-03 03:53:43,281 EPOCH 27
2024-02-03 03:53:45,484 [Epoch: 027 Step: 00003500] Batch Recognition Loss:   0.018900 => Gls Tokens per Sec:     1527 || Batch Translation Loss:  16.876574 => Txt Tokens per Sec:     4017 || Lr: 0.000100
2024-02-03 03:53:50,896 Epoch  27: Total Training Recognition Loss 12.40  Total Training Translation Loss 2093.87 
2024-02-03 03:53:50,897 EPOCH 28
2024-02-03 03:53:51,321 [Epoch: 028 Step: 00003600] Batch Recognition Loss:   0.178007 => Gls Tokens per Sec:     1700 || Batch Translation Loss:  16.992315 => Txt Tokens per Sec:     4956 || Lr: 0.000100
2024-02-03 03:53:57,082 [Epoch: 028 Step: 00003700] Batch Recognition Loss:   0.059752 => Gls Tokens per Sec:     1389 || Batch Translation Loss:   9.492186 => Txt Tokens per Sec:     3875 || Lr: 0.000100
2024-02-03 03:53:58,443 Epoch  28: Total Training Recognition Loss 11.67  Total Training Translation Loss 1834.85 
2024-02-03 03:53:58,443 EPOCH 29
2024-02-03 03:54:02,799 [Epoch: 029 Step: 00003800] Batch Recognition Loss:   0.254733 => Gls Tokens per Sec:     1396 || Batch Translation Loss:  14.889761 => Txt Tokens per Sec:     3953 || Lr: 0.000100
2024-02-03 03:54:05,831 Epoch  29: Total Training Recognition Loss 11.35  Total Training Translation Loss 1609.89 
2024-02-03 03:54:05,831 EPOCH 30
2024-02-03 03:54:08,421 [Epoch: 030 Step: 00003900] Batch Recognition Loss:   0.201339 => Gls Tokens per Sec:     1329 || Batch Translation Loss:  14.437736 => Txt Tokens per Sec:     3914 || Lr: 0.000100
2024-02-03 03:54:13,455 Epoch  30: Total Training Recognition Loss 10.73  Total Training Translation Loss 1405.08 
2024-02-03 03:54:13,456 EPOCH 31
2024-02-03 03:54:13,942 [Epoch: 031 Step: 00004000] Batch Recognition Loss:   0.235138 => Gls Tokens per Sec:     1646 || Batch Translation Loss:   4.786935 => Txt Tokens per Sec:     4152 || Lr: 0.000100
2024-02-03 03:54:24,811 Hooray! New best validation result [eval_metric]!
2024-02-03 03:54:24,812 Saving new checkpoint.
2024-02-03 03:54:25,091 Validation result at epoch  31, step     4000: duration: 11.1483s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.22052	Translation Loss: 63756.08984	PPL: 751.40509
	Eval Metric: BLEU
	WER 6.01	(DEL: 0.07,	INS: 0.00,	SUB: 5.94)
	BLEU-4 0.68	(BLEU-1: 12.61,	BLEU-2: 4.15,	BLEU-3: 1.54,	BLEU-4: 0.68)
	CHRF 16.78	ROUGE 10.30
2024-02-03 03:54:25,092 Logging Recognition and Translation Outputs
2024-02-03 03:54:25,092 ========================================================================================================================
2024-02-03 03:54:25,092 Logging Sequence: 52_208.00
2024-02-03 03:54:25,093 	Gloss Reference :	A B+C+D+E
2024-02-03 03:54:25,093 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:54:25,093 	Gloss Alignment :	         
2024-02-03 03:54:25,093 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:54:25,095 	Text Reference  :	**** ** after seeing    dhoni ** *** **** ** *** *** play  within 3      hours 36     lakh people downloaded candy crush
2024-02-03 03:54:25,095 	Text Hypothesis :	when he was   presented dhoni to the tray of the ipl which he     shared a     mobile and  is     not        ask   me   
2024-02-03 03:54:25,095 	Text Alignment  :	I    I  S     S               I  I   I    I  I   I   S     S      S      S     S      S    S      S          S     S    
2024-02-03 03:54:25,095 ========================================================================================================================
2024-02-03 03:54:25,095 Logging Sequence: 177_79.00
2024-02-03 03:54:25,095 	Gloss Reference :	A B+C+D+E
2024-02-03 03:54:25,095 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:54:25,096 	Gloss Alignment :	         
2024-02-03 03:54:25,096 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:54:25,097 	Text Reference  :	finally on  23rd may   both  sushil and    ajay were arrested in delhi' mundka area  
2024-02-03 03:54:25,097 	Text Hypothesis :	as      per the  rules after the    police to   be   held     in london in     london
2024-02-03 03:54:25,097 	Text Alignment  :	S       S   S    S     S     S      S      S    S    S           S      S      S     
2024-02-03 03:54:25,097 ========================================================================================================================
2024-02-03 03:54:25,098 Logging Sequence: 107_94.00
2024-02-03 03:54:25,098 	Gloss Reference :	A B+C+D+E
2024-02-03 03:54:25,098 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:54:25,098 	Gloss Alignment :	         
2024-02-03 03:54:25,098 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:54:25,099 	Text Reference  :	and currently development officer of  the **** *** *** bengal tennis association bta said
2024-02-03 03:54:25,099 	Text Hypothesis :	*** they      were        also    won the toss and t20 world  cup    to          be  held
2024-02-03 03:54:25,099 	Text Alignment  :	D   S         S           S       S       I    I   I   S      S      S           S   S   
2024-02-03 03:54:25,099 ========================================================================================================================
2024-02-03 03:54:25,100 Logging Sequence: 114_153.00
2024-02-03 03:54:25,100 	Gloss Reference :	A B+C+D+E
2024-02-03 03:54:25,100 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:54:25,100 	Gloss Alignment :	         
2024-02-03 03:54:25,100 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:54:25,101 	Text Reference  :	**** ** ******* ** *** ***** another big football news is   that the copa america final   
2024-02-03 03:54:25,101 	Text Hypothesis :	this is because he was known as      a   very     euro gold at   the **** tokyo   olympics
2024-02-03 03:54:25,101 	Text Alignment  :	I    I  I       I  I   I     S       S   S        S    S    S        D    S       S       
2024-02-03 03:54:25,101 ========================================================================================================================
2024-02-03 03:54:25,102 Logging Sequence: 52_36.00
2024-02-03 03:54:25,102 	Gloss Reference :	A B+C+D+E
2024-02-03 03:54:25,102 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:54:25,102 	Gloss Alignment :	         
2024-02-03 03:54:25,102 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:54:25,103 	Text Reference  :	** **** recently dhoni was travellin on  an  indigo  flight
2024-02-03 03:54:25,103 	Text Hypothesis :	he said there    is    a   huge      fan fan thanked dhoni 
2024-02-03 03:54:25,103 	Text Alignment  :	I  I    S        S     S   S         S   S   S       S     
2024-02-03 03:54:25,103 ========================================================================================================================
2024-02-03 03:54:31,038 [Epoch: 031 Step: 00004100] Batch Recognition Loss:   0.104711 => Gls Tokens per Sec:     1345 || Batch Translation Loss:  12.970459 => Txt Tokens per Sec:     3780 || Lr: 0.000100
2024-02-03 03:54:32,343 Epoch  31: Total Training Recognition Loss 11.16  Total Training Translation Loss 1224.95 
2024-02-03 03:54:32,343 EPOCH 32
2024-02-03 03:54:36,311 [Epoch: 032 Step: 00004200] Batch Recognition Loss:   0.060360 => Gls Tokens per Sec:     1553 || Batch Translation Loss:  10.398934 => Txt Tokens per Sec:     4253 || Lr: 0.000100
2024-02-03 03:54:39,524 Epoch  32: Total Training Recognition Loss 10.15  Total Training Translation Loss 1076.55 
2024-02-03 03:54:39,524 EPOCH 33
2024-02-03 03:54:42,212 [Epoch: 033 Step: 00004300] Batch Recognition Loss:   0.222335 => Gls Tokens per Sec:     1311 || Batch Translation Loss:   9.908751 => Txt Tokens per Sec:     3777 || Lr: 0.000100
2024-02-03 03:54:47,367 Epoch  33: Total Training Recognition Loss 9.61  Total Training Translation Loss 934.46 
2024-02-03 03:54:47,367 EPOCH 34
2024-02-03 03:54:47,949 [Epoch: 034 Step: 00004400] Batch Recognition Loss:   0.064199 => Gls Tokens per Sec:     1517 || Batch Translation Loss:   5.930263 => Txt Tokens per Sec:     4045 || Lr: 0.000100
2024-02-03 03:54:53,566 [Epoch: 034 Step: 00004500] Batch Recognition Loss:   0.154843 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   5.684948 => Txt Tokens per Sec:     3964 || Lr: 0.000100
2024-02-03 03:54:54,965 Epoch  34: Total Training Recognition Loss 9.76  Total Training Translation Loss 815.35 
2024-02-03 03:54:54,966 EPOCH 35
2024-02-03 03:54:59,297 [Epoch: 035 Step: 00004600] Batch Recognition Loss:   0.015565 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   6.246669 => Txt Tokens per Sec:     3981 || Lr: 0.000100
2024-02-03 03:55:02,338 Epoch  35: Total Training Recognition Loss 9.00  Total Training Translation Loss 730.24 
2024-02-03 03:55:02,339 EPOCH 36
2024-02-03 03:55:04,588 [Epoch: 036 Step: 00004700] Batch Recognition Loss:   0.032591 => Gls Tokens per Sec:     1601 || Batch Translation Loss:   4.608879 => Txt Tokens per Sec:     4415 || Lr: 0.000100
2024-02-03 03:55:09,532 Epoch  36: Total Training Recognition Loss 9.05  Total Training Translation Loss 638.34 
2024-02-03 03:55:09,533 EPOCH 37
2024-02-03 03:55:10,269 [Epoch: 037 Step: 00004800] Batch Recognition Loss:   0.011620 => Gls Tokens per Sec:     1307 || Batch Translation Loss:   3.322318 => Txt Tokens per Sec:     3783 || Lr: 0.000100
2024-02-03 03:55:16,051 [Epoch: 037 Step: 00004900] Batch Recognition Loss:   0.239091 => Gls Tokens per Sec:     1382 || Batch Translation Loss:   6.333986 => Txt Tokens per Sec:     3853 || Lr: 0.000100
2024-02-03 03:55:17,218 Epoch  37: Total Training Recognition Loss 9.32  Total Training Translation Loss 549.39 
2024-02-03 03:55:17,219 EPOCH 38
2024-02-03 03:55:21,429 [Epoch: 038 Step: 00005000] Batch Recognition Loss:   0.038589 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   4.025274 => Txt Tokens per Sec:     4220 || Lr: 0.000100
2024-02-03 03:55:24,574 Epoch  38: Total Training Recognition Loss 8.20  Total Training Translation Loss 484.65 
2024-02-03 03:55:24,575 EPOCH 39
2024-02-03 03:55:27,139 [Epoch: 039 Step: 00005100] Batch Recognition Loss:   0.014996 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   2.899832 => Txt Tokens per Sec:     3991 || Lr: 0.000100
2024-02-03 03:55:32,104 Epoch  39: Total Training Recognition Loss 7.49  Total Training Translation Loss 440.06 
2024-02-03 03:55:32,104 EPOCH 40
2024-02-03 03:55:32,861 [Epoch: 040 Step: 00005200] Batch Recognition Loss:   0.083254 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   2.308951 => Txt Tokens per Sec:     3857 || Lr: 0.000100
2024-02-03 03:55:38,471 [Epoch: 040 Step: 00005300] Batch Recognition Loss:   0.006894 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   2.831468 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-03 03:55:39,629 Epoch  40: Total Training Recognition Loss 7.26  Total Training Translation Loss 397.42 
2024-02-03 03:55:39,629 EPOCH 41
2024-02-03 03:55:43,425 [Epoch: 041 Step: 00005400] Batch Recognition Loss:   0.025440 => Gls Tokens per Sec:     1686 || Batch Translation Loss:   2.848190 => Txt Tokens per Sec:     4650 || Lr: 0.000100
2024-02-03 03:55:46,283 Epoch  41: Total Training Recognition Loss 7.42  Total Training Translation Loss 364.41 
2024-02-03 03:55:46,283 EPOCH 42
2024-02-03 03:55:49,156 [Epoch: 042 Step: 00005500] Batch Recognition Loss:   0.197544 => Gls Tokens per Sec:     1309 || Batch Translation Loss:   3.334211 => Txt Tokens per Sec:     3524 || Lr: 0.000100
2024-02-03 03:55:53,765 Epoch  42: Total Training Recognition Loss 7.84  Total Training Translation Loss 334.10 
2024-02-03 03:55:53,765 EPOCH 43
2024-02-03 03:55:54,565 [Epoch: 043 Step: 00005600] Batch Recognition Loss:   0.101458 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   2.878173 => Txt Tokens per Sec:     4144 || Lr: 0.000100
2024-02-03 03:56:00,048 [Epoch: 043 Step: 00005700] Batch Recognition Loss:   0.072390 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   1.805480 => Txt Tokens per Sec:     4040 || Lr: 0.000100
2024-02-03 03:56:01,032 Epoch  43: Total Training Recognition Loss 6.78  Total Training Translation Loss 309.32 
2024-02-03 03:56:01,032 EPOCH 44
2024-02-03 03:56:05,277 [Epoch: 044 Step: 00005800] Batch Recognition Loss:   0.006916 => Gls Tokens per Sec:     1527 || Batch Translation Loss:   2.089992 => Txt Tokens per Sec:     4206 || Lr: 0.000100
2024-02-03 03:56:08,398 Epoch  44: Total Training Recognition Loss 6.44  Total Training Translation Loss 286.31 
2024-02-03 03:56:08,398 EPOCH 45
2024-02-03 03:56:11,038 [Epoch: 045 Step: 00005900] Batch Recognition Loss:   0.019872 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   1.100970 => Txt Tokens per Sec:     4050 || Lr: 0.000100
2024-02-03 03:56:15,795 Epoch  45: Total Training Recognition Loss 6.59  Total Training Translation Loss 261.44 
2024-02-03 03:56:15,795 EPOCH 46
2024-02-03 03:56:16,485 [Epoch: 046 Step: 00006000] Batch Recognition Loss:   0.022892 => Gls Tokens per Sec:     1741 || Batch Translation Loss:   1.716519 => Txt Tokens per Sec:     4687 || Lr: 0.000100
2024-02-03 03:56:27,536 Validation result at epoch  46, step     6000: duration: 11.0502s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.73374	Translation Loss: 71701.13281	PPL: 1714.96313
	Eval Metric: BLEU
	WER 5.16	(DEL: 0.07,	INS: 0.00,	SUB: 5.09)
	BLEU-4 0.60	(BLEU-1: 12.77,	BLEU-2: 4.08,	BLEU-3: 1.43,	BLEU-4: 0.60)
	CHRF 17.00	ROUGE 10.60
2024-02-03 03:56:27,537 Logging Recognition and Translation Outputs
2024-02-03 03:56:27,537 ========================================================================================================================
2024-02-03 03:56:27,537 Logging Sequence: 101_39.00
2024-02-03 03:56:27,537 	Gloss Reference :	A B+C+D+E
2024-02-03 03:56:27,537 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:56:27,538 	Gloss Alignment :	         
2024-02-03 03:56:27,538 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:56:27,539 	Text Reference  :	star batsmen and bowlers of     the indian team were infected by the coronavirus
2024-02-03 03:56:27,539 	Text Hypothesis :	**** ******* the match   proved to  be     a    tie  for      rs 30  lakh       
2024-02-03 03:56:27,539 	Text Alignment  :	D    D       S   S       S      S   S      S    S    S        S  S   S          
2024-02-03 03:56:27,539 ========================================================================================================================
2024-02-03 03:56:27,539 Logging Sequence: 105_139.00
2024-02-03 03:56:27,539 	Gloss Reference :	A B+C+D+E
2024-02-03 03:56:27,539 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:56:27,540 	Gloss Alignment :	         
2024-02-03 03:56:27,540 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:56:27,540 	Text Reference  :	and now  he  has     finally achieved his dream  by    defeating carlsen
2024-02-03 03:56:27,541 	Text Hypothesis :	*** that too tweeted the     image    on  social media with      him    
2024-02-03 03:56:27,541 	Text Alignment  :	D   S    S   S       S       S        S   S      S     S         S      
2024-02-03 03:56:27,541 ========================================================================================================================
2024-02-03 03:56:27,541 Logging Sequence: 85_17.00
2024-02-03 03:56:27,541 	Gloss Reference :	A B+C+D+E
2024-02-03 03:56:27,541 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:56:27,541 	Gloss Alignment :	         
2024-02-03 03:56:27,542 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:56:27,543 	Text Reference  :	in the ****** 2003 world cup ***** ******* symonds scored an  unbeaten 143    against pakistan
2024-02-03 03:56:27,543 	Text Hypothesis :	** the women' t20  world cup match against south   africa for the      women' t20     match   
2024-02-03 03:56:27,543 	Text Alignment  :	D      I      S              I     I       S       S      S   S        S      S       S       
2024-02-03 03:56:27,543 ========================================================================================================================
2024-02-03 03:56:27,543 Logging Sequence: 150_98.00
2024-02-03 03:56:27,543 	Gloss Reference :	A B+C+D+E
2024-02-03 03:56:27,543 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:56:27,544 	Gloss Alignment :	         
2024-02-03 03:56:27,544 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:56:27,544 	Text Reference  :	** **** **** chhetri was    the captain
2024-02-03 03:56:27,544 	Text Hypothesis :	we were just joking  around the reason 
2024-02-03 03:56:27,544 	Text Alignment  :	I  I    I    S       S          S      
2024-02-03 03:56:27,544 ========================================================================================================================
2024-02-03 03:56:27,544 Logging Sequence: 147_76.00
2024-02-03 03:56:27,545 	Gloss Reference :	A B+C+D+E
2024-02-03 03:56:27,545 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:56:27,545 	Gloss Alignment :	         
2024-02-03 03:56:27,545 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:56:27,546 	Text Reference  :	however on 28 july she announced her withdrawal from    the    olympic games
2024-02-03 03:56:27,546 	Text Hypothesis :	******* ** ** **** *** ********* *** new        zealand scored 2       teams
2024-02-03 03:56:27,546 	Text Alignment  :	D       D  D  D    D   D         D   S          S       S      S       S    
2024-02-03 03:56:27,546 ========================================================================================================================
2024-02-03 03:56:33,314 [Epoch: 046 Step: 00006100] Batch Recognition Loss:   0.014349 => Gls Tokens per Sec:     1383 || Batch Translation Loss:   1.886630 => Txt Tokens per Sec:     3868 || Lr: 0.000100
2024-02-03 03:56:34,266 Epoch  46: Total Training Recognition Loss 6.67  Total Training Translation Loss 242.28 
2024-02-03 03:56:34,266 EPOCH 47
2024-02-03 03:56:38,773 [Epoch: 047 Step: 00006200] Batch Recognition Loss:   0.028549 => Gls Tokens per Sec:     1456 || Batch Translation Loss:   1.245227 => Txt Tokens per Sec:     3993 || Lr: 0.000100
2024-02-03 03:56:41,533 Epoch  47: Total Training Recognition Loss 6.14  Total Training Translation Loss 219.71 
2024-02-03 03:56:41,533 EPOCH 48
2024-02-03 03:56:43,984 [Epoch: 048 Step: 00006300] Batch Recognition Loss:   0.119147 => Gls Tokens per Sec:     1600 || Batch Translation Loss:   1.753791 => Txt Tokens per Sec:     4457 || Lr: 0.000100
2024-02-03 03:56:48,664 Epoch  48: Total Training Recognition Loss 6.02  Total Training Translation Loss 207.68 
2024-02-03 03:56:48,665 EPOCH 49
2024-02-03 03:56:49,575 [Epoch: 049 Step: 00006400] Batch Recognition Loss:   0.007794 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   1.071559 => Txt Tokens per Sec:     4148 || Lr: 0.000100
2024-02-03 03:56:55,264 [Epoch: 049 Step: 00006500] Batch Recognition Loss:   0.018024 => Gls Tokens per Sec:     1406 || Batch Translation Loss:   1.671414 => Txt Tokens per Sec:     3863 || Lr: 0.000100
2024-02-03 03:56:56,326 Epoch  49: Total Training Recognition Loss 5.67  Total Training Translation Loss 196.82 
2024-02-03 03:56:56,326 EPOCH 50
2024-02-03 03:57:00,809 [Epoch: 050 Step: 00006600] Batch Recognition Loss:   0.049116 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   1.007111 => Txt Tokens per Sec:     4143 || Lr: 0.000100
2024-02-03 03:57:03,433 Epoch  50: Total Training Recognition Loss 5.93  Total Training Translation Loss 193.72 
2024-02-03 03:57:03,434 EPOCH 51
2024-02-03 03:57:06,082 [Epoch: 051 Step: 00006700] Batch Recognition Loss:   0.014644 => Gls Tokens per Sec:     1511 || Batch Translation Loss:   1.270943 => Txt Tokens per Sec:     4172 || Lr: 0.000100
2024-02-03 03:57:10,684 Epoch  51: Total Training Recognition Loss 6.19  Total Training Translation Loss 193.20 
2024-02-03 03:57:10,685 EPOCH 52
2024-02-03 03:57:11,619 [Epoch: 052 Step: 00006800] Batch Recognition Loss:   0.020588 => Gls Tokens per Sec:     1456 || Batch Translation Loss:   1.253156 => Txt Tokens per Sec:     4050 || Lr: 0.000100
2024-02-03 03:57:17,422 [Epoch: 052 Step: 00006900] Batch Recognition Loss:   0.031056 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   1.229811 => Txt Tokens per Sec:     3804 || Lr: 0.000100
2024-02-03 03:57:18,526 Epoch  52: Total Training Recognition Loss 5.50  Total Training Translation Loss 166.32 
2024-02-03 03:57:18,527 EPOCH 53
2024-02-03 03:57:23,105 [Epoch: 053 Step: 00007000] Batch Recognition Loss:   0.101730 => Gls Tokens per Sec:     1468 || Batch Translation Loss:   1.284072 => Txt Tokens per Sec:     4126 || Lr: 0.000100
2024-02-03 03:57:25,511 Epoch  53: Total Training Recognition Loss 4.89  Total Training Translation Loss 167.05 
2024-02-03 03:57:25,511 EPOCH 54
2024-02-03 03:57:28,097 [Epoch: 054 Step: 00007100] Batch Recognition Loss:   0.004702 => Gls Tokens per Sec:     1578 || Batch Translation Loss:   1.169959 => Txt Tokens per Sec:     4378 || Lr: 0.000100
2024-02-03 03:57:33,027 Epoch  54: Total Training Recognition Loss 5.09  Total Training Translation Loss 152.58 
2024-02-03 03:57:33,028 EPOCH 55
2024-02-03 03:57:33,979 [Epoch: 055 Step: 00007200] Batch Recognition Loss:   0.017360 => Gls Tokens per Sec:     1514 || Batch Translation Loss:   1.814426 => Txt Tokens per Sec:     4113 || Lr: 0.000100
2024-02-03 03:57:39,698 [Epoch: 055 Step: 00007300] Batch Recognition Loss:   0.002655 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   1.327096 => Txt Tokens per Sec:     3909 || Lr: 0.000100
2024-02-03 03:57:40,525 Epoch  55: Total Training Recognition Loss 4.74  Total Training Translation Loss 144.86 
2024-02-03 03:57:40,525 EPOCH 56
2024-02-03 03:57:45,321 [Epoch: 056 Step: 00007400] Batch Recognition Loss:   0.003285 => Gls Tokens per Sec:     1418 || Batch Translation Loss:   0.767520 => Txt Tokens per Sec:     3936 || Lr: 0.000100
2024-02-03 03:57:48,080 Epoch  56: Total Training Recognition Loss 4.73  Total Training Translation Loss 134.07 
2024-02-03 03:57:48,081 EPOCH 57
2024-02-03 03:57:50,837 [Epoch: 057 Step: 00007500] Batch Recognition Loss:   0.090650 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   1.260694 => Txt Tokens per Sec:     4143 || Lr: 0.000100
2024-02-03 03:57:55,420 Epoch  57: Total Training Recognition Loss 4.34  Total Training Translation Loss 129.89 
2024-02-03 03:57:55,421 EPOCH 58
2024-02-03 03:57:56,592 [Epoch: 058 Step: 00007600] Batch Recognition Loss:   0.073041 => Gls Tokens per Sec:     1298 || Batch Translation Loss:   0.472738 => Txt Tokens per Sec:     3882 || Lr: 0.000100
2024-02-03 03:58:02,260 [Epoch: 058 Step: 00007700] Batch Recognition Loss:   0.009646 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   1.069406 => Txt Tokens per Sec:     3874 || Lr: 0.000100
2024-02-03 03:58:03,143 Epoch  58: Total Training Recognition Loss 4.25  Total Training Translation Loss 136.71 
2024-02-03 03:58:03,143 EPOCH 59
2024-02-03 03:58:07,940 [Epoch: 059 Step: 00007800] Batch Recognition Loss:   0.084744 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   1.445118 => Txt Tokens per Sec:     4050 || Lr: 0.000100
2024-02-03 03:58:10,483 Epoch  59: Total Training Recognition Loss 4.62  Total Training Translation Loss 120.10 
2024-02-03 03:58:10,483 EPOCH 60
2024-02-03 03:58:13,639 [Epoch: 060 Step: 00007900] Batch Recognition Loss:   0.019039 => Gls Tokens per Sec:     1344 || Batch Translation Loss:   0.511178 => Txt Tokens per Sec:     3977 || Lr: 0.000100
2024-02-03 03:58:17,983 Epoch  60: Total Training Recognition Loss 4.14  Total Training Translation Loss 116.52 
2024-02-03 03:58:17,984 EPOCH 61
2024-02-03 03:58:18,986 [Epoch: 061 Step: 00008000] Batch Recognition Loss:   0.018579 => Gls Tokens per Sec:     1598 || Batch Translation Loss:   1.283011 => Txt Tokens per Sec:     4245 || Lr: 0.000100
2024-02-03 03:58:29,354 Validation result at epoch  61, step     8000: duration: 10.3678s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.73261	Translation Loss: 76995.04688	PPL: 2972.00659
	Eval Metric: BLEU
	WER 4.24	(DEL: 0.14,	INS: 0.00,	SUB: 4.10)
	BLEU-4 0.52	(BLEU-1: 11.07,	BLEU-2: 3.53,	BLEU-3: 1.19,	BLEU-4: 0.52)
	CHRF 16.67	ROUGE 9.18
2024-02-03 03:58:29,355 Logging Recognition and Translation Outputs
2024-02-03 03:58:29,355 ========================================================================================================================
2024-02-03 03:58:29,355 Logging Sequence: 109_16.00
2024-02-03 03:58:29,356 	Gloss Reference :	A B+C+D+E
2024-02-03 03:58:29,356 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:58:29,356 	Gloss Alignment :	         
2024-02-03 03:58:29,356 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:58:29,357 	Text Reference  :	**** * however the  match   was  rescheduled as     two      kkr players -   
2024-02-03 03:58:29,357 	Text Hypothesis :	with a strong  team members were immediately tested positive for the     team
2024-02-03 03:58:29,357 	Text Alignment  :	I    I S       S    S       S    S           S      S        S   S       S   
2024-02-03 03:58:29,357 ========================================================================================================================
2024-02-03 03:58:29,357 Logging Sequence: 156_272.00
2024-02-03 03:58:29,357 	Gloss Reference :	A B+C+D+E
2024-02-03 03:58:29,357 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:58:29,358 	Gloss Alignment :	         
2024-02-03 03:58:29,358 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:58:29,359 	Text Reference  :	miny' original captain was  kieron    pollard nicholas pooran was    stand-in captain in     place of  him 
2024-02-03 03:58:29,359 	Text Hypothesis :	***** ******** ******* bcci president sourav  ganguly  and    social media    to      donate to    his life
2024-02-03 03:58:29,359 	Text Alignment  :	D     D        D       S    S         S       S        S      S      S        S       S      S     S   S   
2024-02-03 03:58:29,359 ========================================================================================================================
2024-02-03 03:58:29,359 Logging Sequence: 115_59.00
2024-02-03 03:58:29,360 	Gloss Reference :	A B+C+D+E
2024-02-03 03:58:29,360 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:58:29,360 	Gloss Alignment :	         
2024-02-03 03:58:29,360 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:58:29,361 	Text Reference  :	** *** **** ******* **** she now    hosts      several cricket programmes
2024-02-03 03:58:29,361 	Text Hypothesis :	on the 15th october 2023 the indian cricketers for     a       series    
2024-02-03 03:58:29,361 	Text Alignment  :	I  I   I    I       I    S   S      S          S       S       S         
2024-02-03 03:58:29,361 ========================================================================================================================
2024-02-03 03:58:29,361 Logging Sequence: 63_35.00
2024-02-03 03:58:29,361 	Gloss Reference :	A B+C+D+E
2024-02-03 03:58:29,361 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:58:29,361 	Gloss Alignment :	         
2024-02-03 03:58:29,362 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:58:29,363 	Text Reference  :	companies interested in buying the teams need to   fill the tender form by paying rs     10      lakh  
2024-02-03 03:58:29,363 	Text Hypothesis :	********* ********** ** he     has taken a    part of   the ****** **** ** ****** indian premier league
2024-02-03 03:58:29,363 	Text Alignment  :	D         D          D  S      S   S     S    S    S        D      D    D  D      S      S       S     
2024-02-03 03:58:29,363 ========================================================================================================================
2024-02-03 03:58:29,363 Logging Sequence: 100_97.00
2024-02-03 03:58:29,363 	Gloss Reference :	A B+C+D+E
2024-02-03 03:58:29,364 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 03:58:29,364 	Gloss Alignment :	         
2024-02-03 03:58:29,364 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 03:58:29,365 	Text Reference  :	india had to play against pakistan in the   sahara cup in    canada
2024-02-03 03:58:29,365 	Text Hypothesis :	he    won a  gold medal   for      3  balls with   the first time  
2024-02-03 03:58:29,365 	Text Alignment  :	S     S   S  S    S       S        S  S     S      S   S     S     
2024-02-03 03:58:29,365 ========================================================================================================================
2024-02-03 03:58:35,136 [Epoch: 061 Step: 00008100] Batch Recognition Loss:   0.035980 => Gls Tokens per Sec:     1384 || Batch Translation Loss:   1.039304 => Txt Tokens per Sec:     3844 || Lr: 0.000100
2024-02-03 03:58:35,968 Epoch  61: Total Training Recognition Loss 3.91  Total Training Translation Loss 111.25 
2024-02-03 03:58:35,968 EPOCH 62
2024-02-03 03:58:40,683 [Epoch: 062 Step: 00008200] Batch Recognition Loss:   0.156056 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.915900 => Txt Tokens per Sec:     4111 || Lr: 0.000100
2024-02-03 03:58:43,243 Epoch  62: Total Training Recognition Loss 4.71  Total Training Translation Loss 117.08 
2024-02-03 03:58:43,243 EPOCH 63
2024-02-03 03:58:46,191 [Epoch: 063 Step: 00008300] Batch Recognition Loss:   0.182671 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   1.224730 => Txt Tokens per Sec:     3957 || Lr: 0.000100
2024-02-03 03:58:50,827 Epoch  63: Total Training Recognition Loss 3.99  Total Training Translation Loss 111.24 
2024-02-03 03:58:50,828 EPOCH 64
2024-02-03 03:58:51,842 [Epoch: 064 Step: 00008400] Batch Recognition Loss:   0.008650 => Gls Tokens per Sec:     1659 || Batch Translation Loss:   0.415440 => Txt Tokens per Sec:     4574 || Lr: 0.000100
2024-02-03 03:58:56,982 [Epoch: 064 Step: 00008500] Batch Recognition Loss:   0.027875 => Gls Tokens per Sec:     1554 || Batch Translation Loss:   0.953678 => Txt Tokens per Sec:     4343 || Lr: 0.000100
2024-02-03 03:58:57,560 Epoch  64: Total Training Recognition Loss 4.62  Total Training Translation Loss 95.47 
2024-02-03 03:58:57,561 EPOCH 65
2024-02-03 03:59:01,986 [Epoch: 065 Step: 00008600] Batch Recognition Loss:   0.021438 => Gls Tokens per Sec:     1591 || Batch Translation Loss:   0.737061 => Txt Tokens per Sec:     4383 || Lr: 0.000100
2024-02-03 03:59:04,468 Epoch  65: Total Training Recognition Loss 3.65  Total Training Translation Loss 103.41 
2024-02-03 03:59:04,469 EPOCH 66
2024-02-03 03:59:07,548 [Epoch: 066 Step: 00008700] Batch Recognition Loss:   0.026774 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.894547 => Txt Tokens per Sec:     3995 || Lr: 0.000100
2024-02-03 03:59:11,666 Epoch  66: Total Training Recognition Loss 3.97  Total Training Translation Loss 97.70 
2024-02-03 03:59:11,667 EPOCH 67
2024-02-03 03:59:12,999 [Epoch: 067 Step: 00008800] Batch Recognition Loss:   0.047972 => Gls Tokens per Sec:     1324 || Batch Translation Loss:   0.841127 => Txt Tokens per Sec:     3750 || Lr: 0.000100
2024-02-03 03:59:18,628 [Epoch: 067 Step: 00008900] Batch Recognition Loss:   0.056231 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.433829 => Txt Tokens per Sec:     3934 || Lr: 0.000100
2024-02-03 03:59:19,338 Epoch  67: Total Training Recognition Loss 4.10  Total Training Translation Loss 95.20 
2024-02-03 03:59:19,338 EPOCH 68
2024-02-03 03:59:24,257 [Epoch: 068 Step: 00009000] Batch Recognition Loss:   0.006165 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.759314 => Txt Tokens per Sec:     4001 || Lr: 0.000100
2024-02-03 03:59:26,790 Epoch  68: Total Training Recognition Loss 3.81  Total Training Translation Loss 83.12 
2024-02-03 03:59:26,791 EPOCH 69
2024-02-03 03:59:29,845 [Epoch: 069 Step: 00009100] Batch Recognition Loss:   0.011422 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.316946 => Txt Tokens per Sec:     4076 || Lr: 0.000100
2024-02-03 03:59:34,229 Epoch  69: Total Training Recognition Loss 3.67  Total Training Translation Loss 84.95 
2024-02-03 03:59:34,229 EPOCH 70
2024-02-03 03:59:35,541 [Epoch: 070 Step: 00009200] Batch Recognition Loss:   0.005911 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.261442 => Txt Tokens per Sec:     3962 || Lr: 0.000100
2024-02-03 03:59:41,231 [Epoch: 070 Step: 00009300] Batch Recognition Loss:   0.073345 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.216115 => Txt Tokens per Sec:     3863 || Lr: 0.000100
2024-02-03 03:59:41,841 Epoch  70: Total Training Recognition Loss 3.50  Total Training Translation Loss 95.39 
2024-02-03 03:59:41,841 EPOCH 71
2024-02-03 03:59:46,748 [Epoch: 071 Step: 00009400] Batch Recognition Loss:   0.007710 => Gls Tokens per Sec:     1468 || Batch Translation Loss:   0.596639 => Txt Tokens per Sec:     4080 || Lr: 0.000100
2024-02-03 03:59:48,931 Epoch  71: Total Training Recognition Loss 3.59  Total Training Translation Loss 93.77 
2024-02-03 03:59:48,931 EPOCH 72
2024-02-03 03:59:52,131 [Epoch: 072 Step: 00009500] Batch Recognition Loss:   0.016872 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.605164 => Txt Tokens per Sec:     3894 || Lr: 0.000100
2024-02-03 03:59:56,337 Epoch  72: Total Training Recognition Loss 3.60  Total Training Translation Loss 89.95 
2024-02-03 03:59:56,337 EPOCH 73
2024-02-03 03:59:57,634 [Epoch: 073 Step: 00009600] Batch Recognition Loss:   0.005817 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.254896 => Txt Tokens per Sec:     4182 || Lr: 0.000100
2024-02-03 04:00:03,428 [Epoch: 073 Step: 00009700] Batch Recognition Loss:   0.007204 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.591193 => Txt Tokens per Sec:     3837 || Lr: 0.000100
2024-02-03 04:00:03,896 Epoch  73: Total Training Recognition Loss 3.43  Total Training Translation Loss 78.59 
2024-02-03 04:00:03,896 EPOCH 74
2024-02-03 04:00:08,969 [Epoch: 074 Step: 00009800] Batch Recognition Loss:   0.023452 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.413605 => Txt Tokens per Sec:     3973 || Lr: 0.000100
2024-02-03 04:00:11,562 Epoch  74: Total Training Recognition Loss 3.48  Total Training Translation Loss 80.25 
2024-02-03 04:00:11,562 EPOCH 75
2024-02-03 04:00:14,689 [Epoch: 075 Step: 00009900] Batch Recognition Loss:   0.023194 => Gls Tokens per Sec:     1485 || Batch Translation Loss:   0.571376 => Txt Tokens per Sec:     4195 || Lr: 0.000100
2024-02-03 04:00:18,452 Epoch  75: Total Training Recognition Loss 3.63  Total Training Translation Loss 81.25 
2024-02-03 04:00:18,452 EPOCH 76
2024-02-03 04:00:20,039 [Epoch: 076 Step: 00010000] Batch Recognition Loss:   0.012055 => Gls Tokens per Sec:     1261 || Batch Translation Loss:   0.425534 => Txt Tokens per Sec:     3675 || Lr: 0.000100
2024-02-03 04:00:31,234 Validation result at epoch  76, step    10000: duration: 11.1937s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.95090	Translation Loss: 80615.60938	PPL: 4328.76416
	Eval Metric: BLEU
	WER 4.88	(DEL: 0.14,	INS: 0.00,	SUB: 4.74)
	BLEU-4 0.51	(BLEU-1: 10.99,	BLEU-2: 3.21,	BLEU-3: 1.15,	BLEU-4: 0.51)
	CHRF 17.02	ROUGE 9.01
2024-02-03 04:00:31,235 Logging Recognition and Translation Outputs
2024-02-03 04:00:31,235 ========================================================================================================================
2024-02-03 04:00:31,235 Logging Sequence: 78_43.00
2024-02-03 04:00:31,235 	Gloss Reference :	A B+C+D+E
2024-02-03 04:00:31,235 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:00:31,236 	Gloss Alignment :	         
2024-02-03 04:00:31,236 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:00:31,236 	Text Reference  :	*** however something happened which made the      team very happy
2024-02-03 04:00:31,236 	Text Hypothesis :	she was     ecstatic  with     this  is   selected in   the  match
2024-02-03 04:00:31,237 	Text Alignment  :	I   S       S         S        S     S    S        S    S    S    
2024-02-03 04:00:31,237 ========================================================================================================================
2024-02-03 04:00:31,237 Logging Sequence: 98_97.00
2024-02-03 04:00:31,237 	Gloss Reference :	A B+C+D+E
2024-02-03 04:00:31,237 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:00:31,237 	Gloss Alignment :	         
2024-02-03 04:00:31,238 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:00:31,238 	Text Reference  :	the teams in the series were india legends england legends sri     lanka legends
2024-02-03 04:00:31,238 	Text Hypothesis :	*** ***** ** *** if     her  team  is      an      amazing batsman and   hotel  
2024-02-03 04:00:31,239 	Text Alignment  :	D   D     D  D   S      S    S     S       S       S       S       S     S      
2024-02-03 04:00:31,239 ========================================================================================================================
2024-02-03 04:00:31,239 Logging Sequence: 143_11.00
2024-02-03 04:00:31,239 	Gloss Reference :	A B+C+D+E
2024-02-03 04:00:31,239 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:00:31,239 	Gloss Alignment :	         
2024-02-03 04:00:31,240 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:00:31,242 	Text Reference  :	ronaldo ***** **** has  also        become the **** first person to    have 500 million followers on  instagram he    is the most loved    footballer
2024-02-03 04:00:31,242 	Text Hypothesis :	ronaldo would have been quarantined at     the loss if    she    would have *** a       loss      and that      there is *** a    whopping amount    
2024-02-03 04:00:31,242 	Text Alignment  :	        I     I    S    S           S          I    S     S      S          D   S       S         S   S         S        D   S    S        S         
2024-02-03 04:00:31,242 ========================================================================================================================
2024-02-03 04:00:31,242 Logging Sequence: 179_386.00
2024-02-03 04:00:31,243 	Gloss Reference :	A B+C+D+E
2024-02-03 04:00:31,243 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:00:31,243 	Gloss Alignment :	         
2024-02-03 04:00:31,243 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:00:31,244 	Text Reference  :	and the   federation or    sai  people are their servants to *** ******** ** ******* pick up   their passport
2024-02-03 04:00:31,244 	Text Hypothesis :	*** these kids       think that they   are ***** going    to the olympics so they've from kind of    stars   
2024-02-03 04:00:31,245 	Text Alignment  :	D   S     S          S     S    S          D     S           I   I        I  I       S    S    S     S       
2024-02-03 04:00:31,245 ========================================================================================================================
2024-02-03 04:00:31,245 Logging Sequence: 77_60.00
2024-02-03 04:00:31,245 	Gloss Reference :	A B+C+D+E
2024-02-03 04:00:31,245 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:00:31,245 	Gloss Alignment :	         
2024-02-03 04:00:31,245 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:00:31,246 	Text Reference  :	**** ******* *** he      remained not  out      
2024-02-03 04:00:31,246 	Text Hypothesis :	many batsmen and decided to       have commented
2024-02-03 04:00:31,246 	Text Alignment  :	I    I       I   S       S        S    S        
2024-02-03 04:00:31,246 ========================================================================================================================
2024-02-03 04:00:36,864 [Epoch: 076 Step: 00010100] Batch Recognition Loss:   0.007063 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.966836 => Txt Tokens per Sec:     3903 || Lr: 0.000100
2024-02-03 04:00:37,299 Epoch  76: Total Training Recognition Loss 3.40  Total Training Translation Loss 75.79 
2024-02-03 04:00:37,299 EPOCH 77
2024-02-03 04:00:42,535 [Epoch: 077 Step: 00010200] Batch Recognition Loss:   0.007838 => Gls Tokens per Sec:     1406 || Batch Translation Loss:   0.547580 => Txt Tokens per Sec:     3948 || Lr: 0.000100
2024-02-03 04:00:44,878 Epoch  77: Total Training Recognition Loss 3.60  Total Training Translation Loss 69.18 
2024-02-03 04:00:44,878 EPOCH 78
2024-02-03 04:00:47,781 [Epoch: 078 Step: 00010300] Batch Recognition Loss:   0.014496 => Gls Tokens per Sec:     1627 || Batch Translation Loss:   0.465438 => Txt Tokens per Sec:     4583 || Lr: 0.000100
2024-02-03 04:00:51,313 Epoch  78: Total Training Recognition Loss 3.01  Total Training Translation Loss 65.69 
2024-02-03 04:00:51,313 EPOCH 79
2024-02-03 04:00:52,494 [Epoch: 079 Step: 00010400] Batch Recognition Loss:   0.008359 => Gls Tokens per Sec:     1764 || Batch Translation Loss:   0.375121 => Txt Tokens per Sec:     5090 || Lr: 0.000100
2024-02-03 04:00:57,768 [Epoch: 079 Step: 00010500] Batch Recognition Loss:   0.112209 => Gls Tokens per Sec:     1515 || Batch Translation Loss:   0.486579 => Txt Tokens per Sec:     4202 || Lr: 0.000100
2024-02-03 04:00:58,062 Epoch  79: Total Training Recognition Loss 3.27  Total Training Translation Loss 63.20 
2024-02-03 04:00:58,062 EPOCH 80
2024-02-03 04:01:02,885 [Epoch: 080 Step: 00010600] Batch Recognition Loss:   0.024441 => Gls Tokens per Sec:     1543 || Batch Translation Loss:   1.005659 => Txt Tokens per Sec:     4250 || Lr: 0.000100
2024-02-03 04:01:05,089 Epoch  80: Total Training Recognition Loss 2.82  Total Training Translation Loss 55.49 
2024-02-03 04:01:05,089 EPOCH 81
2024-02-03 04:01:08,319 [Epoch: 081 Step: 00010700] Batch Recognition Loss:   0.003957 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.595606 => Txt Tokens per Sec:     4095 || Lr: 0.000100
2024-02-03 04:01:12,485 Epoch  81: Total Training Recognition Loss 2.66  Total Training Translation Loss 58.41 
2024-02-03 04:01:12,486 EPOCH 82
2024-02-03 04:01:13,822 [Epoch: 082 Step: 00010800] Batch Recognition Loss:   0.015812 => Gls Tokens per Sec:     1616 || Batch Translation Loss:   0.589595 => Txt Tokens per Sec:     4156 || Lr: 0.000100
2024-02-03 04:01:19,634 [Epoch: 082 Step: 00010900] Batch Recognition Loss:   0.009672 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.509520 => Txt Tokens per Sec:     3902 || Lr: 0.000100
2024-02-03 04:01:19,945 Epoch  82: Total Training Recognition Loss 2.89  Total Training Translation Loss 73.24 
2024-02-03 04:01:19,945 EPOCH 83
2024-02-03 04:01:25,274 [Epoch: 083 Step: 00011000] Batch Recognition Loss:   0.002241 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.416848 => Txt Tokens per Sec:     3939 || Lr: 0.000100
2024-02-03 04:01:27,536 Epoch  83: Total Training Recognition Loss 3.20  Total Training Translation Loss 76.61 
2024-02-03 04:01:27,536 EPOCH 84
2024-02-03 04:01:30,873 [Epoch: 084 Step: 00011100] Batch Recognition Loss:   0.005708 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.754529 => Txt Tokens per Sec:     4164 || Lr: 0.000100
2024-02-03 04:01:34,828 Epoch  84: Total Training Recognition Loss 2.89  Total Training Translation Loss 71.33 
2024-02-03 04:01:34,829 EPOCH 85
2024-02-03 04:01:36,377 [Epoch: 085 Step: 00011200] Batch Recognition Loss:   0.044690 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.560873 => Txt Tokens per Sec:     4258 || Lr: 0.000100
2024-02-03 04:01:42,207 [Epoch: 085 Step: 00011300] Batch Recognition Loss:   0.035998 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.744010 => Txt Tokens per Sec:     3748 || Lr: 0.000100
2024-02-03 04:01:42,524 Epoch  85: Total Training Recognition Loss 2.66  Total Training Translation Loss 61.46 
2024-02-03 04:01:42,525 EPOCH 86
2024-02-03 04:01:47,736 [Epoch: 086 Step: 00011400] Batch Recognition Loss:   0.038525 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.437400 => Txt Tokens per Sec:     4095 || Lr: 0.000100
2024-02-03 04:01:50,098 Epoch  86: Total Training Recognition Loss 2.99  Total Training Translation Loss 62.64 
2024-02-03 04:01:50,098 EPOCH 87
2024-02-03 04:01:53,691 [Epoch: 087 Step: 00011500] Batch Recognition Loss:   0.008183 => Gls Tokens per Sec:     1381 || Batch Translation Loss:   0.521620 => Txt Tokens per Sec:     3875 || Lr: 0.000100
2024-02-03 04:01:57,382 Epoch  87: Total Training Recognition Loss 2.63  Total Training Translation Loss 55.12 
2024-02-03 04:01:57,382 EPOCH 88
2024-02-03 04:01:58,832 [Epoch: 088 Step: 00011600] Batch Recognition Loss:   0.015874 => Gls Tokens per Sec:     1602 || Batch Translation Loss:   0.314300 => Txt Tokens per Sec:     4348 || Lr: 0.000100
2024-02-03 04:02:04,767 [Epoch: 088 Step: 00011700] Batch Recognition Loss:   0.005463 => Gls Tokens per Sec:     1346 || Batch Translation Loss:   0.786968 => Txt Tokens per Sec:     3775 || Lr: 0.000100
2024-02-03 04:02:04,958 Epoch  88: Total Training Recognition Loss 2.62  Total Training Translation Loss 65.26 
2024-02-03 04:02:04,958 EPOCH 89
2024-02-03 04:02:10,009 [Epoch: 089 Step: 00011800] Batch Recognition Loss:   0.027035 => Gls Tokens per Sec:     1521 || Batch Translation Loss:   0.711712 => Txt Tokens per Sec:     4251 || Lr: 0.000100
2024-02-03 04:02:12,059 Epoch  89: Total Training Recognition Loss 2.52  Total Training Translation Loss 57.87 
2024-02-03 04:02:12,059 EPOCH 90
2024-02-03 04:02:15,621 [Epoch: 090 Step: 00011900] Batch Recognition Loss:   0.002891 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.272082 => Txt Tokens per Sec:     3971 || Lr: 0.000100
2024-02-03 04:02:19,524 Epoch  90: Total Training Recognition Loss 2.69  Total Training Translation Loss 55.18 
2024-02-03 04:02:19,524 EPOCH 91
2024-02-03 04:02:21,185 [Epoch: 091 Step: 00012000] Batch Recognition Loss:   0.005187 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.287111 => Txt Tokens per Sec:     4014 || Lr: 0.000100
2024-02-03 04:02:32,187 Validation result at epoch  91, step    12000: duration: 11.0018s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.20636	Translation Loss: 83240.53906	PPL: 5685.49072
	Eval Metric: BLEU
	WER 4.10	(DEL: 0.07,	INS: 0.00,	SUB: 4.03)
	BLEU-4 0.62	(BLEU-1: 11.24,	BLEU-2: 3.34,	BLEU-3: 1.31,	BLEU-4: 0.62)
	CHRF 17.28	ROUGE 9.36
2024-02-03 04:02:32,188 Logging Recognition and Translation Outputs
2024-02-03 04:02:32,188 ========================================================================================================================
2024-02-03 04:02:32,188 Logging Sequence: 180_138.00
2024-02-03 04:02:32,188 	Gloss Reference :	A B+C+D+E        
2024-02-03 04:02:32,188 	Gloss Hypothesis:	A B+C+B+E+B+C+D+B
2024-02-03 04:02:32,189 	Gloss Alignment :	  S              
2024-02-03 04:02:32,189 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:02:32,191 	Text Reference  :	ioa  president p     t      usha      constituted a seven-member panel which  included   world     champions from various sports to    inquire into the    allegations
2024-02-03 04:02:32,191 	Text Hypothesis :	also say       seven female wrestlers filed       a ************ ***** sexual harassment complaint against   brij bhushan sharan singh at      cp   police station    
2024-02-03 04:02:32,191 	Text Alignment  :	S    S         S     S      S         S             D            D     S      S          S         S         S    S       S      S     S       S    S      S          
2024-02-03 04:02:32,191 ========================================================================================================================
2024-02-03 04:02:32,191 Logging Sequence: 126_99.00
2024-02-03 04:02:32,192 	Gloss Reference :	A B+C+D+E
2024-02-03 04:02:32,192 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:02:32,192 	Gloss Alignment :	         
2024-02-03 04:02:32,192 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:02:32,192 	Text Reference  :	he dedicated the ****** medal to   sprinter milkha singh
2024-02-03 04:02:32,193 	Text Hypothesis :	** ********* the nation is    very happy    and    proud
2024-02-03 04:02:32,193 	Text Alignment  :	D  D             I      S     S    S        S      S    
2024-02-03 04:02:32,193 ========================================================================================================================
2024-02-03 04:02:32,193 Logging Sequence: 90_146.00
2024-02-03 04:02:32,193 	Gloss Reference :	A B+C+D+E
2024-02-03 04:02:32,193 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:02:32,193 	Gloss Alignment :	         
2024-02-03 04:02:32,194 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:02:32,194 	Text Reference  :	******** ***** **** similarly natasa and hardik  both decided to      renew their  vows
2024-02-03 04:02:32,194 	Text Hypothesis :	everyone hoped that england   would  be  wrapped in   the     stadium and   that's etc 
2024-02-03 04:02:32,195 	Text Alignment  :	I        I     I    S         S      S   S       S    S       S       S     S      S   
2024-02-03 04:02:32,195 ========================================================================================================================
2024-02-03 04:02:32,195 Logging Sequence: 79_198.00
2024-02-03 04:02:32,195 	Gloss Reference :	A B+C+D+E    
2024-02-03 04:02:32,195 	Gloss Hypothesis:	A B+D+B+C+D+E
2024-02-03 04:02:32,195 	Gloss Alignment :	  S          
2024-02-03 04:02:32,195 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:02:32,197 	Text Reference  :	*** will try  to  reschedule the match before the finals now hope the  team tests negative
2024-02-03 04:02:32,197 	Text Hypothesis :	all the  bcci had asked      the bcci  has    go  down   as  well with them test  captain 
2024-02-03 04:02:32,197 	Text Alignment  :	I   S    S    S   S              S     S      S   S      S   S    S    S    S     S       
2024-02-03 04:02:32,197 ========================================================================================================================
2024-02-03 04:02:32,197 Logging Sequence: 138_182.00
2024-02-03 04:02:32,197 	Gloss Reference :	A B+C+D+E
2024-02-03 04:02:32,198 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:02:32,198 	Gloss Alignment :	         
2024-02-03 04:02:32,198 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:02:32,199 	Text Reference  :	** **** there is  a    mural   of *** ******* ***** ** *** marcus rashford's face in   machester
2024-02-03 04:02:32,199 	Text Hypothesis :	so then in    the over because of the penalty shoot by any skin   or         are  sold out      
2024-02-03 04:02:32,199 	Text Alignment  :	I  I    S     S   S    S          I   I       I     I  I   S      S          S    S    S        
2024-02-03 04:02:32,199 ========================================================================================================================
2024-02-03 04:02:38,396 [Epoch: 091 Step: 00012100] Batch Recognition Loss:   0.008956 => Gls Tokens per Sec:     1287 || Batch Translation Loss:   0.214087 => Txt Tokens per Sec:     3594 || Lr: 0.000100
2024-02-03 04:02:38,557 Epoch  91: Total Training Recognition Loss 2.04  Total Training Translation Loss 53.70 
2024-02-03 04:02:38,557 EPOCH 92
2024-02-03 04:02:44,315 [Epoch: 092 Step: 00012200] Batch Recognition Loss:   0.032045 => Gls Tokens per Sec:     1348 || Batch Translation Loss:   0.403638 => Txt Tokens per Sec:     3767 || Lr: 0.000100
2024-02-03 04:02:46,299 Epoch  92: Total Training Recognition Loss 2.15  Total Training Translation Loss 55.85 
2024-02-03 04:02:46,299 EPOCH 93
2024-02-03 04:02:49,488 [Epoch: 093 Step: 00012300] Batch Recognition Loss:   0.003631 => Gls Tokens per Sec:     1606 || Batch Translation Loss:   0.453048 => Txt Tokens per Sec:     4422 || Lr: 0.000100
2024-02-03 04:02:53,458 Epoch  93: Total Training Recognition Loss 2.47  Total Training Translation Loss 65.45 
2024-02-03 04:02:53,459 EPOCH 94
2024-02-03 04:02:55,302 [Epoch: 094 Step: 00012400] Batch Recognition Loss:   0.082188 => Gls Tokens per Sec:     1346 || Batch Translation Loss:   0.380214 => Txt Tokens per Sec:     3902 || Lr: 0.000100
2024-02-03 04:03:00,806 [Epoch: 094 Step: 00012500] Batch Recognition Loss:   0.008430 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.471146 => Txt Tokens per Sec:     3964 || Lr: 0.000100
2024-02-03 04:03:00,944 Epoch  94: Total Training Recognition Loss 2.26  Total Training Translation Loss 52.12 
2024-02-03 04:03:00,944 EPOCH 95
2024-02-03 04:03:06,313 [Epoch: 095 Step: 00012600] Batch Recognition Loss:   0.001846 => Gls Tokens per Sec:     1460 || Batch Translation Loss:   0.213902 => Txt Tokens per Sec:     4077 || Lr: 0.000100
2024-02-03 04:03:08,395 Epoch  95: Total Training Recognition Loss 2.41  Total Training Translation Loss 51.73 
2024-02-03 04:03:08,395 EPOCH 96
2024-02-03 04:03:11,622 [Epoch: 096 Step: 00012700] Batch Recognition Loss:   0.062520 => Gls Tokens per Sec:     1612 || Batch Translation Loss:   0.157766 => Txt Tokens per Sec:     4544 || Lr: 0.000100
2024-02-03 04:03:15,404 Epoch  96: Total Training Recognition Loss 2.46  Total Training Translation Loss 42.13 
2024-02-03 04:03:15,405 EPOCH 97
2024-02-03 04:03:17,350 [Epoch: 097 Step: 00012800] Batch Recognition Loss:   0.002515 => Gls Tokens per Sec:     1317 || Batch Translation Loss:   0.311111 => Txt Tokens per Sec:     3781 || Lr: 0.000100
2024-02-03 04:03:22,699 [Epoch: 097 Step: 00012900] Batch Recognition Loss:   0.004998 => Gls Tokens per Sec:     1494 || Batch Translation Loss:   0.547639 => Txt Tokens per Sec:     4111 || Lr: 0.000100
2024-02-03 04:03:22,746 Epoch  97: Total Training Recognition Loss 2.40  Total Training Translation Loss 45.87 
2024-02-03 04:03:22,746 EPOCH 98
2024-02-03 04:03:28,401 [Epoch: 098 Step: 00013000] Batch Recognition Loss:   0.045350 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.156166 => Txt Tokens per Sec:     3883 || Lr: 0.000100
2024-02-03 04:03:30,596 Epoch  98: Total Training Recognition Loss 2.22  Total Training Translation Loss 55.31 
2024-02-03 04:03:30,596 EPOCH 99
2024-02-03 04:03:34,132 [Epoch: 099 Step: 00013100] Batch Recognition Loss:   0.003157 => Gls Tokens per Sec:     1494 || Batch Translation Loss:   0.271083 => Txt Tokens per Sec:     3927 || Lr: 0.000100
2024-02-03 04:03:37,956 Epoch  99: Total Training Recognition Loss 2.22  Total Training Translation Loss 48.50 
2024-02-03 04:03:37,957 EPOCH 100
2024-02-03 04:03:39,663 [Epoch: 100 Step: 00013200] Batch Recognition Loss:   0.011581 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.483652 => Txt Tokens per Sec:     4427 || Lr: 0.000100
2024-02-03 04:03:45,388 [Epoch: 100 Step: 00013300] Batch Recognition Loss:   0.004797 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.472323 => Txt Tokens per Sec:     3846 || Lr: 0.000100
2024-02-03 04:03:45,389 Epoch 100: Total Training Recognition Loss 2.54  Total Training Translation Loss 56.83 
2024-02-03 04:03:45,389 EPOCH 101
2024-02-03 04:03:51,196 [Epoch: 101 Step: 00013400] Batch Recognition Loss:   0.000783 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.128761 => Txt Tokens per Sec:     3845 || Lr: 0.000100
2024-02-03 04:03:53,028 Epoch 101: Total Training Recognition Loss 2.21  Total Training Translation Loss 51.26 
2024-02-03 04:03:53,028 EPOCH 102
2024-02-03 04:03:56,702 [Epoch: 102 Step: 00013500] Batch Recognition Loss:   0.048606 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.173202 => Txt Tokens per Sec:     4067 || Lr: 0.000100
2024-02-03 04:04:00,189 Epoch 102: Total Training Recognition Loss 2.22  Total Training Translation Loss 48.03 
2024-02-03 04:04:00,189 EPOCH 103
2024-02-03 04:04:01,979 [Epoch: 103 Step: 00013600] Batch Recognition Loss:   0.024178 => Gls Tokens per Sec:     1521 || Batch Translation Loss:   0.337304 => Txt Tokens per Sec:     4219 || Lr: 0.000100
2024-02-03 04:04:07,129 Epoch 103: Total Training Recognition Loss 2.29  Total Training Translation Loss 45.56 
2024-02-03 04:04:07,129 EPOCH 104
2024-02-03 04:04:07,191 [Epoch: 104 Step: 00013700] Batch Recognition Loss:   0.005838 => Gls Tokens per Sec:     1303 || Batch Translation Loss:   0.201721 => Txt Tokens per Sec:     3812 || Lr: 0.000100
2024-02-03 04:04:13,132 [Epoch: 104 Step: 00013800] Batch Recognition Loss:   0.005299 => Gls Tokens per Sec:     1347 || Batch Translation Loss:   0.199033 => Txt Tokens per Sec:     3708 || Lr: 0.000100
2024-02-03 04:04:14,969 Epoch 104: Total Training Recognition Loss 2.33  Total Training Translation Loss 44.67 
2024-02-03 04:04:14,969 EPOCH 105
2024-02-03 04:04:18,384 [Epoch: 105 Step: 00013900] Batch Recognition Loss:   0.007002 => Gls Tokens per Sec:     1593 || Batch Translation Loss:   0.494197 => Txt Tokens per Sec:     4310 || Lr: 0.000100
2024-02-03 04:04:22,179 Epoch 105: Total Training Recognition Loss 2.09  Total Training Translation Loss 47.80 
2024-02-03 04:04:22,180 EPOCH 106
2024-02-03 04:04:23,963 [Epoch: 106 Step: 00014000] Batch Recognition Loss:   0.007585 => Gls Tokens per Sec:     1571 || Batch Translation Loss:   0.243517 => Txt Tokens per Sec:     4112 || Lr: 0.000100
2024-02-03 04:04:34,639 Validation result at epoch 106, step    14000: duration: 10.6760s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.97527	Translation Loss: 85926.30469	PPL: 7514.77490
	Eval Metric: BLEU
	WER 4.67	(DEL: 0.00,	INS: 0.00,	SUB: 4.67)
	BLEU-4 0.53	(BLEU-1: 9.97,	BLEU-2: 2.88,	BLEU-3: 1.10,	BLEU-4: 0.53)
	CHRF 16.54	ROUGE 8.74
2024-02-03 04:04:34,640 Logging Recognition and Translation Outputs
2024-02-03 04:04:34,640 ========================================================================================================================
2024-02-03 04:04:34,641 Logging Sequence: 123_76.00
2024-02-03 04:04:34,641 	Gloss Reference :	A B+C+D+E
2024-02-03 04:04:34,641 	Gloss Hypothesis:	A B+C+B  
2024-02-03 04:04:34,641 	Gloss Alignment :	  S      
2024-02-03 04:04:34,641 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:04:34,642 	Text Reference  :	here there are
2024-02-03 04:04:34,642 	Text Hypothesis :	i'll tell  you
2024-02-03 04:04:34,642 	Text Alignment  :	S    S     S  
2024-02-03 04:04:34,642 ========================================================================================================================
2024-02-03 04:04:34,642 Logging Sequence: 87_224.00
2024-02-03 04:04:34,642 	Gloss Reference :	A B+C+D+E
2024-02-03 04:04:34,642 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:04:34,642 	Gloss Alignment :	         
2024-02-03 04:04:34,643 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:04:34,643 	Text Reference  :	***** ****** so  i  lost  my   cool and it  was my natural reaction
2024-02-03 04:04:34,644 	Text Hypothesis :	ishan kishan and kl rahul both know in  the age of 61      medals  
2024-02-03 04:04:34,644 	Text Alignment  :	I     I      S   S  S     S    S    S   S   S   S  S       S       
2024-02-03 04:04:34,644 ========================================================================================================================
2024-02-03 04:04:34,644 Logging Sequence: 182_20.00
2024-02-03 04:04:34,644 	Gloss Reference :	A B+C+D+E
2024-02-03 04:04:34,644 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:04:34,644 	Gloss Alignment :	         
2024-02-03 04:04:34,645 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:04:34,646 	Text Reference  :	in 2019 june yuvraj shocked the world when he   announced his international retirement many people were sad with  the         news   
2024-02-03 04:04:34,646 	Text Hypothesis :	** **** **** ****** ******* *** ***** god  will decide    if  she           used       to   pay    this is  named confederate problem
2024-02-03 04:04:34,647 	Text Alignment  :	D  D    D    D      D       D   D     S    S    S         S   S             S          S    S      S    S   S     S           S      
2024-02-03 04:04:34,647 ========================================================================================================================
2024-02-03 04:04:34,647 Logging Sequence: 116_133.00
2024-02-03 04:04:34,647 	Gloss Reference :	A B+C+D+E
2024-02-03 04:04:34,647 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:04:34,647 	Gloss Alignment :	         
2024-02-03 04:04:34,647 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:04:34,648 	Text Reference  :	*** he    expressed his sadness     in   the caption
2024-02-03 04:04:34,648 	Text Hypothesis :	the match was       not comfortable with the hotel  
2024-02-03 04:04:34,648 	Text Alignment  :	I   S     S         S   S           S        S      
2024-02-03 04:04:34,648 ========================================================================================================================
2024-02-03 04:04:34,648 Logging Sequence: 180_409.00
2024-02-03 04:04:34,649 	Gloss Reference :	A B+C+D+E
2024-02-03 04:04:34,649 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:04:34,649 	Gloss Alignment :	         
2024-02-03 04:04:34,649 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:04:34,650 	Text Reference  :	** cricketer kapil        dev  etc    have also shown   support to the wrestlers through their tweets
2024-02-03 04:04:34,650 	Text Hypothesis :	on police    instructions even subway and  tram traffic had     to *** ********* ******* be    halted
2024-02-03 04:04:34,650 	Text Alignment  :	I  S         S            S    S      S    S    S       S          D   D         D       S     S     
2024-02-03 04:04:34,650 ========================================================================================================================
2024-02-03 04:04:40,100 Epoch 106: Total Training Recognition Loss 1.85  Total Training Translation Loss 43.49 
2024-02-03 04:04:40,100 EPOCH 107
2024-02-03 04:04:40,223 [Epoch: 107 Step: 00014100] Batch Recognition Loss:   0.001070 => Gls Tokens per Sec:     1321 || Batch Translation Loss:   0.449625 => Txt Tokens per Sec:     3816 || Lr: 0.000100
2024-02-03 04:04:46,048 [Epoch: 107 Step: 00014200] Batch Recognition Loss:   0.003430 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.688159 => Txt Tokens per Sec:     3817 || Lr: 0.000100
2024-02-03 04:04:47,780 Epoch 107: Total Training Recognition Loss 1.65  Total Training Translation Loss 50.32 
2024-02-03 04:04:47,780 EPOCH 108
2024-02-03 04:04:51,142 [Epoch: 108 Step: 00014300] Batch Recognition Loss:   0.075973 => Gls Tokens per Sec:     1642 || Batch Translation Loss:   0.225316 => Txt Tokens per Sec:     4640 || Lr: 0.000100
2024-02-03 04:04:54,654 Epoch 108: Total Training Recognition Loss 1.97  Total Training Translation Loss 44.13 
2024-02-03 04:04:54,655 EPOCH 109
2024-02-03 04:04:56,484 [Epoch: 109 Step: 00014400] Batch Recognition Loss:   0.002489 => Gls Tokens per Sec:     1575 || Batch Translation Loss:   0.207352 => Txt Tokens per Sec:     4164 || Lr: 0.000100
2024-02-03 04:05:02,163 Epoch 109: Total Training Recognition Loss 2.01  Total Training Translation Loss 42.81 
2024-02-03 04:05:02,163 EPOCH 110
2024-02-03 04:05:02,322 [Epoch: 110 Step: 00014500] Batch Recognition Loss:   0.001254 => Gls Tokens per Sec:     1519 || Batch Translation Loss:   0.268992 => Txt Tokens per Sec:     4608 || Lr: 0.000100
2024-02-03 04:05:07,641 [Epoch: 110 Step: 00014600] Batch Recognition Loss:   0.007189 => Gls Tokens per Sec:     1504 || Batch Translation Loss:   0.653132 => Txt Tokens per Sec:     4219 || Lr: 0.000100
2024-02-03 04:05:09,583 Epoch 110: Total Training Recognition Loss 1.98  Total Training Translation Loss 46.11 
2024-02-03 04:05:09,584 EPOCH 111
2024-02-03 04:05:13,475 [Epoch: 111 Step: 00014700] Batch Recognition Loss:   0.003126 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.532415 => Txt Tokens per Sec:     3919 || Lr: 0.000100
2024-02-03 04:05:16,920 Epoch 111: Total Training Recognition Loss 2.08  Total Training Translation Loss 44.36 
2024-02-03 04:05:16,920 EPOCH 112
2024-02-03 04:05:18,574 [Epoch: 112 Step: 00014800] Batch Recognition Loss:   0.051793 => Gls Tokens per Sec:     1791 || Batch Translation Loss:   0.243973 => Txt Tokens per Sec:     4850 || Lr: 0.000100
2024-02-03 04:05:23,917 Epoch 112: Total Training Recognition Loss 1.84  Total Training Translation Loss 44.87 
2024-02-03 04:05:23,918 EPOCH 113
2024-02-03 04:05:24,147 [Epoch: 113 Step: 00014900] Batch Recognition Loss:   0.006391 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.136834 => Txt Tokens per Sec:     3829 || Lr: 0.000100
2024-02-03 04:05:29,538 [Epoch: 113 Step: 00015000] Batch Recognition Loss:   0.007136 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.370747 => Txt Tokens per Sec:     4136 || Lr: 0.000100
2024-02-03 04:05:31,425 Epoch 113: Total Training Recognition Loss 2.01  Total Training Translation Loss 48.98 
2024-02-03 04:05:31,426 EPOCH 114
2024-02-03 04:05:35,512 [Epoch: 114 Step: 00015100] Batch Recognition Loss:   0.008866 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.323576 => Txt Tokens per Sec:     3908 || Lr: 0.000100
2024-02-03 04:05:39,073 Epoch 114: Total Training Recognition Loss 1.95  Total Training Translation Loss 42.87 
2024-02-03 04:05:39,074 EPOCH 115
2024-02-03 04:05:41,346 [Epoch: 115 Step: 00015200] Batch Recognition Loss:   0.006558 => Gls Tokens per Sec:     1339 || Batch Translation Loss:   0.204723 => Txt Tokens per Sec:     3778 || Lr: 0.000100
2024-02-03 04:05:46,407 Epoch 115: Total Training Recognition Loss 1.68  Total Training Translation Loss 33.71 
2024-02-03 04:05:46,407 EPOCH 116
2024-02-03 04:05:46,733 [Epoch: 116 Step: 00015300] Batch Recognition Loss:   0.007063 => Gls Tokens per Sec:     1228 || Batch Translation Loss:   0.193865 => Txt Tokens per Sec:     3752 || Lr: 0.000100
2024-02-03 04:05:52,441 [Epoch: 116 Step: 00015400] Batch Recognition Loss:   0.006064 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.150554 => Txt Tokens per Sec:     3925 || Lr: 0.000100
2024-02-03 04:05:54,039 Epoch 116: Total Training Recognition Loss 1.75  Total Training Translation Loss 30.70 
2024-02-03 04:05:54,039 EPOCH 117
2024-02-03 04:05:58,099 [Epoch: 117 Step: 00015500] Batch Recognition Loss:   0.041544 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.553283 => Txt Tokens per Sec:     4011 || Lr: 0.000100
2024-02-03 04:06:01,332 Epoch 117: Total Training Recognition Loss 1.52  Total Training Translation Loss 31.12 
2024-02-03 04:06:01,333 EPOCH 118
2024-02-03 04:06:03,389 [Epoch: 118 Step: 00015600] Batch Recognition Loss:   0.002339 => Gls Tokens per Sec:     1519 || Batch Translation Loss:   0.162494 => Txt Tokens per Sec:     4272 || Lr: 0.000100
2024-02-03 04:06:08,657 Epoch 118: Total Training Recognition Loss 1.70  Total Training Translation Loss 43.16 
2024-02-03 04:06:08,657 EPOCH 119
2024-02-03 04:06:09,059 [Epoch: 119 Step: 00015700] Batch Recognition Loss:   0.020000 => Gls Tokens per Sec:     1197 || Batch Translation Loss:   0.225954 => Txt Tokens per Sec:     3741 || Lr: 0.000100
2024-02-03 04:06:14,803 [Epoch: 119 Step: 00015800] Batch Recognition Loss:   0.138676 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   0.366936 => Txt Tokens per Sec:     3857 || Lr: 0.000100
2024-02-03 04:06:16,260 Epoch 119: Total Training Recognition Loss 1.93  Total Training Translation Loss 41.00 
2024-02-03 04:06:16,260 EPOCH 120
2024-02-03 04:06:20,563 [Epoch: 120 Step: 00015900] Batch Recognition Loss:   0.001018 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.168272 => Txt Tokens per Sec:     3856 || Lr: 0.000100
2024-02-03 04:06:23,846 Epoch 120: Total Training Recognition Loss 1.92  Total Training Translation Loss 39.41 
2024-02-03 04:06:23,847 EPOCH 121
2024-02-03 04:06:25,978 [Epoch: 121 Step: 00016000] Batch Recognition Loss:   0.004203 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   0.167029 => Txt Tokens per Sec:     4217 || Lr: 0.000100
2024-02-03 04:06:37,552 Validation result at epoch 121, step    16000: duration: 11.5728s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 12.74510	Translation Loss: 86733.92969	PPL: 8172.33301
	Eval Metric: BLEU
	WER 4.31	(DEL: 0.07,	INS: 0.00,	SUB: 4.24)
	BLEU-4 0.32	(BLEU-1: 10.43,	BLEU-2: 2.92,	BLEU-3: 0.91,	BLEU-4: 0.32)
	CHRF 17.18	ROUGE 9.01
2024-02-03 04:06:37,553 Logging Recognition and Translation Outputs
2024-02-03 04:06:37,553 ========================================================================================================================
2024-02-03 04:06:37,553 Logging Sequence: 182_20.00
2024-02-03 04:06:37,554 	Gloss Reference :	A B+C+D+E
2024-02-03 04:06:37,554 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:06:37,554 	Gloss Alignment :	         
2024-02-03 04:06:37,554 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:06:37,556 	Text Reference  :	in 2019           june   yuvraj shocked the world when he announced his international retirement many  people were     sad  with   the ***** news
2024-02-03 04:06:37,556 	Text Hypothesis :	** praggnanandhaa played well   in      the ***** **** ** ********* *** ball          however    virat kohli  received love across the world cup 
2024-02-03 04:06:37,556 	Text Alignment  :	D  S              S      S      S           D     D    D  D         D   S             S          S     S      S        S    S          I     S   
2024-02-03 04:06:37,556 ========================================================================================================================
2024-02-03 04:06:37,556 Logging Sequence: 180_409.00
2024-02-03 04:06:37,556 	Gloss Reference :	A B+C+D+E
2024-02-03 04:06:37,557 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:06:37,557 	Gloss Alignment :	         
2024-02-03 04:06:37,557 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:06:37,558 	Text Reference  :	*** ** ******* cricketer kapil dev etc  have  also shown support to ******** the ***** wrestlers through their tweets
2024-02-03 04:06:37,558 	Text Hypothesis :	the oc started the       probe and were given 2    more  weeks   to complete the probe and       submit  the   report
2024-02-03 04:06:37,559 	Text Alignment  :	I   I  I       S         S     S   S    S     S    S     S          I            I     S         S       S     S     
2024-02-03 04:06:37,559 ========================================================================================================================
2024-02-03 04:06:37,559 Logging Sequence: 59_2.00
2024-02-03 04:06:37,559 	Gloss Reference :	A B+C+D+E
2024-02-03 04:06:37,559 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:06:37,559 	Gloss Alignment :	         
2024-02-03 04:06:37,559 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:06:37,560 	Text Reference  :	at the 2020 tokyo olympics in japan  
2024-02-03 04:06:37,560 	Text Hypothesis :	** *** **** ***** ronaldo  is strange
2024-02-03 04:06:37,560 	Text Alignment  :	D  D   D    D     S        S  S      
2024-02-03 04:06:37,560 ========================================================================================================================
2024-02-03 04:06:37,560 Logging Sequence: 118_100.00
2024-02-03 04:06:37,560 	Gloss Reference :	A B+C+D+E
2024-02-03 04:06:37,560 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:06:37,561 	Gloss Alignment :	         
2024-02-03 04:06:37,561 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:06:37,561 	Text Reference  :	while the      french were very  heartbroken by this
2024-02-03 04:06:37,561 	Text Hypothesis :	***** shocking to     see  these next        40 lakh
2024-02-03 04:06:37,562 	Text Alignment  :	D     S        S      S    S     S           S  S   
2024-02-03 04:06:37,562 ========================================================================================================================
2024-02-03 04:06:37,562 Logging Sequence: 69_204.00
2024-02-03 04:06:37,562 	Gloss Reference :	A B+C+D+E
2024-02-03 04:06:37,562 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:06:37,562 	Gloss Alignment :	         
2024-02-03 04:06:37,562 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:06:37,563 	Text Reference  :	however i am  hoping  to      play the     next   season'
2024-02-03 04:06:37,563 	Text Hypothesis :	******* * the winning skipper was  finally called upon   
2024-02-03 04:06:37,563 	Text Alignment  :	D       D S   S       S       S    S       S      S      
2024-02-03 04:06:37,563 ========================================================================================================================
2024-02-03 04:06:42,922 Epoch 121: Total Training Recognition Loss 2.16  Total Training Translation Loss 47.87 
2024-02-03 04:06:42,923 EPOCH 122
2024-02-03 04:06:43,311 [Epoch: 122 Step: 00016100] Batch Recognition Loss:   0.004635 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.462443 => Txt Tokens per Sec:     3584 || Lr: 0.000100
2024-02-03 04:06:49,035 [Epoch: 122 Step: 00016200] Batch Recognition Loss:   0.009491 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.769941 => Txt Tokens per Sec:     3942 || Lr: 0.000100
2024-02-03 04:06:50,512 Epoch 122: Total Training Recognition Loss 1.94  Total Training Translation Loss 41.88 
2024-02-03 04:06:50,513 EPOCH 123
2024-02-03 04:06:54,997 [Epoch: 123 Step: 00016300] Batch Recognition Loss:   0.017958 => Gls Tokens per Sec:     1321 || Batch Translation Loss:   0.283248 => Txt Tokens per Sec:     3677 || Lr: 0.000100
2024-02-03 04:06:58,347 Epoch 123: Total Training Recognition Loss 2.02  Total Training Translation Loss 44.07 
2024-02-03 04:06:58,348 EPOCH 124
2024-02-03 04:07:00,446 [Epoch: 124 Step: 00016400] Batch Recognition Loss:   0.011408 => Gls Tokens per Sec:     1564 || Batch Translation Loss:   0.147918 => Txt Tokens per Sec:     4334 || Lr: 0.000100
2024-02-03 04:07:05,795 Epoch 124: Total Training Recognition Loss 1.62  Total Training Translation Loss 49.07 
2024-02-03 04:07:05,796 EPOCH 125
2024-02-03 04:07:06,393 [Epoch: 125 Step: 00016500] Batch Recognition Loss:   0.036907 => Gls Tokens per Sec:     1074 || Batch Translation Loss:   0.140577 => Txt Tokens per Sec:     3592 || Lr: 0.000100
2024-02-03 04:07:12,056 [Epoch: 125 Step: 00016600] Batch Recognition Loss:   0.014484 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.600150 => Txt Tokens per Sec:     3851 || Lr: 0.000100
2024-02-03 04:07:13,544 Epoch 125: Total Training Recognition Loss 2.04  Total Training Translation Loss 40.68 
2024-02-03 04:07:13,545 EPOCH 126
2024-02-03 04:07:17,967 [Epoch: 126 Step: 00016700] Batch Recognition Loss:   0.011512 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.308313 => Txt Tokens per Sec:     3869 || Lr: 0.000100
2024-02-03 04:07:21,203 Epoch 126: Total Training Recognition Loss 1.75  Total Training Translation Loss 37.61 
2024-02-03 04:07:21,203 EPOCH 127
2024-02-03 04:07:23,646 [Epoch: 127 Step: 00016800] Batch Recognition Loss:   0.001945 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.579529 => Txt Tokens per Sec:     3877 || Lr: 0.000100
2024-02-03 04:07:28,613 Epoch 127: Total Training Recognition Loss 1.54  Total Training Translation Loss 38.21 
2024-02-03 04:07:28,614 EPOCH 128
2024-02-03 04:07:29,056 [Epoch: 128 Step: 00016900] Batch Recognition Loss:   0.028746 => Gls Tokens per Sec:     1636 || Batch Translation Loss:   0.623999 => Txt Tokens per Sec:     4600 || Lr: 0.000100
2024-02-03 04:07:34,891 [Epoch: 128 Step: 00017000] Batch Recognition Loss:   0.006825 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.166884 => Txt Tokens per Sec:     3839 || Lr: 0.000100
2024-02-03 04:07:36,330 Epoch 128: Total Training Recognition Loss 1.79  Total Training Translation Loss 28.32 
2024-02-03 04:07:36,330 EPOCH 129
2024-02-03 04:07:40,550 [Epoch: 129 Step: 00017100] Batch Recognition Loss:   0.000997 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.230145 => Txt Tokens per Sec:     3940 || Lr: 0.000100
2024-02-03 04:07:43,746 Epoch 129: Total Training Recognition Loss 1.39  Total Training Translation Loss 29.15 
2024-02-03 04:07:43,746 EPOCH 130
2024-02-03 04:07:46,310 [Epoch: 130 Step: 00017200] Batch Recognition Loss:   0.001582 => Gls Tokens per Sec:     1343 || Batch Translation Loss:   0.490468 => Txt Tokens per Sec:     3825 || Lr: 0.000100
2024-02-03 04:07:51,362 Epoch 130: Total Training Recognition Loss 1.78  Total Training Translation Loss 36.09 
2024-02-03 04:07:51,363 EPOCH 131
2024-02-03 04:07:51,998 [Epoch: 131 Step: 00017300] Batch Recognition Loss:   0.009933 => Gls Tokens per Sec:     1262 || Batch Translation Loss:   0.237194 => Txt Tokens per Sec:     3697 || Lr: 0.000100
2024-02-03 04:07:57,620 [Epoch: 131 Step: 00017400] Batch Recognition Loss:   0.005500 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.430867 => Txt Tokens per Sec:     3923 || Lr: 0.000100
2024-02-03 04:07:58,970 Epoch 131: Total Training Recognition Loss 1.69  Total Training Translation Loss 35.19 
2024-02-03 04:07:58,971 EPOCH 132
2024-02-03 04:08:03,430 [Epoch: 132 Step: 00017500] Batch Recognition Loss:   0.002894 => Gls Tokens per Sec:     1382 || Batch Translation Loss:   0.366032 => Txt Tokens per Sec:     3876 || Lr: 0.000100
2024-02-03 04:08:06,613 Epoch 132: Total Training Recognition Loss 1.84  Total Training Translation Loss 37.63 
2024-02-03 04:08:06,614 EPOCH 133
2024-02-03 04:08:08,752 [Epoch: 133 Step: 00017600] Batch Recognition Loss:   0.004606 => Gls Tokens per Sec:     1648 || Batch Translation Loss:   0.652178 => Txt Tokens per Sec:     4580 || Lr: 0.000100
2024-02-03 04:08:13,630 Epoch 133: Total Training Recognition Loss 1.69  Total Training Translation Loss 31.65 
2024-02-03 04:08:13,630 EPOCH 134
2024-02-03 04:08:14,298 [Epoch: 134 Step: 00017700] Batch Recognition Loss:   0.002828 => Gls Tokens per Sec:     1325 || Batch Translation Loss:   0.190673 => Txt Tokens per Sec:     3887 || Lr: 0.000100
2024-02-03 04:08:19,625 [Epoch: 134 Step: 00017800] Batch Recognition Loss:   0.002811 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   0.226645 => Txt Tokens per Sec:     4101 || Lr: 0.000100
2024-02-03 04:08:20,911 Epoch 134: Total Training Recognition Loss 1.67  Total Training Translation Loss 33.98 
2024-02-03 04:08:20,912 EPOCH 135
2024-02-03 04:08:25,067 [Epoch: 135 Step: 00017900] Batch Recognition Loss:   0.000690 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   0.112076 => Txt Tokens per Sec:     4186 || Lr: 0.000100
2024-02-03 04:08:28,200 Epoch 135: Total Training Recognition Loss 1.40  Total Training Translation Loss 34.91 
2024-02-03 04:08:28,200 EPOCH 136
2024-02-03 04:08:30,558 [Epoch: 136 Step: 00018000] Batch Recognition Loss:   0.012375 => Gls Tokens per Sec:     1527 || Batch Translation Loss:   0.492625 => Txt Tokens per Sec:     4099 || Lr: 0.000100
2024-02-03 04:08:41,370 Validation result at epoch 136, step    18000: duration: 10.8122s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.30259	Translation Loss: 88500.23438	PPL: 9817.91602
	Eval Metric: BLEU
	WER 3.96	(DEL: 0.21,	INS: 0.00,	SUB: 3.75)
	BLEU-4 0.34	(BLEU-1: 10.38,	BLEU-2: 2.95,	BLEU-3: 0.97,	BLEU-4: 0.34)
	CHRF 17.05	ROUGE 8.43
2024-02-03 04:08:41,372 Logging Recognition and Translation Outputs
2024-02-03 04:08:41,372 ========================================================================================================================
2024-02-03 04:08:41,372 Logging Sequence: 64_53.00
2024-02-03 04:08:41,372 	Gloss Reference :	A B+C+D+E
2024-02-03 04:08:41,372 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:08:41,372 	Gloss Alignment :	         
2024-02-03 04:08:41,373 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:08:41,374 	Text Reference  :	*** the  bcci and ipl does        not  want to    compromise on the safety of the players
2024-02-03 04:08:41,374 	Text Hypothesis :	but then came to  be  quarantined till both don't go         on *** ****** ** his jersey 
2024-02-03 04:08:41,374 	Text Alignment  :	I   S    S    S   S   S           S    S    S     S             D   D      D  S   S      
2024-02-03 04:08:41,374 ========================================================================================================================
2024-02-03 04:08:41,374 Logging Sequence: 165_252.00
2024-02-03 04:08:41,375 	Gloss Reference :	A B+C+D+E
2024-02-03 04:08:41,375 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:08:41,375 	Gloss Alignment :	         
2024-02-03 04:08:41,375 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:08:41,376 	Text Reference  :	*** **** *** *** **** ** ****** *** 4    rahul dravid also has      his  own  superstitions
2024-02-03 04:08:41,376 	Text Hypothesis :	but also did not want to change the team for   6      and  pakistan also been quarantined  
2024-02-03 04:08:41,376 	Text Alignment  :	I   I    I   I   I    I  I      I   S    S     S      S    S        S    S    S            
2024-02-03 04:08:41,376 ========================================================================================================================
2024-02-03 04:08:41,377 Logging Sequence: 90_7.00
2024-02-03 04:08:41,377 	Gloss Reference :	A B+C+D+E
2024-02-03 04:08:41,377 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:08:41,377 	Gloss Alignment :	         
2024-02-03 04:08:41,377 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:08:41,378 	Text Reference  :	let me  tell you the exciting story of how    they were introduced
2024-02-03 04:08:41,378 	Text Hypothesis :	*** but why  is  the ******** ***** ** couple to   do   anything  
2024-02-03 04:08:41,378 	Text Alignment  :	D   S   S    S       D        D     D  S      S    S    S         
2024-02-03 04:08:41,378 ========================================================================================================================
2024-02-03 04:08:41,378 Logging Sequence: 137_307.00
2024-02-03 04:08:41,379 	Gloss Reference :	A B+C+D+E
2024-02-03 04:08:41,379 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:08:41,379 	Gloss Alignment :	         
2024-02-03 04:08:41,379 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:08:41,380 	Text Reference  :	so to be extra careful the player's flight was escorted  by    the flighter jets     
2024-02-03 04:08:41,380 	Text Hypothesis :	** ** ** here  is      the ******** ****** *** governing board of  indian   cricketer
2024-02-03 04:08:41,380 	Text Alignment  :	D  D  D  S     S           D        D      D   S         S     S   S        S        
2024-02-03 04:08:41,380 ========================================================================================================================
2024-02-03 04:08:41,380 Logging Sequence: 165_200.00
2024-02-03 04:08:41,381 	Gloss Reference :	A B+C+D+E
2024-02-03 04:08:41,381 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:08:41,381 	Gloss Alignment :	         
2024-02-03 04:08:41,381 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:08:41,382 	Text Reference  :	you may be  wondering what bag     remember in  2011      when india won  the world cup   
2024-02-03 04:08:41,382 	Text Hypothesis :	*** *** but that      is   amazing batsman  who qualified for  the   team on  his   jersey
2024-02-03 04:08:41,382 	Text Alignment  :	D   D   S   S         S    S       S        S   S         S    S     S    S   S     S     
2024-02-03 04:08:41,383 ========================================================================================================================
2024-02-03 04:08:46,450 Epoch 136: Total Training Recognition Loss 1.21  Total Training Translation Loss 33.82 
2024-02-03 04:08:46,450 EPOCH 137
2024-02-03 04:08:47,184 [Epoch: 137 Step: 00018100] Batch Recognition Loss:   0.080869 => Gls Tokens per Sec:     1311 || Batch Translation Loss:   0.193322 => Txt Tokens per Sec:     3593 || Lr: 0.000100
2024-02-03 04:08:52,703 [Epoch: 137 Step: 00018200] Batch Recognition Loss:   0.002824 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.422263 => Txt Tokens per Sec:     4028 || Lr: 0.000100
2024-02-03 04:08:53,915 Epoch 137: Total Training Recognition Loss 1.51  Total Training Translation Loss 32.58 
2024-02-03 04:08:53,916 EPOCH 138
2024-02-03 04:08:58,416 [Epoch: 138 Step: 00018300] Batch Recognition Loss:   0.002654 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.146581 => Txt Tokens per Sec:     3923 || Lr: 0.000100
2024-02-03 04:09:01,626 Epoch 138: Total Training Recognition Loss 1.24  Total Training Translation Loss 35.96 
2024-02-03 04:09:01,626 EPOCH 139
2024-02-03 04:09:04,486 [Epoch: 139 Step: 00018400] Batch Recognition Loss:   0.001461 => Gls Tokens per Sec:     1288 || Batch Translation Loss:   0.137677 => Txt Tokens per Sec:     3594 || Lr: 0.000100
2024-02-03 04:09:09,006 Epoch 139: Total Training Recognition Loss 1.72  Total Training Translation Loss 31.79 
2024-02-03 04:09:09,007 EPOCH 140
2024-02-03 04:09:09,781 [Epoch: 140 Step: 00018500] Batch Recognition Loss:   0.023732 => Gls Tokens per Sec:     1345 || Batch Translation Loss:   0.249907 => Txt Tokens per Sec:     3558 || Lr: 0.000100
2024-02-03 04:09:15,541 [Epoch: 140 Step: 00018600] Batch Recognition Loss:   0.000716 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.185685 => Txt Tokens per Sec:     3895 || Lr: 0.000100
2024-02-03 04:09:16,566 Epoch 140: Total Training Recognition Loss 1.90  Total Training Translation Loss 28.62 
2024-02-03 04:09:16,566 EPOCH 141
2024-02-03 04:09:20,907 [Epoch: 141 Step: 00018700] Batch Recognition Loss:   0.328880 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.260468 => Txt Tokens per Sec:     4133 || Lr: 0.000100
2024-02-03 04:09:23,607 Epoch 141: Total Training Recognition Loss 2.07  Total Training Translation Loss 30.08 
2024-02-03 04:09:23,607 EPOCH 142
2024-02-03 04:09:26,390 [Epoch: 142 Step: 00018800] Batch Recognition Loss:   0.002230 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   0.299764 => Txt Tokens per Sec:     3867 || Lr: 0.000100
2024-02-03 04:09:31,021 Epoch 142: Total Training Recognition Loss 2.63  Total Training Translation Loss 37.97 
2024-02-03 04:09:31,021 EPOCH 143
2024-02-03 04:09:31,686 [Epoch: 143 Step: 00018900] Batch Recognition Loss:   0.003587 => Gls Tokens per Sec:     1688 || Batch Translation Loss:   0.709037 => Txt Tokens per Sec:     4696 || Lr: 0.000100
2024-02-03 04:09:37,353 [Epoch: 143 Step: 00019000] Batch Recognition Loss:   0.001308 => Gls Tokens per Sec:     1412 || Batch Translation Loss:   0.206889 => Txt Tokens per Sec:     3958 || Lr: 0.000100
2024-02-03 04:09:38,485 Epoch 143: Total Training Recognition Loss 1.83  Total Training Translation Loss 31.15 
2024-02-03 04:09:38,485 EPOCH 144
2024-02-03 04:09:43,097 [Epoch: 144 Step: 00019100] Batch Recognition Loss:   0.001844 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.112848 => Txt Tokens per Sec:     3927 || Lr: 0.000100
2024-02-03 04:09:45,985 Epoch 144: Total Training Recognition Loss 1.62  Total Training Translation Loss 38.04 
2024-02-03 04:09:45,986 EPOCH 145
2024-02-03 04:09:48,213 [Epoch: 145 Step: 00019200] Batch Recognition Loss:   0.005728 => Gls Tokens per Sec:     1724 || Batch Translation Loss:   0.214402 => Txt Tokens per Sec:     4605 || Lr: 0.000100
2024-02-03 04:09:53,123 Epoch 145: Total Training Recognition Loss 1.49  Total Training Translation Loss 32.63 
2024-02-03 04:09:53,124 EPOCH 146
2024-02-03 04:09:54,038 [Epoch: 146 Step: 00019300] Batch Recognition Loss:   0.002980 => Gls Tokens per Sec:     1313 || Batch Translation Loss:   0.206332 => Txt Tokens per Sec:     3490 || Lr: 0.000100
2024-02-03 04:09:59,948 [Epoch: 146 Step: 00019400] Batch Recognition Loss:   0.003334 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   0.309389 => Txt Tokens per Sec:     3777 || Lr: 0.000100
2024-02-03 04:10:00,976 Epoch 146: Total Training Recognition Loss 1.19  Total Training Translation Loss 38.39 
2024-02-03 04:10:00,976 EPOCH 147
2024-02-03 04:10:05,602 [Epoch: 147 Step: 00019500] Batch Recognition Loss:   0.015099 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.195706 => Txt Tokens per Sec:     4054 || Lr: 0.000100
2024-02-03 04:10:08,596 Epoch 147: Total Training Recognition Loss 1.18  Total Training Translation Loss 34.75 
2024-02-03 04:10:08,596 EPOCH 148
2024-02-03 04:10:11,436 [Epoch: 148 Step: 00019600] Batch Recognition Loss:   0.029565 => Gls Tokens per Sec:     1382 || Batch Translation Loss:   0.079449 => Txt Tokens per Sec:     3862 || Lr: 0.000100
2024-02-03 04:10:15,981 Epoch 148: Total Training Recognition Loss 1.24  Total Training Translation Loss 21.75 
2024-02-03 04:10:15,982 EPOCH 149
2024-02-03 04:10:16,685 [Epoch: 149 Step: 00019700] Batch Recognition Loss:   0.001588 => Gls Tokens per Sec:     1825 || Batch Translation Loss:   0.167527 => Txt Tokens per Sec:     4958 || Lr: 0.000100
2024-02-03 04:10:22,179 [Epoch: 149 Step: 00019800] Batch Recognition Loss:   0.007419 => Gls Tokens per Sec:     1456 || Batch Translation Loss:   0.592229 => Txt Tokens per Sec:     4088 || Lr: 0.000100
2024-02-03 04:10:23,283 Epoch 149: Total Training Recognition Loss 1.34  Total Training Translation Loss 24.03 
2024-02-03 04:10:23,283 EPOCH 150
2024-02-03 04:10:28,180 [Epoch: 150 Step: 00019900] Batch Recognition Loss:   0.015779 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.246753 => Txt Tokens per Sec:     3790 || Lr: 0.000100
2024-02-03 04:10:31,064 Epoch 150: Total Training Recognition Loss 1.28  Total Training Translation Loss 22.54 
2024-02-03 04:10:31,064 EPOCH 151
2024-02-03 04:10:33,825 [Epoch: 151 Step: 00020000] Batch Recognition Loss:   0.003956 => Gls Tokens per Sec:     1450 || Batch Translation Loss:   0.106894 => Txt Tokens per Sec:     4026 || Lr: 0.000100
2024-02-03 04:10:44,417 Hooray! New best validation result [eval_metric]!
2024-02-03 04:10:44,418 Saving new checkpoint.
2024-02-03 04:10:44,684 Validation result at epoch 151, step    20000: duration: 10.8594s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.69543	Translation Loss: 89356.85938	PPL: 10731.47461
	Eval Metric: BLEU
	WER 4.03	(DEL: 0.21,	INS: 0.00,	SUB: 3.82)
	BLEU-4 0.70	(BLEU-1: 10.28,	BLEU-2: 3.27,	BLEU-3: 1.40,	BLEU-4: 0.70)
	CHRF 16.76	ROUGE 8.58
2024-02-03 04:10:44,685 Logging Recognition and Translation Outputs
2024-02-03 04:10:44,685 ========================================================================================================================
2024-02-03 04:10:44,686 Logging Sequence: 153_218.00
2024-02-03 04:10:44,686 	Gloss Reference :	A B+C+D+E
2024-02-03 04:10:44,686 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:10:44,686 	Gloss Alignment :	         
2024-02-03 04:10:44,686 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:10:44,688 	Text Reference  :	the ****** **** 2022  final match     is  being held    in         the same melbourne stadium where  the 1992  match  was   held    
2024-02-03 04:10:44,688 	Text Hypothesis :	the couple were found in    australia for deaf  cricket tournament and are  crazy     to      emerge as  india needed their families
2024-02-03 04:10:44,688 	Text Alignment  :	    I      I    S     S     S         S   S     S       S          S   S    S         S       S      S   S     S      S     S       
2024-02-03 04:10:44,689 ========================================================================================================================
2024-02-03 04:10:44,689 Logging Sequence: 168_115.00
2024-02-03 04:10:44,689 	Gloss Reference :	A B+C+D+E
2024-02-03 04:10:44,689 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:10:44,689 	Gloss Alignment :	         
2024-02-03 04:10:44,689 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:10:44,690 	Text Reference  :	this has sparked a     major discussion on  social media
2024-02-03 04:10:44,690 	Text Hypothesis :	**** *** many    teams are   all        out for    189  
2024-02-03 04:10:44,690 	Text Alignment  :	D    D   S       S     S     S          S   S      S    
2024-02-03 04:10:44,690 ========================================================================================================================
2024-02-03 04:10:44,690 Logging Sequence: 180_82.00
2024-02-03 04:10:44,690 	Gloss Reference :	A B+C+D+E
2024-02-03 04:10:44,691 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:10:44,691 	Gloss Alignment :	         
2024-02-03 04:10:44,691 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:10:44,693 	Text Reference  :	let me tell you *** about the protest that * **** ****** has      been going    on  since  23rd april 2023
2024-02-03 04:10:44,693 	Text Hypothesis :	i   am sure you all are   all know    that i have tested positive for  covid-19 and called him  about it  
2024-02-03 04:10:44,693 	Text Alignment  :	S   S  S        I   S     S   S            I I    I      S        S    S        S   S      S    S     S   
2024-02-03 04:10:44,693 ========================================================================================================================
2024-02-03 04:10:44,693 Logging Sequence: 56_14.00
2024-02-03 04:10:44,693 	Gloss Reference :	A B+C+D+E
2024-02-03 04:10:44,693 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:10:44,693 	Gloss Alignment :	         
2024-02-03 04:10:44,694 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:10:44,694 	Text Reference  :	people were glued to their screens during the     match 
2024-02-03 04:10:44,694 	Text Hypothesis :	****** **** ***** ** ***** what    an     amazing player
2024-02-03 04:10:44,694 	Text Alignment  :	D      D    D     D  D     S       S      S       S     
2024-02-03 04:10:44,694 ========================================================================================================================
2024-02-03 04:10:44,695 Logging Sequence: 62_135.00
2024-02-03 04:10:44,695 	Gloss Reference :	A B+C+D+E
2024-02-03 04:10:44,695 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:10:44,695 	Gloss Alignment :	         
2024-02-03 04:10:44,695 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:10:44,696 	Text Reference  :	a   grade player    is the    one           who 
2024-02-03 04:10:44,696 	Text Hypothesis :	the pay   disparity is really international team
2024-02-03 04:10:44,696 	Text Alignment  :	S   S     S            S      S             S   
2024-02-03 04:10:44,696 ========================================================================================================================
2024-02-03 04:10:49,102 Epoch 151: Total Training Recognition Loss 1.39  Total Training Translation Loss 27.55 
2024-02-03 04:10:49,102 EPOCH 152
2024-02-03 04:10:49,923 [Epoch: 152 Step: 00020100] Batch Recognition Loss:   0.005629 => Gls Tokens per Sec:     1658 || Batch Translation Loss:   0.179708 => Txt Tokens per Sec:     4454 || Lr: 0.000100
2024-02-03 04:10:55,542 [Epoch: 152 Step: 00020200] Batch Recognition Loss:   0.034162 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.579949 => Txt Tokens per Sec:     3985 || Lr: 0.000100
2024-02-03 04:10:56,359 Epoch 152: Total Training Recognition Loss 1.12  Total Training Translation Loss 39.25 
2024-02-03 04:10:56,359 EPOCH 153
2024-02-03 04:11:01,379 [Epoch: 153 Step: 00020300] Batch Recognition Loss:   0.010631 => Gls Tokens per Sec:     1339 || Batch Translation Loss:   0.943720 => Txt Tokens per Sec:     3750 || Lr: 0.000100
2024-02-03 04:11:03,988 Epoch 153: Total Training Recognition Loss 1.34  Total Training Translation Loss 46.40 
2024-02-03 04:11:03,988 EPOCH 154
2024-02-03 04:11:06,834 [Epoch: 154 Step: 00020400] Batch Recognition Loss:   0.005827 => Gls Tokens per Sec:     1434 || Batch Translation Loss:   0.103363 => Txt Tokens per Sec:     3806 || Lr: 0.000100
2024-02-03 04:11:11,606 Epoch 154: Total Training Recognition Loss 1.45  Total Training Translation Loss 33.46 
2024-02-03 04:11:11,607 EPOCH 155
2024-02-03 04:11:12,586 [Epoch: 155 Step: 00020500] Batch Recognition Loss:   0.002696 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.155495 => Txt Tokens per Sec:     4073 || Lr: 0.000100
2024-02-03 04:11:17,819 [Epoch: 155 Step: 00020600] Batch Recognition Loss:   0.006749 => Gls Tokens per Sec:     1529 || Batch Translation Loss:   0.128105 => Txt Tokens per Sec:     4269 || Lr: 0.000100
2024-02-03 04:11:18,708 Epoch 155: Total Training Recognition Loss 1.50  Total Training Translation Loss 28.23 
2024-02-03 04:11:18,708 EPOCH 156
2024-02-03 04:11:23,675 [Epoch: 156 Step: 00020700] Batch Recognition Loss:   0.002103 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.079091 => Txt Tokens per Sec:     3845 || Lr: 0.000100
2024-02-03 04:11:26,493 Epoch 156: Total Training Recognition Loss 1.16  Total Training Translation Loss 23.93 
2024-02-03 04:11:26,494 EPOCH 157
2024-02-03 04:11:29,399 [Epoch: 157 Step: 00020800] Batch Recognition Loss:   0.003048 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.163593 => Txt Tokens per Sec:     4034 || Lr: 0.000100
2024-02-03 04:11:33,865 Epoch 157: Total Training Recognition Loss 1.30  Total Training Translation Loss 25.51 
2024-02-03 04:11:33,866 EPOCH 158
2024-02-03 04:11:34,929 [Epoch: 158 Step: 00020900] Batch Recognition Loss:   0.009306 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.082316 => Txt Tokens per Sec:     3881 || Lr: 0.000100
2024-02-03 04:11:40,410 [Epoch: 158 Step: 00021000] Batch Recognition Loss:   0.013426 => Gls Tokens per Sec:     1460 || Batch Translation Loss:   0.104665 => Txt Tokens per Sec:     4102 || Lr: 0.000100
2024-02-03 04:11:41,293 Epoch 158: Total Training Recognition Loss 1.12  Total Training Translation Loss 29.89 
2024-02-03 04:11:41,293 EPOCH 159
2024-02-03 04:11:45,693 [Epoch: 159 Step: 00021100] Batch Recognition Loss:   0.001980 => Gls Tokens per Sec:     1564 || Batch Translation Loss:   0.260636 => Txt Tokens per Sec:     4339 || Lr: 0.000100
2024-02-03 04:11:48,455 Epoch 159: Total Training Recognition Loss 1.19  Total Training Translation Loss 24.96 
2024-02-03 04:11:48,456 EPOCH 160
2024-02-03 04:11:51,225 [Epoch: 160 Step: 00021200] Batch Recognition Loss:   0.000566 => Gls Tokens per Sec:     1532 || Batch Translation Loss:   0.440747 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-03 04:11:55,479 Epoch 160: Total Training Recognition Loss 1.27  Total Training Translation Loss 37.21 
2024-02-03 04:11:55,480 EPOCH 161
2024-02-03 04:11:56,393 [Epoch: 161 Step: 00021300] Batch Recognition Loss:   0.052870 => Gls Tokens per Sec:     1755 || Batch Translation Loss:   0.289376 => Txt Tokens per Sec:     4689 || Lr: 0.000100
2024-02-03 04:12:02,063 [Epoch: 161 Step: 00021400] Batch Recognition Loss:   0.005554 => Gls Tokens per Sec:     1409 || Batch Translation Loss:   0.585738 => Txt Tokens per Sec:     3927 || Lr: 0.000100
2024-02-03 04:12:02,848 Epoch 161: Total Training Recognition Loss 1.95  Total Training Translation Loss 42.37 
2024-02-03 04:12:02,848 EPOCH 162
2024-02-03 04:12:07,726 [Epoch: 162 Step: 00021500] Batch Recognition Loss:   0.005829 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.244807 => Txt Tokens per Sec:     3930 || Lr: 0.000100
2024-02-03 04:12:10,490 Epoch 162: Total Training Recognition Loss 1.06  Total Training Translation Loss 27.24 
2024-02-03 04:12:10,490 EPOCH 163
2024-02-03 04:12:13,442 [Epoch: 163 Step: 00021600] Batch Recognition Loss:   0.042585 => Gls Tokens per Sec:     1464 || Batch Translation Loss:   0.439339 => Txt Tokens per Sec:     4100 || Lr: 0.000100
2024-02-03 04:12:17,969 Epoch 163: Total Training Recognition Loss 1.16  Total Training Translation Loss 25.45 
2024-02-03 04:12:17,970 EPOCH 164
2024-02-03 04:12:19,114 [Epoch: 164 Step: 00021700] Batch Recognition Loss:   0.001937 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.144796 => Txt Tokens per Sec:     4195 || Lr: 0.000100
2024-02-03 04:12:24,502 [Epoch: 164 Step: 00021800] Batch Recognition Loss:   0.002193 => Gls Tokens per Sec:     1485 || Batch Translation Loss:   0.485994 => Txt Tokens per Sec:     4068 || Lr: 0.000100
2024-02-03 04:12:25,302 Epoch 164: Total Training Recognition Loss 1.21  Total Training Translation Loss 29.43 
2024-02-03 04:12:25,302 EPOCH 165
2024-02-03 04:12:30,433 [Epoch: 165 Step: 00021900] Batch Recognition Loss:   0.006043 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.254317 => Txt Tokens per Sec:     3744 || Lr: 0.000100
2024-02-03 04:12:33,043 Epoch 165: Total Training Recognition Loss 1.12  Total Training Translation Loss 30.28 
2024-02-03 04:12:33,043 EPOCH 166
2024-02-03 04:12:36,227 [Epoch: 166 Step: 00022000] Batch Recognition Loss:   0.018719 => Gls Tokens per Sec:     1383 || Batch Translation Loss:   0.061514 => Txt Tokens per Sec:     3800 || Lr: 0.000100
2024-02-03 04:12:46,783 Validation result at epoch 166, step    22000: duration: 10.5558s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.45328	Translation Loss: 89486.42188	PPL: 10876.86719
	Eval Metric: BLEU
	WER 3.82	(DEL: 0.14,	INS: 0.00,	SUB: 3.68)
	BLEU-4 0.61	(BLEU-1: 10.48,	BLEU-2: 3.06,	BLEU-3: 1.31,	BLEU-4: 0.61)
	CHRF 16.64	ROUGE 8.83
2024-02-03 04:12:46,784 Logging Recognition and Translation Outputs
2024-02-03 04:12:46,785 ========================================================================================================================
2024-02-03 04:12:46,785 Logging Sequence: 85_58.00
2024-02-03 04:12:46,785 	Gloss Reference :	A B+C+D+E
2024-02-03 04:12:46,785 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:12:46,785 	Gloss Alignment :	         
2024-02-03 04:12:46,785 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:12:46,786 	Text Reference  :	symonds has been      an amazing player
2024-02-03 04:12:46,786 	Text Hypothesis :	symonds was captained by 31      years 
2024-02-03 04:12:46,786 	Text Alignment  :	        S   S         S  S       S     
2024-02-03 04:12:46,786 ========================================================================================================================
2024-02-03 04:12:46,786 Logging Sequence: 71_120.00
2024-02-03 04:12:46,787 	Gloss Reference :	A B+C+D+E
2024-02-03 04:12:46,787 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:12:46,787 	Gloss Alignment :	         
2024-02-03 04:12:46,787 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:12:46,789 	Text Reference  :	********* ***** * ***** on  3rd august 2022 kartikeya met  his      family and posted    a     heartwarming picture with   his  mother    
2024-02-03 04:12:46,789 	Text Hypothesis :	kartikeya singh a young boy who was    born on        26th december 1997   in  sultanpur uttar pradesh      was     always very passionate
2024-02-03 04:12:46,789 	Text Alignment  :	I         I     I I     S   S   S      S    S         S    S        S      S   S         S     S            S       S      S    S         
2024-02-03 04:12:46,789 ========================================================================================================================
2024-02-03 04:12:46,789 Logging Sequence: 174_64.00
2024-02-03 04:12:46,789 	Gloss Reference :	A B+C+D+E
2024-02-03 04:12:46,790 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:12:46,790 	Gloss Alignment :	         
2024-02-03 04:12:46,790 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:12:46,791 	Text Reference  :	a total of 22 matches will be  played at    only  2  stadiums and  not all over india  
2024-02-03 04:12:46,791 	Text Hypothesis :	* ***** ** ** they    also own joburg super kings in july     2023 as  a   king walking
2024-02-03 04:12:46,791 	Text Alignment  :	D D     D  D  S       S    S   S      S     S     S  S        S    S   S   S    S      
2024-02-03 04:12:46,791 ========================================================================================================================
2024-02-03 04:12:46,792 Logging Sequence: 93_2.00
2024-02-03 04:12:46,792 	Gloss Reference :	A B+C+D+E
2024-02-03 04:12:46,792 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:12:46,792 	Gloss Alignment :	         
2024-02-03 04:12:46,792 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:12:46,793 	Text Reference  :	wayne rooney was an        amazing football player
2024-02-03 04:12:46,793 	Text Hypothesis :	and   filed  a   complaint with    the      police
2024-02-03 04:12:46,793 	Text Alignment  :	S     S      S   S         S       S        S     
2024-02-03 04:12:46,793 ========================================================================================================================
2024-02-03 04:12:46,793 Logging Sequence: 172_270.00
2024-02-03 04:12:46,793 	Gloss Reference :	A B+C+D+E
2024-02-03 04:12:46,793 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:12:46,794 	Gloss Alignment :	         
2024-02-03 04:12:46,794 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:12:46,795 	Text Reference  :	if *** **** ** *** *** ***** **** ****** ********* *** ** it continues to rain today  the tickets will be refunded
2024-02-03 04:12:46,795 	Text Hypothesis :	if you wish to see the delay many people including 935 am it continues to **** follow the ******* **** ** match   
2024-02-03 04:12:46,795 	Text Alignment  :	   I   I    I  I   I   I     I    I      I         I   I                  D    S          D       D    D  S       
2024-02-03 04:12:46,795 ========================================================================================================================
2024-02-03 04:12:51,618 Epoch 166: Total Training Recognition Loss 1.23  Total Training Translation Loss 26.19 
2024-02-03 04:12:51,619 EPOCH 167
2024-02-03 04:12:52,881 [Epoch: 167 Step: 00022100] Batch Recognition Loss:   0.003259 => Gls Tokens per Sec:     1396 || Batch Translation Loss:   0.238023 => Txt Tokens per Sec:     3917 || Lr: 0.000100
2024-02-03 04:12:58,274 [Epoch: 167 Step: 00022200] Batch Recognition Loss:   0.016097 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.130568 => Txt Tokens per Sec:     4121 || Lr: 0.000100
2024-02-03 04:12:58,890 Epoch 167: Total Training Recognition Loss 0.88  Total Training Translation Loss 27.32 
2024-02-03 04:12:58,890 EPOCH 168
2024-02-03 04:13:03,993 [Epoch: 168 Step: 00022300] Batch Recognition Loss:   0.002406 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.047036 => Txt Tokens per Sec:     3826 || Lr: 0.000100
2024-02-03 04:13:06,840 Epoch 168: Total Training Recognition Loss 1.07  Total Training Translation Loss 26.97 
2024-02-03 04:13:06,841 EPOCH 169
2024-02-03 04:13:10,108 [Epoch: 169 Step: 00022400] Batch Recognition Loss:   0.004469 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.070798 => Txt Tokens per Sec:     3901 || Lr: 0.000100
2024-02-03 04:13:14,178 Epoch 169: Total Training Recognition Loss 1.27  Total Training Translation Loss 26.49 
2024-02-03 04:13:14,178 EPOCH 170
2024-02-03 04:13:15,349 [Epoch: 170 Step: 00022500] Batch Recognition Loss:   0.009479 => Gls Tokens per Sec:     1573 || Batch Translation Loss:   0.122975 => Txt Tokens per Sec:     4173 || Lr: 0.000100
2024-02-03 04:13:21,111 [Epoch: 170 Step: 00022600] Batch Recognition Loss:   0.005124 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.165251 => Txt Tokens per Sec:     3909 || Lr: 0.000100
2024-02-03 04:13:21,598 Epoch 170: Total Training Recognition Loss 1.17  Total Training Translation Loss 31.74 
2024-02-03 04:13:21,599 EPOCH 171
2024-02-03 04:13:26,644 [Epoch: 171 Step: 00022700] Batch Recognition Loss:   0.000800 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.076680 => Txt Tokens per Sec:     3940 || Lr: 0.000100
2024-02-03 04:13:29,183 Epoch 171: Total Training Recognition Loss 1.16  Total Training Translation Loss 30.88 
2024-02-03 04:13:29,183 EPOCH 172
2024-02-03 04:13:32,488 [Epoch: 172 Step: 00022800] Batch Recognition Loss:   0.001024 => Gls Tokens per Sec:     1381 || Batch Translation Loss:   0.048389 => Txt Tokens per Sec:     3782 || Lr: 0.000100
2024-02-03 04:13:36,847 Epoch 172: Total Training Recognition Loss 1.37  Total Training Translation Loss 29.35 
2024-02-03 04:13:36,848 EPOCH 173
2024-02-03 04:13:37,945 [Epoch: 173 Step: 00022900] Batch Recognition Loss:   0.004205 => Gls Tokens per Sec:     1751 || Batch Translation Loss:   0.039446 => Txt Tokens per Sec:     4906 || Lr: 0.000100
2024-02-03 04:13:42,836 [Epoch: 173 Step: 00023000] Batch Recognition Loss:   0.003835 => Gls Tokens per Sec:     1634 || Batch Translation Loss:   0.153770 => Txt Tokens per Sec:     4505 || Lr: 0.000100
2024-02-03 04:13:43,335 Epoch 173: Total Training Recognition Loss 0.96  Total Training Translation Loss 28.53 
2024-02-03 04:13:43,335 EPOCH 174
2024-02-03 04:13:48,374 [Epoch: 174 Step: 00023100] Batch Recognition Loss:   0.004010 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.186328 => Txt Tokens per Sec:     3978 || Lr: 0.000100
2024-02-03 04:13:50,825 Epoch 174: Total Training Recognition Loss 1.18  Total Training Translation Loss 31.68 
2024-02-03 04:13:50,825 EPOCH 175
2024-02-03 04:13:53,900 [Epoch: 175 Step: 00023200] Batch Recognition Loss:   0.042616 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.344433 => Txt Tokens per Sec:     4244 || Lr: 0.000100
2024-02-03 04:13:58,229 Epoch 175: Total Training Recognition Loss 1.11  Total Training Translation Loss 27.10 
2024-02-03 04:13:58,230 EPOCH 176
2024-02-03 04:13:59,450 [Epoch: 176 Step: 00023300] Batch Recognition Loss:   0.000845 => Gls Tokens per Sec:     1642 || Batch Translation Loss:   0.184926 => Txt Tokens per Sec:     4373 || Lr: 0.000100
2024-02-03 04:14:05,181 [Epoch: 176 Step: 00023400] Batch Recognition Loss:   0.003239 => Gls Tokens per Sec:     1394 || Batch Translation Loss:   0.101838 => Txt Tokens per Sec:     3934 || Lr: 0.000100
2024-02-03 04:14:05,574 Epoch 176: Total Training Recognition Loss 1.17  Total Training Translation Loss 21.76 
2024-02-03 04:14:05,574 EPOCH 177
2024-02-03 04:14:10,637 [Epoch: 177 Step: 00023500] Batch Recognition Loss:   0.000731 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.033147 => Txt Tokens per Sec:     4013 || Lr: 0.000100
2024-02-03 04:14:13,169 Epoch 177: Total Training Recognition Loss 0.88  Total Training Translation Loss 23.91 
2024-02-03 04:14:13,169 EPOCH 178
2024-02-03 04:14:16,599 [Epoch: 178 Step: 00023600] Batch Recognition Loss:   0.000961 => Gls Tokens per Sec:     1377 || Batch Translation Loss:   0.291943 => Txt Tokens per Sec:     3797 || Lr: 0.000100
2024-02-03 04:14:20,859 Epoch 178: Total Training Recognition Loss 0.89  Total Training Translation Loss 19.50 
2024-02-03 04:14:20,860 EPOCH 179
2024-02-03 04:14:22,181 [Epoch: 179 Step: 00023700] Batch Recognition Loss:   0.011370 => Gls Tokens per Sec:     1574 || Batch Translation Loss:   0.109355 => Txt Tokens per Sec:     4367 || Lr: 0.000100
2024-02-03 04:14:27,819 [Epoch: 179 Step: 00023800] Batch Recognition Loss:   0.001011 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   0.046799 => Txt Tokens per Sec:     3932 || Lr: 0.000100
2024-02-03 04:14:28,193 Epoch 179: Total Training Recognition Loss 0.89  Total Training Translation Loss 24.64 
2024-02-03 04:14:28,193 EPOCH 180
2024-02-03 04:14:33,468 [Epoch: 180 Step: 00023900] Batch Recognition Loss:   0.002564 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.077898 => Txt Tokens per Sec:     3953 || Lr: 0.000100
2024-02-03 04:14:35,682 Epoch 180: Total Training Recognition Loss 1.13  Total Training Translation Loss 28.49 
2024-02-03 04:14:35,682 EPOCH 181
2024-02-03 04:14:39,348 [Epoch: 181 Step: 00024000] Batch Recognition Loss:   0.144509 => Gls Tokens per Sec:     1310 || Batch Translation Loss:   0.059969 => Txt Tokens per Sec:     3638 || Lr: 0.000100
2024-02-03 04:14:49,790 Validation result at epoch 181, step    24000: duration: 10.4414s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 13.25228	Translation Loss: 89521.28906	PPL: 10916.32520
	Eval Metric: BLEU
	WER 3.75	(DEL: 0.07,	INS: 0.00,	SUB: 3.68)
	BLEU-4 0.67	(BLEU-1: 9.92,	BLEU-2: 2.91,	BLEU-3: 1.25,	BLEU-4: 0.67)
	CHRF 16.72	ROUGE 8.36
2024-02-03 04:14:49,792 Logging Recognition and Translation Outputs
2024-02-03 04:14:49,792 ========================================================================================================================
2024-02-03 04:14:49,792 Logging Sequence: 118_46.00
2024-02-03 04:14:49,792 	Gloss Reference :	A B+C+D+E
2024-02-03 04:14:49,792 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:14:49,792 	Gloss Alignment :	         
2024-02-03 04:14:49,793 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:14:49,795 	Text Reference  :	since there was a tie the match went  into the penalty    shootout where each team gets a  chance to score 5   times 
2024-02-03 04:14:49,795 	Text Hypothesis :	***** ***** *** * *** and even  spoke to   the government and      india is   a    lot  of them   on 2nd   and drinks
2024-02-03 04:14:49,795 	Text Alignment  :	D     D     D   D D   S   S     S     S        S          S        S     S    S    S    S  S      S  S     S   S     
2024-02-03 04:14:49,795 ========================================================================================================================
2024-02-03 04:14:49,795 Logging Sequence: 115_59.00
2024-02-03 04:14:49,795 	Gloss Reference :	A B+C+D+E
2024-02-03 04:14:49,796 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:14:49,796 	Gloss Alignment :	         
2024-02-03 04:14:49,796 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:14:49,796 	Text Reference  :	*** *** she now   hosts several cricket programmes
2024-02-03 04:14:49,796 	Text Hypothesis :	for the 2   match on    11th    march   2021      
2024-02-03 04:14:49,796 	Text Alignment  :	I   I   S   S     S     S       S       S         
2024-02-03 04:14:49,797 ========================================================================================================================
2024-02-03 04:14:49,797 Logging Sequence: 128_172.00
2024-02-03 04:14:49,797 	Gloss Reference :	A B+C+D+E
2024-02-03 04:14:49,797 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:14:49,797 	Gloss Alignment :	         
2024-02-03 04:14:49,797 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:14:49,800 	Text Reference  :	the  best test team       can't be decided with just one match     and   it should   be   a       best of   three contest
2024-02-03 04:14:49,800 	Text Hypothesis :	when it   was  australia' turn  to bat     they beat new zealand's score by securing 1732 wickets in   just 185   overs  
2024-02-03 04:14:49,800 	Text Alignment  :	S    S    S    S          S     S  S       S    S    S   S         S     S  S        S    S       S    S    S     S      
2024-02-03 04:14:49,800 ========================================================================================================================
2024-02-03 04:14:49,800 Logging Sequence: 119_151.00
2024-02-03 04:14:49,800 	Gloss Reference :	A B+C+D+E
2024-02-03 04:14:49,800 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:14:49,800 	Gloss Alignment :	         
2024-02-03 04:14:49,801 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:14:49,801 	Text Reference  :	******* **** ******* messi loved the     idea  and ****** ******* placed the order  
2024-02-03 04:14:49,801 	Text Hypothesis :	special gold devices have  each  player' names and jersey numbers next   to  special
2024-02-03 04:14:49,802 	Text Alignment  :	I       I    I       S     S     S       S         I      I       S      S   S      
2024-02-03 04:14:49,802 ========================================================================================================================
2024-02-03 04:14:49,802 Logging Sequence: 61_196.00
2024-02-03 04:14:49,802 	Gloss Reference :	A B+C+D+E
2024-02-03 04:14:49,802 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:14:49,802 	Gloss Alignment :	         
2024-02-03 04:14:49,802 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:14:49,803 	Text Reference  :	another said people should refrain from spreading this video     who    knows   if  that  video     is  fake
2024-02-03 04:14:49,803 	Text Hypothesis :	******* **** ****** ****** ******* **** ********* bcci president sourav ganguly and board secretary jay shah
2024-02-03 04:14:49,804 	Text Alignment  :	D       D    D      D      D       D    D         S    S         S      S       S   S     S         S   S   
2024-02-03 04:14:49,804 ========================================================================================================================
2024-02-03 04:14:53,883 Epoch 181: Total Training Recognition Loss 1.39  Total Training Translation Loss 32.15 
2024-02-03 04:14:53,883 EPOCH 182
2024-02-03 04:14:55,433 [Epoch: 182 Step: 00024100] Batch Recognition Loss:   0.003316 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.176657 => Txt Tokens per Sec:     3912 || Lr: 0.000100
2024-02-03 04:15:00,893 [Epoch: 182 Step: 00024200] Batch Recognition Loss:   0.002426 => Gls Tokens per Sec:     1464 || Batch Translation Loss:   0.195742 => Txt Tokens per Sec:     4069 || Lr: 0.000100
2024-02-03 04:15:01,311 Epoch 182: Total Training Recognition Loss 1.11  Total Training Translation Loss 32.82 
2024-02-03 04:15:01,311 EPOCH 183
2024-02-03 04:15:06,512 [Epoch: 183 Step: 00024300] Batch Recognition Loss:   0.004267 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.254822 => Txt Tokens per Sec:     4000 || Lr: 0.000100
2024-02-03 04:15:08,768 Epoch 183: Total Training Recognition Loss 1.18  Total Training Translation Loss 25.38 
2024-02-03 04:15:08,769 EPOCH 184
2024-02-03 04:15:12,260 [Epoch: 184 Step: 00024400] Batch Recognition Loss:   0.006554 => Gls Tokens per Sec:     1398 || Batch Translation Loss:   0.130181 => Txt Tokens per Sec:     3837 || Lr: 0.000100
2024-02-03 04:15:16,567 Epoch 184: Total Training Recognition Loss 0.85  Total Training Translation Loss 23.81 
2024-02-03 04:15:16,568 EPOCH 185
2024-02-03 04:15:18,218 [Epoch: 185 Step: 00024500] Batch Recognition Loss:   0.003275 => Gls Tokens per Sec:     1359 || Batch Translation Loss:   0.092138 => Txt Tokens per Sec:     3944 || Lr: 0.000100
2024-02-03 04:15:23,422 [Epoch: 185 Step: 00024600] Batch Recognition Loss:   0.003043 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   0.539282 => Txt Tokens per Sec:     4222 || Lr: 0.000100
2024-02-03 04:15:23,715 Epoch 185: Total Training Recognition Loss 0.81  Total Training Translation Loss 23.14 
2024-02-03 04:15:23,715 EPOCH 186
2024-02-03 04:15:29,217 [Epoch: 186 Step: 00024700] Batch Recognition Loss:   0.019923 => Gls Tokens per Sec:     1382 || Batch Translation Loss:   0.163479 => Txt Tokens per Sec:     3831 || Lr: 0.000100
2024-02-03 04:15:31,517 Epoch 186: Total Training Recognition Loss 1.13  Total Training Translation Loss 31.68 
2024-02-03 04:15:31,517 EPOCH 187
2024-02-03 04:15:35,079 [Epoch: 187 Step: 00024800] Batch Recognition Loss:   0.000633 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.087771 => Txt Tokens per Sec:     3896 || Lr: 0.000100
2024-02-03 04:15:38,937 Epoch 187: Total Training Recognition Loss 1.51  Total Training Translation Loss 28.26 
2024-02-03 04:15:38,937 EPOCH 188
2024-02-03 04:15:40,280 [Epoch: 188 Step: 00024900] Batch Recognition Loss:   0.004471 => Gls Tokens per Sec:     1728 || Batch Translation Loss:   0.452085 => Txt Tokens per Sec:     4605 || Lr: 0.000100
2024-02-03 04:15:45,846 [Epoch: 188 Step: 00025000] Batch Recognition Loss:   0.001260 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.267372 => Txt Tokens per Sec:     4039 || Lr: 0.000100
2024-02-03 04:15:46,130 Epoch 188: Total Training Recognition Loss 1.30  Total Training Translation Loss 26.50 
2024-02-03 04:15:46,130 EPOCH 189
2024-02-03 04:15:51,156 [Epoch: 189 Step: 00025100] Batch Recognition Loss:   0.003548 => Gls Tokens per Sec:     1529 || Batch Translation Loss:   0.067298 => Txt Tokens per Sec:     4273 || Lr: 0.000100
2024-02-03 04:15:53,271 Epoch 189: Total Training Recognition Loss 1.11  Total Training Translation Loss 22.67 
2024-02-03 04:15:53,271 EPOCH 190
2024-02-03 04:15:56,956 [Epoch: 190 Step: 00025200] Batch Recognition Loss:   0.003548 => Gls Tokens per Sec:     1369 || Batch Translation Loss:   0.077494 => Txt Tokens per Sec:     3841 || Lr: 0.000100
2024-02-03 04:16:01,106 Epoch 190: Total Training Recognition Loss 1.34  Total Training Translation Loss 23.30 
2024-02-03 04:16:01,107 EPOCH 191
2024-02-03 04:16:02,617 [Epoch: 191 Step: 00025300] Batch Recognition Loss:   0.027294 => Gls Tokens per Sec:     1589 || Batch Translation Loss:   0.086339 => Txt Tokens per Sec:     4541 || Lr: 0.000100
2024-02-03 04:16:08,505 [Epoch: 191 Step: 00025400] Batch Recognition Loss:   0.002941 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.146047 => Txt Tokens per Sec:     3727 || Lr: 0.000100
2024-02-03 04:16:08,684 Epoch 191: Total Training Recognition Loss 0.99  Total Training Translation Loss 28.90 
2024-02-03 04:16:08,684 EPOCH 192
2024-02-03 04:16:13,940 [Epoch: 192 Step: 00025500] Batch Recognition Loss:   0.001985 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.092157 => Txt Tokens per Sec:     4097 || Lr: 0.000100
2024-02-03 04:16:16,115 Epoch 192: Total Training Recognition Loss 0.82  Total Training Translation Loss 24.16 
2024-02-03 04:16:16,116 EPOCH 193
2024-02-03 04:16:19,853 [Epoch: 193 Step: 00025600] Batch Recognition Loss:   0.001570 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.153708 => Txt Tokens per Sec:     3840 || Lr: 0.000100
2024-02-03 04:16:23,628 Epoch 193: Total Training Recognition Loss 0.73  Total Training Translation Loss 21.23 
2024-02-03 04:16:23,628 EPOCH 194
2024-02-03 04:16:25,311 [Epoch: 194 Step: 00025700] Batch Recognition Loss:   0.003593 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.219604 => Txt Tokens per Sec:     4288 || Lr: 0.000100
2024-02-03 04:16:30,884 [Epoch: 194 Step: 00025800] Batch Recognition Loss:   0.001712 => Gls Tokens per Sec:     1434 || Batch Translation Loss:   0.064370 => Txt Tokens per Sec:     3927 || Lr: 0.000100
2024-02-03 04:16:31,008 Epoch 194: Total Training Recognition Loss 0.91  Total Training Translation Loss 25.79 
2024-02-03 04:16:31,008 EPOCH 195
2024-02-03 04:16:36,148 [Epoch: 195 Step: 00025900] Batch Recognition Loss:   0.003020 => Gls Tokens per Sec:     1526 || Batch Translation Loss:   0.231988 => Txt Tokens per Sec:     4272 || Lr: 0.000100
2024-02-03 04:16:38,206 Epoch 195: Total Training Recognition Loss 1.00  Total Training Translation Loss 27.28 
2024-02-03 04:16:38,207 EPOCH 196
2024-02-03 04:16:42,005 [Epoch: 196 Step: 00026000] Batch Recognition Loss:   0.002158 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.224001 => Txt Tokens per Sec:     3887 || Lr: 0.000100
2024-02-03 04:16:52,237 Validation result at epoch 196, step    26000: duration: 10.2309s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 12.56267	Translation Loss: 88210.17969	PPL: 9526.55566
	Eval Metric: BLEU
	WER 3.54	(DEL: 0.00,	INS: 0.00,	SUB: 3.54)
	BLEU-4 0.33	(BLEU-1: 10.62,	BLEU-2: 2.79,	BLEU-3: 0.94,	BLEU-4: 0.33)
	CHRF 16.68	ROUGE 8.74
2024-02-03 04:16:52,238 Logging Recognition and Translation Outputs
2024-02-03 04:16:52,238 ========================================================================================================================
2024-02-03 04:16:52,238 Logging Sequence: 140_34.00
2024-02-03 04:16:52,238 	Gloss Reference :	A B+C+D+E
2024-02-03 04:16:52,238 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:16:52,239 	Gloss Alignment :	         
2024-02-03 04:16:52,239 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:16:52,240 	Text Reference  :	pant made his debut in     international cricket in february 2017 against england india   won the    match because of    pant
2024-02-03 04:16:52,240 	Text Hypothesis :	pant **** *** has   scored 2             people  in ******** **** the     same    formats in  mumbai and   t20     world cup 
2024-02-03 04:16:52,241 	Text Alignment  :	     D    D   S     S      S             S          D        D    S       S       S       S   S      S     S       S     S   
2024-02-03 04:16:52,241 ========================================================================================================================
2024-02-03 04:16:52,241 Logging Sequence: 142_111.00
2024-02-03 04:16:52,241 	Gloss Reference :	A B+C+D+E
2024-02-03 04:16:52,241 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:16:52,241 	Gloss Alignment :	         
2024-02-03 04:16:52,241 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:16:52,242 	Text Reference  :	oh god how embarassing will the young boy be able to    pay    such a     huge  amount
2024-02-03 04:16:52,242 	Text Hypothesis :	** *** *** *********** **** the ***** *** ** name seems indian but  asked about it    
2024-02-03 04:16:52,243 	Text Alignment  :	D  D   D   D           D        D     D   D  S    S     S      S    S     S     S     
2024-02-03 04:16:52,243 ========================================================================================================================
2024-02-03 04:16:52,243 Logging Sequence: 135_9.00
2024-02-03 04:16:52,243 	Gloss Reference :	A B+C+D+E
2024-02-03 04:16:52,243 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:16:52,243 	Gloss Alignment :	         
2024-02-03 04:16:52,243 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:16:52,244 	Text Reference  :	flew to the tokyo olympics won a silver medal in javelin throw 
2024-02-03 04:16:52,244 	Text Hypothesis :	**** ** *** ***** ******** *** * ****** that  is roughly 385000
2024-02-03 04:16:52,244 	Text Alignment  :	D    D  D   D     D        D   D D      S     S  S       S     
2024-02-03 04:16:52,244 ========================================================================================================================
2024-02-03 04:16:52,244 Logging Sequence: 118_444.00
2024-02-03 04:16:52,245 	Gloss Reference :	A B+C+D+E
2024-02-03 04:16:52,245 	Gloss Hypothesis:	A B+C+D  
2024-02-03 04:16:52,245 	Gloss Alignment :	  S      
2024-02-03 04:16:52,245 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:16:52,245 	Text Reference  :	what a match but      cheers to argentina for winning the ******** match
2024-02-03 04:16:52,246 	Text Hypothesis :	**** * ***** everyone wanted to ********* *** see     the exciting match
2024-02-03 04:16:52,246 	Text Alignment  :	D    D D     S        S         D         D   S           I             
2024-02-03 04:16:52,246 ========================================================================================================================
2024-02-03 04:16:52,246 Logging Sequence: 52_36.00
2024-02-03 04:16:52,246 	Gloss Reference :	A B+C+D+E
2024-02-03 04:16:52,246 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:16:52,246 	Gloss Alignment :	         
2024-02-03 04:16:52,246 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:16:52,247 	Text Reference  :	*** ****** **** ******* * ************ recently dhoni      was travellin on      an       indigo flight
2024-02-03 04:16:52,247 	Text Hypothesis :	the indian team follows a superstition of       chocolates to  the       batsmen received many   run   
2024-02-03 04:16:52,247 	Text Alignment  :	I   I      I    I       I I            S        S          S   S         S       S        S      S     
2024-02-03 04:16:52,248 ========================================================================================================================
2024-02-03 04:16:56,109 Epoch 196: Total Training Recognition Loss 0.87  Total Training Translation Loss 25.66 
2024-02-03 04:16:56,110 EPOCH 197
2024-02-03 04:16:58,229 [Epoch: 197 Step: 00026100] Batch Recognition Loss:   0.006166 => Gls Tokens per Sec:     1208 || Batch Translation Loss:   0.223217 => Txt Tokens per Sec:     3681 || Lr: 0.000100
2024-02-03 04:17:03,384 [Epoch: 197 Step: 00026200] Batch Recognition Loss:   0.000586 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.055611 => Txt Tokens per Sec:     4181 || Lr: 0.000100
2024-02-03 04:17:03,437 Epoch 197: Total Training Recognition Loss 0.94  Total Training Translation Loss 19.25 
2024-02-03 04:17:03,438 EPOCH 198
2024-02-03 04:17:09,154 [Epoch: 198 Step: 00026300] Batch Recognition Loss:   0.001099 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.095413 => Txt Tokens per Sec:     3835 || Lr: 0.000100
2024-02-03 04:17:10,982 Epoch 198: Total Training Recognition Loss 0.82  Total Training Translation Loss 23.45 
2024-02-03 04:17:10,982 EPOCH 199
2024-02-03 04:17:14,618 [Epoch: 199 Step: 00026400] Batch Recognition Loss:   0.001462 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.141175 => Txt Tokens per Sec:     4079 || Lr: 0.000100
2024-02-03 04:17:18,410 Epoch 199: Total Training Recognition Loss 0.93  Total Training Translation Loss 21.75 
2024-02-03 04:17:18,411 EPOCH 200
2024-02-03 04:17:20,249 [Epoch: 200 Step: 00026500] Batch Recognition Loss:   0.003782 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.104152 => Txt Tokens per Sec:     4007 || Lr: 0.000100
2024-02-03 04:17:25,988 [Epoch: 200 Step: 00026600] Batch Recognition Loss:   0.004415 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.066842 => Txt Tokens per Sec:     3869 || Lr: 0.000100
2024-02-03 04:17:25,989 Epoch 200: Total Training Recognition Loss 1.11  Total Training Translation Loss 22.69 
2024-02-03 04:17:25,989 EPOCH 201
2024-02-03 04:17:31,155 [Epoch: 201 Step: 00026700] Batch Recognition Loss:   0.000430 => Gls Tokens per Sec:     1549 || Batch Translation Loss:   0.042527 => Txt Tokens per Sec:     4311 || Lr: 0.000100
2024-02-03 04:17:33,139 Epoch 201: Total Training Recognition Loss 0.98  Total Training Translation Loss 24.81 
2024-02-03 04:17:33,139 EPOCH 202
2024-02-03 04:17:37,184 [Epoch: 202 Step: 00026800] Batch Recognition Loss:   0.003306 => Gls Tokens per Sec:     1325 || Batch Translation Loss:   0.130307 => Txt Tokens per Sec:     3738 || Lr: 0.000100
2024-02-03 04:17:40,451 Epoch 202: Total Training Recognition Loss 0.84  Total Training Translation Loss 27.68 
2024-02-03 04:17:40,451 EPOCH 203
2024-02-03 04:17:42,084 [Epoch: 203 Step: 00026900] Batch Recognition Loss:   0.024434 => Gls Tokens per Sec:     1667 || Batch Translation Loss:   0.118161 => Txt Tokens per Sec:     4483 || Lr: 0.000100
2024-02-03 04:17:47,503 Epoch 203: Total Training Recognition Loss 1.12  Total Training Translation Loss 27.65 
2024-02-03 04:17:47,503 EPOCH 204
2024-02-03 04:17:47,570 [Epoch: 204 Step: 00027000] Batch Recognition Loss:   0.001830 => Gls Tokens per Sec:     1212 || Batch Translation Loss:   0.184902 => Txt Tokens per Sec:     4106 || Lr: 0.000100
2024-02-03 04:17:53,167 [Epoch: 204 Step: 00027100] Batch Recognition Loss:   0.012545 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.407827 => Txt Tokens per Sec:     3991 || Lr: 0.000100
2024-02-03 04:17:54,985 Epoch 204: Total Training Recognition Loss 1.03  Total Training Translation Loss 24.79 
2024-02-03 04:17:54,986 EPOCH 205
2024-02-03 04:17:58,876 [Epoch: 205 Step: 00027200] Batch Recognition Loss:   0.001084 => Gls Tokens per Sec:     1399 || Batch Translation Loss:   0.048230 => Txt Tokens per Sec:     3864 || Lr: 0.000100
2024-02-03 04:18:02,924 Epoch 205: Total Training Recognition Loss 0.78  Total Training Translation Loss 16.23 
2024-02-03 04:18:02,924 EPOCH 206
2024-02-03 04:18:04,914 [Epoch: 206 Step: 00027300] Batch Recognition Loss:   0.002214 => Gls Tokens per Sec:     1408 || Batch Translation Loss:   0.155451 => Txt Tokens per Sec:     3926 || Lr: 0.000100
2024-02-03 04:18:10,182 Epoch 206: Total Training Recognition Loss 0.88  Total Training Translation Loss 17.65 
2024-02-03 04:18:10,182 EPOCH 207
2024-02-03 04:18:10,255 [Epoch: 207 Step: 00027400] Batch Recognition Loss:   0.019157 => Gls Tokens per Sec:     2222 || Batch Translation Loss:   0.093770 => Txt Tokens per Sec:     4667 || Lr: 0.000100
2024-02-03 04:18:15,843 [Epoch: 207 Step: 00027500] Batch Recognition Loss:   0.001851 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.116233 => Txt Tokens per Sec:     4013 || Lr: 0.000100
2024-02-03 04:18:17,661 Epoch 207: Total Training Recognition Loss 0.82  Total Training Translation Loss 24.41 
2024-02-03 04:18:17,661 EPOCH 208
2024-02-03 04:18:21,663 [Epoch: 208 Step: 00027600] Batch Recognition Loss:   0.003779 => Gls Tokens per Sec:     1380 || Batch Translation Loss:   0.169811 => Txt Tokens per Sec:     3909 || Lr: 0.000100
2024-02-03 04:18:25,311 Epoch 208: Total Training Recognition Loss 0.99  Total Training Translation Loss 20.33 
2024-02-03 04:18:25,311 EPOCH 209
2024-02-03 04:18:27,225 [Epoch: 209 Step: 00027700] Batch Recognition Loss:   0.006064 => Gls Tokens per Sec:     1505 || Batch Translation Loss:   0.068703 => Txt Tokens per Sec:     4125 || Lr: 0.000100
2024-02-03 04:18:32,826 Epoch 209: Total Training Recognition Loss 0.93  Total Training Translation Loss 26.57 
2024-02-03 04:18:32,827 EPOCH 210
2024-02-03 04:18:32,961 [Epoch: 210 Step: 00027800] Batch Recognition Loss:   0.003752 => Gls Tokens per Sec:     1805 || Batch Translation Loss:   0.179372 => Txt Tokens per Sec:     4466 || Lr: 0.000100
2024-02-03 04:18:38,417 [Epoch: 210 Step: 00027900] Batch Recognition Loss:   0.003005 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.163479 => Txt Tokens per Sec:     4126 || Lr: 0.000100
2024-02-03 04:18:40,268 Epoch 210: Total Training Recognition Loss 0.73  Total Training Translation Loss 27.16 
2024-02-03 04:18:40,268 EPOCH 211
2024-02-03 04:18:44,410 [Epoch: 211 Step: 00028000] Batch Recognition Loss:   0.024021 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   0.137766 => Txt Tokens per Sec:     3786 || Lr: 0.000100
2024-02-03 04:18:55,481 Validation result at epoch 211, step    28000: duration: 11.0692s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.25285	Translation Loss: 90007.16406	PPL: 11481.34961
	Eval Metric: BLEU
	WER 3.47	(DEL: 0.00,	INS: 0.00,	SUB: 3.47)
	BLEU-4 0.62	(BLEU-1: 10.33,	BLEU-2: 3.17,	BLEU-3: 1.28,	BLEU-4: 0.62)
	CHRF 16.97	ROUGE 8.63
2024-02-03 04:18:55,482 Logging Recognition and Translation Outputs
2024-02-03 04:18:55,482 ========================================================================================================================
2024-02-03 04:18:55,482 Logging Sequence: 79_33.00
2024-02-03 04:18:55,483 	Gloss Reference :	A B+C+D+E
2024-02-03 04:18:55,483 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:18:55,483 	Gloss Alignment :	         
2024-02-03 04:18:55,483 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:18:55,484 	Text Reference  :	result in cancellation and other hassles this is something the bcci   does not ***** want and *** is taking all     precautions
2024-02-03 04:18:55,484 	Text Hypothesis :	****** ** ************ *** ***** ******* **** ** ********* *** dahiya did  not loose hope and put up a      similar joke       
2024-02-03 04:18:55,485 	Text Alignment  :	D      D  D            D   D     D       D    D  D         D   S      S        I     S        I   S  S      S       S          
2024-02-03 04:18:55,485 ========================================================================================================================
2024-02-03 04:18:55,485 Logging Sequence: 113_75.00
2024-02-03 04:18:55,485 	Gloss Reference :	A B+C+D+E
2024-02-03 04:18:55,485 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:18:55,485 	Gloss Alignment :	         
2024-02-03 04:18:55,485 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:18:55,487 	Text Reference  :	mirza responded 'œpeople can   date a person for years but     break up    as   soon as   they ** * ***** ** get married
2024-02-03 04:18:55,488 	Text Hypothesis :	***** he        said     there is   a total  of  9     minutes after which they have guts they am a video of 9   medal  
2024-02-03 04:18:55,488 	Text Alignment  :	D     S         S        S     S      S      S   S     S       S     S     S    S    S         I  I I     I  S   S      
2024-02-03 04:18:55,488 ========================================================================================================================
2024-02-03 04:18:55,488 Logging Sequence: 96_165.00
2024-02-03 04:18:55,488 	Gloss Reference :	A B+C+D+E
2024-02-03 04:18:55,488 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:18:55,488 	Gloss Alignment :	         
2024-02-03 04:18:55,489 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:18:55,489 	Text Reference  :	7 runs were needed from 6 balls and india had lost a ***** wicket 
2024-02-03 04:18:55,489 	Text Hypothesis :	* **** **** ****** **** * ***** *** it    is  was  a tough auction
2024-02-03 04:18:55,489 	Text Alignment  :	D D    D    D      D    D D     D   S     S   S      I     S      
2024-02-03 04:18:55,490 ========================================================================================================================
2024-02-03 04:18:55,490 Logging Sequence: 91_133.00
2024-02-03 04:18:55,490 	Gloss Reference :	A B+C+D+E
2024-02-03 04:18:55,490 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:18:55,490 	Gloss Alignment :	         
2024-02-03 04:18:55,490 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:18:55,491 	Text Reference  :	all the   umpires in the tournament were    from     bangalesh'
2024-02-03 04:18:55,491 	Text Hypothesis :	*** there needs   to be  a          neutral umpiring system    
2024-02-03 04:18:55,491 	Text Alignment  :	D   S     S       S  S   S          S       S        S         
2024-02-03 04:18:55,491 ========================================================================================================================
2024-02-03 04:18:55,491 Logging Sequence: 105_139.00
2024-02-03 04:18:55,492 	Gloss Reference :	A B+C+D+E
2024-02-03 04:18:55,492 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:18:55,492 	Gloss Alignment :	         
2024-02-03 04:18:55,492 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:18:55,493 	Text Reference  :	** *** and  now  he has         finally achieved his    dream by   defeating carlsen
2024-02-03 04:18:55,493 	Text Hypothesis :	it was just like an interesting history on       social media that too       up     
2024-02-03 04:18:55,493 	Text Alignment  :	I  I   S    S    S  S           S       S        S      S     S    S         S      
2024-02-03 04:18:55,493 ========================================================================================================================
2024-02-03 04:18:59,185 Epoch 211: Total Training Recognition Loss 0.86  Total Training Translation Loss 23.53 
2024-02-03 04:18:59,185 EPOCH 212
2024-02-03 04:19:01,324 [Epoch: 212 Step: 00028100] Batch Recognition Loss:   0.000858 => Gls Tokens per Sec:     1384 || Batch Translation Loss:   0.172836 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-03 04:19:06,743 Epoch 212: Total Training Recognition Loss 1.03  Total Training Translation Loss 21.97 
2024-02-03 04:19:06,743 EPOCH 213
2024-02-03 04:19:06,962 [Epoch: 213 Step: 00028200] Batch Recognition Loss:   0.003645 => Gls Tokens per Sec:     1478 || Batch Translation Loss:   0.180602 => Txt Tokens per Sec:     3894 || Lr: 0.000100
2024-02-03 04:19:12,210 [Epoch: 213 Step: 00028300] Batch Recognition Loss:   0.003252 => Gls Tokens per Sec:     1525 || Batch Translation Loss:   0.098701 => Txt Tokens per Sec:     4215 || Lr: 0.000100
2024-02-03 04:19:13,938 Epoch 213: Total Training Recognition Loss 0.86  Total Training Translation Loss 21.48 
2024-02-03 04:19:13,938 EPOCH 214
2024-02-03 04:19:17,962 [Epoch: 214 Step: 00028400] Batch Recognition Loss:   0.002917 => Gls Tokens per Sec:     1412 || Batch Translation Loss:   0.120560 => Txt Tokens per Sec:     3884 || Lr: 0.000100
2024-02-03 04:19:21,412 Epoch 214: Total Training Recognition Loss 0.84  Total Training Translation Loss 20.93 
2024-02-03 04:19:21,412 EPOCH 215
2024-02-03 04:19:23,473 [Epoch: 215 Step: 00028500] Batch Recognition Loss:   0.000938 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.061132 => Txt Tokens per Sec:     4175 || Lr: 0.000100
2024-02-03 04:19:28,793 Epoch 215: Total Training Recognition Loss 0.81  Total Training Translation Loss 19.94 
2024-02-03 04:19:28,794 EPOCH 216
2024-02-03 04:19:29,058 [Epoch: 216 Step: 00028600] Batch Recognition Loss:   0.002878 => Gls Tokens per Sec:     1521 || Batch Translation Loss:   0.090779 => Txt Tokens per Sec:     3833 || Lr: 0.000100
2024-02-03 04:19:34,497 [Epoch: 216 Step: 00028700] Batch Recognition Loss:   0.000706 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.200253 => Txt Tokens per Sec:     4120 || Lr: 0.000100
2024-02-03 04:19:36,129 Epoch 216: Total Training Recognition Loss 0.62  Total Training Translation Loss 21.71 
2024-02-03 04:19:36,130 EPOCH 217
2024-02-03 04:19:40,397 [Epoch: 217 Step: 00028800] Batch Recognition Loss:   0.002267 => Gls Tokens per Sec:     1350 || Batch Translation Loss:   0.074486 => Txt Tokens per Sec:     3739 || Lr: 0.000100
2024-02-03 04:19:43,882 Epoch 217: Total Training Recognition Loss 0.80  Total Training Translation Loss 24.10 
2024-02-03 04:19:43,882 EPOCH 218
2024-02-03 04:19:45,845 [Epoch: 218 Step: 00028900] Batch Recognition Loss:   0.000573 => Gls Tokens per Sec:     1591 || Batch Translation Loss:   0.170823 => Txt Tokens per Sec:     4405 || Lr: 0.000100
2024-02-03 04:19:51,225 Epoch 218: Total Training Recognition Loss 0.87  Total Training Translation Loss 24.58 
2024-02-03 04:19:51,226 EPOCH 219
2024-02-03 04:19:51,530 [Epoch: 219 Step: 00029000] Batch Recognition Loss:   0.008744 => Gls Tokens per Sec:     1584 || Batch Translation Loss:   0.156812 => Txt Tokens per Sec:     4376 || Lr: 0.000100
2024-02-03 04:19:56,798 [Epoch: 219 Step: 00029100] Batch Recognition Loss:   0.000134 => Gls Tokens per Sec:     1518 || Batch Translation Loss:   0.120943 => Txt Tokens per Sec:     4229 || Lr: 0.000100
2024-02-03 04:19:58,445 Epoch 219: Total Training Recognition Loss 0.82  Total Training Translation Loss 24.03 
2024-02-03 04:19:58,445 EPOCH 220
2024-02-03 04:20:02,664 [Epoch: 220 Step: 00029200] Batch Recognition Loss:   0.013678 => Gls Tokens per Sec:     1384 || Batch Translation Loss:   0.390366 => Txt Tokens per Sec:     3863 || Lr: 0.000100
2024-02-03 04:20:06,137 Epoch 220: Total Training Recognition Loss 0.77  Total Training Translation Loss 18.12 
2024-02-03 04:20:06,137 EPOCH 221
2024-02-03 04:20:08,549 [Epoch: 221 Step: 00029300] Batch Recognition Loss:   0.001277 => Gls Tokens per Sec:     1327 || Batch Translation Loss:   0.086064 => Txt Tokens per Sec:     3574 || Lr: 0.000100
2024-02-03 04:20:13,852 Epoch 221: Total Training Recognition Loss 0.72  Total Training Translation Loss 23.95 
2024-02-03 04:20:13,852 EPOCH 222
2024-02-03 04:20:14,256 [Epoch: 222 Step: 00029400] Batch Recognition Loss:   0.052722 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.068486 => Txt Tokens per Sec:     4134 || Lr: 0.000100
2024-02-03 04:20:19,634 [Epoch: 222 Step: 00029500] Batch Recognition Loss:   0.001308 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   0.118514 => Txt Tokens per Sec:     4089 || Lr: 0.000100
2024-02-03 04:20:21,199 Epoch 222: Total Training Recognition Loss 0.82  Total Training Translation Loss 29.21 
2024-02-03 04:20:21,199 EPOCH 223
2024-02-03 04:20:24,940 [Epoch: 223 Step: 00029600] Batch Recognition Loss:   0.000855 => Gls Tokens per Sec:     1583 || Batch Translation Loss:   0.060202 => Txt Tokens per Sec:     4320 || Lr: 0.000100
2024-02-03 04:20:28,364 Epoch 223: Total Training Recognition Loss 0.86  Total Training Translation Loss 21.31 
2024-02-03 04:20:28,364 EPOCH 224
2024-02-03 04:20:30,643 [Epoch: 224 Step: 00029700] Batch Recognition Loss:   0.016831 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.043995 => Txt Tokens per Sec:     3983 || Lr: 0.000100
2024-02-03 04:20:35,708 Epoch 224: Total Training Recognition Loss 0.89  Total Training Translation Loss 25.98 
2024-02-03 04:20:35,708 EPOCH 225
2024-02-03 04:20:36,174 [Epoch: 225 Step: 00029800] Batch Recognition Loss:   0.031641 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.189678 => Txt Tokens per Sec:     3692 || Lr: 0.000100
2024-02-03 04:20:41,799 [Epoch: 225 Step: 00029900] Batch Recognition Loss:   0.013477 => Gls Tokens per Sec:     1420 || Batch Translation Loss:   0.080066 => Txt Tokens per Sec:     3954 || Lr: 0.000100
2024-02-03 04:20:43,022 Epoch 225: Total Training Recognition Loss 1.19  Total Training Translation Loss 24.44 
2024-02-03 04:20:43,022 EPOCH 226
2024-02-03 04:20:47,239 [Epoch: 226 Step: 00030000] Batch Recognition Loss:   0.038437 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.078832 => Txt Tokens per Sec:     3966 || Lr: 0.000100
2024-02-03 04:20:57,966 Validation result at epoch 226, step    30000: duration: 10.7259s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.91121	Translation Loss: 90457.17969	PPL: 12030.73438
	Eval Metric: BLEU
	WER 3.68	(DEL: 0.21,	INS: 0.00,	SUB: 3.47)
	BLEU-4 0.35	(BLEU-1: 9.92,	BLEU-2: 2.51,	BLEU-3: 0.80,	BLEU-4: 0.35)
	CHRF 16.78	ROUGE 8.20
2024-02-03 04:20:57,967 Logging Recognition and Translation Outputs
2024-02-03 04:20:57,968 ========================================================================================================================
2024-02-03 04:20:57,968 Logging Sequence: 177_16.00
2024-02-03 04:20:57,968 	Gloss Reference :	A B+C+D+E
2024-02-03 04:20:57,968 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:20:57,968 	Gloss Alignment :	         
2024-02-03 04:20:57,968 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:20:57,969 	Text Reference  :	** ***** *** *** ***** ********** and severely injured 2     others
2024-02-03 04:20:57,969 	Text Hypothesis :	ms dhoni was the brand ambassador for six      to      seven years 
2024-02-03 04:20:57,969 	Text Alignment  :	I  I     I   I   I     I          S   S        S       S     S     
2024-02-03 04:20:57,969 ========================================================================================================================
2024-02-03 04:20:57,969 Logging Sequence: 165_200.00
2024-02-03 04:20:57,970 	Gloss Reference :	A B+C+D+E
2024-02-03 04:20:57,970 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:20:57,970 	Gloss Alignment :	         
2024-02-03 04:20:57,970 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:20:57,971 	Text Reference  :	you may be wondering what bag  remember  in     2011    when  india won   the       world cup 
2024-02-03 04:20:57,971 	Text Hypothesis :	*** *** ** ********* **** bcci president sourav ganguly along with  board secretary jay   shah
2024-02-03 04:20:57,971 	Text Alignment  :	D   D   D  D         D    S    S         S      S       S     S     S     S         S     S   
2024-02-03 04:20:57,971 ========================================================================================================================
2024-02-03 04:20:57,971 Logging Sequence: 125_119.00
2024-02-03 04:20:57,972 	Gloss Reference :	A B+C+D+E
2024-02-03 04:20:57,972 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:20:57,972 	Gloss Alignment :	         
2024-02-03 04:20:57,972 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:20:57,973 	Text Reference  :	people must not     post such baseless comments  on  social media     
2024-02-03 04:20:57,973 	Text Hypothesis :	****** the  stadium was  full with     pakistani and indian supporters
2024-02-03 04:20:57,973 	Text Alignment  :	D      S    S       S    S    S        S         S   S      S         
2024-02-03 04:20:57,973 ========================================================================================================================
2024-02-03 04:20:57,973 Logging Sequence: 53_25.00
2024-02-03 04:20:57,973 	Gloss Reference :	A B+C+D+E
2024-02-03 04:20:57,974 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:20:57,974 	Gloss Alignment :	         
2024-02-03 04:20:57,974 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:20:57,975 	Text Reference  :	there is absolute chaos on     the  country as residents are    trying to    flee  
2024-02-03 04:20:57,975 	Text Hypothesis :	***** ** for      the   indian team is      an amazing   player has    asked sindhu
2024-02-03 04:20:57,975 	Text Alignment  :	D     D  S        S     S      S    S       S  S         S      S      S     S     
2024-02-03 04:20:57,975 ========================================================================================================================
2024-02-03 04:20:57,976 Logging Sequence: 70_81.00
2024-02-03 04:20:57,976 	Gloss Reference :	A B+C+D+E
2024-02-03 04:20:57,976 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:20:57,976 	Gloss Alignment :	         
2024-02-03 04:20:57,976 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:20:57,977 	Text Reference  :	euro 2020 has   many  sponsors but   coca-cola is the official sponsor for  the ******* tournament
2024-02-03 04:20:57,978 	Text Hypothesis :	each team takes turns 5        times shooting  at the ******** goal    from the penalty mark      
2024-02-03 04:20:57,978 	Text Alignment  :	S    S    S     S     S        S     S         S      D        S       S        I       S         
2024-02-03 04:20:57,978 ========================================================================================================================
2024-02-03 04:21:01,465 Epoch 226: Total Training Recognition Loss 0.92  Total Training Translation Loss 21.96 
2024-02-03 04:21:01,465 EPOCH 227
2024-02-03 04:21:03,524 [Epoch: 227 Step: 00030100] Batch Recognition Loss:   0.001293 => Gls Tokens per Sec:     1633 || Batch Translation Loss:   0.023191 => Txt Tokens per Sec:     4432 || Lr: 0.000100
2024-02-03 04:21:08,818 Epoch 227: Total Training Recognition Loss 0.76  Total Training Translation Loss 12.88 
2024-02-03 04:21:08,818 EPOCH 228
2024-02-03 04:21:09,299 [Epoch: 228 Step: 00030200] Batch Recognition Loss:   0.000919 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.671367 => Txt Tokens per Sec:     4219 || Lr: 0.000100
2024-02-03 04:21:14,716 [Epoch: 228 Step: 00030300] Batch Recognition Loss:   0.046579 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.110482 => Txt Tokens per Sec:     4103 || Lr: 0.000100
2024-02-03 04:21:15,887 Epoch 228: Total Training Recognition Loss 0.75  Total Training Translation Loss 10.87 
2024-02-03 04:21:15,887 EPOCH 229
2024-02-03 04:21:19,977 [Epoch: 229 Step: 00030400] Batch Recognition Loss:   0.003446 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.373609 => Txt Tokens per Sec:     4099 || Lr: 0.000100
2024-02-03 04:21:23,333 Epoch 229: Total Training Recognition Loss 0.74  Total Training Translation Loss 12.39 
2024-02-03 04:21:23,333 EPOCH 230
2024-02-03 04:21:25,793 [Epoch: 230 Step: 00030500] Batch Recognition Loss:   0.005854 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.040866 => Txt Tokens per Sec:     3779 || Lr: 0.000100
2024-02-03 04:21:30,821 Epoch 230: Total Training Recognition Loss 0.72  Total Training Translation Loss 13.00 
2024-02-03 04:21:30,821 EPOCH 231
2024-02-03 04:21:31,291 [Epoch: 231 Step: 00030600] Batch Recognition Loss:   0.001318 => Gls Tokens per Sec:     1705 || Batch Translation Loss:   0.027457 => Txt Tokens per Sec:     4850 || Lr: 0.000100
2024-02-03 04:21:36,766 [Epoch: 231 Step: 00030700] Batch Recognition Loss:   0.008736 => Gls Tokens per Sec:     1461 || Batch Translation Loss:   0.023118 => Txt Tokens per Sec:     4027 || Lr: 0.000100
2024-02-03 04:21:38,012 Epoch 231: Total Training Recognition Loss 0.72  Total Training Translation Loss 21.79 
2024-02-03 04:21:38,012 EPOCH 232
2024-02-03 04:21:42,253 [Epoch: 232 Step: 00030800] Batch Recognition Loss:   0.004669 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.719134 => Txt Tokens per Sec:     4068 || Lr: 0.000100
2024-02-03 04:21:45,539 Epoch 232: Total Training Recognition Loss 0.89  Total Training Translation Loss 35.05 
2024-02-03 04:21:45,540 EPOCH 233
2024-02-03 04:21:48,080 [Epoch: 233 Step: 00030900] Batch Recognition Loss:   0.006580 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.136300 => Txt Tokens per Sec:     3839 || Lr: 0.000100
2024-02-03 04:21:53,389 Epoch 233: Total Training Recognition Loss 0.93  Total Training Translation Loss 31.89 
2024-02-03 04:21:53,390 EPOCH 234
2024-02-03 04:21:53,973 [Epoch: 234 Step: 00031000] Batch Recognition Loss:   0.000981 => Gls Tokens per Sec:     1515 || Batch Translation Loss:   0.238920 => Txt Tokens per Sec:     4074 || Lr: 0.000100
2024-02-03 04:21:59,277 [Epoch: 234 Step: 00031100] Batch Recognition Loss:   0.001196 => Gls Tokens per Sec:     1508 || Batch Translation Loss:   0.045451 => Txt Tokens per Sec:     4192 || Lr: 0.000100
2024-02-03 04:22:00,506 Epoch 234: Total Training Recognition Loss 0.82  Total Training Translation Loss 31.92 
2024-02-03 04:22:00,506 EPOCH 235
2024-02-03 04:22:05,016 [Epoch: 235 Step: 00031200] Batch Recognition Loss:   0.002646 => Gls Tokens per Sec:     1384 || Batch Translation Loss:   0.167652 => Txt Tokens per Sec:     3923 || Lr: 0.000100
2024-02-03 04:22:08,130 Epoch 235: Total Training Recognition Loss 0.74  Total Training Translation Loss 22.94 
2024-02-03 04:22:08,131 EPOCH 236
2024-02-03 04:22:10,758 [Epoch: 236 Step: 00031300] Batch Recognition Loss:   0.000473 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.161279 => Txt Tokens per Sec:     3987 || Lr: 0.000100
2024-02-03 04:22:15,841 Epoch 236: Total Training Recognition Loss 0.71  Total Training Translation Loss 16.74 
2024-02-03 04:22:15,841 EPOCH 237
2024-02-03 04:22:16,454 [Epoch: 237 Step: 00031400] Batch Recognition Loss:   0.000452 => Gls Tokens per Sec:     1570 || Batch Translation Loss:   0.150223 => Txt Tokens per Sec:     4535 || Lr: 0.000100
2024-02-03 04:22:22,297 [Epoch: 237 Step: 00031500] Batch Recognition Loss:   0.046922 => Gls Tokens per Sec:     1367 || Batch Translation Loss:   0.123084 => Txt Tokens per Sec:     3813 || Lr: 0.000100
2024-02-03 04:22:23,354 Epoch 237: Total Training Recognition Loss 0.58  Total Training Translation Loss 14.60 
2024-02-03 04:22:23,354 EPOCH 238
2024-02-03 04:22:27,116 [Epoch: 238 Step: 00031600] Batch Recognition Loss:   0.001928 => Gls Tokens per Sec:     1680 || Batch Translation Loss:   0.041064 => Txt Tokens per Sec:     4691 || Lr: 0.000100
2024-02-03 04:22:30,332 Epoch 238: Total Training Recognition Loss 0.46  Total Training Translation Loss 15.30 
2024-02-03 04:22:30,333 EPOCH 239
2024-02-03 04:22:33,113 [Epoch: 239 Step: 00031700] Batch Recognition Loss:   0.002969 => Gls Tokens per Sec:     1324 || Batch Translation Loss:   0.214346 => Txt Tokens per Sec:     3697 || Lr: 0.000100
2024-02-03 04:22:38,369 Epoch 239: Total Training Recognition Loss 0.66  Total Training Translation Loss 21.55 
2024-02-03 04:22:38,370 EPOCH 240
2024-02-03 04:22:39,150 [Epoch: 240 Step: 00031800] Batch Recognition Loss:   0.028055 => Gls Tokens per Sec:     1336 || Batch Translation Loss:   0.523077 => Txt Tokens per Sec:     4220 || Lr: 0.000100
2024-02-03 04:22:44,484 [Epoch: 240 Step: 00031900] Batch Recognition Loss:   0.002889 => Gls Tokens per Sec:     1500 || Batch Translation Loss:   0.187670 => Txt Tokens per Sec:     4099 || Lr: 0.000100
2024-02-03 04:22:45,617 Epoch 240: Total Training Recognition Loss 0.86  Total Training Translation Loss 25.08 
2024-02-03 04:22:45,618 EPOCH 241
2024-02-03 04:22:50,069 [Epoch: 241 Step: 00032000] Batch Recognition Loss:   0.003241 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.148531 => Txt Tokens per Sec:     4001 || Lr: 0.000100
2024-02-03 04:23:00,897 Validation result at epoch 241, step    32000: duration: 10.8264s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.74185	Translation Loss: 90495.48438	PPL: 12078.69629
	Eval Metric: BLEU
	WER 3.18	(DEL: 0.07,	INS: 0.00,	SUB: 3.11)
	BLEU-4 0.46	(BLEU-1: 9.77,	BLEU-2: 2.76,	BLEU-3: 1.01,	BLEU-4: 0.46)
	CHRF 16.41	ROUGE 8.40
2024-02-03 04:23:00,898 Logging Recognition and Translation Outputs
2024-02-03 04:23:00,898 ========================================================================================================================
2024-02-03 04:23:00,899 Logging Sequence: 73_57.00
2024-02-03 04:23:00,899 	Gloss Reference :	A B+C+D+E
2024-02-03 04:23:00,899 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:23:00,899 	Gloss Alignment :	         
2024-02-03 04:23:00,899 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:23:00,901 	Text Reference  :	he made this announcement on instagram with a   photo which had  raina   standing along    with  the chefs at       restaurant
2024-02-03 04:23:00,901 	Text Hypothesis :	** **** **** ************ ** ********* **** ipl has   the   many batsmen who      messaged kohli and 13th  february 2023      
2024-02-03 04:23:00,901 	Text Alignment  :	D  D    D    D            D  D         D    S   S     S     S    S       S        S        S     S   S     S        S         
2024-02-03 04:23:00,901 ========================================================================================================================
2024-02-03 04:23:00,901 Logging Sequence: 177_16.00
2024-02-03 04:23:00,901 	Gloss Reference :	A B+C+D+E
2024-02-03 04:23:00,901 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:23:00,902 	Gloss Alignment :	         
2024-02-03 04:23:00,902 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:23:00,902 	Text Reference  :	******* *** *** **** and severely injured  2       others
2024-02-03 04:23:00,902 	Text Hypothesis :	however for the bcci has an       american because singh 
2024-02-03 04:23:00,902 	Text Alignment  :	I       I   I   I    S   S        S        S       S     
2024-02-03 04:23:00,902 ========================================================================================================================
2024-02-03 04:23:00,903 Logging Sequence: 124_134.00
2024-02-03 04:23:00,903 	Gloss Reference :	A B+C+D+E
2024-02-03 04:23:00,903 	Gloss Hypothesis:	A B+D+E  
2024-02-03 04:23:00,903 	Gloss Alignment :	  S      
2024-02-03 04:23:00,903 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:23:00,905 	Text Reference  :	fans are now wondering why he       did      not     say     anything about dhoni as he   is very           close  to  dhoni 
2024-02-03 04:23:00,905 	Text Hypothesis :	**** *** *** ********* *** farewell messages started pouring in       for   dhoni as well as congratulatory wishes for jadeja
2024-02-03 04:23:00,905 	Text Alignment  :	D    D   D   D         D   S        S        S       S       S        S              S    S  S              S      S   S     
2024-02-03 04:23:00,905 ========================================================================================================================
2024-02-03 04:23:00,905 Logging Sequence: 117_50.00
2024-02-03 04:23:00,905 	Gloss Reference :	A B+C+D+E
2024-02-03 04:23:00,905 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:23:00,906 	Gloss Alignment :	         
2024-02-03 04:23:00,906 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:23:00,906 	Text Reference  :	*** this     was krunal pandya's maiden odi  
2024-02-03 04:23:00,906 	Text Hypothesis :	the decision was ****** ******** ****** wrong
2024-02-03 04:23:00,906 	Text Alignment  :	I   S            D      D        D      S    
2024-02-03 04:23:00,906 ========================================================================================================================
2024-02-03 04:23:00,906 Logging Sequence: 136_55.00
2024-02-03 04:23:00,907 	Gloss Reference :	A B+C+D+E
2024-02-03 04:23:00,907 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:23:00,907 	Gloss Alignment :	         
2024-02-03 04:23:00,907 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:23:00,908 	Text Reference  :	she had earlier  won    a   silver at  the **** rio     de         janeiro olympics in 2016
2024-02-03 04:23:00,908 	Text Hypothesis :	*** *** recently during the reason for the 2021 cricket tournament was     held     in 2021
2024-02-03 04:23:00,908 	Text Alignment  :	D   D   S        S      S   S      S       I    S       S          S       S           S   
2024-02-03 04:23:00,908 ========================================================================================================================
2024-02-03 04:23:04,235 Epoch 241: Total Training Recognition Loss 0.77  Total Training Translation Loss 28.57 
2024-02-03 04:23:04,236 EPOCH 242
2024-02-03 04:23:06,872 [Epoch: 242 Step: 00032100] Batch Recognition Loss:   0.007028 => Gls Tokens per Sec:     1427 || Batch Translation Loss:   0.108000 => Txt Tokens per Sec:     4025 || Lr: 0.000100
2024-02-03 04:23:11,902 Epoch 242: Total Training Recognition Loss 0.83  Total Training Translation Loss 25.28 
2024-02-03 04:23:11,902 EPOCH 243
2024-02-03 04:23:12,533 [Epoch: 243 Step: 00032200] Batch Recognition Loss:   0.019113 => Gls Tokens per Sec:     1778 || Batch Translation Loss:   0.042459 => Txt Tokens per Sec:     4837 || Lr: 0.000100
2024-02-03 04:23:17,491 [Epoch: 243 Step: 00032300] Batch Recognition Loss:   0.006288 => Gls Tokens per Sec:     1614 || Batch Translation Loss:   0.362359 => Txt Tokens per Sec:     4508 || Lr: 0.000100
2024-02-03 04:23:18,496 Epoch 243: Total Training Recognition Loss 0.87  Total Training Translation Loss 17.58 
2024-02-03 04:23:18,497 EPOCH 244
2024-02-03 04:23:22,863 [Epoch: 244 Step: 00032400] Batch Recognition Loss:   0.002997 => Gls Tokens per Sec:     1485 || Batch Translation Loss:   0.091477 => Txt Tokens per Sec:     4105 || Lr: 0.000100
2024-02-03 04:23:25,774 Epoch 244: Total Training Recognition Loss 0.78  Total Training Translation Loss 14.58 
2024-02-03 04:23:25,774 EPOCH 245
2024-02-03 04:23:28,562 [Epoch: 245 Step: 00032500] Batch Recognition Loss:   0.001622 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.037729 => Txt Tokens per Sec:     3840 || Lr: 0.000100
2024-02-03 04:23:33,408 Epoch 245: Total Training Recognition Loss 0.58  Total Training Translation Loss 19.15 
2024-02-03 04:23:33,408 EPOCH 246
2024-02-03 04:23:34,109 [Epoch: 246 Step: 00032600] Batch Recognition Loss:   0.014606 => Gls Tokens per Sec:     1714 || Batch Translation Loss:   0.037745 => Txt Tokens per Sec:     4199 || Lr: 0.000100
2024-02-03 04:23:39,472 [Epoch: 246 Step: 00032700] Batch Recognition Loss:   0.001198 => Gls Tokens per Sec:     1492 || Batch Translation Loss:   0.285209 => Txt Tokens per Sec:     4249 || Lr: 0.000100
2024-02-03 04:23:40,458 Epoch 246: Total Training Recognition Loss 0.77  Total Training Translation Loss 19.44 
2024-02-03 04:23:40,459 EPOCH 247
2024-02-03 04:23:44,688 [Epoch: 247 Step: 00032800] Batch Recognition Loss:   0.009299 => Gls Tokens per Sec:     1551 || Batch Translation Loss:   0.076143 => Txt Tokens per Sec:     4321 || Lr: 0.000100
2024-02-03 04:23:47,732 Epoch 247: Total Training Recognition Loss 1.00  Total Training Translation Loss 20.67 
2024-02-03 04:23:47,732 EPOCH 248
2024-02-03 04:23:50,352 [Epoch: 248 Step: 00032900] Batch Recognition Loss:   0.005716 => Gls Tokens per Sec:     1497 || Batch Translation Loss:   0.598573 => Txt Tokens per Sec:     4103 || Lr: 0.000100
2024-02-03 04:23:55,307 Epoch 248: Total Training Recognition Loss 0.68  Total Training Translation Loss 26.05 
2024-02-03 04:23:55,308 EPOCH 249
2024-02-03 04:23:56,258 [Epoch: 249 Step: 00033000] Batch Recognition Loss:   0.021266 => Gls Tokens per Sec:     1349 || Batch Translation Loss:   0.195926 => Txt Tokens per Sec:     3880 || Lr: 0.000100
2024-02-03 04:24:01,923 [Epoch: 249 Step: 00033100] Batch Recognition Loss:   0.004925 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.624215 => Txt Tokens per Sec:     3882 || Lr: 0.000100
2024-02-03 04:24:02,898 Epoch 249: Total Training Recognition Loss 0.92  Total Training Translation Loss 27.09 
2024-02-03 04:24:02,898 EPOCH 250
2024-02-03 04:24:07,252 [Epoch: 250 Step: 00033200] Batch Recognition Loss:   0.001772 => Gls Tokens per Sec:     1526 || Batch Translation Loss:   0.038474 => Txt Tokens per Sec:     4183 || Lr: 0.000100
2024-02-03 04:24:10,070 Epoch 250: Total Training Recognition Loss 1.00  Total Training Translation Loss 27.50 
2024-02-03 04:24:10,070 EPOCH 251
2024-02-03 04:24:12,777 [Epoch: 251 Step: 00033300] Batch Recognition Loss:   0.016565 => Gls Tokens per Sec:     1478 || Batch Translation Loss:   0.123776 => Txt Tokens per Sec:     4100 || Lr: 0.000100
2024-02-03 04:24:17,215 Epoch 251: Total Training Recognition Loss 0.81  Total Training Translation Loss 19.63 
2024-02-03 04:24:17,215 EPOCH 252
2024-02-03 04:24:18,010 [Epoch: 252 Step: 00033400] Batch Recognition Loss:   0.001359 => Gls Tokens per Sec:     1713 || Batch Translation Loss:   0.656604 => Txt Tokens per Sec:     4509 || Lr: 0.000100
2024-02-03 04:24:23,095 [Epoch: 252 Step: 00033500] Batch Recognition Loss:   0.001267 => Gls Tokens per Sec:     1571 || Batch Translation Loss:   0.057294 => Txt Tokens per Sec:     4410 || Lr: 0.000100
2024-02-03 04:24:23,948 Epoch 252: Total Training Recognition Loss 0.55  Total Training Translation Loss 21.10 
2024-02-03 04:24:23,949 EPOCH 253
2024-02-03 04:24:28,555 [Epoch: 253 Step: 00033600] Batch Recognition Loss:   0.003417 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.132717 => Txt Tokens per Sec:     4008 || Lr: 0.000100
2024-02-03 04:24:31,435 Epoch 253: Total Training Recognition Loss 0.66  Total Training Translation Loss 21.20 
2024-02-03 04:24:31,436 EPOCH 254
2024-02-03 04:24:34,406 [Epoch: 254 Step: 00033700] Batch Recognition Loss:   0.007395 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.049638 => Txt Tokens per Sec:     3908 || Lr: 0.000100
2024-02-03 04:24:39,174 Epoch 254: Total Training Recognition Loss 0.49  Total Training Translation Loss 18.97 
2024-02-03 04:24:39,174 EPOCH 255
2024-02-03 04:24:40,070 [Epoch: 255 Step: 00033800] Batch Recognition Loss:   0.000969 => Gls Tokens per Sec:     1611 || Batch Translation Loss:   0.209019 => Txt Tokens per Sec:     3932 || Lr: 0.000100
2024-02-03 04:24:45,903 [Epoch: 255 Step: 00033900] Batch Recognition Loss:   0.001798 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.086594 => Txt Tokens per Sec:     3896 || Lr: 0.000100
2024-02-03 04:24:46,752 Epoch 255: Total Training Recognition Loss 0.64  Total Training Translation Loss 17.24 
2024-02-03 04:24:46,753 EPOCH 256
2024-02-03 04:24:51,329 [Epoch: 256 Step: 00034000] Batch Recognition Loss:   0.000424 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.206598 => Txt Tokens per Sec:     4113 || Lr: 0.000100
2024-02-03 04:25:02,318 Validation result at epoch 256, step    34000: duration: 10.9883s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.30823	Translation Loss: 89608.52344	PPL: 11015.68555
	Eval Metric: BLEU
	WER 3.47	(DEL: 0.14,	INS: 0.00,	SUB: 3.32)
	BLEU-4 0.54	(BLEU-1: 10.45,	BLEU-2: 2.90,	BLEU-3: 1.07,	BLEU-4: 0.54)
	CHRF 16.91	ROUGE 8.65
2024-02-03 04:25:02,320 Logging Recognition and Translation Outputs
2024-02-03 04:25:02,320 ========================================================================================================================
2024-02-03 04:25:02,320 Logging Sequence: 92_117.00
2024-02-03 04:25:02,320 	Gloss Reference :	A B+C+D+E
2024-02-03 04:25:02,320 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:25:02,320 	Gloss Alignment :	         
2024-02-03 04:25:02,320 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:25:02,321 	Text Reference  :	vandana's brother shekhar  filed  a   complaint against the 2        men  
2024-02-03 04:25:02,321 	Text Hypothesis :	********* ******* recently during the match     india   -   pakistan match
2024-02-03 04:25:02,321 	Text Alignment  :	D         D       S        S      S   S         S       S   S        S    
2024-02-03 04:25:02,321 ========================================================================================================================
2024-02-03 04:25:02,322 Logging Sequence: 70_219.00
2024-02-03 04:25:02,322 	Gloss Reference :	A B+C+D+E
2024-02-03 04:25:02,322 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:25:02,322 	Gloss Alignment :	         
2024-02-03 04:25:02,322 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:25:02,323 	Text Reference  :	after this there   was another similar  incident
2024-02-03 04:25:02,323 	Text Hypothesis :	since the  denmark vs  finland football match   
2024-02-03 04:25:02,323 	Text Alignment  :	S     S    S       S   S       S        S       
2024-02-03 04:25:02,323 ========================================================================================================================
2024-02-03 04:25:02,323 Logging Sequence: 181_101.00
2024-02-03 04:25:02,323 	Gloss Reference :	A B+C+D+E
2024-02-03 04:25:02,323 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:25:02,324 	Gloss Alignment :	         
2024-02-03 04:25:02,324 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:25:02,324 	Text Reference  :	the cutest comment was by yuvraj' father yograj singh who    is a former cricketer and       actor 
2024-02-03 04:25:02,325 	Text Hypothesis :	*** ****** ******* *** ** ******* ****** ****** she   really is a ****** ********* fantastic player
2024-02-03 04:25:02,325 	Text Alignment  :	D   D      D       D   D  D       D      D      S     S           D      D         S         S     
2024-02-03 04:25:02,325 ========================================================================================================================
2024-02-03 04:25:02,325 Logging Sequence: 112_117.00
2024-02-03 04:25:02,325 	Gloss Reference :	A B+C+D+E
2024-02-03 04:25:02,325 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:25:02,325 	Gloss Alignment :	         
2024-02-03 04:25:02,325 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:25:02,327 	Text Reference  :	the ********** ******* rpsg group    previously owned        the         rising pune supergiant in 2016    and 2017
2024-02-03 04:25:02,327 	Text Hypothesis :	the government company -    national buildings  construction corporation and    they will       be allowed to  play
2024-02-03 04:25:02,327 	Text Alignment  :	    I          I       S    S        S          S            S           S      S    S          S  S       S   S   
2024-02-03 04:25:02,327 ========================================================================================================================
2024-02-03 04:25:02,327 Logging Sequence: 156_248.00
2024-02-03 04:25:02,327 	Gloss Reference :	A B+C+D+E
2024-02-03 04:25:02,328 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:25:02,328 	Gloss Alignment :	         
2024-02-03 04:25:02,328 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:25:02,329 	Text Reference  :	**** ** ******* ** miny reached 1843 in   16 overs   they won   the     match this was very   shocking
2024-02-03 04:25:02,329 	Text Hypothesis :	this is because he was  known   to   have a  married of   their seattle orcas sor  on  social media   
2024-02-03 04:25:02,329 	Text Alignment  :	I    I  I       I  S    S       S    S    S  S       S    S     S       S     S    S   S      S       
2024-02-03 04:25:02,330 ========================================================================================================================
2024-02-03 04:25:05,100 Epoch 256: Total Training Recognition Loss 0.61  Total Training Translation Loss 17.11 
2024-02-03 04:25:05,100 EPOCH 257
2024-02-03 04:25:08,159 [Epoch: 257 Step: 00034100] Batch Recognition Loss:   0.069572 => Gls Tokens per Sec:     1360 || Batch Translation Loss:   0.082178 => Txt Tokens per Sec:     3748 || Lr: 0.000100
2024-02-03 04:25:13,014 Epoch 257: Total Training Recognition Loss 0.74  Total Training Translation Loss 14.84 
2024-02-03 04:25:13,015 EPOCH 258
2024-02-03 04:25:14,014 [Epoch: 258 Step: 00034200] Batch Recognition Loss:   0.002759 => Gls Tokens per Sec:     1523 || Batch Translation Loss:   0.019379 => Txt Tokens per Sec:     4239 || Lr: 0.000100
2024-02-03 04:25:19,564 [Epoch: 258 Step: 00034300] Batch Recognition Loss:   0.003140 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.460272 => Txt Tokens per Sec:     3993 || Lr: 0.000100
2024-02-03 04:25:20,413 Epoch 258: Total Training Recognition Loss 0.61  Total Training Translation Loss 16.54 
2024-02-03 04:25:20,413 EPOCH 259
2024-02-03 04:25:24,927 [Epoch: 259 Step: 00034400] Batch Recognition Loss:   0.000619 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.025157 => Txt Tokens per Sec:     4260 || Lr: 0.000100
2024-02-03 04:25:27,549 Epoch 259: Total Training Recognition Loss 0.63  Total Training Translation Loss 15.99 
2024-02-03 04:25:27,549 EPOCH 260
2024-02-03 04:25:30,697 [Epoch: 260 Step: 00034500] Batch Recognition Loss:   0.000881 => Gls Tokens per Sec:     1347 || Batch Translation Loss:   0.058341 => Txt Tokens per Sec:     3780 || Lr: 0.000100
2024-02-03 04:25:35,128 Epoch 260: Total Training Recognition Loss 0.55  Total Training Translation Loss 23.22 
2024-02-03 04:25:35,128 EPOCH 261
2024-02-03 04:25:36,280 [Epoch: 261 Step: 00034600] Batch Recognition Loss:   0.037438 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.056088 => Txt Tokens per Sec:     3892 || Lr: 0.000100
2024-02-03 04:25:41,747 [Epoch: 261 Step: 00034700] Batch Recognition Loss:   0.000525 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.103767 => Txt Tokens per Sec:     4058 || Lr: 0.000100
2024-02-03 04:25:42,434 Epoch 261: Total Training Recognition Loss 0.70  Total Training Translation Loss 21.30 
2024-02-03 04:25:42,435 EPOCH 262
2024-02-03 04:25:47,148 [Epoch: 262 Step: 00034800] Batch Recognition Loss:   0.000659 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.049470 => Txt Tokens per Sec:     4130 || Lr: 0.000100
2024-02-03 04:25:49,681 Epoch 262: Total Training Recognition Loss 0.49  Total Training Translation Loss 19.07 
2024-02-03 04:25:49,682 EPOCH 263
2024-02-03 04:25:52,906 [Epoch: 263 Step: 00034900] Batch Recognition Loss:   0.000558 => Gls Tokens per Sec:     1340 || Batch Translation Loss:   0.053915 => Txt Tokens per Sec:     3877 || Lr: 0.000100
2024-02-03 04:25:57,221 Epoch 263: Total Training Recognition Loss 0.54  Total Training Translation Loss 16.40 
2024-02-03 04:25:57,222 EPOCH 264
2024-02-03 04:25:58,319 [Epoch: 264 Step: 00035000] Batch Recognition Loss:   0.001277 => Gls Tokens per Sec:     1533 || Batch Translation Loss:   0.157855 => Txt Tokens per Sec:     4025 || Lr: 0.000100
2024-02-03 04:26:03,944 [Epoch: 264 Step: 00035100] Batch Recognition Loss:   0.006433 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.449090 => Txt Tokens per Sec:     3981 || Lr: 0.000100
2024-02-03 04:26:04,619 Epoch 264: Total Training Recognition Loss 0.74  Total Training Translation Loss 26.95 
2024-02-03 04:26:04,620 EPOCH 265
2024-02-03 04:26:09,288 [Epoch: 265 Step: 00035200] Batch Recognition Loss:   0.001134 => Gls Tokens per Sec:     1509 || Batch Translation Loss:   0.220809 => Txt Tokens per Sec:     4173 || Lr: 0.000100
2024-02-03 04:26:11,766 Epoch 265: Total Training Recognition Loss 0.86  Total Training Translation Loss 22.74 
2024-02-03 04:26:11,766 EPOCH 266
2024-02-03 04:26:14,750 [Epoch: 266 Step: 00035300] Batch Recognition Loss:   0.007628 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.071142 => Txt Tokens per Sec:     4045 || Lr: 0.000100
2024-02-03 04:26:19,050 Epoch 266: Total Training Recognition Loss 0.65  Total Training Translation Loss 19.16 
2024-02-03 04:26:19,050 EPOCH 267
2024-02-03 04:26:20,314 [Epoch: 267 Step: 00035400] Batch Recognition Loss:   0.002219 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   1.059353 => Txt Tokens per Sec:     3663 || Lr: 0.000100
2024-02-03 04:26:25,889 [Epoch: 267 Step: 00035500] Batch Recognition Loss:   0.017267 => Gls Tokens per Sec:     1433 || Batch Translation Loss:   0.074998 => Txt Tokens per Sec:     4050 || Lr: 0.000100
2024-02-03 04:26:26,450 Epoch 267: Total Training Recognition Loss 0.78  Total Training Translation Loss 22.77 
2024-02-03 04:26:26,450 EPOCH 268
2024-02-03 04:26:30,984 [Epoch: 268 Step: 00035600] Batch Recognition Loss:   0.021871 => Gls Tokens per Sec:     1571 || Batch Translation Loss:   0.196132 => Txt Tokens per Sec:     4278 || Lr: 0.000100
2024-02-03 04:26:33,575 Epoch 268: Total Training Recognition Loss 0.46  Total Training Translation Loss 17.50 
2024-02-03 04:26:33,576 EPOCH 269
2024-02-03 04:26:36,190 [Epoch: 269 Step: 00035700] Batch Recognition Loss:   0.000837 => Gls Tokens per Sec:     1714 || Batch Translation Loss:   0.052147 => Txt Tokens per Sec:     4720 || Lr: 0.000100
2024-02-03 04:26:40,679 Epoch 269: Total Training Recognition Loss 0.66  Total Training Translation Loss 16.55 
2024-02-03 04:26:40,680 EPOCH 270
2024-02-03 04:26:42,056 [Epoch: 270 Step: 00035800] Batch Recognition Loss:   0.000948 => Gls Tokens per Sec:     1338 || Batch Translation Loss:   0.051542 => Txt Tokens per Sec:     3676 || Lr: 0.000100
2024-02-03 04:26:47,711 [Epoch: 270 Step: 00035900] Batch Recognition Loss:   0.018152 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.046310 => Txt Tokens per Sec:     3946 || Lr: 0.000100
2024-02-03 04:26:48,210 Epoch 270: Total Training Recognition Loss 0.59  Total Training Translation Loss 18.80 
2024-02-03 04:26:48,211 EPOCH 271
2024-02-03 04:26:53,141 [Epoch: 271 Step: 00036000] Batch Recognition Loss:   0.004290 => Gls Tokens per Sec:     1460 || Batch Translation Loss:   0.056847 => Txt Tokens per Sec:     4017 || Lr: 0.000100
2024-02-03 04:27:04,310 Validation result at epoch 271, step    36000: duration: 11.1663s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.14249	Translation Loss: 89697.05469	PPL: 11117.44531
	Eval Metric: BLEU
	WER 3.32	(DEL: 0.14,	INS: 0.00,	SUB: 3.18)
	BLEU-4 0.55	(BLEU-1: 9.57,	BLEU-2: 2.69,	BLEU-3: 1.08,	BLEU-4: 0.55)
	CHRF 16.46	ROUGE 8.11
2024-02-03 04:27:04,311 Logging Recognition and Translation Outputs
2024-02-03 04:27:04,311 ========================================================================================================================
2024-02-03 04:27:04,311 Logging Sequence: 109_16.00
2024-02-03 04:27:04,311 	Gloss Reference :	A B+C+D+E
2024-02-03 04:27:04,311 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:27:04,311 	Gloss Alignment :	         
2024-02-03 04:27:04,311 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:27:04,312 	Text Reference  :	however the match was rescheduled as two    kkr   players -            
2024-02-03 04:27:04,312 	Text Hypothesis :	******* *** ***** she secure      a  silver medal for     weightlifting
2024-02-03 04:27:04,312 	Text Alignment  :	D       D   D     S   S           S  S      S     S       S            
2024-02-03 04:27:04,312 ========================================================================================================================
2024-02-03 04:27:04,312 Logging Sequence: 146_120.00
2024-02-03 04:27:04,313 	Gloss Reference :	A B+C+D+E
2024-02-03 04:27:04,313 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:27:04,313 	Gloss Alignment :	         
2024-02-03 04:27:04,313 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:27:04,315 	Text Reference  :	bwf also announced that  the doubles partners of     the ***** players infected with the virus  would also  be     
2024-02-03 04:27:04,315 	Text Hypothesis :	*** a    maruti    wagon r   car     circled  around the pitch during  which    was  a   report on    their matches
2024-02-03 04:27:04,315 	Text Alignment  :	D   S    S         S     S   S       S        S          I     S       S        S    S   S      S     S     S      
2024-02-03 04:27:04,315 ========================================================================================================================
2024-02-03 04:27:04,315 Logging Sequence: 130_38.00
2024-02-03 04:27:04,315 	Gloss Reference :	A B+C+D+E
2024-02-03 04:27:04,315 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:27:04,316 	Gloss Alignment :	         
2024-02-03 04:27:04,316 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:27:04,317 	Text Reference  :	and is * now   married to   the    oscar-winning film-maker dustin lance black
2024-02-03 04:27:04,317 	Text Hypothesis :	he  is a diver had     been diving from          the        age    of    7    
2024-02-03 04:27:04,317 	Text Alignment  :	S      I S     S       S    S      S             S          S      S     S    
2024-02-03 04:27:04,317 ========================================================================================================================
2024-02-03 04:27:04,317 Logging Sequence: 161_170.00
2024-02-03 04:27:04,317 	Gloss Reference :	A B+C+D+E
2024-02-03 04:27:04,317 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:27:04,317 	Gloss Alignment :	         
2024-02-03 04:27:04,318 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:27:04,319 	Text Reference  :	however when the bcci replaced him with rohit sharma he decided to    step down as    test captain as       well
2024-02-03 04:27:04,319 	Text Hypothesis :	******* **** the **** ******** *** **** ***** ****** ** ******* match has  an   image on   6       december 2021
2024-02-03 04:27:04,319 	Text Alignment  :	D       D        D    D        D   D    D     D      D  D       S     S    S    S     S    S       S        S   
2024-02-03 04:27:04,319 ========================================================================================================================
2024-02-03 04:27:04,319 Logging Sequence: 89_14.00
2024-02-03 04:27:04,319 	Gloss Reference :	A B+C+D+E
2024-02-03 04:27:04,319 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:27:04,320 	Gloss Alignment :	         
2024-02-03 04:27:04,320 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:27:04,321 	Text Reference  :	*** ******* **** **** ** ** **** he has completed 23 years of    playing cricket
2024-02-03 04:27:04,321 	Text Hypothesis :	the spinner also went on to pick up 25  wickets   in 28    t20is for     india  
2024-02-03 04:27:04,321 	Text Alignment  :	I   I       I    I    I  I  I    S  S   S         S  S     S     S       S      
2024-02-03 04:27:04,321 ========================================================================================================================
2024-02-03 04:27:06,874 Epoch 271: Total Training Recognition Loss 0.54  Total Training Translation Loss 19.24 
2024-02-03 04:27:06,874 EPOCH 272
2024-02-03 04:27:10,060 [Epoch: 272 Step: 00036100] Batch Recognition Loss:   0.000410 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.081316 => Txt Tokens per Sec:     3983 || Lr: 0.000100
2024-02-03 04:27:14,496 Epoch 272: Total Training Recognition Loss 0.50  Total Training Translation Loss 19.15 
2024-02-03 04:27:14,496 EPOCH 273
2024-02-03 04:27:15,808 [Epoch: 273 Step: 00036200] Batch Recognition Loss:   0.000738 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   0.049118 => Txt Tokens per Sec:     4295 || Lr: 0.000100
2024-02-03 04:27:21,491 [Epoch: 273 Step: 00036300] Batch Recognition Loss:   0.000390 => Gls Tokens per Sec:     1406 || Batch Translation Loss:   0.183633 => Txt Tokens per Sec:     3864 || Lr: 0.000100
2024-02-03 04:27:21,962 Epoch 273: Total Training Recognition Loss 0.47  Total Training Translation Loss 20.13 
2024-02-03 04:27:21,962 EPOCH 274
2024-02-03 04:27:26,852 [Epoch: 274 Step: 00036400] Batch Recognition Loss:   0.000631 => Gls Tokens per Sec:     1489 || Batch Translation Loss:   0.126365 => Txt Tokens per Sec:     4122 || Lr: 0.000100
2024-02-03 04:27:29,333 Epoch 274: Total Training Recognition Loss 0.60  Total Training Translation Loss 22.19 
2024-02-03 04:27:29,334 EPOCH 275
2024-02-03 04:27:32,513 [Epoch: 275 Step: 00036500] Batch Recognition Loss:   0.006243 => Gls Tokens per Sec:     1460 || Batch Translation Loss:   0.106979 => Txt Tokens per Sec:     4141 || Lr: 0.000100
2024-02-03 04:27:36,778 Epoch 275: Total Training Recognition Loss 0.67  Total Training Translation Loss 22.05 
2024-02-03 04:27:36,778 EPOCH 276
2024-02-03 04:27:38,260 [Epoch: 276 Step: 00036600] Batch Recognition Loss:   0.001199 => Gls Tokens per Sec:     1351 || Batch Translation Loss:   0.079651 => Txt Tokens per Sec:     3803 || Lr: 0.000100
2024-02-03 04:27:43,938 [Epoch: 276 Step: 00036700] Batch Recognition Loss:   0.001902 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.244396 => Txt Tokens per Sec:     3911 || Lr: 0.000100
2024-02-03 04:27:44,363 Epoch 276: Total Training Recognition Loss 0.61  Total Training Translation Loss 19.59 
2024-02-03 04:27:44,363 EPOCH 277
2024-02-03 04:27:49,209 [Epoch: 277 Step: 00036800] Batch Recognition Loss:   0.000801 => Gls Tokens per Sec:     1519 || Batch Translation Loss:   0.349776 => Txt Tokens per Sec:     4226 || Lr: 0.000100
2024-02-03 04:27:51,484 Epoch 277: Total Training Recognition Loss 0.52  Total Training Translation Loss 17.75 
2024-02-03 04:27:51,485 EPOCH 278
2024-02-03 04:27:54,887 [Epoch: 278 Step: 00036900] Batch Recognition Loss:   0.000496 => Gls Tokens per Sec:     1388 || Batch Translation Loss:   0.369590 => Txt Tokens per Sec:     3970 || Lr: 0.000100
2024-02-03 04:27:59,068 Epoch 278: Total Training Recognition Loss 0.59  Total Training Translation Loss 13.72 
2024-02-03 04:27:59,069 EPOCH 279
2024-02-03 04:28:00,566 [Epoch: 279 Step: 00037000] Batch Recognition Loss:   0.000422 => Gls Tokens per Sec:     1389 || Batch Translation Loss:   0.200225 => Txt Tokens per Sec:     3726 || Lr: 0.000100
2024-02-03 04:28:06,285 [Epoch: 279 Step: 00037100] Batch Recognition Loss:   0.000339 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.064381 => Txt Tokens per Sec:     3903 || Lr: 0.000100
2024-02-03 04:28:06,684 Epoch 279: Total Training Recognition Loss 0.57  Total Training Translation Loss 14.67 
2024-02-03 04:28:06,684 EPOCH 280
2024-02-03 04:28:11,527 [Epoch: 280 Step: 00037200] Batch Recognition Loss:   0.005608 => Gls Tokens per Sec:     1537 || Batch Translation Loss:   0.065513 => Txt Tokens per Sec:     4270 || Lr: 0.000100
2024-02-03 04:28:13,670 Epoch 280: Total Training Recognition Loss 0.61  Total Training Translation Loss 23.84 
2024-02-03 04:28:13,670 EPOCH 281
2024-02-03 04:28:16,663 [Epoch: 281 Step: 00037300] Batch Recognition Loss:   0.001242 => Gls Tokens per Sec:     1604 || Batch Translation Loss:   0.431558 => Txt Tokens per Sec:     4387 || Lr: 0.000100
2024-02-03 04:28:20,854 Epoch 281: Total Training Recognition Loss 0.89  Total Training Translation Loss 27.54 
2024-02-03 04:28:20,855 EPOCH 282
2024-02-03 04:28:22,310 [Epoch: 282 Step: 00037400] Batch Recognition Loss:   0.000365 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.090548 => Txt Tokens per Sec:     4020 || Lr: 0.000100
2024-02-03 04:28:27,940 [Epoch: 282 Step: 00037500] Batch Recognition Loss:   0.046783 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.160428 => Txt Tokens per Sec:     3969 || Lr: 0.000100
2024-02-03 04:28:28,375 Epoch 282: Total Training Recognition Loss 0.68  Total Training Translation Loss 18.21 
2024-02-03 04:28:28,375 EPOCH 283
2024-02-03 04:28:33,452 [Epoch: 283 Step: 00037600] Batch Recognition Loss:   0.011290 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.059452 => Txt Tokens per Sec:     4123 || Lr: 0.000100
2024-02-03 04:28:35,516 Epoch 283: Total Training Recognition Loss 0.59  Total Training Translation Loss 14.81 
2024-02-03 04:28:35,516 EPOCH 284
2024-02-03 04:28:38,893 [Epoch: 284 Step: 00037700] Batch Recognition Loss:   0.000471 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.024546 => Txt Tokens per Sec:     3994 || Lr: 0.000100
2024-02-03 04:28:43,174 Epoch 284: Total Training Recognition Loss 0.49  Total Training Translation Loss 19.25 
2024-02-03 04:28:43,174 EPOCH 285
2024-02-03 04:28:44,971 [Epoch: 285 Step: 00037800] Batch Recognition Loss:   0.001885 => Gls Tokens per Sec:     1248 || Batch Translation Loss:   0.260753 => Txt Tokens per Sec:     3469 || Lr: 0.000100
2024-02-03 04:28:50,524 [Epoch: 285 Step: 00037900] Batch Recognition Loss:   0.000807 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.054157 => Txt Tokens per Sec:     4016 || Lr: 0.000100
2024-02-03 04:28:50,758 Epoch 285: Total Training Recognition Loss 0.57  Total Training Translation Loss 16.72 
2024-02-03 04:28:50,758 EPOCH 286
2024-02-03 04:28:55,810 [Epoch: 286 Step: 00038000] Batch Recognition Loss:   0.000346 => Gls Tokens per Sec:     1505 || Batch Translation Loss:   0.040202 => Txt Tokens per Sec:     4179 || Lr: 0.000100
2024-02-03 04:29:07,160 Validation result at epoch 286, step    38000: duration: 11.3500s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.14592	Translation Loss: 88775.84375	PPL: 10103.01953
	Eval Metric: BLEU
	WER 3.68	(DEL: 0.07,	INS: 0.00,	SUB: 3.61)
	BLEU-4 0.41	(BLEU-1: 9.92,	BLEU-2: 2.80,	BLEU-3: 0.98,	BLEU-4: 0.41)
	CHRF 16.68	ROUGE 8.26
2024-02-03 04:29:07,161 Logging Recognition and Translation Outputs
2024-02-03 04:29:07,161 ========================================================================================================================
2024-02-03 04:29:07,161 Logging Sequence: 180_124.00
2024-02-03 04:29:07,162 	Gloss Reference :	A B+C+D+E
2024-02-03 04:29:07,162 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:29:07,162 	Gloss Alignment :	         
2024-02-03 04:29:07,162 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:29:07,163 	Text Reference  :	********* **** ***** * ********* **** *** ********* ********* demanding singh'     resignation dissolution of   wfi   committee and appointing a      new committee
2024-02-03 04:29:07,164 	Text Hypothesis :	wrestlers then wrote a complaint with the wrestlers including started   protesting again       from        23rd april 2023      at  jantar     mantar in  delhi    
2024-02-03 04:29:07,164 	Text Alignment  :	I         I    I     I I         I    I   I         I         S         S          S           S           S    S     S         S   S          S      S   S        
2024-02-03 04:29:07,164 ========================================================================================================================
2024-02-03 04:29:07,164 Logging Sequence: 67_16.00
2024-02-03 04:29:07,164 	Gloss Reference :	A B+C+D+E
2024-02-03 04:29:07,164 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:29:07,164 	Gloss Alignment :	         
2024-02-03 04:29:07,165 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:29:07,165 	Text Reference  :	**** **** to help india's fight against the ****** ******* covid-19 pandemic
2024-02-03 04:29:07,165 	Text Hypothesis :	then came in the  yadav   to    play    the indian premier league   ipl     
2024-02-03 04:29:07,165 	Text Alignment  :	I    I    S  S    S       S     S           I      I       S        S       
2024-02-03 04:29:07,166 ========================================================================================================================
2024-02-03 04:29:07,166 Logging Sequence: 79_57.00
2024-02-03 04:29:07,166 	Gloss Reference :	A B+C+D+E
2024-02-03 04:29:07,166 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:29:07,166 	Gloss Alignment :	         
2024-02-03 04:29:07,166 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:29:07,168 	Text Reference  :	***** ******** **** ******** ** **** ******* ****** ***** the board organised the matches only in   mumbai navi mumbai and pune  
2024-02-03 04:29:07,168 	Text Hypothesis :	delhi capitals were supposed to play against punjab kings on  april 20        now we      will have to     see  if     the rising
2024-02-03 04:29:07,168 	Text Alignment  :	I     I        I    I        I  I    I       I      I     S   S     S         S   S       S    S    S      S    S      S   S     
2024-02-03 04:29:07,168 ========================================================================================================================
2024-02-03 04:29:07,168 Logging Sequence: 109_161.00
2024-02-03 04:29:07,168 	Gloss Reference :	A B+C+D+E
2024-02-03 04:29:07,169 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:29:07,169 	Gloss Alignment :	         
2024-02-03 04:29:07,169 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:29:07,169 	Text Reference  :	he had severe pain   in       his lower abdomen 
2024-02-03 04:29:07,169 	Text Hypothesis :	he *** ****** tested positive for covid pandemic
2024-02-03 04:29:07,169 	Text Alignment  :	   D   D      S      S        S   S     S       
2024-02-03 04:29:07,170 ========================================================================================================================
2024-02-03 04:29:07,170 Logging Sequence: 135_136.00
2024-02-03 04:29:07,170 	Gloss Reference :	A B+C+D+E
2024-02-03 04:29:07,170 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:29:07,170 	Gloss Alignment :	         
2024-02-03 04:29:07,170 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:29:07,172 	Text Reference  :	***** ***** **** in 2018  maria was   diagnosed with cancer         and ******* required surgery she    is a       cancer suvivor
2024-02-03 04:29:07,172 	Text Hypothesis :	maria wrote that to cover the   costs of        his  transportation and medical care     maå‚ysa needed 15 million polish zlotys 
2024-02-03 04:29:07,172 	Text Alignment  :	I     I     I    S  S     S     S     S         S    S                  I       S        S       S      S  S       S      S      
2024-02-03 04:29:07,172 ========================================================================================================================
2024-02-03 04:29:09,218 Epoch 286: Total Training Recognition Loss 0.55  Total Training Translation Loss 13.65 
2024-02-03 04:29:09,218 EPOCH 287
2024-02-03 04:29:12,460 [Epoch: 287 Step: 00038100] Batch Recognition Loss:   0.001460 => Gls Tokens per Sec:     1530 || Batch Translation Loss:   0.087371 => Txt Tokens per Sec:     4281 || Lr: 0.000100
2024-02-03 04:29:16,723 Epoch 287: Total Training Recognition Loss 0.63  Total Training Translation Loss 13.10 
2024-02-03 04:29:16,724 EPOCH 288
2024-02-03 04:29:18,432 [Epoch: 288 Step: 00038200] Batch Recognition Loss:   0.000355 => Gls Tokens per Sec:     1358 || Batch Translation Loss:   0.046075 => Txt Tokens per Sec:     3800 || Lr: 0.000100
2024-02-03 04:29:24,324 [Epoch: 288 Step: 00038300] Batch Recognition Loss:   0.001518 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.045421 => Txt Tokens per Sec:     3747 || Lr: 0.000100
2024-02-03 04:29:24,560 Epoch 288: Total Training Recognition Loss 0.51  Total Training Translation Loss 16.85 
2024-02-03 04:29:24,560 EPOCH 289
2024-02-03 04:29:29,604 [Epoch: 289 Step: 00038400] Batch Recognition Loss:   0.000341 => Gls Tokens per Sec:     1523 || Batch Translation Loss:   0.347226 => Txt Tokens per Sec:     4218 || Lr: 0.000100
2024-02-03 04:29:31,800 Epoch 289: Total Training Recognition Loss 0.69  Total Training Translation Loss 18.57 
2024-02-03 04:29:31,801 EPOCH 290
2024-02-03 04:29:35,323 [Epoch: 290 Step: 00038500] Batch Recognition Loss:   0.006916 => Gls Tokens per Sec:     1431 || Batch Translation Loss:   0.156998 => Txt Tokens per Sec:     3957 || Lr: 0.000100
2024-02-03 04:29:39,328 Epoch 290: Total Training Recognition Loss 0.50  Total Training Translation Loss 18.51 
2024-02-03 04:29:39,328 EPOCH 291
2024-02-03 04:29:40,886 [Epoch: 291 Step: 00038600] Batch Recognition Loss:   0.000989 => Gls Tokens per Sec:     1541 || Batch Translation Loss:   0.018806 => Txt Tokens per Sec:     4516 || Lr: 0.000100
2024-02-03 04:29:46,318 [Epoch: 291 Step: 00038700] Batch Recognition Loss:   0.000160 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.222438 => Txt Tokens per Sec:     4029 || Lr: 0.000100
2024-02-03 04:29:46,454 Epoch 291: Total Training Recognition Loss 0.45  Total Training Translation Loss 23.37 
2024-02-03 04:29:46,454 EPOCH 292
2024-02-03 04:29:51,487 [Epoch: 292 Step: 00038800] Batch Recognition Loss:   0.001116 => Gls Tokens per Sec:     1542 || Batch Translation Loss:   0.062280 => Txt Tokens per Sec:     4251 || Lr: 0.000100
2024-02-03 04:29:53,444 Epoch 292: Total Training Recognition Loss 0.57  Total Training Translation Loss 20.21 
2024-02-03 04:29:53,444 EPOCH 293
2024-02-03 04:29:57,167 [Epoch: 293 Step: 00038900] Batch Recognition Loss:   0.001115 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.090878 => Txt Tokens per Sec:     3888 || Lr: 0.000100
2024-02-03 04:30:01,146 Epoch 293: Total Training Recognition Loss 0.54  Total Training Translation Loss 17.95 
2024-02-03 04:30:01,147 EPOCH 294
2024-02-03 04:30:02,720 [Epoch: 294 Step: 00039000] Batch Recognition Loss:   0.001472 => Gls Tokens per Sec:     1578 || Batch Translation Loss:   0.045358 => Txt Tokens per Sec:     4246 || Lr: 0.000100
2024-02-03 04:30:08,650 [Epoch: 294 Step: 00039100] Batch Recognition Loss:   0.000370 => Gls Tokens per Sec:     1347 || Batch Translation Loss:   0.198188 => Txt Tokens per Sec:     3770 || Lr: 0.000100
2024-02-03 04:30:08,814 Epoch 294: Total Training Recognition Loss 0.49  Total Training Translation Loss 21.16 
2024-02-03 04:30:08,814 EPOCH 295
2024-02-03 04:30:14,380 [Epoch: 295 Step: 00039200] Batch Recognition Loss:   0.000060 => Gls Tokens per Sec:     1409 || Batch Translation Loss:   0.030646 => Txt Tokens per Sec:     3901 || Lr: 0.000100
2024-02-03 04:30:16,425 Epoch 295: Total Training Recognition Loss 0.87  Total Training Translation Loss 19.35 
2024-02-03 04:30:16,425 EPOCH 296
2024-02-03 04:30:19,874 [Epoch: 296 Step: 00039300] Batch Recognition Loss:   0.008136 => Gls Tokens per Sec:     1508 || Batch Translation Loss:   0.076961 => Txt Tokens per Sec:     4080 || Lr: 0.000100
2024-02-03 04:30:24,017 Epoch 296: Total Training Recognition Loss 0.69  Total Training Translation Loss 17.85 
2024-02-03 04:30:24,017 EPOCH 297
2024-02-03 04:30:25,832 [Epoch: 297 Step: 00039400] Batch Recognition Loss:   0.005635 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.082410 => Txt Tokens per Sec:     4010 || Lr: 0.000100
2024-02-03 04:30:31,645 [Epoch: 297 Step: 00039500] Batch Recognition Loss:   0.002963 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.236418 => Txt Tokens per Sec:     3802 || Lr: 0.000100
2024-02-03 04:30:31,687 Epoch 297: Total Training Recognition Loss 0.60  Total Training Translation Loss 11.59 
2024-02-03 04:30:31,688 EPOCH 298
2024-02-03 04:30:36,928 [Epoch: 298 Step: 00039600] Batch Recognition Loss:   0.001210 => Gls Tokens per Sec:     1512 || Batch Translation Loss:   0.053067 => Txt Tokens per Sec:     4180 || Lr: 0.000100
2024-02-03 04:30:38,983 Epoch 298: Total Training Recognition Loss 0.48  Total Training Translation Loss 12.57 
2024-02-03 04:30:38,984 EPOCH 299
2024-02-03 04:30:42,706 [Epoch: 299 Step: 00039700] Batch Recognition Loss:   0.019031 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.115260 => Txt Tokens per Sec:     4070 || Lr: 0.000100
2024-02-03 04:30:46,304 Epoch 299: Total Training Recognition Loss 0.44  Total Training Translation Loss 16.88 
2024-02-03 04:30:46,305 EPOCH 300
2024-02-03 04:30:48,121 [Epoch: 300 Step: 00039800] Batch Recognition Loss:   0.000788 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.082041 => Txt Tokens per Sec:     4144 || Lr: 0.000100
2024-02-03 04:30:54,155 [Epoch: 300 Step: 00039900] Batch Recognition Loss:   0.002603 => Gls Tokens per Sec:     1324 || Batch Translation Loss:   0.123918 => Txt Tokens per Sec:     3653 || Lr: 0.000100
2024-02-03 04:30:54,156 Epoch 300: Total Training Recognition Loss 0.51  Total Training Translation Loss 17.12 
2024-02-03 04:30:54,156 EPOCH 301
2024-02-03 04:30:59,846 [Epoch: 301 Step: 00040000] Batch Recognition Loss:   0.000954 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.319675 => Txt Tokens per Sec:     3915 || Lr: 0.000100
2024-02-03 04:31:11,486 Validation result at epoch 301, step    40000: duration: 11.6396s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 13.56354	Translation Loss: 89659.76562	PPL: 11074.46191
	Eval Metric: BLEU
	WER 4.10	(DEL: 0.07,	INS: 0.00,	SUB: 4.03)
	BLEU-4 0.67	(BLEU-1: 9.76,	BLEU-2: 2.96,	BLEU-3: 1.25,	BLEU-4: 0.67)
	CHRF 16.92	ROUGE 8.19
2024-02-03 04:31:11,487 Logging Recognition and Translation Outputs
2024-02-03 04:31:11,487 ========================================================================================================================
2024-02-03 04:31:11,487 Logging Sequence: 142_182.00
2024-02-03 04:31:11,487 	Gloss Reference :	A B+C+D+E
2024-02-03 04:31:11,487 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:31:11,487 	Gloss Alignment :	         
2024-02-03 04:31:11,488 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:31:11,490 	Text Reference  :	many indians  commented that hope    he     does    not miss the match as  he    is    important while playing against england  
2024-02-03 04:31:11,490 	Text Hypothesis :	and  arrested danushka  for  alleged sexual assault of  a    29  year  old woman whose name      has   not     been    disclosed
2024-02-03 04:31:11,490 	Text Alignment  :	S    S        S         S    S       S      S       S   S    S   S     S   S     S     S         S     S       S       S        
2024-02-03 04:31:11,490 ========================================================================================================================
2024-02-03 04:31:11,490 Logging Sequence: 58_97.00
2024-02-03 04:31:11,490 	Gloss Reference :	A B+C+D+E
2024-02-03 04:31:11,491 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:31:11,491 	Gloss Alignment :	         
2024-02-03 04:31:11,491 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:31:11,492 	Text Reference  :	*** the *** *** ** indian athletes have already   bagged a   total of 28    medals
2024-02-03 04:31:11,492 	Text Hypothesis :	but the 3rd day of these  teams    were postponed so     far final of these teams 
2024-02-03 04:31:11,492 	Text Alignment  :	I       I   I   I  S      S        S    S         S      S   S        S     S     
2024-02-03 04:31:11,492 ========================================================================================================================
2024-02-03 04:31:11,492 Logging Sequence: 62_76.00
2024-02-03 04:31:11,493 	Gloss Reference :	A B+C+D+E
2024-02-03 04:31:11,493 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:31:11,493 	Gloss Alignment :	         
2024-02-03 04:31:11,493 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:31:11,495 	Text Reference  :	** *** *** for  t20 the   male player is     paid  rs   3   lakh information is   not  available for women players
2024-02-03 04:31:11,495 	Text Hypothesis :	it was not only any match and  the    indian takes into the loss and         were seen even      in  the   team   
2024-02-03 04:31:11,495 	Text Alignment  :	I  I   I   S    S   S     S    S      S      S     S    S   S    S           S    S    S         S   S     S      
2024-02-03 04:31:11,495 ========================================================================================================================
2024-02-03 04:31:11,496 Logging Sequence: 171_52.00
2024-02-03 04:31:11,496 	Gloss Reference :	A B+C+D+E
2024-02-03 04:31:11,496 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:31:11,496 	Gloss Alignment :	         
2024-02-03 04:31:11,496 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:31:11,498 	Text Reference  :	* during  the       second half      of       the match when gujarat titans were     batting sometime during the 14th-15th over       
2024-02-03 04:31:11,498 	Text Hypothesis :	4 another argentine enzo   fernandez recieved the ***** **** ******* silver youngest player  award    for    his amazing   performance
2024-02-03 04:31:11,498 	Text Alignment  :	I S       S         S      S         S            D     D    D       S      S        S       S        S      S   S         S          
2024-02-03 04:31:11,498 ========================================================================================================================
2024-02-03 04:31:11,498 Logging Sequence: 92_22.00
2024-02-03 04:31:11,498 	Gloss Reference :	A B+C+D+E
2024-02-03 04:31:11,499 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:31:11,499 	Gloss Alignment :	         
2024-02-03 04:31:11,499 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:31:11,500 	Text Reference  :	******* **** the team was   devastated as  they were hoping to win and secure a gold medal in the     finals   
2024-02-03 04:31:11,500 	Text Hypothesis :	england lost the **** match because    she was  not  able   to *** *** take   a **** ***** ** penalty shoot-out
2024-02-03 04:31:11,501 	Text Alignment  :	I       I        D    S     S          S   S    S    S         D   D   S        D    D     D  S       S        
2024-02-03 04:31:11,501 ========================================================================================================================
2024-02-03 04:31:13,456 Epoch 301: Total Training Recognition Loss 1.23  Total Training Translation Loss 17.01 
2024-02-03 04:31:13,457 EPOCH 302
2024-02-03 04:31:17,227 [Epoch: 302 Step: 00040100] Batch Recognition Loss:   0.005376 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.196493 => Txt Tokens per Sec:     3935 || Lr: 0.000100
2024-02-03 04:31:21,140 Epoch 302: Total Training Recognition Loss 1.19  Total Training Translation Loss 21.37 
2024-02-03 04:31:21,140 EPOCH 303
2024-02-03 04:31:23,042 [Epoch: 303 Step: 00040200] Batch Recognition Loss:   0.000622 => Gls Tokens per Sec:     1431 || Batch Translation Loss:   0.231110 => Txt Tokens per Sec:     4016 || Lr: 0.000100
2024-02-03 04:31:29,015 Epoch 303: Total Training Recognition Loss 0.82  Total Training Translation Loss 18.51 
2024-02-03 04:31:29,015 EPOCH 304
2024-02-03 04:31:29,072 [Epoch: 304 Step: 00040300] Batch Recognition Loss:   0.003724 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.181272 => Txt Tokens per Sec:     4179 || Lr: 0.000100
2024-02-03 04:31:34,528 [Epoch: 304 Step: 00040400] Batch Recognition Loss:   0.000545 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   0.047277 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-03 04:31:36,412 Epoch 304: Total Training Recognition Loss 0.74  Total Training Translation Loss 20.59 
2024-02-03 04:31:36,412 EPOCH 305
2024-02-03 04:31:40,385 [Epoch: 305 Step: 00040500] Batch Recognition Loss:   0.000896 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.087702 => Txt Tokens per Sec:     3728 || Lr: 0.000100
2024-02-03 04:31:44,353 Epoch 305: Total Training Recognition Loss 0.60  Total Training Translation Loss 15.42 
2024-02-03 04:31:44,353 EPOCH 306
2024-02-03 04:31:46,270 [Epoch: 306 Step: 00040600] Batch Recognition Loss:   0.003244 => Gls Tokens per Sec:     1462 || Batch Translation Loss:   0.066548 => Txt Tokens per Sec:     3848 || Lr: 0.000100
2024-02-03 04:31:52,186 Epoch 306: Total Training Recognition Loss 0.63  Total Training Translation Loss 16.51 
2024-02-03 04:31:52,186 EPOCH 307
2024-02-03 04:31:52,300 [Epoch: 307 Step: 00040700] Batch Recognition Loss:   0.001083 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.028193 => Txt Tokens per Sec:     3752 || Lr: 0.000100
2024-02-03 04:31:57,876 [Epoch: 307 Step: 00040800] Batch Recognition Loss:   0.010237 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.091812 => Txt Tokens per Sec:     4011 || Lr: 0.000100
2024-02-03 04:31:59,604 Epoch 307: Total Training Recognition Loss 0.59  Total Training Translation Loss 14.04 
2024-02-03 04:31:59,605 EPOCH 308
2024-02-03 04:32:03,189 [Epoch: 308 Step: 00040900] Batch Recognition Loss:   0.000942 => Gls Tokens per Sec:     1541 || Batch Translation Loss:   0.059942 => Txt Tokens per Sec:     4273 || Lr: 0.000100
2024-02-03 04:32:06,741 Epoch 308: Total Training Recognition Loss 0.52  Total Training Translation Loss 16.25 
2024-02-03 04:32:06,741 EPOCH 309
2024-02-03 04:32:08,696 [Epoch: 309 Step: 00041000] Batch Recognition Loss:   0.000505 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.013539 => Txt Tokens per Sec:     3979 || Lr: 0.000100
2024-02-03 04:32:14,424 Epoch 309: Total Training Recognition Loss 0.54  Total Training Translation Loss 13.78 
2024-02-03 04:32:14,425 EPOCH 310
2024-02-03 04:32:14,560 [Epoch: 310 Step: 00041100] Batch Recognition Loss:   0.000594 => Gls Tokens per Sec:     1791 || Batch Translation Loss:   0.037857 => Txt Tokens per Sec:     4082 || Lr: 0.000100
2024-02-03 04:32:20,380 [Epoch: 310 Step: 00041200] Batch Recognition Loss:   0.000626 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.038109 => Txt Tokens per Sec:     3831 || Lr: 0.000100
2024-02-03 04:32:22,022 Epoch 310: Total Training Recognition Loss 0.56  Total Training Translation Loss 16.56 
2024-02-03 04:32:22,023 EPOCH 311
2024-02-03 04:32:25,957 [Epoch: 311 Step: 00041300] Batch Recognition Loss:   0.000751 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.168103 => Txt Tokens per Sec:     4040 || Lr: 0.000100
2024-02-03 04:32:29,454 Epoch 311: Total Training Recognition Loss 0.59  Total Training Translation Loss 13.50 
2024-02-03 04:32:29,454 EPOCH 312
2024-02-03 04:32:31,659 [Epoch: 312 Step: 00041400] Batch Recognition Loss:   0.048115 => Gls Tokens per Sec:     1343 || Batch Translation Loss:   0.053748 => Txt Tokens per Sec:     3740 || Lr: 0.000100
2024-02-03 04:32:37,242 Epoch 312: Total Training Recognition Loss 0.55  Total Training Translation Loss 22.43 
2024-02-03 04:32:37,243 EPOCH 313
2024-02-03 04:32:37,452 [Epoch: 313 Step: 00041500] Batch Recognition Loss:   0.000397 => Gls Tokens per Sec:     1546 || Batch Translation Loss:   0.168493 => Txt Tokens per Sec:     4266 || Lr: 0.000100
2024-02-03 04:32:43,046 [Epoch: 313 Step: 00041600] Batch Recognition Loss:   0.000340 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.082281 => Txt Tokens per Sec:     3974 || Lr: 0.000100
2024-02-03 04:32:44,648 Epoch 313: Total Training Recognition Loss 0.57  Total Training Translation Loss 22.19 
2024-02-03 04:32:44,648 EPOCH 314
2024-02-03 04:32:48,570 [Epoch: 314 Step: 00041700] Batch Recognition Loss:   0.000547 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.044667 => Txt Tokens per Sec:     3951 || Lr: 0.000100
2024-02-03 04:32:52,207 Epoch 314: Total Training Recognition Loss 0.73  Total Training Translation Loss 20.92 
2024-02-03 04:32:52,208 EPOCH 315
2024-02-03 04:32:54,168 [Epoch: 315 Step: 00041800] Batch Recognition Loss:   0.002837 => Gls Tokens per Sec:     1552 || Batch Translation Loss:   0.040139 => Txt Tokens per Sec:     4266 || Lr: 0.000100
2024-02-03 04:32:59,564 Epoch 315: Total Training Recognition Loss 0.81  Total Training Translation Loss 19.87 
2024-02-03 04:32:59,565 EPOCH 316
2024-02-03 04:32:59,809 [Epoch: 316 Step: 00041900] Batch Recognition Loss:   0.000832 => Gls Tokens per Sec:     1657 || Batch Translation Loss:   0.022995 => Txt Tokens per Sec:     4315 || Lr: 0.000100
2024-02-03 04:33:05,285 [Epoch: 316 Step: 00042000] Batch Recognition Loss:   0.000426 => Gls Tokens per Sec:     1461 || Batch Translation Loss:   0.033932 => Txt Tokens per Sec:     4129 || Lr: 0.000100
2024-02-03 04:33:16,158 Hooray! New best validation result [eval_metric]!
2024-02-03 04:33:16,160 Saving new checkpoint.
2024-02-03 04:33:16,441 Validation result at epoch 316, step    42000: duration: 11.1559s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.69344	Translation Loss: 89908.03906	PPL: 11363.75684
	Eval Metric: BLEU
	WER 3.61	(DEL: 0.00,	INS: 0.00,	SUB: 3.61)
	BLEU-4 0.78	(BLEU-1: 10.73,	BLEU-2: 3.41,	BLEU-3: 1.46,	BLEU-4: 0.78)
	CHRF 16.92	ROUGE 9.07
2024-02-03 04:33:16,442 Logging Recognition and Translation Outputs
2024-02-03 04:33:16,442 ========================================================================================================================
2024-02-03 04:33:16,442 Logging Sequence: 130_18.00
2024-02-03 04:33:16,443 	Gloss Reference :	A B+C+D+E
2024-02-03 04:33:16,443 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:33:16,443 	Gloss Alignment :	         
2024-02-03 04:33:16,443 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:33:16,445 	Text Reference  :	** when he   was  only  14 years old    he    participated in      the   2008     olympic games in *** beijing china
2024-02-03 04:33:16,445 	Text Hypothesis :	do you  know that daley is a     strong diver but          respect their athletes take    part  in the same    venue
2024-02-03 04:33:16,445 	Text Alignment  :	I  S    S    S    S     S  S     S      S     S            S       S     S        S       S        I   S       S    
2024-02-03 04:33:16,445 ========================================================================================================================
2024-02-03 04:33:16,446 Logging Sequence: 106_112.00
2024-02-03 04:33:16,446 	Gloss Reference :	A B+C+D+E
2024-02-03 04:33:16,446 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:33:16,446 	Gloss Alignment :	         
2024-02-03 04:33:16,446 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:33:16,447 	Text Reference  :	this     was ****** ** *** ******** ***** **** ** ***** *** *** indian  team's 7th    asia     cup t20 win 
2024-02-03 04:33:16,447 	Text Hypothesis :	everyone was hooked to the exciting match even in india and new zealand had    tested positive for 9   days
2024-02-03 04:33:16,448 	Text Alignment  :	S            I      I  I   I        I     I    I  I     I   I   S       S      S      S        S   S   S   
2024-02-03 04:33:16,448 ========================================================================================================================
2024-02-03 04:33:16,448 Logging Sequence: 109_161.00
2024-02-03 04:33:16,448 	Gloss Reference :	A B+C+D+E
2024-02-03 04:33:16,448 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:33:16,448 	Gloss Alignment :	         
2024-02-03 04:33:16,448 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:33:16,449 	Text Reference  :	he *** had  severe pain   in his lower abdomen
2024-02-03 04:33:16,449 	Text Hypothesis :	he won four gold   medals at the asian games  
2024-02-03 04:33:16,449 	Text Alignment  :	   I   S    S      S      S  S   S     S      
2024-02-03 04:33:16,449 ========================================================================================================================
2024-02-03 04:33:16,449 Logging Sequence: 136_202.00
2024-02-03 04:33:16,450 	Gloss Reference :	A B+C+D+E
2024-02-03 04:33:16,450 	Gloss Hypothesis:	A B+E+D  
2024-02-03 04:33:16,450 	Gloss Alignment :	  S      
2024-02-03 04:33:16,450 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:33:16,451 	Text Reference  :	*** ***** *** ** ***** **** now we   will  have to     wait for updates
2024-02-03 04:33:16,451 	Text Hypothesis :	the world cup is being held in  2020 after the  finals of   4   years  
2024-02-03 04:33:16,451 	Text Alignment  :	I   I     I   I  I     I    S   S    S     S    S      S    S   S      
2024-02-03 04:33:16,451 ========================================================================================================================
2024-02-03 04:33:16,451 Logging Sequence: 140_2.00
2024-02-03 04:33:16,451 	Gloss Reference :	A B+C+D+E
2024-02-03 04:33:16,452 	Gloss Hypothesis:	A B+C+D  
2024-02-03 04:33:16,452 	Gloss Alignment :	  S      
2024-02-03 04:33:16,452 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:33:16,453 	Text Reference  :	** **** **** ****** indian batsman-wicket keeper rishabh pant has   outstanding    skills in * ********** cricket
2024-02-03 04:33:16,453 	Text Hypothesis :	so then they change their  routes         close  to      this while praggnanandhaa came   in a commercial flight 
2024-02-03 04:33:16,453 	Text Alignment  :	I  I    I    I      S      S              S      S       S    S     S              S         I I          S      
2024-02-03 04:33:16,453 ========================================================================================================================
2024-02-03 04:33:18,050 Epoch 316: Total Training Recognition Loss 0.51  Total Training Translation Loss 14.18 
2024-02-03 04:33:18,050 EPOCH 317
2024-02-03 04:33:22,173 [Epoch: 317 Step: 00042100] Batch Recognition Loss:   0.000286 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.035362 => Txt Tokens per Sec:     3879 || Lr: 0.000100
2024-02-03 04:33:25,686 Epoch 317: Total Training Recognition Loss 0.40  Total Training Translation Loss 11.25 
2024-02-03 04:33:25,686 EPOCH 318
2024-02-03 04:33:28,044 [Epoch: 318 Step: 00042200] Batch Recognition Loss:   0.000998 => Gls Tokens per Sec:     1324 || Batch Translation Loss:   0.287340 => Txt Tokens per Sec:     3775 || Lr: 0.000100
2024-02-03 04:33:33,419 Epoch 318: Total Training Recognition Loss 0.62  Total Training Translation Loss 16.99 
2024-02-03 04:33:33,419 EPOCH 319
2024-02-03 04:33:33,766 [Epoch: 319 Step: 00042300] Batch Recognition Loss:   0.001529 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.074827 => Txt Tokens per Sec:     4168 || Lr: 0.000100
2024-02-03 04:33:39,475 [Epoch: 319 Step: 00042400] Batch Recognition Loss:   0.017742 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.134463 => Txt Tokens per Sec:     3854 || Lr: 0.000100
2024-02-03 04:33:40,954 Epoch 319: Total Training Recognition Loss 0.52  Total Training Translation Loss 17.47 
2024-02-03 04:33:40,955 EPOCH 320
2024-02-03 04:33:44,798 [Epoch: 320 Step: 00042500] Batch Recognition Loss:   0.023402 => Gls Tokens per Sec:     1520 || Batch Translation Loss:   0.349099 => Txt Tokens per Sec:     4261 || Lr: 0.000100
2024-02-03 04:33:48,164 Epoch 320: Total Training Recognition Loss 0.48  Total Training Translation Loss 18.59 
2024-02-03 04:33:48,164 EPOCH 321
2024-02-03 04:33:50,318 [Epoch: 321 Step: 00042600] Batch Recognition Loss:   0.000470 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.240669 => Txt Tokens per Sec:     4087 || Lr: 0.000100
2024-02-03 04:33:55,650 Epoch 321: Total Training Recognition Loss 0.39  Total Training Translation Loss 22.88 
2024-02-03 04:33:55,651 EPOCH 322
2024-02-03 04:33:56,060 [Epoch: 322 Step: 00042700] Batch Recognition Loss:   0.004197 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.164712 => Txt Tokens per Sec:     3659 || Lr: 0.000100
2024-02-03 04:34:01,468 [Epoch: 322 Step: 00042800] Batch Recognition Loss:   0.002363 => Gls Tokens per Sec:     1480 || Batch Translation Loss:   0.171109 => Txt Tokens per Sec:     4118 || Lr: 0.000100
2024-02-03 04:34:03,040 Epoch 322: Total Training Recognition Loss 0.59  Total Training Translation Loss 20.20 
2024-02-03 04:34:03,041 EPOCH 323
2024-02-03 04:34:06,871 [Epoch: 323 Step: 00042900] Batch Recognition Loss:   0.000907 => Gls Tokens per Sec:     1546 || Batch Translation Loss:   0.036620 => Txt Tokens per Sec:     4303 || Lr: 0.000100
2024-02-03 04:34:10,555 Epoch 323: Total Training Recognition Loss 0.47  Total Training Translation Loss 17.54 
2024-02-03 04:34:10,555 EPOCH 324
2024-02-03 04:34:12,911 [Epoch: 324 Step: 00043000] Batch Recognition Loss:   0.000553 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.042522 => Txt Tokens per Sec:     3961 || Lr: 0.000100
2024-02-03 04:34:18,356 Epoch 324: Total Training Recognition Loss 0.47  Total Training Translation Loss 15.24 
2024-02-03 04:34:18,356 EPOCH 325
2024-02-03 04:34:18,821 [Epoch: 325 Step: 00043100] Batch Recognition Loss:   0.002419 => Gls Tokens per Sec:     1380 || Batch Translation Loss:   0.045656 => Txt Tokens per Sec:     3587 || Lr: 0.000100
2024-02-03 04:34:24,164 [Epoch: 325 Step: 00043200] Batch Recognition Loss:   0.000460 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.042430 => Txt Tokens per Sec:     4173 || Lr: 0.000100
2024-02-03 04:34:25,664 Epoch 325: Total Training Recognition Loss 0.61  Total Training Translation Loss 19.65 
2024-02-03 04:34:25,665 EPOCH 326
2024-02-03 04:34:29,855 [Epoch: 326 Step: 00043300] Batch Recognition Loss:   0.008441 => Gls Tokens per Sec:     1432 || Batch Translation Loss:   0.047671 => Txt Tokens per Sec:     3961 || Lr: 0.000100
2024-02-03 04:34:33,426 Epoch 326: Total Training Recognition Loss 0.53  Total Training Translation Loss 13.26 
2024-02-03 04:34:33,426 EPOCH 327
2024-02-03 04:34:35,681 [Epoch: 327 Step: 00043400] Batch Recognition Loss:   0.008542 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.113389 => Txt Tokens per Sec:     4295 || Lr: 0.000100
2024-02-03 04:34:40,989 Epoch 327: Total Training Recognition Loss 0.45  Total Training Translation Loss 12.42 
2024-02-03 04:34:40,989 EPOCH 328
2024-02-03 04:34:41,523 [Epoch: 328 Step: 00043500] Batch Recognition Loss:   0.004223 => Gls Tokens per Sec:     1351 || Batch Translation Loss:   0.032450 => Txt Tokens per Sec:     3505 || Lr: 0.000100
2024-02-03 04:34:46,801 [Epoch: 328 Step: 00043600] Batch Recognition Loss:   0.005756 => Gls Tokens per Sec:     1516 || Batch Translation Loss:   0.009622 => Txt Tokens per Sec:     4202 || Lr: 0.000100
2024-02-03 04:34:48,095 Epoch 328: Total Training Recognition Loss 0.38  Total Training Translation Loss 13.38 
2024-02-03 04:34:48,095 EPOCH 329
2024-02-03 04:34:52,279 [Epoch: 329 Step: 00043700] Batch Recognition Loss:   0.000985 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.245336 => Txt Tokens per Sec:     4020 || Lr: 0.000100
2024-02-03 04:34:55,671 Epoch 329: Total Training Recognition Loss 0.59  Total Training Translation Loss 14.10 
2024-02-03 04:34:55,671 EPOCH 330
2024-02-03 04:34:58,404 [Epoch: 330 Step: 00043800] Batch Recognition Loss:   0.004315 => Gls Tokens per Sec:     1260 || Batch Translation Loss:   0.072534 => Txt Tokens per Sec:     3646 || Lr: 0.000100
2024-02-03 04:35:03,593 Epoch 330: Total Training Recognition Loss 0.47  Total Training Translation Loss 19.79 
2024-02-03 04:35:03,594 EPOCH 331
2024-02-03 04:35:04,123 [Epoch: 331 Step: 00043900] Batch Recognition Loss:   0.001193 => Gls Tokens per Sec:     1513 || Batch Translation Loss:   0.599166 => Txt Tokens per Sec:     4435 || Lr: 0.000100
2024-02-03 04:35:09,563 [Epoch: 331 Step: 00044000] Batch Recognition Loss:   0.001230 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.176123 => Txt Tokens per Sec:     4086 || Lr: 0.000100
2024-02-03 04:35:20,433 Validation result at epoch 331, step    44000: duration: 10.8695s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.27934	Translation Loss: 88476.50000	PPL: 9793.74219
	Eval Metric: BLEU
	WER 3.68	(DEL: 0.07,	INS: 0.00,	SUB: 3.61)
	BLEU-4 0.55	(BLEU-1: 10.00,	BLEU-2: 3.08,	BLEU-3: 1.15,	BLEU-4: 0.55)
	CHRF 17.50	ROUGE 8.44
2024-02-03 04:35:20,434 Logging Recognition and Translation Outputs
2024-02-03 04:35:20,434 ========================================================================================================================
2024-02-03 04:35:20,434 Logging Sequence: 101_234.00
2024-02-03 04:35:20,434 	Gloss Reference :	A B+C+D+E          
2024-02-03 04:35:20,435 	Gloss Hypothesis:	A B+C+D+E+C+D+E+B+C
2024-02-03 04:35:20,435 	Gloss Alignment :	  S                
2024-02-03 04:35:20,435 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:35:20,436 	Text Reference  :	now similarly in u-19  world cup the winning runs were scored by hitting a      six   
2024-02-03 04:35:20,436 	Text Hypothesis :	*** ********* ** virat kohli is  the ******* **** **** ****** ** first   muslim player
2024-02-03 04:35:20,436 	Text Alignment  :	D   D         D  S     S     S       D       D    D    D      D  S       S      S     
2024-02-03 04:35:20,437 ========================================================================================================================
2024-02-03 04:35:20,437 Logging Sequence: 156_260.00
2024-02-03 04:35:20,437 	Gloss Reference :	A B+C+D+E
2024-02-03 04:35:20,437 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:35:20,437 	Gloss Alignment :	         
2024-02-03 04:35:20,437 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:35:20,439 	Text Reference  :	this was because of some fine batting from nicholas pooran pooran smacked an unbeaten knock of 137 runs off 55 balls and led         miny    to *** victory
2024-02-03 04:35:20,439 	Text Hypothesis :	**** *** ******* ** **** **** ******* **** ******** ****** they   would   be the      loss  of *** **** *** ** ***** the opportunity forward to abu dhabi  
2024-02-03 04:35:20,440 	Text Alignment  :	D    D   D       D  D    D    D       D    D        D      S      S       S  S        S        D   D    D   D  D     S   S           S          I   S      
2024-02-03 04:35:20,440 ========================================================================================================================
2024-02-03 04:35:20,440 Logging Sequence: 78_16.00
2024-02-03 04:35:20,440 	Gloss Reference :	A B+C+D+E
2024-02-03 04:35:20,440 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:35:20,440 	Gloss Alignment :	         
2024-02-03 04:35:20,440 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:35:20,441 	Text Reference  :	** the **** ***** ****** *** full    csk team  was    very sad   
2024-02-03 04:35:20,441 	Text Hypothesis :	in the name seems indian but whether he  never forget the  women'
2024-02-03 04:35:20,441 	Text Alignment  :	I      I    I     I      I   S       S   S     S      S    S     
2024-02-03 04:35:20,442 ========================================================================================================================
2024-02-03 04:35:20,442 Logging Sequence: 166_45.00
2024-02-03 04:35:20,442 	Gloss Reference :	A B+C+D+E
2024-02-03 04:35:20,442 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:35:20,442 	Gloss Alignment :	         
2024-02-03 04:35:20,442 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:35:20,444 	Text Reference  :	after an odi or a t20 ******* ***** match the next day  is      a  rest day
2024-02-03 04:35:20,444 	Text Hypothesis :	***** ** it  is a t20 cricket along with  the left left halfway by an   odi
2024-02-03 04:35:20,444 	Text Alignment  :	D     D  S   S        I       I     S         S    S    S       S  S    S  
2024-02-03 04:35:20,444 ========================================================================================================================
2024-02-03 04:35:20,444 Logging Sequence: 105_139.00
2024-02-03 04:35:20,444 	Gloss Reference :	A B+C+D+E
2024-02-03 04:35:20,444 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:35:20,445 	Gloss Alignment :	         
2024-02-03 04:35:20,445 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:35:20,446 	Text Reference  :	*** and now  he   has   finally achieved his   dream by      defeating carlsen
2024-02-03 04:35:20,446 	Text Hypothesis :	did you know that other than    cricket  dhoni had   allowed to        bat    
2024-02-03 04:35:20,446 	Text Alignment  :	I   S   S    S    S     S       S        S     S     S       S         S      
2024-02-03 04:35:20,446 ========================================================================================================================
2024-02-03 04:35:21,726 Epoch 331: Total Training Recognition Loss 0.48  Total Training Translation Loss 20.54 
2024-02-03 04:35:21,726 EPOCH 332
2024-02-03 04:35:26,132 [Epoch: 332 Step: 00044100] Batch Recognition Loss:   0.000904 => Gls Tokens per Sec:     1398 || Batch Translation Loss:   0.211261 => Txt Tokens per Sec:     3951 || Lr: 0.000100
2024-02-03 04:35:29,148 Epoch 332: Total Training Recognition Loss 0.48  Total Training Translation Loss 25.57 
2024-02-03 04:35:29,149 EPOCH 333
2024-02-03 04:35:31,279 [Epoch: 333 Step: 00044200] Batch Recognition Loss:   0.000407 => Gls Tokens per Sec:     1653 || Batch Translation Loss:   1.041787 => Txt Tokens per Sec:     4645 || Lr: 0.000100
2024-02-03 04:35:36,493 Epoch 333: Total Training Recognition Loss 0.93  Total Training Translation Loss 23.66 
2024-02-03 04:35:36,494 EPOCH 334
2024-02-03 04:35:37,037 [Epoch: 334 Step: 00044300] Batch Recognition Loss:   0.008031 => Gls Tokens per Sec:     1624 || Batch Translation Loss:   0.089111 => Txt Tokens per Sec:     4310 || Lr: 0.000100
2024-02-03 04:35:42,482 [Epoch: 334 Step: 00044400] Batch Recognition Loss:   0.003752 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.084298 => Txt Tokens per Sec:     4103 || Lr: 0.000100
2024-02-03 04:35:43,937 Epoch 334: Total Training Recognition Loss 0.53  Total Training Translation Loss 19.06 
2024-02-03 04:35:43,938 EPOCH 335
2024-02-03 04:35:48,509 [Epoch: 335 Step: 00044500] Batch Recognition Loss:   0.001756 => Gls Tokens per Sec:     1365 || Batch Translation Loss:   0.068092 => Txt Tokens per Sec:     3809 || Lr: 0.000100
2024-02-03 04:35:51,677 Epoch 335: Total Training Recognition Loss 0.43  Total Training Translation Loss 14.73 
2024-02-03 04:35:51,677 EPOCH 336
2024-02-03 04:35:54,158 [Epoch: 336 Step: 00044600] Batch Recognition Loss:   0.001823 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.068949 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-03 04:35:59,348 Epoch 336: Total Training Recognition Loss 0.28  Total Training Translation Loss 13.92 
2024-02-03 04:35:59,349 EPOCH 337
2024-02-03 04:36:00,071 [Epoch: 337 Step: 00044700] Batch Recognition Loss:   0.009238 => Gls Tokens per Sec:     1332 || Batch Translation Loss:   0.708257 => Txt Tokens per Sec:     3891 || Lr: 0.000100
2024-02-03 04:36:05,404 [Epoch: 337 Step: 00044800] Batch Recognition Loss:   0.000284 => Gls Tokens per Sec:     1500 || Batch Translation Loss:   0.127431 => Txt Tokens per Sec:     4140 || Lr: 0.000100
2024-02-03 04:36:06,575 Epoch 337: Total Training Recognition Loss 0.35  Total Training Translation Loss 15.26 
2024-02-03 04:36:06,575 EPOCH 338
2024-02-03 04:36:10,776 [Epoch: 338 Step: 00044900] Batch Recognition Loss:   0.000631 => Gls Tokens per Sec:     1505 || Batch Translation Loss:   0.063464 => Txt Tokens per Sec:     4236 || Lr: 0.000100
2024-02-03 04:36:13,849 Epoch 338: Total Training Recognition Loss 0.38  Total Training Translation Loss 13.09 
2024-02-03 04:36:13,850 EPOCH 339
2024-02-03 04:36:16,458 [Epoch: 339 Step: 00045000] Batch Recognition Loss:   0.001043 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.098029 => Txt Tokens per Sec:     3975 || Lr: 0.000100
2024-02-03 04:36:21,370 Epoch 339: Total Training Recognition Loss 0.39  Total Training Translation Loss 14.16 
2024-02-03 04:36:21,370 EPOCH 340
2024-02-03 04:36:22,087 [Epoch: 340 Step: 00045100] Batch Recognition Loss:   0.002169 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.062041 => Txt Tokens per Sec:     4435 || Lr: 0.000100
2024-02-03 04:36:27,502 [Epoch: 340 Step: 00045200] Batch Recognition Loss:   0.001661 => Gls Tokens per Sec:     1478 || Batch Translation Loss:   0.072324 => Txt Tokens per Sec:     4031 || Lr: 0.000100
2024-02-03 04:36:28,644 Epoch 340: Total Training Recognition Loss 0.51  Total Training Translation Loss 23.34 
2024-02-03 04:36:28,644 EPOCH 341
2024-02-03 04:36:33,014 [Epoch: 341 Step: 00045300] Batch Recognition Loss:   0.001050 => Gls Tokens per Sec:     1465 || Batch Translation Loss:   0.116720 => Txt Tokens per Sec:     4075 || Lr: 0.000100
2024-02-03 04:36:36,059 Epoch 341: Total Training Recognition Loss 1.27  Total Training Translation Loss 26.17 
2024-02-03 04:36:36,059 EPOCH 342
2024-02-03 04:36:38,704 [Epoch: 342 Step: 00045400] Batch Recognition Loss:   0.008881 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.056146 => Txt Tokens per Sec:     3897 || Lr: 0.000100
2024-02-03 04:36:43,686 Epoch 342: Total Training Recognition Loss 0.75  Total Training Translation Loss 14.71 
2024-02-03 04:36:43,687 EPOCH 343
2024-02-03 04:36:44,476 [Epoch: 343 Step: 00045500] Batch Recognition Loss:   0.004197 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.056211 => Txt Tokens per Sec:     3920 || Lr: 0.000100
2024-02-03 04:36:49,549 [Epoch: 343 Step: 00045600] Batch Recognition Loss:   0.000473 => Gls Tokens per Sec:     1577 || Batch Translation Loss:   0.266556 => Txt Tokens per Sec:     4352 || Lr: 0.000100
2024-02-03 04:36:50,844 Epoch 343: Total Training Recognition Loss 0.43  Total Training Translation Loss 12.51 
2024-02-03 04:36:50,845 EPOCH 344
2024-02-03 04:36:55,390 [Epoch: 344 Step: 00045700] Batch Recognition Loss:   0.000346 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.057665 => Txt Tokens per Sec:     3977 || Lr: 0.000100
2024-02-03 04:36:58,517 Epoch 344: Total Training Recognition Loss 0.47  Total Training Translation Loss 14.14 
2024-02-03 04:36:58,518 EPOCH 345
2024-02-03 04:37:01,112 [Epoch: 345 Step: 00045800] Batch Recognition Loss:   0.000323 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.023505 => Txt Tokens per Sec:     4136 || Lr: 0.000100
2024-02-03 04:37:05,834 Epoch 345: Total Training Recognition Loss 0.51  Total Training Translation Loss 15.46 
2024-02-03 04:37:05,835 EPOCH 346
2024-02-03 04:37:06,602 [Epoch: 346 Step: 00045900] Batch Recognition Loss:   0.051342 => Gls Tokens per Sec:     1564 || Batch Translation Loss:   0.103442 => Txt Tokens per Sec:     4754 || Lr: 0.000100
2024-02-03 04:37:12,165 [Epoch: 346 Step: 00046000] Batch Recognition Loss:   0.001042 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.050739 => Txt Tokens per Sec:     3927 || Lr: 0.000100
2024-02-03 04:37:23,011 Hooray! New best validation result [eval_metric]!
2024-02-03 04:37:23,012 Saving new checkpoint.
2024-02-03 04:37:23,301 Validation result at epoch 346, step    46000: duration: 11.1353s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.89213	Translation Loss: 87832.90625	PPL: 9160.47266
	Eval Metric: BLEU
	WER 3.47	(DEL: 0.21,	INS: 0.00,	SUB: 3.25)
	BLEU-4 0.95	(BLEU-1: 10.88,	BLEU-2: 3.50,	BLEU-3: 1.62,	BLEU-4: 0.95)
	CHRF 17.09	ROUGE 9.16
2024-02-03 04:37:23,302 Logging Recognition and Translation Outputs
2024-02-03 04:37:23,302 ========================================================================================================================
2024-02-03 04:37:23,302 Logging Sequence: 83_108.00
2024-02-03 04:37:23,303 	Gloss Reference :	A B+C+D+E
2024-02-03 04:37:23,303 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:37:23,303 	Gloss Alignment :	         
2024-02-03 04:37:23,303 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:37:23,304 	Text Reference  :	eriksen' wife sabrina  kvist jensen rushed  to  the pitch on hearing about her husband
2024-02-03 04:37:23,304 	Text Hypothesis :	viewers  in   pictures were  seen   sitting for the ***** ** umpire  but   had lost   
2024-02-03 04:37:23,304 	Text Alignment  :	S        S    S        S     S      S       S       D     D  S       S     S   S      
2024-02-03 04:37:23,305 ========================================================================================================================
2024-02-03 04:37:23,305 Logging Sequence: 171_150.00
2024-02-03 04:37:23,305 	Gloss Reference :	A B+C+D+E
2024-02-03 04:37:23,305 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:37:23,305 	Gloss Alignment :	         
2024-02-03 04:37:23,305 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:37:23,306 	Text Reference  :	as per rules players can     be  fined for purposely delaying a match which runs on a fixed schedule
2024-02-03 04:37:23,306 	Text Hypothesis :	** *** ***** we      request the media for ********* ******** * ***** ***** **** ** * 9     minutes 
2024-02-03 04:37:23,307 	Text Alignment  :	D  D   D     S       S       S   S         D         D        D D     D     D    D  D S     S       
2024-02-03 04:37:23,307 ========================================================================================================================
2024-02-03 04:37:23,307 Logging Sequence: 72_139.00
2024-02-03 04:37:23,307 	Gloss Reference :	A B+C+D+E
2024-02-03 04:37:23,307 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:37:23,307 	Gloss Alignment :	         
2024-02-03 04:37:23,307 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:37:23,309 	Text Reference  :	when shah was taking a   u-turn all  those   on the bike  got down   and  broke the    windshield of     the        car
2024-02-03 04:37:23,309 	Text Hypothesis :	**** **** *** ****** she said   that earlier in the final on  celebs like their height age        family background etc
2024-02-03 04:37:23,309 	Text Alignment  :	D    D    D   D      S   S      S    S       S      S     S   S      S    S     S      S          S      S          S  
2024-02-03 04:37:23,310 ========================================================================================================================
2024-02-03 04:37:23,310 Logging Sequence: 161_47.00
2024-02-03 04:37:23,310 	Gloss Reference :	A B+C+D+E
2024-02-03 04:37:23,310 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:37:23,310 	Gloss Alignment :	         
2024-02-03 04:37:23,310 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:37:23,311 	Text Reference  :	he requested confidentiality as he      was   planning to           make   an official announcement
2024-02-03 04:37:23,311 	Text Hypothesis :	** ********* *************** ** sanjana began her      professional career as a        model       
2024-02-03 04:37:23,311 	Text Alignment  :	D  D         D               D  S       S     S        S            S      S  S        S           
2024-02-03 04:37:23,311 ========================================================================================================================
2024-02-03 04:37:23,311 Logging Sequence: 118_284.00
2024-02-03 04:37:23,312 	Gloss Reference :	A B+C+D+E
2024-02-03 04:37:23,312 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:37:23,312 	Gloss Alignment :	         
2024-02-03 04:37:23,312 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:37:23,313 	Text Reference  :	**** ** *** the second time they won in   1986  under the leadership of diego maradona
2024-02-03 04:37:23,313 	Text Hypothesis :	when it was the first  time **** *** that there was   a   lot        of 2nd   may     
2024-02-03 04:37:23,313 	Text Alignment  :	I    I  I       S           D    D   S    S     S     S   S             S     S       
2024-02-03 04:37:23,313 ========================================================================================================================
2024-02-03 04:37:24,373 Epoch 346: Total Training Recognition Loss 0.55  Total Training Translation Loss 18.86 
2024-02-03 04:37:24,373 EPOCH 347
2024-02-03 04:37:29,079 [Epoch: 347 Step: 00046100] Batch Recognition Loss:   0.001666 => Gls Tokens per Sec:     1394 || Batch Translation Loss:   0.045830 => Txt Tokens per Sec:     3849 || Lr: 0.000100
2024-02-03 04:37:31,892 Epoch 347: Total Training Recognition Loss 0.41  Total Training Translation Loss 15.57 
2024-02-03 04:37:31,893 EPOCH 348
2024-02-03 04:37:34,513 [Epoch: 348 Step: 00046200] Batch Recognition Loss:   0.014457 => Gls Tokens per Sec:     1496 || Batch Translation Loss:   0.025720 => Txt Tokens per Sec:     4072 || Lr: 0.000100
2024-02-03 04:37:39,377 Epoch 348: Total Training Recognition Loss 0.39  Total Training Translation Loss 14.47 
2024-02-03 04:37:39,377 EPOCH 349
2024-02-03 04:37:40,297 [Epoch: 349 Step: 00046300] Batch Recognition Loss:   0.001529 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.030309 => Txt Tokens per Sec:     3907 || Lr: 0.000100
2024-02-03 04:37:45,444 [Epoch: 349 Step: 00046400] Batch Recognition Loss:   0.000927 => Gls Tokens per Sec:     1553 || Batch Translation Loss:   0.045696 => Txt Tokens per Sec:     4284 || Lr: 0.000100
2024-02-03 04:37:46,504 Epoch 349: Total Training Recognition Loss 0.53  Total Training Translation Loss 9.71 
2024-02-03 04:37:46,506 EPOCH 350
2024-02-03 04:37:51,071 [Epoch: 350 Step: 00046500] Batch Recognition Loss:   0.001259 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.034911 => Txt Tokens per Sec:     4016 || Lr: 0.000100
2024-02-03 04:37:54,371 Epoch 350: Total Training Recognition Loss 0.59  Total Training Translation Loss 9.93 
2024-02-03 04:37:54,371 EPOCH 351
2024-02-03 04:37:57,067 [Epoch: 351 Step: 00046600] Batch Recognition Loss:   0.000314 => Gls Tokens per Sec:     1485 || Batch Translation Loss:   0.048817 => Txt Tokens per Sec:     4190 || Lr: 0.000100
2024-02-03 04:38:01,864 Epoch 351: Total Training Recognition Loss 0.62  Total Training Translation Loss 15.46 
2024-02-03 04:38:01,864 EPOCH 352
2024-02-03 04:38:02,735 [Epoch: 352 Step: 00046700] Batch Recognition Loss:   0.010284 => Gls Tokens per Sec:     1562 || Batch Translation Loss:   0.016740 => Txt Tokens per Sec:     4247 || Lr: 0.000100
2024-02-03 04:38:08,562 [Epoch: 352 Step: 00046800] Batch Recognition Loss:   0.003521 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.096878 => Txt Tokens per Sec:     3821 || Lr: 0.000100
2024-02-03 04:38:09,387 Epoch 352: Total Training Recognition Loss 0.65  Total Training Translation Loss 14.22 
2024-02-03 04:38:09,387 EPOCH 353
2024-02-03 04:38:13,938 [Epoch: 353 Step: 00046900] Batch Recognition Loss:   0.002613 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.124654 => Txt Tokens per Sec:     4153 || Lr: 0.000100
2024-02-03 04:38:16,640 Epoch 353: Total Training Recognition Loss 0.41  Total Training Translation Loss 11.73 
2024-02-03 04:38:16,640 EPOCH 354
2024-02-03 04:38:19,564 [Epoch: 354 Step: 00047000] Batch Recognition Loss:   0.000966 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.186152 => Txt Tokens per Sec:     3941 || Lr: 0.000100
2024-02-03 04:38:24,456 Epoch 354: Total Training Recognition Loss 0.45  Total Training Translation Loss 21.52 
2024-02-03 04:38:24,456 EPOCH 355
2024-02-03 04:38:25,439 [Epoch: 355 Step: 00047100] Batch Recognition Loss:   0.015619 => Gls Tokens per Sec:     1468 || Batch Translation Loss:   0.030894 => Txt Tokens per Sec:     4025 || Lr: 0.000100
2024-02-03 04:38:30,773 [Epoch: 355 Step: 00047200] Batch Recognition Loss:   0.007679 => Gls Tokens per Sec:     1500 || Batch Translation Loss:   0.098385 => Txt Tokens per Sec:     4196 || Lr: 0.000100
2024-02-03 04:38:31,613 Epoch 355: Total Training Recognition Loss 0.58  Total Training Translation Loss 20.36 
2024-02-03 04:38:31,613 EPOCH 356
2024-02-03 04:38:36,387 [Epoch: 356 Step: 00047300] Batch Recognition Loss:   0.002054 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.103706 => Txt Tokens per Sec:     3991 || Lr: 0.000100
2024-02-03 04:38:39,211 Epoch 356: Total Training Recognition Loss 0.47  Total Training Translation Loss 18.40 
2024-02-03 04:38:39,212 EPOCH 357
2024-02-03 04:38:42,391 [Epoch: 357 Step: 00047400] Batch Recognition Loss:   0.001796 => Gls Tokens per Sec:     1309 || Batch Translation Loss:   0.193440 => Txt Tokens per Sec:     3676 || Lr: 0.000100
2024-02-03 04:38:46,908 Epoch 357: Total Training Recognition Loss 0.56  Total Training Translation Loss 17.60 
2024-02-03 04:38:46,908 EPOCH 358
2024-02-03 04:38:48,046 [Epoch: 358 Step: 00047500] Batch Recognition Loss:   0.007029 => Gls Tokens per Sec:     1339 || Batch Translation Loss:   0.054276 => Txt Tokens per Sec:     3942 || Lr: 0.000100
2024-02-03 04:38:53,576 [Epoch: 358 Step: 00047600] Batch Recognition Loss:   0.000626 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.221100 => Txt Tokens per Sec:     4011 || Lr: 0.000100
2024-02-03 04:38:54,300 Epoch 358: Total Training Recognition Loss 0.49  Total Training Translation Loss 11.77 
2024-02-03 04:38:54,300 EPOCH 359
2024-02-03 04:38:58,483 [Epoch: 359 Step: 00047700] Batch Recognition Loss:   0.000860 => Gls Tokens per Sec:     1645 || Batch Translation Loss:   0.030499 => Txt Tokens per Sec:     4515 || Lr: 0.000100
2024-02-03 04:39:01,343 Epoch 359: Total Training Recognition Loss 0.34  Total Training Translation Loss 9.27 
2024-02-03 04:39:01,343 EPOCH 360
2024-02-03 04:39:04,238 [Epoch: 360 Step: 00047800] Batch Recognition Loss:   0.000586 => Gls Tokens per Sec:     1465 || Batch Translation Loss:   0.072885 => Txt Tokens per Sec:     4065 || Lr: 0.000100
2024-02-03 04:39:09,006 Epoch 360: Total Training Recognition Loss 0.36  Total Training Translation Loss 11.76 
2024-02-03 04:39:09,006 EPOCH 361
2024-02-03 04:39:10,083 [Epoch: 361 Step: 00047900] Batch Recognition Loss:   0.003308 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.054526 => Txt Tokens per Sec:     4315 || Lr: 0.000100
2024-02-03 04:39:15,687 [Epoch: 361 Step: 00048000] Batch Recognition Loss:   0.000556 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.061183 => Txt Tokens per Sec:     3923 || Lr: 0.000100
2024-02-03 04:39:27,275 Validation result at epoch 361, step    48000: duration: 11.5876s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.47736	Translation Loss: 89756.92188	PPL: 11186.78906
	Eval Metric: BLEU
	WER 3.47	(DEL: 0.14,	INS: 0.00,	SUB: 3.32)
	BLEU-4 0.79	(BLEU-1: 10.49,	BLEU-2: 2.92,	BLEU-3: 1.28,	BLEU-4: 0.79)
	CHRF 17.10	ROUGE 8.50
2024-02-03 04:39:27,276 Logging Recognition and Translation Outputs
2024-02-03 04:39:27,276 ========================================================================================================================
2024-02-03 04:39:27,276 Logging Sequence: 155_56.00
2024-02-03 04:39:27,276 	Gloss Reference :	A B+C+D+E
2024-02-03 04:39:27,277 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:39:27,277 	Gloss Alignment :	         
2024-02-03 04:39:27,277 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:39:27,278 	Text Reference  :	*** **** the ***** ******* *** *** *** ***** team   would have  been disqualified
2024-02-03 04:39:27,278 	Text Hypothesis :	she lost the match because she was not their father and   uncle are  wrestlers   
2024-02-03 04:39:27,278 	Text Alignment  :	I   I        I     I       I   I   I   I     S      S     S     S    S           
2024-02-03 04:39:27,278 ========================================================================================================================
2024-02-03 04:39:27,278 Logging Sequence: 161_170.00
2024-02-03 04:39:27,278 	Gloss Reference :	A B+C+D+E
2024-02-03 04:39:27,278 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:39:27,279 	Gloss Alignment :	         
2024-02-03 04:39:27,279 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:39:27,281 	Text Reference  :	** however when the  bcci  replaced    him     with rohit sharma he     decided to  step      down as   test captain as well
2024-02-03 04:39:27,281 	Text Hypothesis :	he owns    a    bike named confederate hellcat x132 which was    bought by      the cricketer in   2018 for  rs      27 lakh
2024-02-03 04:39:27,281 	Text Alignment  :	I  S       S    S    S     S           S       S    S     S      S      S       S   S         S    S    S    S       S  S   
2024-02-03 04:39:27,281 ========================================================================================================================
2024-02-03 04:39:27,281 Logging Sequence: 88_13.00
2024-02-03 04:39:27,282 	Gloss Reference :	A B+C+D+E
2024-02-03 04:39:27,282 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:39:27,282 	Gloss Alignment :	         
2024-02-03 04:39:27,282 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:39:27,283 	Text Reference  :	while his fans were elated by  the victory   there were     some who are  jealous and want to   kill messi
2024-02-03 04:39:27,284 	Text Hypothesis :	***** *** **** **** ****** but the argentina team  recently won  the fifa world   cup 2022 held in   qatar
2024-02-03 04:39:27,284 	Text Alignment  :	D     D   D    D    D      S       S         S     S        S    S   S    S       S   S    S    S    S    
2024-02-03 04:39:27,284 ========================================================================================================================
2024-02-03 04:39:27,284 Logging Sequence: 103_25.00
2024-02-03 04:39:27,284 	Gloss Reference :	A B+C+D+E
2024-02-03 04:39:27,284 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:39:27,284 	Gloss Alignment :	         
2024-02-03 04:39:27,284 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:39:27,286 	Text Reference  :	****** *** earlier   ish          news  had    released  a  video       when india had    won 6 medals  
2024-02-03 04:39:27,286 	Text Hypothesis :	amidst the financial transactions rhiti sports complaint of non-payment of   dues  sakshi is  a director
2024-02-03 04:39:27,286 	Text Alignment  :	I      I   S         S            S     S      S         S  S           S    S     S      S   S S       
2024-02-03 04:39:27,286 ========================================================================================================================
2024-02-03 04:39:27,286 Logging Sequence: 85_36.00
2024-02-03 04:39:27,286 	Gloss Reference :	A B+C+D+E
2024-02-03 04:39:27,286 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:39:27,286 	Gloss Alignment :	         
2024-02-03 04:39:27,287 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:39:27,287 	Text Reference  :	symonds has scored 2 centuries in 26  tests that    he  played for his country       
2024-02-03 04:39:27,288 	Text Hypothesis :	******* *** ****** * ********* in his 142   matches for odi    and t20 internationals
2024-02-03 04:39:27,288 	Text Alignment  :	D       D   D      D D            S   S     S       S   S      S   S   S             
2024-02-03 04:39:27,288 ========================================================================================================================
2024-02-03 04:39:28,030 Epoch 361: Total Training Recognition Loss 0.60  Total Training Translation Loss 17.59 
2024-02-03 04:39:28,030 EPOCH 362
2024-02-03 04:39:32,628 [Epoch: 362 Step: 00048100] Batch Recognition Loss:   0.000862 => Gls Tokens per Sec:     1514 || Batch Translation Loss:   0.061546 => Txt Tokens per Sec:     4188 || Lr: 0.000100
2024-02-03 04:39:35,398 Epoch 362: Total Training Recognition Loss 0.48  Total Training Translation Loss 24.19 
2024-02-03 04:39:35,399 EPOCH 363
2024-02-03 04:39:38,325 [Epoch: 363 Step: 00048200] Batch Recognition Loss:   0.000381 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.101350 => Txt Tokens per Sec:     3996 || Lr: 0.000100
2024-02-03 04:39:43,205 Epoch 363: Total Training Recognition Loss 0.62  Total Training Translation Loss 28.74 
2024-02-03 04:39:43,206 EPOCH 364
2024-02-03 04:39:44,534 [Epoch: 364 Step: 00048300] Batch Recognition Loss:   0.009359 => Gls Tokens per Sec:     1266 || Batch Translation Loss:   0.128687 => Txt Tokens per Sec:     3515 || Lr: 0.000100
2024-02-03 04:39:50,328 [Epoch: 364 Step: 00048400] Batch Recognition Loss:   0.001407 => Gls Tokens per Sec:     1381 || Batch Translation Loss:   0.076979 => Txt Tokens per Sec:     3834 || Lr: 0.000100
2024-02-03 04:39:51,060 Epoch 364: Total Training Recognition Loss 0.48  Total Training Translation Loss 18.24 
2024-02-03 04:39:51,060 EPOCH 365
2024-02-03 04:39:55,840 [Epoch: 365 Step: 00048500] Batch Recognition Loss:   0.002049 => Gls Tokens per Sec:     1473 || Batch Translation Loss:   0.049510 => Txt Tokens per Sec:     4043 || Lr: 0.000100
2024-02-03 04:39:58,698 Epoch 365: Total Training Recognition Loss 0.33  Total Training Translation Loss 16.78 
2024-02-03 04:39:58,698 EPOCH 366
2024-02-03 04:40:01,791 [Epoch: 366 Step: 00048600] Batch Recognition Loss:   0.000990 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.043039 => Txt Tokens per Sec:     3829 || Lr: 0.000100
2024-02-03 04:40:06,407 Epoch 366: Total Training Recognition Loss 0.44  Total Training Translation Loss 9.38 
2024-02-03 04:40:06,407 EPOCH 367
2024-02-03 04:40:07,791 [Epoch: 367 Step: 00048700] Batch Recognition Loss:   0.000727 => Gls Tokens per Sec:     1273 || Batch Translation Loss:   0.017775 => Txt Tokens per Sec:     3734 || Lr: 0.000100
2024-02-03 04:40:13,261 [Epoch: 367 Step: 00048800] Batch Recognition Loss:   0.000661 => Gls Tokens per Sec:     1461 || Batch Translation Loss:   0.065940 => Txt Tokens per Sec:     4023 || Lr: 0.000100
2024-02-03 04:40:13,863 Epoch 367: Total Training Recognition Loss 0.39  Total Training Translation Loss 12.80 
2024-02-03 04:40:13,863 EPOCH 368
2024-02-03 04:40:18,685 [Epoch: 368 Step: 00048900] Batch Recognition Loss:   0.000550 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.057813 => Txt Tokens per Sec:     4089 || Lr: 0.000100
2024-02-03 04:40:21,367 Epoch 368: Total Training Recognition Loss 0.30  Total Training Translation Loss 13.89 
2024-02-03 04:40:21,367 EPOCH 369
2024-02-03 04:40:24,492 [Epoch: 369 Step: 00049000] Batch Recognition Loss:   0.001810 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.813577 => Txt Tokens per Sec:     4004 || Lr: 0.000100
2024-02-03 04:40:29,188 Epoch 369: Total Training Recognition Loss 0.27  Total Training Translation Loss 15.30 
2024-02-03 04:40:29,188 EPOCH 370
2024-02-03 04:40:30,410 [Epoch: 370 Step: 00049100] Batch Recognition Loss:   0.000505 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.067380 => Txt Tokens per Sec:     4126 || Lr: 0.000100
2024-02-03 04:40:35,920 [Epoch: 370 Step: 00049200] Batch Recognition Loss:   0.001310 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.688104 => Txt Tokens per Sec:     4055 || Lr: 0.000100
2024-02-03 04:40:36,575 Epoch 370: Total Training Recognition Loss 0.40  Total Training Translation Loss 18.13 
2024-02-03 04:40:36,576 EPOCH 371
2024-02-03 04:40:41,548 [Epoch: 371 Step: 00049300] Batch Recognition Loss:   0.001513 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.234549 => Txt Tokens per Sec:     4010 || Lr: 0.000100
2024-02-03 04:40:43,959 Epoch 371: Total Training Recognition Loss 0.48  Total Training Translation Loss 19.81 
2024-02-03 04:40:43,959 EPOCH 372
2024-02-03 04:40:47,088 [Epoch: 372 Step: 00049400] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.028214 => Txt Tokens per Sec:     3961 || Lr: 0.000100
2024-02-03 04:40:51,681 Epoch 372: Total Training Recognition Loss 0.57  Total Training Translation Loss 17.87 
2024-02-03 04:40:51,682 EPOCH 373
2024-02-03 04:40:53,069 [Epoch: 373 Step: 00049500] Batch Recognition Loss:   0.004933 => Gls Tokens per Sec:     1385 || Batch Translation Loss:   0.094399 => Txt Tokens per Sec:     3966 || Lr: 0.000100
2024-02-03 04:40:58,629 [Epoch: 373 Step: 00049600] Batch Recognition Loss:   0.001228 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.048618 => Txt Tokens per Sec:     3986 || Lr: 0.000100
2024-02-03 04:40:59,175 Epoch 373: Total Training Recognition Loss 0.43  Total Training Translation Loss 17.92 
2024-02-03 04:40:59,175 EPOCH 374
2024-02-03 04:41:03,614 [Epoch: 374 Step: 00049700] Batch Recognition Loss:   0.000399 => Gls Tokens per Sec:     1640 || Batch Translation Loss:   0.052268 => Txt Tokens per Sec:     4547 || Lr: 0.000100
2024-02-03 04:41:05,850 Epoch 374: Total Training Recognition Loss 0.46  Total Training Translation Loss 16.49 
2024-02-03 04:41:05,851 EPOCH 375
2024-02-03 04:41:09,061 [Epoch: 375 Step: 00049800] Batch Recognition Loss:   0.000121 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.014015 => Txt Tokens per Sec:     3991 || Lr: 0.000100
2024-02-03 04:41:13,552 Epoch 375: Total Training Recognition Loss 0.40  Total Training Translation Loss 11.76 
2024-02-03 04:41:13,552 EPOCH 376
2024-02-03 04:41:14,907 [Epoch: 376 Step: 00049900] Batch Recognition Loss:   0.001109 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.068570 => Txt Tokens per Sec:     4165 || Lr: 0.000100
2024-02-03 04:41:20,537 [Epoch: 376 Step: 00050000] Batch Recognition Loss:   0.000513 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.028191 => Txt Tokens per Sec:     3913 || Lr: 0.000100
2024-02-03 04:41:31,975 Validation result at epoch 376, step    50000: duration: 11.4365s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.20014	Translation Loss: 88730.83594	PPL: 10055.90918
	Eval Metric: BLEU
	WER 3.39	(DEL: 0.07,	INS: 0.00,	SUB: 3.32)
	BLEU-4 0.57	(BLEU-1: 10.76,	BLEU-2: 3.26,	BLEU-3: 1.22,	BLEU-4: 0.57)
	CHRF 16.88	ROUGE 8.94
2024-02-03 04:41:31,976 Logging Recognition and Translation Outputs
2024-02-03 04:41:31,977 ========================================================================================================================
2024-02-03 04:41:31,977 Logging Sequence: 154_33.00
2024-02-03 04:41:31,977 	Gloss Reference :	A B+C+D+E
2024-02-03 04:41:31,977 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:41:31,977 	Gloss Alignment :	         
2024-02-03 04:41:31,977 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:41:31,978 	Text Reference  :	******* ** the t20 world cup      will   now be held     in uae oman    
2024-02-03 04:41:31,978 	Text Hypothesis :	because of the *** covid pandemic people are at stressed at the olympics
2024-02-03 04:41:31,978 	Text Alignment  :	I       I      D   S     S        S      S   S  S        S  S   S       
2024-02-03 04:41:31,979 ========================================================================================================================
2024-02-03 04:41:31,979 Logging Sequence: 155_56.00
2024-02-03 04:41:31,979 	Gloss Reference :	A B+C+D+E
2024-02-03 04:41:31,979 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:41:31,979 	Gloss Alignment :	         
2024-02-03 04:41:31,979 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:41:31,980 	Text Reference  :	*** **** the ***** *** ****** ** team would have been   disqualified
2024-02-03 04:41:31,980 	Text Hypothesis :	she lost the match and wanted to work for   the  second home        
2024-02-03 04:41:31,980 	Text Alignment  :	I   I        I     I   I      I  S    S     S    S      S           
2024-02-03 04:41:31,980 ========================================================================================================================
2024-02-03 04:41:31,980 Logging Sequence: 125_119.00
2024-02-03 04:41:31,981 	Gloss Reference :	A B+C+D+E
2024-02-03 04:41:31,981 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:41:31,981 	Gloss Alignment :	         
2024-02-03 04:41:31,981 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:41:31,982 	Text Reference  :	people must  not post  such   baseless comments on social media   
2024-02-03 04:41:31,982 	Text Hypothesis :	****** after the match yuvraj was      taken    to the    hospital
2024-02-03 04:41:31,982 	Text Alignment  :	D      S     S   S     S      S        S        S  S      S       
2024-02-03 04:41:31,982 ========================================================================================================================
2024-02-03 04:41:31,982 Logging Sequence: 59_152.00
2024-02-03 04:41:31,982 	Gloss Reference :	A B+C+D+E
2024-02-03 04:41:31,982 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:41:31,982 	Gloss Alignment :	         
2024-02-03 04:41:31,983 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:41:31,984 	Text Reference  :	the organisers encouraged athletes to ***** * **** **** *** * use      the condoms in their home countries
2024-02-03 04:41:31,984 	Text Hypothesis :	*** once       she        returns  to india i will give you a suitable job as      a  token of   gratitude
2024-02-03 04:41:31,984 	Text Alignment  :	D   S          S          S           I     I I    I    I   I S        S   S       S  S     S    S        
2024-02-03 04:41:31,984 ========================================================================================================================
2024-02-03 04:41:31,984 Logging Sequence: 151_94.00
2024-02-03 04:41:31,985 	Gloss Reference :	A B+C+D+E
2024-02-03 04:41:31,985 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:41:31,985 	Gloss Alignment :	         
2024-02-03 04:41:31,985 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:41:31,986 	Text Reference  :	suresh raina was also known as mr ipl for his amazing    performance in the tournament
2024-02-03 04:41:31,986 	Text Hypothesis :	****** ***** *** **** ***** as ** *** he  was eventually kept        in ipl 2021      
2024-02-03 04:41:31,986 	Text Alignment  :	D      D     D   D    D        D  D   S   S   S          S              S   S         
2024-02-03 04:41:31,986 ========================================================================================================================
2024-02-03 04:41:32,406 Epoch 376: Total Training Recognition Loss 0.33  Total Training Translation Loss 13.01 
2024-02-03 04:41:32,406 EPOCH 377
2024-02-03 04:41:37,407 [Epoch: 377 Step: 00050100] Batch Recognition Loss:   0.000952 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.140395 => Txt Tokens per Sec:     4142 || Lr: 0.000100
2024-02-03 04:41:39,860 Epoch 377: Total Training Recognition Loss 0.53  Total Training Translation Loss 15.68 
2024-02-03 04:41:39,860 EPOCH 378
2024-02-03 04:41:43,357 [Epoch: 378 Step: 00050200] Batch Recognition Loss:   0.038053 => Gls Tokens per Sec:     1350 || Batch Translation Loss:   0.008371 => Txt Tokens per Sec:     3726 || Lr: 0.000100
2024-02-03 04:41:47,644 Epoch 378: Total Training Recognition Loss 0.37  Total Training Translation Loss 17.86 
2024-02-03 04:41:47,644 EPOCH 379
2024-02-03 04:41:49,084 [Epoch: 379 Step: 00050300] Batch Recognition Loss:   0.000560 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.210457 => Txt Tokens per Sec:     4219 || Lr: 0.000100
2024-02-03 04:41:54,633 [Epoch: 379 Step: 00050400] Batch Recognition Loss:   0.000646 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.094708 => Txt Tokens per Sec:     3951 || Lr: 0.000100
2024-02-03 04:41:54,998 Epoch 379: Total Training Recognition Loss 0.30  Total Training Translation Loss 17.78 
2024-02-03 04:41:54,998 EPOCH 380
2024-02-03 04:42:00,050 [Epoch: 380 Step: 00050500] Batch Recognition Loss:   0.001751 => Gls Tokens per Sec:     1473 || Batch Translation Loss:   0.658303 => Txt Tokens per Sec:     4073 || Lr: 0.000100
2024-02-03 04:42:02,356 Epoch 380: Total Training Recognition Loss 0.49  Total Training Translation Loss 16.39 
2024-02-03 04:42:02,357 EPOCH 381
2024-02-03 04:42:05,551 [Epoch: 381 Step: 00050600] Batch Recognition Loss:   0.002627 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.010076 => Txt Tokens per Sec:     4207 || Lr: 0.000100
2024-02-03 04:42:10,055 Epoch 381: Total Training Recognition Loss 0.41  Total Training Translation Loss 17.61 
2024-02-03 04:42:10,056 EPOCH 382
2024-02-03 04:42:11,498 [Epoch: 382 Step: 00050700] Batch Recognition Loss:   0.001125 => Gls Tokens per Sec:     1498 || Batch Translation Loss:   0.077103 => Txt Tokens per Sec:     3864 || Lr: 0.000100
2024-02-03 04:42:17,266 [Epoch: 382 Step: 00050800] Batch Recognition Loss:   0.003285 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.012096 => Txt Tokens per Sec:     3927 || Lr: 0.000100
2024-02-03 04:42:17,588 Epoch 382: Total Training Recognition Loss 0.29  Total Training Translation Loss 11.38 
2024-02-03 04:42:17,588 EPOCH 383
2024-02-03 04:42:22,828 [Epoch: 383 Step: 00050900] Batch Recognition Loss:   0.001862 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.089736 => Txt Tokens per Sec:     3970 || Lr: 0.000100
2024-02-03 04:42:25,091 Epoch 383: Total Training Recognition Loss 0.48  Total Training Translation Loss 11.57 
2024-02-03 04:42:25,092 EPOCH 384
2024-02-03 04:42:28,524 [Epoch: 384 Step: 00051000] Batch Recognition Loss:   0.001159 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.486966 => Txt Tokens per Sec:     3920 || Lr: 0.000100
2024-02-03 04:42:32,872 Epoch 384: Total Training Recognition Loss 0.54  Total Training Translation Loss 14.27 
2024-02-03 04:42:32,873 EPOCH 385
2024-02-03 04:42:34,521 [Epoch: 385 Step: 00051100] Batch Recognition Loss:   0.003415 => Gls Tokens per Sec:     1360 || Batch Translation Loss:   0.024325 => Txt Tokens per Sec:     3850 || Lr: 0.000100
2024-02-03 04:42:40,179 [Epoch: 385 Step: 00051200] Batch Recognition Loss:   0.006914 => Gls Tokens per Sec:     1412 || Batch Translation Loss:   0.070766 => Txt Tokens per Sec:     3918 || Lr: 0.000100
2024-02-03 04:42:40,408 Epoch 385: Total Training Recognition Loss 0.38  Total Training Translation Loss 11.78 
2024-02-03 04:42:40,409 EPOCH 386
2024-02-03 04:42:45,170 [Epoch: 386 Step: 00051300] Batch Recognition Loss:   0.000707 => Gls Tokens per Sec:     1597 || Batch Translation Loss:   0.046408 => Txt Tokens per Sec:     4408 || Lr: 0.000100
2024-02-03 04:42:47,372 Epoch 386: Total Training Recognition Loss 0.58  Total Training Translation Loss 13.45 
2024-02-03 04:42:47,372 EPOCH 387
2024-02-03 04:42:50,761 [Epoch: 387 Step: 00051400] Batch Recognition Loss:   0.009494 => Gls Tokens per Sec:     1464 || Batch Translation Loss:   0.354305 => Txt Tokens per Sec:     4154 || Lr: 0.000100
2024-02-03 04:42:54,973 Epoch 387: Total Training Recognition Loss 0.34  Total Training Translation Loss 13.77 
2024-02-03 04:42:54,974 EPOCH 388
2024-02-03 04:42:56,446 [Epoch: 388 Step: 00051500] Batch Recognition Loss:   0.001713 => Gls Tokens per Sec:     1578 || Batch Translation Loss:   0.051672 => Txt Tokens per Sec:     4505 || Lr: 0.000100
2024-02-03 04:43:01,886 [Epoch: 388 Step: 00051600] Batch Recognition Loss:   0.039182 => Gls Tokens per Sec:     1469 || Batch Translation Loss:   0.046462 => Txt Tokens per Sec:     4047 || Lr: 0.000100
2024-02-03 04:43:02,130 Epoch 388: Total Training Recognition Loss 4.25  Total Training Translation Loss 16.60 
2024-02-03 04:43:02,130 EPOCH 389
2024-02-03 04:43:07,358 [Epoch: 389 Step: 00051700] Batch Recognition Loss:   0.021207 => Gls Tokens per Sec:     1469 || Batch Translation Loss:   0.199474 => Txt Tokens per Sec:     4103 || Lr: 0.000100
2024-02-03 04:43:09,404 Epoch 389: Total Training Recognition Loss 28.59  Total Training Translation Loss 32.13 
2024-02-03 04:43:09,405 EPOCH 390
2024-02-03 04:43:13,179 [Epoch: 390 Step: 00051800] Batch Recognition Loss:   0.001171 => Gls Tokens per Sec:     1335 || Batch Translation Loss:   0.101950 => Txt Tokens per Sec:     3707 || Lr: 0.000100
2024-02-03 04:43:17,195 Epoch 390: Total Training Recognition Loss 3.30  Total Training Translation Loss 20.80 
2024-02-03 04:43:17,195 EPOCH 391
2024-02-03 04:43:18,788 [Epoch: 391 Step: 00051900] Batch Recognition Loss:   0.000922 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.135630 => Txt Tokens per Sec:     4020 || Lr: 0.000100
2024-02-03 04:43:24,155 [Epoch: 391 Step: 00052000] Batch Recognition Loss:   0.007081 => Gls Tokens per Sec:     1491 || Batch Translation Loss:   0.061997 => Txt Tokens per Sec:     4188 || Lr: 0.000100
2024-02-03 04:43:35,210 Validation result at epoch 391, step    52000: duration: 11.0548s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.55337	Translation Loss: 88664.80469	PPL: 9987.17383
	Eval Metric: BLEU
	WER 3.32	(DEL: 0.07,	INS: 0.00,	SUB: 3.25)
	BLEU-4 0.51	(BLEU-1: 9.39,	BLEU-2: 2.54,	BLEU-3: 0.97,	BLEU-4: 0.51)
	CHRF 16.93	ROUGE 8.09
2024-02-03 04:43:35,211 Logging Recognition and Translation Outputs
2024-02-03 04:43:35,212 ========================================================================================================================
2024-02-03 04:43:35,212 Logging Sequence: 84_206.00
2024-02-03 04:43:35,212 	Gloss Reference :	A B+C+D+E
2024-02-03 04:43:35,212 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:43:35,212 	Gloss Alignment :	         
2024-02-03 04:43:35,212 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:43:35,214 	Text Reference  :	football fans in t he stadium too agreed with   the players and wished to      support the lgbtqia community
2024-02-03 04:43:35,214 	Text Hypothesis :	******** **** ** * ** ******* *** ****** fifa's ban was     a   huge   mistake it      was bad     decision 
2024-02-03 04:43:35,214 	Text Alignment  :	D        D    D  D D  D       D   D      S      S   S       S   S      S       S       S   S       S        
2024-02-03 04:43:35,214 ========================================================================================================================
2024-02-03 04:43:35,214 Logging Sequence: 126_263.00
2024-02-03 04:43:35,214 	Gloss Reference :	A B+C+D+E
2024-02-03 04:43:35,214 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:43:35,215 	Gloss Alignment :	         
2024-02-03 04:43:35,215 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:43:35,216 	Text Reference  :	indian airline indigo has announced unlimited free year      travel for   the gold medalist
2024-02-03 04:43:35,216 	Text Hypothesis :	****** ******* he     has named     his       gold wrestling 65kg   final on  7th  august  
2024-02-03 04:43:35,216 	Text Alignment  :	D      D       S          S         S         S    S         S      S     S   S    S       
2024-02-03 04:43:35,216 ========================================================================================================================
2024-02-03 04:43:35,216 Logging Sequence: 93_11.00
2024-02-03 04:43:35,216 	Gloss Reference :	A B+C+D+E
2024-02-03 04:43:35,216 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:43:35,216 	Gloss Alignment :	         
2024-02-03 04:43:35,217 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:43:35,217 	Text Reference  :	he also  played  for     the     manchester united football team   
2024-02-03 04:43:35,217 	Text Hypothesis :	** after surgery doctors cleared him        to     resume   cricket
2024-02-03 04:43:35,217 	Text Alignment  :	D  S     S       S       S       S          S      S        S      
2024-02-03 04:43:35,218 ========================================================================================================================
2024-02-03 04:43:35,218 Logging Sequence: 155_62.00
2024-02-03 04:43:35,218 	Gloss Reference :	A B+C+D+E
2024-02-03 04:43:35,218 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:43:35,218 	Gloss Alignment :	         
2024-02-03 04:43:35,218 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:43:35,221 	Text Reference  :	however they were fortunate that the      icc had drafted the match schedule well in advance  with the afghan team in   the  tournament
2024-02-03 04:43:35,221 	Text Hypothesis :	******* **** i    am        very thankful to  my  father  and icc   also     been an outbreak of   tv  and    icc  also been odis      
2024-02-03 04:43:35,221 	Text Alignment  :	D       D    S    S         S    S        S   S   S       S   S     S        S    S  S        S    S   S      S    S    S    S         
2024-02-03 04:43:35,221 ========================================================================================================================
2024-02-03 04:43:35,221 Logging Sequence: 93_267.00
2024-02-03 04:43:35,221 	Gloss Reference :	A B+C+D+E
2024-02-03 04:43:35,222 	Gloss Hypothesis:	A B      
2024-02-03 04:43:35,222 	Gloss Alignment :	  S      
2024-02-03 04:43:35,222 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:43:35,224 	Text Reference  :	one girl who       was  wearing a thong flashed her      bottom next  to   rooney the image went    viral on   snapchat
2024-02-03 04:43:35,224 	Text Hypothesis :	and they confirmed they had     a great time    spending the    night with rooney *** but   refused to    give them    
2024-02-03 04:43:35,224 	Text Alignment  :	S   S    S         S    S         S     S       S        S      S     S           D   S     S       S     S    S       
2024-02-03 04:43:35,224 ========================================================================================================================
2024-02-03 04:43:35,503 Epoch 391: Total Training Recognition Loss 1.17  Total Training Translation Loss 13.41 
2024-02-03 04:43:35,503 EPOCH 392
2024-02-03 04:43:40,839 [Epoch: 392 Step: 00052100] Batch Recognition Loss:   0.001167 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.039016 => Txt Tokens per Sec:     4102 || Lr: 0.000100
2024-02-03 04:43:42,890 Epoch 392: Total Training Recognition Loss 0.69  Total Training Translation Loss 8.34 
2024-02-03 04:43:42,891 EPOCH 393
2024-02-03 04:43:46,556 [Epoch: 393 Step: 00052200] Batch Recognition Loss:   0.000336 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.026081 => Txt Tokens per Sec:     3892 || Lr: 0.000100
2024-02-03 04:43:50,635 Epoch 393: Total Training Recognition Loss 0.38  Total Training Translation Loss 6.92 
2024-02-03 04:43:50,635 EPOCH 394
2024-02-03 04:43:52,307 [Epoch: 394 Step: 00052300] Batch Recognition Loss:   0.004005 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.034504 => Txt Tokens per Sec:     4048 || Lr: 0.000100
2024-02-03 04:43:57,263 [Epoch: 394 Step: 00052400] Batch Recognition Loss:   0.000997 => Gls Tokens per Sec:     1612 || Batch Translation Loss:   0.028857 => Txt Tokens per Sec:     4502 || Lr: 0.000100
2024-02-03 04:43:57,352 Epoch 394: Total Training Recognition Loss 0.37  Total Training Translation Loss 6.51 
2024-02-03 04:43:57,353 EPOCH 395
2024-02-03 04:44:02,834 [Epoch: 395 Step: 00052500] Batch Recognition Loss:   0.000442 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.022302 => Txt Tokens per Sec:     3997 || Lr: 0.000100
2024-02-03 04:44:04,881 Epoch 395: Total Training Recognition Loss 0.29  Total Training Translation Loss 6.89 
2024-02-03 04:44:04,881 EPOCH 396
2024-02-03 04:44:08,414 [Epoch: 396 Step: 00052600] Batch Recognition Loss:   0.001308 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.061267 => Txt Tokens per Sec:     3985 || Lr: 0.000100
2024-02-03 04:44:12,525 Epoch 396: Total Training Recognition Loss 0.26  Total Training Translation Loss 7.86 
2024-02-03 04:44:12,526 EPOCH 397
2024-02-03 04:44:14,051 [Epoch: 397 Step: 00052700] Batch Recognition Loss:   0.001617 => Gls Tokens per Sec:     1679 || Batch Translation Loss:   0.242276 => Txt Tokens per Sec:     4577 || Lr: 0.000100
2024-02-03 04:44:19,710 [Epoch: 397 Step: 00052800] Batch Recognition Loss:   0.010964 => Gls Tokens per Sec:     1412 || Batch Translation Loss:   0.112374 => Txt Tokens per Sec:     3959 || Lr: 0.000100
2024-02-03 04:44:19,751 Epoch 397: Total Training Recognition Loss 0.44  Total Training Translation Loss 14.40 
2024-02-03 04:44:19,751 EPOCH 398
2024-02-03 04:44:24,818 [Epoch: 398 Step: 00052900] Batch Recognition Loss:   0.000390 => Gls Tokens per Sec:     1564 || Batch Translation Loss:   0.122266 => Txt Tokens per Sec:     4360 || Lr: 0.000100
2024-02-03 04:44:26,709 Epoch 398: Total Training Recognition Loss 0.37  Total Training Translation Loss 20.80 
2024-02-03 04:44:26,709 EPOCH 399
2024-02-03 04:44:30,912 [Epoch: 399 Step: 00053000] Batch Recognition Loss:   0.009771 => Gls Tokens per Sec:     1257 || Batch Translation Loss:   0.059367 => Txt Tokens per Sec:     3521 || Lr: 0.000100
2024-02-03 04:44:34,551 Epoch 399: Total Training Recognition Loss 0.58  Total Training Translation Loss 37.19 
2024-02-03 04:44:34,551 EPOCH 400
2024-02-03 04:44:36,467 [Epoch: 400 Step: 00053100] Batch Recognition Loss:   0.001251 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.097573 => Txt Tokens per Sec:     3891 || Lr: 0.000100
2024-02-03 04:44:41,845 [Epoch: 400 Step: 00053200] Batch Recognition Loss:   0.000393 => Gls Tokens per Sec:     1486 || Batch Translation Loss:   0.456362 => Txt Tokens per Sec:     4112 || Lr: 0.000100
2024-02-03 04:44:41,846 Epoch 400: Total Training Recognition Loss 0.57  Total Training Translation Loss 19.86 
2024-02-03 04:44:41,846 EPOCH 401
2024-02-03 04:44:47,355 [Epoch: 401 Step: 00053300] Batch Recognition Loss:   0.000454 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.033221 => Txt Tokens per Sec:     4053 || Lr: 0.000100
2024-02-03 04:44:49,207 Epoch 401: Total Training Recognition Loss 0.42  Total Training Translation Loss 11.40 
2024-02-03 04:44:49,207 EPOCH 402
2024-02-03 04:44:52,670 [Epoch: 402 Step: 00053400] Batch Recognition Loss:   0.002035 => Gls Tokens per Sec:     1548 || Batch Translation Loss:   0.071790 => Txt Tokens per Sec:     4245 || Lr: 0.000100
2024-02-03 04:44:56,830 Epoch 402: Total Training Recognition Loss 0.33  Total Training Translation Loss 9.83 
2024-02-03 04:44:56,830 EPOCH 403
2024-02-03 04:44:58,696 [Epoch: 403 Step: 00053500] Batch Recognition Loss:   0.000176 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.021646 => Txt Tokens per Sec:     3888 || Lr: 0.000100
2024-02-03 04:45:04,264 Epoch 403: Total Training Recognition Loss 0.27  Total Training Translation Loss 8.18 
2024-02-03 04:45:04,265 EPOCH 404
2024-02-03 04:45:04,315 [Epoch: 404 Step: 00053600] Batch Recognition Loss:   0.001371 => Gls Tokens per Sec:     1633 || Batch Translation Loss:   0.038492 => Txt Tokens per Sec:     4878 || Lr: 0.000100
2024-02-03 04:45:09,741 [Epoch: 404 Step: 00053700] Batch Recognition Loss:   0.000256 => Gls Tokens per Sec:     1474 || Batch Translation Loss:   0.061673 => Txt Tokens per Sec:     4111 || Lr: 0.000100
2024-02-03 04:45:11,614 Epoch 404: Total Training Recognition Loss 0.32  Total Training Translation Loss 11.32 
2024-02-03 04:45:11,614 EPOCH 405
2024-02-03 04:45:15,314 [Epoch: 405 Step: 00053800] Batch Recognition Loss:   0.000501 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.042868 => Txt Tokens per Sec:     4085 || Lr: 0.000100
2024-02-03 04:45:19,088 Epoch 405: Total Training Recognition Loss 0.41  Total Training Translation Loss 15.25 
2024-02-03 04:45:19,088 EPOCH 406
2024-02-03 04:45:20,999 [Epoch: 406 Step: 00053900] Batch Recognition Loss:   0.015081 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   0.076958 => Txt Tokens per Sec:     4094 || Lr: 0.000100
2024-02-03 04:45:26,538 Epoch 406: Total Training Recognition Loss 0.28  Total Training Translation Loss 17.70 
2024-02-03 04:45:26,539 EPOCH 407
2024-02-03 04:45:26,626 [Epoch: 407 Step: 00054000] Batch Recognition Loss:   0.000210 => Gls Tokens per Sec:     1860 || Batch Translation Loss:   0.031478 => Txt Tokens per Sec:     4663 || Lr: 0.000100
2024-02-03 04:45:37,637 Validation result at epoch 407, step    54000: duration: 11.0107s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.54005	Translation Loss: 88399.86719	PPL: 9716.09961
	Eval Metric: BLEU
	WER 3.47	(DEL: 0.07,	INS: 0.00,	SUB: 3.39)
	BLEU-4 0.47	(BLEU-1: 9.37,	BLEU-2: 2.64,	BLEU-3: 1.04,	BLEU-4: 0.47)
	CHRF 16.43	ROUGE 8.08
2024-02-03 04:45:37,638 Logging Recognition and Translation Outputs
2024-02-03 04:45:37,638 ========================================================================================================================
2024-02-03 04:45:37,638 Logging Sequence: 77_140.00
2024-02-03 04:45:37,638 	Gloss Reference :	A B+C+D+E
2024-02-03 04:45:37,638 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:45:37,639 	Gloss Alignment :	         
2024-02-03 04:45:37,639 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:45:37,639 	Text Reference  :	he was up against chennai's   ravindra  jadeja who  hit multiple    sixes       
2024-02-03 04:45:37,640 	Text Hypothesis :	** *** ** royal   challengers bangalore pm     that an  interesting superstition
2024-02-03 04:45:37,640 	Text Alignment  :	D  D   D  S       S           S         S      S    S   S           S           
2024-02-03 04:45:37,640 ========================================================================================================================
2024-02-03 04:45:37,640 Logging Sequence: 100_78.00
2024-02-03 04:45:37,640 	Gloss Reference :	A B+C+D+E
2024-02-03 04:45:37,640 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:45:37,640 	Gloss Alignment :	         
2024-02-03 04:45:37,640 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:45:37,641 	Text Reference  :	***** bcci  had sent two separate indian teams to compete in the    cwg and          the     sahara  cup   
2024-02-03 04:45:37,642 	Text Hypothesis :	delhi court had **** *** ******** ****** ***** ** ******* ** issued a   non-bailable warrant against sushil
2024-02-03 04:45:37,642 	Text Alignment  :	I     S         D    D   D        D      D     D  D       D  S      S   S            S       S       S     
2024-02-03 04:45:37,642 ========================================================================================================================
2024-02-03 04:45:37,642 Logging Sequence: 153_230.00
2024-02-03 04:45:37,642 	Gloss Reference :	A B+C+D+E
2024-02-03 04:45:37,642 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:45:37,642 	Gloss Alignment :	         
2024-02-03 04:45:37,643 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:45:37,643 	Text Reference  :	the imran khan-led the    pakistan side in 1992 and went on to      become the pm        
2024-02-03 04:45:37,644 	Text Hypothesis :	the ***** ******** indian team     is   in **** *** **** ** england for    a   tournament
2024-02-03 04:45:37,644 	Text Alignment  :	    D     D        S      S        S       D    D   D    D  S       S      S   S         
2024-02-03 04:45:37,644 ========================================================================================================================
2024-02-03 04:45:37,644 Logging Sequence: 154_25.00
2024-02-03 04:45:37,644 	Gloss Reference :	A B+C+D+E
2024-02-03 04:45:37,644 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:45:37,644 	Gloss Alignment :	         
2024-02-03 04:45:37,644 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:45:37,645 	Text Reference  :	bcci chief sourav ganguly on  28th  june  said that    the     
2024-02-03 04:45:37,645 	Text Hypothesis :	**** ***** for    the     ipl media users made furious comments
2024-02-03 04:45:37,645 	Text Alignment  :	D    D     S      S       S   S     S     S    S       S       
2024-02-03 04:45:37,645 ========================================================================================================================
2024-02-03 04:45:37,646 Logging Sequence: 81_394.00
2024-02-03 04:45:37,646 	Gloss Reference :	A B+C+D+E
2024-02-03 04:45:37,646 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:45:37,646 	Gloss Alignment :	         
2024-02-03 04:45:37,646 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:45:37,647 	Text Reference  :	*** the apex court is going to   launch a *** ****** ** strict     investigation
2024-02-03 04:45:37,647 	Text Hypothesis :	for the 4th  match he was   held in     a few months of australian cricket      
2024-02-03 04:45:37,647 	Text Alignment  :	I       S    S     S  S     S    S        I   I      I  S          S            
2024-02-03 04:45:37,647 ========================================================================================================================
2024-02-03 04:45:43,394 [Epoch: 407 Step: 00054100] Batch Recognition Loss:   0.001024 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.053517 => Txt Tokens per Sec:     3886 || Lr: 0.000100
2024-02-03 04:45:45,146 Epoch 407: Total Training Recognition Loss 0.36  Total Training Translation Loss 18.55 
2024-02-03 04:45:45,146 EPOCH 408
2024-02-03 04:45:48,987 [Epoch: 408 Step: 00054200] Batch Recognition Loss:   0.000669 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.105071 => Txt Tokens per Sec:     4002 || Lr: 0.000100
2024-02-03 04:45:52,427 Epoch 408: Total Training Recognition Loss 0.78  Total Training Translation Loss 12.71 
2024-02-03 04:45:52,428 EPOCH 409
2024-02-03 04:45:54,560 [Epoch: 409 Step: 00054300] Batch Recognition Loss:   0.001432 => Gls Tokens per Sec:     1351 || Batch Translation Loss:   0.098952 => Txt Tokens per Sec:     3812 || Lr: 0.000100
2024-02-03 04:46:00,029 Epoch 409: Total Training Recognition Loss 0.43  Total Training Translation Loss 10.61 
2024-02-03 04:46:00,029 EPOCH 410
2024-02-03 04:46:00,185 [Epoch: 410 Step: 00054400] Batch Recognition Loss:   0.003513 => Gls Tokens per Sec:     1548 || Batch Translation Loss:   0.040834 => Txt Tokens per Sec:     4413 || Lr: 0.000100
2024-02-03 04:46:05,789 [Epoch: 410 Step: 00054500] Batch Recognition Loss:   0.005334 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.046022 => Txt Tokens per Sec:     3987 || Lr: 0.000100
2024-02-03 04:46:07,356 Epoch 410: Total Training Recognition Loss 0.36  Total Training Translation Loss 11.73 
2024-02-03 04:46:07,357 EPOCH 411
2024-02-03 04:46:11,233 [Epoch: 411 Step: 00054600] Batch Recognition Loss:   0.000480 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.081824 => Txt Tokens per Sec:     3997 || Lr: 0.000100
2024-02-03 04:46:14,831 Epoch 411: Total Training Recognition Loss 0.32  Total Training Translation Loss 12.69 
2024-02-03 04:46:14,832 EPOCH 412
2024-02-03 04:46:16,570 [Epoch: 412 Step: 00054700] Batch Recognition Loss:   0.000552 => Gls Tokens per Sec:     1704 || Batch Translation Loss:   0.040853 => Txt Tokens per Sec:     4603 || Lr: 0.000100
2024-02-03 04:46:22,118 Epoch 412: Total Training Recognition Loss 0.31  Total Training Translation Loss 10.17 
2024-02-03 04:46:22,118 EPOCH 413
2024-02-03 04:46:22,303 [Epoch: 413 Step: 00054800] Batch Recognition Loss:   0.001053 => Gls Tokens per Sec:     1739 || Batch Translation Loss:   0.018439 => Txt Tokens per Sec:     4451 || Lr: 0.000100
2024-02-03 04:46:27,965 [Epoch: 413 Step: 00054900] Batch Recognition Loss:   0.001217 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.141245 => Txt Tokens per Sec:     3961 || Lr: 0.000100
2024-02-03 04:46:29,625 Epoch 413: Total Training Recognition Loss 0.23  Total Training Translation Loss 12.74 
2024-02-03 04:46:29,626 EPOCH 414
2024-02-03 04:46:33,766 [Epoch: 414 Step: 00055000] Batch Recognition Loss:   0.007417 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.024052 => Txt Tokens per Sec:     3790 || Lr: 0.000100
2024-02-03 04:46:37,449 Epoch 414: Total Training Recognition Loss 0.32  Total Training Translation Loss 15.13 
2024-02-03 04:46:37,450 EPOCH 415
2024-02-03 04:46:39,510 [Epoch: 415 Step: 00055100] Batch Recognition Loss:   0.009075 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.061318 => Txt Tokens per Sec:     4080 || Lr: 0.000100
2024-02-03 04:46:44,752 Epoch 415: Total Training Recognition Loss 0.36  Total Training Translation Loss 17.02 
2024-02-03 04:46:44,752 EPOCH 416
2024-02-03 04:46:44,999 [Epoch: 416 Step: 00055200] Batch Recognition Loss:   0.000266 => Gls Tokens per Sec:     1633 || Batch Translation Loss:   0.050141 => Txt Tokens per Sec:     4714 || Lr: 0.000100
2024-02-03 04:46:50,496 [Epoch: 416 Step: 00055300] Batch Recognition Loss:   0.000247 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.039501 => Txt Tokens per Sec:     4071 || Lr: 0.000100
2024-02-03 04:46:52,078 Epoch 416: Total Training Recognition Loss 0.43  Total Training Translation Loss 22.15 
2024-02-03 04:46:52,078 EPOCH 417
2024-02-03 04:46:56,147 [Epoch: 417 Step: 00055400] Batch Recognition Loss:   0.022368 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.172072 => Txt Tokens per Sec:     3829 || Lr: 0.000100
2024-02-03 04:46:59,822 Epoch 417: Total Training Recognition Loss 0.32  Total Training Translation Loss 19.78 
2024-02-03 04:46:59,822 EPOCH 418
2024-02-03 04:47:02,087 [Epoch: 418 Step: 00055500] Batch Recognition Loss:   0.000317 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.034288 => Txt Tokens per Sec:     3703 || Lr: 0.000100
2024-02-03 04:47:07,547 Epoch 418: Total Training Recognition Loss 0.38  Total Training Translation Loss 14.83 
2024-02-03 04:47:07,548 EPOCH 419
2024-02-03 04:47:07,844 [Epoch: 419 Step: 00055600] Batch Recognition Loss:   0.000370 => Gls Tokens per Sec:     1625 || Batch Translation Loss:   0.032399 => Txt Tokens per Sec:     4238 || Lr: 0.000100
2024-02-03 04:47:13,455 [Epoch: 419 Step: 00055700] Batch Recognition Loss:   0.000156 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.015669 => Txt Tokens per Sec:     3964 || Lr: 0.000100
2024-02-03 04:47:14,920 Epoch 419: Total Training Recognition Loss 0.39  Total Training Translation Loss 7.88 
2024-02-03 04:47:14,921 EPOCH 420
2024-02-03 04:47:19,114 [Epoch: 420 Step: 00055800] Batch Recognition Loss:   0.001063 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.049043 => Txt Tokens per Sec:     3895 || Lr: 0.000100
2024-02-03 04:47:22,688 Epoch 420: Total Training Recognition Loss 0.33  Total Training Translation Loss 11.41 
2024-02-03 04:47:22,688 EPOCH 421
2024-02-03 04:47:24,905 [Epoch: 421 Step: 00055900] Batch Recognition Loss:   0.000994 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.021343 => Txt Tokens per Sec:     4031 || Lr: 0.000100
2024-02-03 04:47:29,837 Epoch 421: Total Training Recognition Loss 0.28  Total Training Translation Loss 7.77 
2024-02-03 04:47:29,837 EPOCH 422
2024-02-03 04:47:30,291 [Epoch: 422 Step: 00056000] Batch Recognition Loss:   0.024264 => Gls Tokens per Sec:     1239 || Batch Translation Loss:   0.104162 => Txt Tokens per Sec:     3606 || Lr: 0.000100
2024-02-03 04:47:41,271 Validation result at epoch 422, step    56000: duration: 10.9806s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.84851	Translation Loss: 88467.95312	PPL: 9785.04980
	Eval Metric: BLEU
	WER 3.47	(DEL: 0.14,	INS: 0.00,	SUB: 3.32)
	BLEU-4 0.47	(BLEU-1: 9.75,	BLEU-2: 2.67,	BLEU-3: 0.95,	BLEU-4: 0.47)
	CHRF 16.67	ROUGE 8.27
2024-02-03 04:47:41,272 Logging Recognition and Translation Outputs
2024-02-03 04:47:41,272 ========================================================================================================================
2024-02-03 04:47:41,272 Logging Sequence: 92_59.00
2024-02-03 04:47:41,273 	Gloss Reference :	A B+C+D+E
2024-02-03 04:47:41,273 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:47:41,273 	Gloss Alignment :	         
2024-02-03 04:47:41,273 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:47:41,274 	Text Reference  :	after the indian team's defeat 2   men    dancing and     bursting crackers outside her    house
2024-02-03 04:47:41,274 	Text Hypothesis :	***** it  is     sad    that   the bowler was     injured but      in       the     bowler lost 
2024-02-03 04:47:41,275 	Text Alignment  :	D     S   S      S      S      S   S      S       S       S        S        S       S      S    
2024-02-03 04:47:41,275 ========================================================================================================================
2024-02-03 04:47:41,275 Logging Sequence: 81_73.00
2024-02-03 04:47:41,275 	Gloss Reference :	A B+C+D+E
2024-02-03 04:47:41,275 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:47:41,275 	Gloss Alignment :	         
2024-02-03 04:47:41,276 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:47:41,277 	Text Reference  :	buyers liked the ads and booked many    houses with     the builder sadly    they were   duped       
2024-02-03 04:47:41,277 	Text Hypothesis :	****** ***** the *** *** ****** supreme court  canceled the ******* builder' real estate registration
2024-02-03 04:47:41,277 	Text Alignment  :	D      D         D   D   D      S       S      S            D       S        S    S      S           
2024-02-03 04:47:41,277 ========================================================================================================================
2024-02-03 04:47:41,277 Logging Sequence: 166_41.00
2024-02-03 04:47:41,277 	Gloss Reference :	A B+C+D+E
2024-02-03 04:47:41,277 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:47:41,278 	Gloss Alignment :	         
2024-02-03 04:47:41,278 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:47:41,279 	Text Reference  :	*** test match is  played patiently till   the ****** ***** ***** ***** opponents are all out        
2024-02-03 04:47:41,279 	Text Hypothesis :	but this can   not go     on        amidst the rising cases human lives need      to  be  safeguarded
2024-02-03 04:47:41,279 	Text Alignment  :	I   S    S     S   S      S         S          I      I     I     I     S         S   S   S          
2024-02-03 04:47:41,279 ========================================================================================================================
2024-02-03 04:47:41,279 Logging Sequence: 171_33.00
2024-02-03 04:47:41,280 	Gloss Reference :	A B+C+D+E
2024-02-03 04:47:41,280 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:47:41,280 	Gloss Alignment :	         
2024-02-03 04:47:41,280 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:47:41,281 	Text Reference  :	the gujarat titans vs chennai super kings    match was held on           23rd may  
2024-02-03 04:47:41,281 	Text Hypothesis :	the ******* ****** ** video   has   garnered a     lot of   appreciation and  likes
2024-02-03 04:47:41,281 	Text Alignment  :	    D       D      D  S       S     S        S     S   S    S            S    S    
2024-02-03 04:47:41,281 ========================================================================================================================
2024-02-03 04:47:41,282 Logging Sequence: 140_2.00
2024-02-03 04:47:41,282 	Gloss Reference :	A B+C+D+E
2024-02-03 04:47:41,282 	Gloss Hypothesis:	A B+C+D  
2024-02-03 04:47:41,282 	Gloss Alignment :	  S      
2024-02-03 04:47:41,282 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:47:41,284 	Text Reference  :	** ** ********* ********** *** **** ** **** ****** *** ** **** ** indian   batsman-wicket keeper rishabh pant has   outstanding skills in   cricket
2024-02-03 04:47:41,284 	Text Hypothesis :	he is currently unemployed and used to work during the cm aims to motivate the            youth  of      the  state to          be     like him    
2024-02-03 04:47:41,284 	Text Alignment  :	I  I  I         I          I   I    I  I    I      I   I  I    I  S        S              S      S       S    S     S           S      S    S      
2024-02-03 04:47:41,284 ========================================================================================================================
2024-02-03 04:47:46,833 [Epoch: 422 Step: 00056100] Batch Recognition Loss:   0.000144 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.008693 => Txt Tokens per Sec:     3998 || Lr: 0.000100
2024-02-03 04:47:48,411 Epoch 422: Total Training Recognition Loss 0.39  Total Training Translation Loss 7.18 
2024-02-03 04:47:48,411 EPOCH 423
2024-02-03 04:47:52,549 [Epoch: 423 Step: 00056200] Batch Recognition Loss:   0.000319 => Gls Tokens per Sec:     1431 || Batch Translation Loss:   0.015699 => Txt Tokens per Sec:     4060 || Lr: 0.000100
2024-02-03 04:47:55,934 Epoch 423: Total Training Recognition Loss 0.38  Total Training Translation Loss 10.43 
2024-02-03 04:47:55,935 EPOCH 424
2024-02-03 04:47:58,267 [Epoch: 424 Step: 00056300] Batch Recognition Loss:   0.004375 => Gls Tokens per Sec:     1408 || Batch Translation Loss:   0.069598 => Txt Tokens per Sec:     3945 || Lr: 0.000100
2024-02-03 04:48:03,475 Epoch 424: Total Training Recognition Loss 0.55  Total Training Translation Loss 13.23 
2024-02-03 04:48:03,476 EPOCH 425
2024-02-03 04:48:03,904 [Epoch: 425 Step: 00056400] Batch Recognition Loss:   0.001760 => Gls Tokens per Sec:     1501 || Batch Translation Loss:   0.066552 => Txt Tokens per Sec:     3952 || Lr: 0.000100
2024-02-03 04:48:09,500 [Epoch: 425 Step: 00056500] Batch Recognition Loss:   0.003517 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.103700 => Txt Tokens per Sec:     4018 || Lr: 0.000100
2024-02-03 04:48:11,044 Epoch 425: Total Training Recognition Loss 0.73  Total Training Translation Loss 32.28 
2024-02-03 04:48:11,045 EPOCH 426
2024-02-03 04:48:15,279 [Epoch: 426 Step: 00056600] Batch Recognition Loss:   0.001926 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   0.015448 => Txt Tokens per Sec:     3906 || Lr: 0.000100
2024-02-03 04:48:18,602 Epoch 426: Total Training Recognition Loss 0.74  Total Training Translation Loss 19.52 
2024-02-03 04:48:18,602 EPOCH 427
2024-02-03 04:48:21,194 [Epoch: 427 Step: 00056700] Batch Recognition Loss:   0.002013 => Gls Tokens per Sec:     1297 || Batch Translation Loss:   0.099536 => Txt Tokens per Sec:     3672 || Lr: 0.000100
2024-02-03 04:48:26,265 Epoch 427: Total Training Recognition Loss 0.41  Total Training Translation Loss 11.87 
2024-02-03 04:48:26,266 EPOCH 428
2024-02-03 04:48:26,735 [Epoch: 428 Step: 00056800] Batch Recognition Loss:   0.000345 => Gls Tokens per Sec:     1537 || Batch Translation Loss:   0.041302 => Txt Tokens per Sec:     4514 || Lr: 0.000100
2024-02-03 04:48:31,684 [Epoch: 428 Step: 00056900] Batch Recognition Loss:   0.006028 => Gls Tokens per Sec:     1617 || Batch Translation Loss:   0.850299 => Txt Tokens per Sec:     4480 || Lr: 0.000100
2024-02-03 04:48:33,036 Epoch 428: Total Training Recognition Loss 0.39  Total Training Translation Loss 13.96 
2024-02-03 04:48:33,037 EPOCH 429
2024-02-03 04:48:37,703 [Epoch: 429 Step: 00057000] Batch Recognition Loss:   0.000796 => Gls Tokens per Sec:     1303 || Batch Translation Loss:   0.058268 => Txt Tokens per Sec:     3655 || Lr: 0.000100
2024-02-03 04:48:41,070 Epoch 429: Total Training Recognition Loss 0.39  Total Training Translation Loss 13.18 
2024-02-03 04:48:41,071 EPOCH 430
2024-02-03 04:48:43,622 [Epoch: 430 Step: 00057100] Batch Recognition Loss:   0.000613 => Gls Tokens per Sec:     1349 || Batch Translation Loss:   0.024070 => Txt Tokens per Sec:     3860 || Lr: 0.000100
2024-02-03 04:48:48,612 Epoch 430: Total Training Recognition Loss 0.34  Total Training Translation Loss 11.18 
2024-02-03 04:48:48,613 EPOCH 431
2024-02-03 04:48:49,049 [Epoch: 431 Step: 00057200] Batch Recognition Loss:   0.000164 => Gls Tokens per Sec:     1839 || Batch Translation Loss:   0.023317 => Txt Tokens per Sec:     4793 || Lr: 0.000100
2024-02-03 04:48:54,751 [Epoch: 431 Step: 00057300] Batch Recognition Loss:   0.001867 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.078820 => Txt Tokens per Sec:     3931 || Lr: 0.000100
2024-02-03 04:48:55,978 Epoch 431: Total Training Recognition Loss 0.35  Total Training Translation Loss 15.75 
2024-02-03 04:48:55,978 EPOCH 432
2024-02-03 04:49:00,043 [Epoch: 432 Step: 00057400] Batch Recognition Loss:   0.002126 => Gls Tokens per Sec:     1516 || Batch Translation Loss:   0.022230 => Txt Tokens per Sec:     4136 || Lr: 0.000100
2024-02-03 04:49:03,240 Epoch 432: Total Training Recognition Loss 0.35  Total Training Translation Loss 14.68 
2024-02-03 04:49:03,240 EPOCH 433
2024-02-03 04:49:05,502 [Epoch: 433 Step: 00057500] Batch Recognition Loss:   0.001060 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   0.235735 => Txt Tokens per Sec:     4342 || Lr: 0.000100
2024-02-03 04:49:10,538 Epoch 433: Total Training Recognition Loss 0.41  Total Training Translation Loss 18.38 
2024-02-03 04:49:10,538 EPOCH 434
2024-02-03 04:49:11,102 [Epoch: 434 Step: 00057600] Batch Recognition Loss:   0.008043 => Gls Tokens per Sec:     1563 || Batch Translation Loss:   0.021088 => Txt Tokens per Sec:     4622 || Lr: 0.000100
2024-02-03 04:49:16,498 [Epoch: 434 Step: 00057700] Batch Recognition Loss:   0.001118 => Gls Tokens per Sec:     1483 || Batch Translation Loss:   0.296374 => Txt Tokens per Sec:     4049 || Lr: 0.000100
2024-02-03 04:49:17,798 Epoch 434: Total Training Recognition Loss 0.38  Total Training Translation Loss 14.16 
2024-02-03 04:49:17,798 EPOCH 435
2024-02-03 04:49:22,222 [Epoch: 435 Step: 00057800] Batch Recognition Loss:   0.000483 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.374950 => Txt Tokens per Sec:     3935 || Lr: 0.000100
2024-02-03 04:49:25,332 Epoch 435: Total Training Recognition Loss 0.46  Total Training Translation Loss 11.99 
2024-02-03 04:49:25,332 EPOCH 436
2024-02-03 04:49:27,735 [Epoch: 436 Step: 00057900] Batch Recognition Loss:   0.003319 => Gls Tokens per Sec:     1499 || Batch Translation Loss:   0.032000 => Txt Tokens per Sec:     4082 || Lr: 0.000100
2024-02-03 04:49:32,699 Epoch 436: Total Training Recognition Loss 0.45  Total Training Translation Loss 12.17 
2024-02-03 04:49:32,699 EPOCH 437
2024-02-03 04:49:33,386 [Epoch: 437 Step: 00058000] Batch Recognition Loss:   0.001410 => Gls Tokens per Sec:     1399 || Batch Translation Loss:   0.020715 => Txt Tokens per Sec:     3809 || Lr: 0.000100
2024-02-03 04:49:44,387 Validation result at epoch 437, step    58000: duration: 10.9998s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.36120	Translation Loss: 89530.63281	PPL: 10926.92773
	Eval Metric: BLEU
	WER 3.39	(DEL: 0.21,	INS: 0.00,	SUB: 3.18)
	BLEU-4 0.48	(BLEU-1: 9.61,	BLEU-2: 2.70,	BLEU-3: 1.06,	BLEU-4: 0.48)
	CHRF 16.22	ROUGE 8.15
2024-02-03 04:49:44,388 Logging Recognition and Translation Outputs
2024-02-03 04:49:44,388 ========================================================================================================================
2024-02-03 04:49:44,388 Logging Sequence: 135_100.00
2024-02-03 04:49:44,388 	Gloss Reference :	A B+C+D+E
2024-02-03 04:49:44,388 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:49:44,389 	Gloss Alignment :	         
2024-02-03 04:49:44,389 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:49:44,390 	Text Reference  :	and that her    goal was     to  raise the other   half   through   the medal auction
2024-02-03 04:49:44,390 	Text Hypothesis :	*** she  didn't know maå‚ysa but she   had already scored something the ***** support
2024-02-03 04:49:44,390 	Text Alignment  :	D   S    S      S    S       S   S     S   S       S      S             D     S      
2024-02-03 04:49:44,390 ========================================================================================================================
2024-02-03 04:49:44,390 Logging Sequence: 63_35.00
2024-02-03 04:49:44,390 	Gloss Reference :	A B+C+D+E
2024-02-03 04:49:44,391 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:49:44,391 	Gloss Alignment :	         
2024-02-03 04:49:44,391 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:49:44,392 	Text Reference  :	companies interested in buying the teams need to fill the         tender form    by  paying    rs    10  lakh 
2024-02-03 04:49:44,392 	Text Hypothesis :	********* ********** ** ****** *** ***** it   is held alternately in     england and australia every two years
2024-02-03 04:49:44,392 	Text Alignment  :	D         D          D  D      D   D     S    S  S    S           S      S       S   S         S     S   S    
2024-02-03 04:49:44,392 ========================================================================================================================
2024-02-03 04:49:44,393 Logging Sequence: 103_122.00
2024-02-03 04:49:44,393 	Gloss Reference :	A B+C+D+E
2024-02-03 04:49:44,393 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:49:44,393 	Gloss Alignment :	         
2024-02-03 04:49:44,393 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:49:44,394 	Text Reference  :	like india australia canada     pakistan  nigeria in         africa and    many    more
2024-02-03 04:49:44,394 	Text Hypothesis :	**** the   german    government spokesman steffen hebestreit from   berlin germany said
2024-02-03 04:49:44,394 	Text Alignment  :	D    S     S         S          S         S       S          S      S      S       S   
2024-02-03 04:49:44,394 ========================================================================================================================
2024-02-03 04:49:44,394 Logging Sequence: 106_175.00
2024-02-03 04:49:44,394 	Gloss Reference :	A B+C+D+E
2024-02-03 04:49:44,395 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:49:44,395 	Gloss Alignment :	         
2024-02-03 04:49:44,395 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:49:44,395 	Text Reference  :	*** **** wonderful but what about the   deaf women's team    
2024-02-03 04:49:44,396 	Text Hypothesis :	she said that      she was  to    score by   her     hardwork
2024-02-03 04:49:44,396 	Text Alignment  :	I   I    S         S   S    S     S     S    S       S       
2024-02-03 04:49:44,396 ========================================================================================================================
2024-02-03 04:49:44,396 Logging Sequence: 83_57.00
2024-02-03 04:49:44,396 	Gloss Reference :	A B+C+D+E
2024-02-03 04:49:44,396 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:49:44,396 	Gloss Alignment :	         
2024-02-03 04:49:44,396 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:49:44,397 	Text Reference  :	*** collapsed face first   on       the   field he           was **** ** completely unconscious
2024-02-03 04:49:44,397 	Text Hypothesis :	the denmark   vs   finland football match test  championship was held at the        stadium    
2024-02-03 04:49:44,398 	Text Alignment  :	I   S         S    S       S        S     S     S                I    I  S          S          
2024-02-03 04:49:44,398 ========================================================================================================================
2024-02-03 04:49:50,015 [Epoch: 437 Step: 00058100] Batch Recognition Loss:   0.000842 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.019612 => Txt Tokens per Sec:     3980 || Lr: 0.000100
2024-02-03 04:49:51,333 Epoch 437: Total Training Recognition Loss 0.37  Total Training Translation Loss 12.24 
2024-02-03 04:49:51,334 EPOCH 438
2024-02-03 04:49:55,861 [Epoch: 438 Step: 00058200] Batch Recognition Loss:   0.000502 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.064446 => Txt Tokens per Sec:     3976 || Lr: 0.000100
2024-02-03 04:49:59,150 Epoch 438: Total Training Recognition Loss 0.30  Total Training Translation Loss 11.47 
2024-02-03 04:49:59,150 EPOCH 439
2024-02-03 04:50:01,796 [Epoch: 439 Step: 00058300] Batch Recognition Loss:   0.003202 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   0.087208 => Txt Tokens per Sec:     3941 || Lr: 0.000100
2024-02-03 04:50:06,550 Epoch 439: Total Training Recognition Loss 0.23  Total Training Translation Loss 18.97 
2024-02-03 04:50:06,550 EPOCH 440
2024-02-03 04:50:07,091 [Epoch: 440 Step: 00058400] Batch Recognition Loss:   0.001078 => Gls Tokens per Sec:     1926 || Batch Translation Loss:   0.032648 => Txt Tokens per Sec:     4772 || Lr: 0.000100
2024-02-03 04:50:12,661 [Epoch: 440 Step: 00058500] Batch Recognition Loss:   0.000248 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.148705 => Txt Tokens per Sec:     4064 || Lr: 0.000100
2024-02-03 04:50:13,784 Epoch 440: Total Training Recognition Loss 0.31  Total Training Translation Loss 15.05 
2024-02-03 04:50:13,784 EPOCH 441
2024-02-03 04:50:18,575 [Epoch: 441 Step: 00058600] Batch Recognition Loss:   0.003446 => Gls Tokens per Sec:     1336 || Batch Translation Loss:   0.014307 => Txt Tokens per Sec:     3789 || Lr: 0.000100
2024-02-03 04:50:21,709 Epoch 441: Total Training Recognition Loss 0.36  Total Training Translation Loss 12.76 
2024-02-03 04:50:21,709 EPOCH 442
2024-02-03 04:50:24,249 [Epoch: 442 Step: 00058700] Batch Recognition Loss:   0.000531 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.059786 => Txt Tokens per Sec:     4127 || Lr: 0.000100
2024-02-03 04:50:29,273 Epoch 442: Total Training Recognition Loss 0.27  Total Training Translation Loss 12.35 
2024-02-03 04:50:29,273 EPOCH 443
2024-02-03 04:50:29,966 [Epoch: 443 Step: 00058800] Batch Recognition Loss:   0.000395 => Gls Tokens per Sec:     1617 || Batch Translation Loss:   0.061536 => Txt Tokens per Sec:     4374 || Lr: 0.000100
2024-02-03 04:50:35,658 [Epoch: 443 Step: 00058900] Batch Recognition Loss:   0.007643 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.110779 => Txt Tokens per Sec:     3893 || Lr: 0.000100
2024-02-03 04:50:36,665 Epoch 443: Total Training Recognition Loss 0.33  Total Training Translation Loss 16.79 
2024-02-03 04:50:36,665 EPOCH 444
2024-02-03 04:50:41,009 [Epoch: 444 Step: 00059000] Batch Recognition Loss:   0.001627 => Gls Tokens per Sec:     1492 || Batch Translation Loss:   0.370686 => Txt Tokens per Sec:     4104 || Lr: 0.000100
2024-02-03 04:50:44,114 Epoch 444: Total Training Recognition Loss 0.31  Total Training Translation Loss 14.28 
2024-02-03 04:50:44,114 EPOCH 445
2024-02-03 04:50:46,758 [Epoch: 445 Step: 00059100] Batch Recognition Loss:   0.000663 => Gls Tokens per Sec:     1453 || Batch Translation Loss:   0.056900 => Txt Tokens per Sec:     4086 || Lr: 0.000100
2024-02-03 04:50:51,745 Epoch 445: Total Training Recognition Loss 0.23  Total Training Translation Loss 11.51 
2024-02-03 04:50:51,745 EPOCH 446
2024-02-03 04:50:52,552 [Epoch: 446 Step: 00059200] Batch Recognition Loss:   0.000900 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   0.044619 => Txt Tokens per Sec:     3858 || Lr: 0.000100
2024-02-03 04:50:58,186 [Epoch: 446 Step: 00059300] Batch Recognition Loss:   0.004984 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.864851 => Txt Tokens per Sec:     3978 || Lr: 0.000100
2024-02-03 04:50:59,111 Epoch 446: Total Training Recognition Loss 0.48  Total Training Translation Loss 20.40 
2024-02-03 04:50:59,112 EPOCH 447
2024-02-03 04:51:03,702 [Epoch: 447 Step: 00059400] Batch Recognition Loss:   0.000287 => Gls Tokens per Sec:     1430 || Batch Translation Loss:   0.099416 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-03 04:51:06,706 Epoch 447: Total Training Recognition Loss 0.43  Total Training Translation Loss 19.39 
2024-02-03 04:51:06,707 EPOCH 448
2024-02-03 04:51:09,553 [Epoch: 448 Step: 00059500] Batch Recognition Loss:   0.001827 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.043971 => Txt Tokens per Sec:     3890 || Lr: 0.000100
2024-02-03 04:51:14,447 Epoch 448: Total Training Recognition Loss 0.50  Total Training Translation Loss 11.00 
2024-02-03 04:51:14,448 EPOCH 449
2024-02-03 04:51:15,373 [Epoch: 449 Step: 00059600] Batch Recognition Loss:   0.002663 => Gls Tokens per Sec:     1385 || Batch Translation Loss:   0.056987 => Txt Tokens per Sec:     4113 || Lr: 0.000100
2024-02-03 04:51:20,334 [Epoch: 449 Step: 00059700] Batch Recognition Loss:   0.015054 => Gls Tokens per Sec:     1613 || Batch Translation Loss:   0.030270 => Txt Tokens per Sec:     4434 || Lr: 0.000100
2024-02-03 04:51:21,264 Epoch 449: Total Training Recognition Loss 0.79  Total Training Translation Loss 11.73 
2024-02-03 04:51:21,264 EPOCH 450
2024-02-03 04:51:26,101 [Epoch: 450 Step: 00059800] Batch Recognition Loss:   0.002258 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.038603 => Txt Tokens per Sec:     3841 || Lr: 0.000100
2024-02-03 04:51:29,039 Epoch 450: Total Training Recognition Loss 0.54  Total Training Translation Loss 14.73 
2024-02-03 04:51:29,040 EPOCH 451
2024-02-03 04:51:31,882 [Epoch: 451 Step: 00059900] Batch Recognition Loss:   0.000544 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.042839 => Txt Tokens per Sec:     3979 || Lr: 0.000100
2024-02-03 04:51:36,634 Epoch 451: Total Training Recognition Loss 0.49  Total Training Translation Loss 9.59 
2024-02-03 04:51:36,635 EPOCH 452
2024-02-03 04:51:37,489 [Epoch: 452 Step: 00060000] Batch Recognition Loss:   0.000255 => Gls Tokens per Sec:     1593 || Batch Translation Loss:   0.020657 => Txt Tokens per Sec:     4509 || Lr: 0.000100
2024-02-03 04:51:48,262 Validation result at epoch 452, step    60000: duration: 10.7733s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.33252	Translation Loss: 90070.42969	PPL: 11557.04004
	Eval Metric: BLEU
	WER 3.18	(DEL: 0.14,	INS: 0.00,	SUB: 3.04)
	BLEU-4 0.34	(BLEU-1: 9.41,	BLEU-2: 2.51,	BLEU-3: 0.75,	BLEU-4: 0.34)
	CHRF 16.42	ROUGE 7.90
2024-02-03 04:51:48,263 Logging Recognition and Translation Outputs
2024-02-03 04:51:48,264 ========================================================================================================================
2024-02-03 04:51:48,264 Logging Sequence: 161_210.00
2024-02-03 04:51:48,264 	Gloss Reference :	A B+C+D+E
2024-02-03 04:51:48,264 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:51:48,264 	Gloss Alignment :	         
2024-02-03 04:51:48,264 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:51:48,265 	Text Reference  :	***** *** ***** ****** **** ******* **** *** we  hope he  continues playing for          india   
2024-02-03 04:51:48,265 	Text Hypothesis :	after the match people were waiting till the end of   the long      award   presentation ceremony
2024-02-03 04:51:48,265 	Text Alignment  :	I     I   I     I      I    I       I    I   S   S    S   S         S       S            S       
2024-02-03 04:51:48,265 ========================================================================================================================
2024-02-03 04:51:48,266 Logging Sequence: 59_152.00
2024-02-03 04:51:48,266 	Gloss Reference :	A B+C+D+E
2024-02-03 04:51:48,266 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:51:48,266 	Gloss Alignment :	         
2024-02-03 04:51:48,266 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:51:48,267 	Text Reference  :	the organisers encouraged athletes to ***** * **** **** *** * use      the condoms in their home countries
2024-02-03 04:51:48,267 	Text Hypothesis :	*** once       she        returns  to india i will give you a suitable job as      a  token of   gratitude
2024-02-03 04:51:48,268 	Text Alignment  :	D   S          S          S           I     I I    I    I   I S        S   S       S  S     S    S        
2024-02-03 04:51:48,268 ========================================================================================================================
2024-02-03 04:51:48,268 Logging Sequence: 167_67.00
2024-02-03 04:51:48,268 	Gloss Reference :	A B+C+D+E
2024-02-03 04:51:48,268 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:51:48,268 	Gloss Alignment :	         
2024-02-03 04:51:48,268 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:51:48,270 	Text Reference  :	once infected the incubation period  of the  virus is  1-2   weeks after which symptoms begin to appear 
2024-02-03 04:51:48,270 	Text Hypothesis :	**** ******** the 2          players as well as    the youth team  have  been  warned   about to qualify
2024-02-03 04:51:48,270 	Text Alignment  :	D    D            S          S       S  S    S     S   S     S     S     S     S        S        S      
2024-02-03 04:51:48,270 ========================================================================================================================
2024-02-03 04:51:48,270 Logging Sequence: 77_13.00
2024-02-03 04:51:48,270 	Gloss Reference :	A B+C+D+E
2024-02-03 04:51:48,271 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:51:48,271 	Gloss Alignment :	         
2024-02-03 04:51:48,271 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:51:48,272 	Text Reference  :	this was     the   1st match that ended in   a  tie in     this   season's ipl
2024-02-03 04:51:48,272 	Text Hypothesis :	**** however virat is  so    we   will  have to be  played during the      ipl
2024-02-03 04:51:48,272 	Text Alignment  :	D    S       S     S   S     S    S     S    S  S   S      S      S           
2024-02-03 04:51:48,272 ========================================================================================================================
2024-02-03 04:51:48,272 Logging Sequence: 169_245.00
2024-02-03 04:51:48,273 	Gloss Reference :	A B+C+D+E
2024-02-03 04:51:48,273 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:51:48,273 	Gloss Alignment :	         
2024-02-03 04:51:48,273 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:51:48,274 	Text Reference  :	********** ******** ** *** ***** ********* mohammed shami has    said these trolls are  spreading hate through fake accounts
2024-02-03 04:51:48,274 	Text Hypothesis :	pakistan's decision to bat first backfired as       india bowled them out   for    just 99        runs in      18   overs   
2024-02-03 04:51:48,275 	Text Alignment  :	I          I        I  I   I     I         S        S     S      S    S     S      S    S         S    S       S    S       
2024-02-03 04:51:48,275 ========================================================================================================================
2024-02-03 04:51:53,779 [Epoch: 452 Step: 00060100] Batch Recognition Loss:   0.000935 => Gls Tokens per Sec:     1450 || Batch Translation Loss:   0.015159 => Txt Tokens per Sec:     4009 || Lr: 0.000100
2024-02-03 04:51:54,746 Epoch 452: Total Training Recognition Loss 0.36  Total Training Translation Loss 10.36 
2024-02-03 04:51:54,746 EPOCH 453
2024-02-03 04:51:59,763 [Epoch: 453 Step: 00060200] Batch Recognition Loss:   0.000170 => Gls Tokens per Sec:     1340 || Batch Translation Loss:   0.142700 => Txt Tokens per Sec:     3730 || Lr: 0.000100
2024-02-03 04:52:02,523 Epoch 453: Total Training Recognition Loss 0.35  Total Training Translation Loss 10.03 
2024-02-03 04:52:02,523 EPOCH 454
2024-02-03 04:52:05,208 [Epoch: 454 Step: 00060300] Batch Recognition Loss:   0.000856 => Gls Tokens per Sec:     1520 || Batch Translation Loss:   0.086552 => Txt Tokens per Sec:     4348 || Lr: 0.000100
2024-02-03 04:52:09,529 Epoch 454: Total Training Recognition Loss 0.44  Total Training Translation Loss 15.85 
2024-02-03 04:52:09,530 EPOCH 455
2024-02-03 04:52:10,442 [Epoch: 455 Step: 00060400] Batch Recognition Loss:   0.003980 => Gls Tokens per Sec:     1582 || Batch Translation Loss:   0.175670 => Txt Tokens per Sec:     4191 || Lr: 0.000100
2024-02-03 04:52:15,830 [Epoch: 455 Step: 00060500] Batch Recognition Loss:   0.000297 => Gls Tokens per Sec:     1485 || Batch Translation Loss:   0.097788 => Txt Tokens per Sec:     4136 || Lr: 0.000100
2024-02-03 04:52:16,679 Epoch 455: Total Training Recognition Loss 0.68  Total Training Translation Loss 18.14 
2024-02-03 04:52:16,679 EPOCH 456
2024-02-03 04:52:21,632 [Epoch: 456 Step: 00060600] Batch Recognition Loss:   0.088486 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   1.303467 => Txt Tokens per Sec:     3820 || Lr: 0.000100
2024-02-03 04:52:24,461 Epoch 456: Total Training Recognition Loss 0.68  Total Training Translation Loss 17.62 
2024-02-03 04:52:24,461 EPOCH 457
2024-02-03 04:52:27,563 [Epoch: 457 Step: 00060700] Batch Recognition Loss:   0.001482 => Gls Tokens per Sec:     1341 || Batch Translation Loss:   0.140991 => Txt Tokens per Sec:     3853 || Lr: 0.000100
2024-02-03 04:52:31,942 Epoch 457: Total Training Recognition Loss 0.40  Total Training Translation Loss 18.54 
2024-02-03 04:52:31,943 EPOCH 458
2024-02-03 04:52:32,988 [Epoch: 458 Step: 00060800] Batch Recognition Loss:   0.000668 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.339715 => Txt Tokens per Sec:     4291 || Lr: 0.000100
2024-02-03 04:52:38,034 [Epoch: 458 Step: 00060900] Batch Recognition Loss:   0.002412 => Gls Tokens per Sec:     1586 || Batch Translation Loss:   0.057743 => Txt Tokens per Sec:     4422 || Lr: 0.000100
2024-02-03 04:52:38,913 Epoch 458: Total Training Recognition Loss 0.55  Total Training Translation Loss 20.02 
2024-02-03 04:52:38,913 EPOCH 459
2024-02-03 04:52:43,705 [Epoch: 459 Step: 00061000] Batch Recognition Loss:   0.015723 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.056930 => Txt Tokens per Sec:     3922 || Lr: 0.000100
2024-02-03 04:52:46,578 Epoch 459: Total Training Recognition Loss 0.32  Total Training Translation Loss 14.87 
2024-02-03 04:52:46,579 EPOCH 460
2024-02-03 04:52:49,517 [Epoch: 460 Step: 00061100] Batch Recognition Loss:   0.000206 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.067272 => Txt Tokens per Sec:     3927 || Lr: 0.000100
2024-02-03 04:52:54,229 Epoch 460: Total Training Recognition Loss 0.35  Total Training Translation Loss 7.66 
2024-02-03 04:52:54,229 EPOCH 461
2024-02-03 04:52:55,434 [Epoch: 461 Step: 00061200] Batch Recognition Loss:   0.000646 => Gls Tokens per Sec:     1330 || Batch Translation Loss:   0.064105 => Txt Tokens per Sec:     3576 || Lr: 0.000100
2024-02-03 04:53:00,778 [Epoch: 461 Step: 00061300] Batch Recognition Loss:   0.001093 => Gls Tokens per Sec:     1495 || Batch Translation Loss:   0.286428 => Txt Tokens per Sec:     4199 || Lr: 0.000100
2024-02-03 04:53:01,457 Epoch 461: Total Training Recognition Loss 0.36  Total Training Translation Loss 9.18 
2024-02-03 04:53:01,457 EPOCH 462
2024-02-03 04:53:06,489 [Epoch: 462 Step: 00061400] Batch Recognition Loss:   0.002070 => Gls Tokens per Sec:     1383 || Batch Translation Loss:   0.036605 => Txt Tokens per Sec:     3853 || Lr: 0.000100
2024-02-03 04:53:08,941 Epoch 462: Total Training Recognition Loss 0.32  Total Training Translation Loss 14.63 
2024-02-03 04:53:08,941 EPOCH 463
2024-02-03 04:53:11,868 [Epoch: 463 Step: 00061500] Batch Recognition Loss:   0.000346 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.119892 => Txt Tokens per Sec:     4019 || Lr: 0.000100
2024-02-03 04:53:16,222 Epoch 463: Total Training Recognition Loss 0.26  Total Training Translation Loss 13.14 
2024-02-03 04:53:16,222 EPOCH 464
2024-02-03 04:53:17,467 [Epoch: 464 Step: 00061600] Batch Recognition Loss:   0.000101 => Gls Tokens per Sec:     1350 || Batch Translation Loss:   0.041688 => Txt Tokens per Sec:     3976 || Lr: 0.000100
2024-02-03 04:53:23,002 [Epoch: 464 Step: 00061700] Batch Recognition Loss:   0.000165 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.079916 => Txt Tokens per Sec:     3962 || Lr: 0.000100
2024-02-03 04:53:23,584 Epoch 464: Total Training Recognition Loss 0.17  Total Training Translation Loss 12.25 
2024-02-03 04:53:23,584 EPOCH 465
2024-02-03 04:53:28,422 [Epoch: 465 Step: 00061800] Batch Recognition Loss:   0.000625 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.052587 => Txt Tokens per Sec:     4066 || Lr: 0.000100
2024-02-03 04:53:31,002 Epoch 465: Total Training Recognition Loss 0.29  Total Training Translation Loss 10.50 
2024-02-03 04:53:31,003 EPOCH 466
2024-02-03 04:53:34,282 [Epoch: 466 Step: 00061900] Batch Recognition Loss:   0.000886 => Gls Tokens per Sec:     1342 || Batch Translation Loss:   0.019912 => Txt Tokens per Sec:     3641 || Lr: 0.000100
2024-02-03 04:53:38,706 Epoch 466: Total Training Recognition Loss 0.23  Total Training Translation Loss 7.73 
2024-02-03 04:53:38,707 EPOCH 467
2024-02-03 04:53:39,999 [Epoch: 467 Step: 00062000] Batch Recognition Loss:   0.001765 => Gls Tokens per Sec:     1363 || Batch Translation Loss:   0.028149 => Txt Tokens per Sec:     3882 || Lr: 0.000100
2024-02-03 04:53:51,305 Validation result at epoch 467, step    62000: duration: 11.3060s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.91352	Translation Loss: 88920.70312	PPL: 10256.18066
	Eval Metric: BLEU
	WER 3.75	(DEL: 0.28,	INS: 0.00,	SUB: 3.47)
	BLEU-4 0.77	(BLEU-1: 10.40,	BLEU-2: 3.14,	BLEU-3: 1.38,	BLEU-4: 0.77)
	CHRF 16.91	ROUGE 8.55
2024-02-03 04:53:51,307 Logging Recognition and Translation Outputs
2024-02-03 04:53:51,307 ========================================================================================================================
2024-02-03 04:53:51,307 Logging Sequence: 162_86.00
2024-02-03 04:53:51,307 	Gloss Reference :	A B+C+D+E        
2024-02-03 04:53:51,307 	Gloss Hypothesis:	A B+C+D+E+B+C+D+B
2024-02-03 04:53:51,307 	Gloss Alignment :	  S              
2024-02-03 04:53:51,307 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:53:51,309 	Text Reference  :	* **** ** *** ***** ** *** ****** ***** **** *** ***** *** ***** *** do you       know how people responded to  this
2024-02-03 04:53:51,309 	Text Hypothesis :	a look at the video of the indian could beat the final and could not be available as   the host   of        the cup 
2024-02-03 04:53:51,309 	Text Alignment  :	I I    I  I   I     I  I   I      I     I    I   I     I   I     I   S  S         S    S   S      S         S   S   
2024-02-03 04:53:51,309 ========================================================================================================================
2024-02-03 04:53:51,309 Logging Sequence: 98_113.00
2024-02-03 04:53:51,309 	Gloss Reference :	A B+C+D+E
2024-02-03 04:53:51,310 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:53:51,310 	Gloss Alignment :	         
2024-02-03 04:53:51,310 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:53:51,310 	Text Reference  :	however australia legends opted out     due      to the covid situation
2024-02-03 04:53:51,311 	Text Hypothesis :	rooney' friends   said    that  nothing happened at the ***** hotel    
2024-02-03 04:53:51,311 	Text Alignment  :	S       S         S       S     S       S        S      D     S        
2024-02-03 04:53:51,311 ========================================================================================================================
2024-02-03 04:53:51,311 Logging Sequence: 178_25.00
2024-02-03 04:53:51,311 	Gloss Reference :	A B+C+D+E
2024-02-03 04:53:51,311 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:53:51,311 	Gloss Alignment :	         
2024-02-03 04:53:51,311 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:53:51,312 	Text Reference  :	*** **** on 5th may       the police filed   an     fir       
2024-02-03 04:53:51,312 	Text Hypothesis :	and said it was postponed to  have   another famous footballer
2024-02-03 04:53:51,312 	Text Alignment  :	I   I    S  S   S         S   S      S       S      S         
2024-02-03 04:53:51,312 ========================================================================================================================
2024-02-03 04:53:51,313 Logging Sequence: 147_148.00
2024-02-03 04:53:51,313 	Gloss Reference :	A B+C+D+E
2024-02-03 04:53:51,313 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:53:51,313 	Gloss Alignment :	         
2024-02-03 04:53:51,313 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:53:51,314 	Text Reference  :	when explained this  to ***** **** my      teammates they *** * **** ********** ******** understood my  feelings
2024-02-03 04:53:51,314 	Text Hypothesis :	**** people    loved to watch fast bowlers as        they had a very aggressive attitude on         the field   
2024-02-03 04:53:51,314 	Text Alignment  :	D    S         S        I     I    S       S              I   I I    I          I        S          S   S       
2024-02-03 04:53:51,314 ========================================================================================================================
2024-02-03 04:53:51,315 Logging Sequence: 61_326.00
2024-02-03 04:53:51,315 	Gloss Reference :	A B+C+D+E
2024-02-03 04:53:51,315 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:53:51,315 	Gloss Alignment :	         
2024-02-03 04:53:51,315 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:53:51,316 	Text Reference  :	** ******* *** ***** *** **** ****** **** *** ***** *** ******* *** *** ** however no confirmation has     been made     yet 
2024-02-03 04:53:51,316 	Text Hypothesis :	we request the media for 15th august 2023 the first new zealand had not be held    in this         without his  personal life
2024-02-03 04:53:51,317 	Text Alignment  :	I  I       I   I     I   I    I      I    I   I     I   I       I   I   I  S       S  S            S       S    S        S   
2024-02-03 04:53:51,317 ========================================================================================================================
2024-02-03 04:53:57,052 [Epoch: 467 Step: 00062100] Batch Recognition Loss:   0.001304 => Gls Tokens per Sec:     1392 || Batch Translation Loss:   0.087871 => Txt Tokens per Sec:     3847 || Lr: 0.000100
2024-02-03 04:53:57,650 Epoch 467: Total Training Recognition Loss 0.24  Total Training Translation Loss 8.37 
2024-02-03 04:53:57,650 EPOCH 468
2024-02-03 04:54:02,690 [Epoch: 468 Step: 00062200] Batch Recognition Loss:   0.000556 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.135301 => Txt Tokens per Sec:     3886 || Lr: 0.000100
2024-02-03 04:54:05,235 Epoch 468: Total Training Recognition Loss 0.28  Total Training Translation Loss 21.74 
2024-02-03 04:54:05,235 EPOCH 469
2024-02-03 04:54:08,007 [Epoch: 469 Step: 00062300] Batch Recognition Loss:   0.001164 => Gls Tokens per Sec:     1617 || Batch Translation Loss:   0.322032 => Txt Tokens per Sec:     4595 || Lr: 0.000100
2024-02-03 04:54:12,223 Epoch 469: Total Training Recognition Loss 0.38  Total Training Translation Loss 26.40 
2024-02-03 04:54:12,224 EPOCH 470
2024-02-03 04:54:13,480 [Epoch: 470 Step: 00062400] Batch Recognition Loss:   0.034526 => Gls Tokens per Sec:     1466 || Batch Translation Loss:   0.457311 => Txt Tokens per Sec:     4236 || Lr: 0.000100
2024-02-03 04:54:19,023 [Epoch: 470 Step: 00062500] Batch Recognition Loss:   0.000186 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   1.383073 => Txt Tokens per Sec:     3944 || Lr: 0.000100
2024-02-03 04:54:19,674 Epoch 470: Total Training Recognition Loss 3.87  Total Training Translation Loss 19.28 
2024-02-03 04:54:19,674 EPOCH 471
2024-02-03 04:54:24,670 [Epoch: 471 Step: 00062600] Batch Recognition Loss:   0.000875 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.033950 => Txt Tokens per Sec:     3972 || Lr: 0.000100
2024-02-03 04:54:27,257 Epoch 471: Total Training Recognition Loss 4.95  Total Training Translation Loss 19.06 
2024-02-03 04:54:27,258 EPOCH 472
2024-02-03 04:54:30,524 [Epoch: 472 Step: 00062700] Batch Recognition Loss:   0.000639 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.113139 => Txt Tokens per Sec:     3929 || Lr: 0.000100
2024-02-03 04:54:34,777 Epoch 472: Total Training Recognition Loss 0.99  Total Training Translation Loss 17.74 
2024-02-03 04:54:34,777 EPOCH 473
2024-02-03 04:54:35,809 [Epoch: 473 Step: 00062800] Batch Recognition Loss:   0.000950 => Gls Tokens per Sec:     1863 || Batch Translation Loss:   0.017579 => Txt Tokens per Sec:     4907 || Lr: 0.000100
2024-02-03 04:54:41,386 [Epoch: 473 Step: 00062900] Batch Recognition Loss:   0.000820 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.038399 => Txt Tokens per Sec:     4026 || Lr: 0.000100
2024-02-03 04:54:41,911 Epoch 473: Total Training Recognition Loss 0.52  Total Training Translation Loss 10.33 
2024-02-03 04:54:41,911 EPOCH 474
2024-02-03 04:54:47,071 [Epoch: 474 Step: 00063000] Batch Recognition Loss:   0.000508 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.050046 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-03 04:54:49,712 Epoch 474: Total Training Recognition Loss 0.31  Total Training Translation Loss 8.36 
2024-02-03 04:54:49,712 EPOCH 475
2024-02-03 04:54:52,832 [Epoch: 475 Step: 00063100] Batch Recognition Loss:   0.000380 => Gls Tokens per Sec:     1488 || Batch Translation Loss:   0.008101 => Txt Tokens per Sec:     4047 || Lr: 0.000100
2024-02-03 04:54:56,778 Epoch 475: Total Training Recognition Loss 0.37  Total Training Translation Loss 8.39 
2024-02-03 04:54:56,778 EPOCH 476
2024-02-03 04:54:58,194 [Epoch: 476 Step: 00063200] Batch Recognition Loss:   0.001039 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.100522 => Txt Tokens per Sec:     3836 || Lr: 0.000100
2024-02-03 04:55:03,369 [Epoch: 476 Step: 00063300] Batch Recognition Loss:   0.008336 => Gls Tokens per Sec:     1544 || Batch Translation Loss:   0.040815 => Txt Tokens per Sec:     4319 || Lr: 0.000100
2024-02-03 04:55:03,919 Epoch 476: Total Training Recognition Loss 0.27  Total Training Translation Loss 10.61 
2024-02-03 04:55:03,919 EPOCH 477
2024-02-03 04:55:09,268 [Epoch: 477 Step: 00063400] Batch Recognition Loss:   0.000700 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.162057 => Txt Tokens per Sec:     3861 || Lr: 0.000100
2024-02-03 04:55:11,664 Epoch 477: Total Training Recognition Loss 0.26  Total Training Translation Loss 11.21 
2024-02-03 04:55:11,664 EPOCH 478
2024-02-03 04:55:15,092 [Epoch: 478 Step: 00063500] Batch Recognition Loss:   0.008715 => Gls Tokens per Sec:     1377 || Batch Translation Loss:   0.036712 => Txt Tokens per Sec:     3800 || Lr: 0.000100
2024-02-03 04:55:19,326 Epoch 478: Total Training Recognition Loss 0.23  Total Training Translation Loss 14.85 
2024-02-03 04:55:19,326 EPOCH 479
2024-02-03 04:55:20,510 [Epoch: 479 Step: 00063600] Batch Recognition Loss:   0.000986 => Gls Tokens per Sec:     1759 || Batch Translation Loss:   0.018368 => Txt Tokens per Sec:     4493 || Lr: 0.000100
2024-02-03 04:55:26,518 [Epoch: 479 Step: 00063700] Batch Recognition Loss:   0.001553 => Gls Tokens per Sec:     1330 || Batch Translation Loss:   0.204207 => Txt Tokens per Sec:     3811 || Lr: 0.000100
2024-02-03 04:55:26,851 Epoch 479: Total Training Recognition Loss 0.26  Total Training Translation Loss 15.98 
2024-02-03 04:55:26,852 EPOCH 480
2024-02-03 04:55:32,233 [Epoch: 480 Step: 00063800] Batch Recognition Loss:   0.006903 => Gls Tokens per Sec:     1383 || Batch Translation Loss:   0.063505 => Txt Tokens per Sec:     3880 || Lr: 0.000100
2024-02-03 04:55:34,669 Epoch 480: Total Training Recognition Loss 0.33  Total Training Translation Loss 9.57 
2024-02-03 04:55:34,669 EPOCH 481
2024-02-03 04:55:38,224 [Epoch: 481 Step: 00063900] Batch Recognition Loss:   0.003425 => Gls Tokens per Sec:     1351 || Batch Translation Loss:   0.046435 => Txt Tokens per Sec:     3822 || Lr: 0.000100
2024-02-03 04:55:42,115 Epoch 481: Total Training Recognition Loss 0.28  Total Training Translation Loss 17.12 
2024-02-03 04:55:42,115 EPOCH 482
2024-02-03 04:55:43,406 [Epoch: 482 Step: 00064000] Batch Recognition Loss:   0.005956 => Gls Tokens per Sec:     1677 || Batch Translation Loss:   0.071868 => Txt Tokens per Sec:     4756 || Lr: 0.000100
2024-02-03 04:55:54,183 Validation result at epoch 482, step    64000: duration: 10.7773s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.26116	Translation Loss: 90024.93750	PPL: 11502.56738
	Eval Metric: BLEU
	WER 3.32	(DEL: 0.07,	INS: 0.00,	SUB: 3.25)
	BLEU-4 0.51	(BLEU-1: 10.18,	BLEU-2: 2.97,	BLEU-3: 1.15,	BLEU-4: 0.51)
	CHRF 16.03	ROUGE 8.32
2024-02-03 04:55:54,184 Logging Recognition and Translation Outputs
2024-02-03 04:55:54,184 ========================================================================================================================
2024-02-03 04:55:54,184 Logging Sequence: 136_107.00
2024-02-03 04:55:54,184 	Gloss Reference :	A B+C+D+E
2024-02-03 04:55:54,184 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:55:54,185 	Gloss Alignment :	         
2024-02-03 04:55:54,185 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:55:54,186 	Text Reference  :	** *** ****** ***** sindhu  replied that she   had    stop        eating  icecream because of ** **** ** her training
2024-02-03 04:55:54,186 	Text Hypothesis :	in the paltry chase shubman gill    and  ishan kishan comfortably reached the      target  of 51 runs in 61  overs   
2024-02-03 04:55:54,186 	Text Alignment  :	I  I   I      I     S       S       S    S     S      S           S       S        S          I  I    I  S   S       
2024-02-03 04:55:54,186 ========================================================================================================================
2024-02-03 04:55:54,187 Logging Sequence: 59_152.00
2024-02-03 04:55:54,187 	Gloss Reference :	A B+C+D+E
2024-02-03 04:55:54,187 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:55:54,187 	Gloss Alignment :	         
2024-02-03 04:55:54,187 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:55:54,188 	Text Reference  :	the organisers encouraged athletes to use   the condoms in        their  home countries
2024-02-03 04:55:54,188 	Text Hypothesis :	*** sharma     will       visit    a  video on  a       september during the  finals   
2024-02-03 04:55:54,188 	Text Alignment  :	D   S          S          S        S  S     S   S       S         S      S    S        
2024-02-03 04:55:54,188 ========================================================================================================================
2024-02-03 04:55:54,189 Logging Sequence: 52_36.00
2024-02-03 04:55:54,189 	Gloss Reference :	A B+C+D+E
2024-02-03 04:55:54,189 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:55:54,189 	Gloss Alignment :	         
2024-02-03 04:55:54,189 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:55:54,190 	Text Reference  :	** ******** ** recently dhoni *** **** ********* ** ****** was     travellin on   an      indigo  flight
2024-02-03 04:55:54,190 	Text Hypothesis :	in response to dhoni    dhoni has been captaincy in mumbai indians and       were amazing bowling attack
2024-02-03 04:55:54,190 	Text Alignment  :	I  I        I  S              I   I    I         I  I      S       S         S    S       S       S     
2024-02-03 04:55:54,190 ========================================================================================================================
2024-02-03 04:55:54,190 Logging Sequence: 91_142.00
2024-02-03 04:55:54,191 	Gloss Reference :	A B+C+D+E    
2024-02-03 04:55:54,191 	Gloss Hypothesis:	A B+E+B+E+C+D
2024-02-03 04:55:54,191 	Gloss Alignment :	  S          
2024-02-03 04:55:54,191 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:55:54,192 	Text Reference  :	the ****** **** ** ** icc has  penalised kaur  by        deducting 75    of  her match ******* *** ***** fee     
2024-02-03 04:55:54,192 	Text Hypothesis :	the images went on to be  held in        these wrestlers -         there are a   match between the covid pandemic
2024-02-03 04:55:54,193 	Text Alignment  :	    I      I    I  I  S   S    S         S     S         S         S     S   S         I       I   I     S       
2024-02-03 04:55:54,193 ========================================================================================================================
2024-02-03 04:55:54,193 Logging Sequence: 134_54.00
2024-02-03 04:55:54,193 	Gloss Reference :	A B+C+D+E
2024-02-03 04:55:54,193 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:55:54,193 	Gloss Alignment :	         
2024-02-03 04:55:54,193 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:55:54,194 	Text Reference  :	**** ** *** * the  news    went viral   
2024-02-03 04:55:54,194 	Text Hypothesis :	this is why i have decided to   withdraw
2024-02-03 04:55:54,194 	Text Alignment  :	I    I  I   I S    S       S    S       
2024-02-03 04:55:54,194 ========================================================================================================================
2024-02-03 04:55:59,906 [Epoch: 482 Step: 00064100] Batch Recognition Loss:   0.000586 => Gls Tokens per Sec:     1396 || Batch Translation Loss:   0.231630 => Txt Tokens per Sec:     3865 || Lr: 0.000100
2024-02-03 04:56:00,242 Epoch 482: Total Training Recognition Loss 0.37  Total Training Translation Loss 19.60 
2024-02-03 04:56:00,242 EPOCH 483
2024-02-03 04:56:05,300 [Epoch: 483 Step: 00064200] Batch Recognition Loss:   0.000708 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.035964 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-03 04:56:07,559 Epoch 483: Total Training Recognition Loss 0.39  Total Training Translation Loss 12.13 
2024-02-03 04:56:07,559 EPOCH 484
2024-02-03 04:56:10,988 [Epoch: 484 Step: 00064300] Batch Recognition Loss:   0.000267 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.075436 => Txt Tokens per Sec:     3952 || Lr: 0.000100
2024-02-03 04:56:15,367 Epoch 484: Total Training Recognition Loss 0.23  Total Training Translation Loss 9.50 
2024-02-03 04:56:15,367 EPOCH 485
2024-02-03 04:56:16,793 [Epoch: 485 Step: 00064400] Batch Recognition Loss:   0.000697 => Gls Tokens per Sec:     1572 || Batch Translation Loss:   0.033582 => Txt Tokens per Sec:     4280 || Lr: 0.000100
2024-02-03 04:56:22,226 [Epoch: 485 Step: 00064500] Batch Recognition Loss:   0.003289 => Gls Tokens per Sec:     1471 || Batch Translation Loss:   0.020984 => Txt Tokens per Sec:     4115 || Lr: 0.000100
2024-02-03 04:56:22,528 Epoch 485: Total Training Recognition Loss 0.21  Total Training Translation Loss 7.73 
2024-02-03 04:56:22,529 EPOCH 486
2024-02-03 04:56:28,015 [Epoch: 486 Step: 00064600] Batch Recognition Loss:   0.000966 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.193174 => Txt Tokens per Sec:     3878 || Lr: 0.000100
2024-02-03 04:56:30,002 Epoch 486: Total Training Recognition Loss 0.26  Total Training Translation Loss 10.56 
2024-02-03 04:56:30,002 EPOCH 487
2024-02-03 04:56:33,222 [Epoch: 487 Step: 00064700] Batch Recognition Loss:   0.006285 => Gls Tokens per Sec:     1541 || Batch Translation Loss:   0.016563 => Txt Tokens per Sec:     4261 || Lr: 0.000100
2024-02-03 04:56:37,014 Epoch 487: Total Training Recognition Loss 0.28  Total Training Translation Loss 9.10 
2024-02-03 04:56:37,015 EPOCH 488
2024-02-03 04:56:38,624 [Epoch: 488 Step: 00064800] Batch Recognition Loss:   0.000167 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.032263 => Txt Tokens per Sec:     4200 || Lr: 0.000100
2024-02-03 04:56:44,179 [Epoch: 488 Step: 00064900] Batch Recognition Loss:   0.000293 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.051220 => Txt Tokens per Sec:     3956 || Lr: 0.000100
2024-02-03 04:56:44,405 Epoch 488: Total Training Recognition Loss 0.26  Total Training Translation Loss 15.69 
2024-02-03 04:56:44,405 EPOCH 489
2024-02-03 04:56:49,698 [Epoch: 489 Step: 00065000] Batch Recognition Loss:   0.007623 => Gls Tokens per Sec:     1451 || Batch Translation Loss:   0.079185 => Txt Tokens per Sec:     4036 || Lr: 0.000100
2024-02-03 04:56:52,015 Epoch 489: Total Training Recognition Loss 0.26  Total Training Translation Loss 18.99 
2024-02-03 04:56:52,016 EPOCH 490
2024-02-03 04:56:55,276 [Epoch: 490 Step: 00065100] Batch Recognition Loss:   0.000940 => Gls Tokens per Sec:     1547 || Batch Translation Loss:   0.058245 => Txt Tokens per Sec:     4069 || Lr: 0.000100
2024-02-03 04:56:59,519 Epoch 490: Total Training Recognition Loss 0.36  Total Training Translation Loss 15.52 
2024-02-03 04:56:59,519 EPOCH 491
2024-02-03 04:57:01,098 [Epoch: 491 Step: 00065200] Batch Recognition Loss:   0.000603 => Gls Tokens per Sec:     1521 || Batch Translation Loss:   0.091669 => Txt Tokens per Sec:     4076 || Lr: 0.000100
2024-02-03 04:57:06,538 [Epoch: 491 Step: 00065300] Batch Recognition Loss:   0.001719 => Gls Tokens per Sec:     1469 || Batch Translation Loss:   0.043109 => Txt Tokens per Sec:     4137 || Lr: 0.000100
2024-02-03 04:57:06,688 Epoch 491: Total Training Recognition Loss 0.38  Total Training Translation Loss 15.77 
2024-02-03 04:57:06,688 EPOCH 492
2024-02-03 04:57:12,400 [Epoch: 492 Step: 00065400] Batch Recognition Loss:   0.000194 => Gls Tokens per Sec:     1359 || Batch Translation Loss:   0.038195 => Txt Tokens per Sec:     3777 || Lr: 0.000100
2024-02-03 04:57:14,421 Epoch 492: Total Training Recognition Loss 0.28  Total Training Translation Loss 13.80 
2024-02-03 04:57:14,421 EPOCH 493
2024-02-03 04:57:18,015 [Epoch: 493 Step: 00065500] Batch Recognition Loss:   0.001201 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.069354 => Txt Tokens per Sec:     3914 || Lr: 0.000100
2024-02-03 04:57:22,146 Epoch 493: Total Training Recognition Loss 0.34  Total Training Translation Loss 19.32 
2024-02-03 04:57:22,147 EPOCH 494
2024-02-03 04:57:23,897 [Epoch: 494 Step: 00065600] Batch Recognition Loss:   0.000219 => Gls Tokens per Sec:     1417 || Batch Translation Loss:   0.049506 => Txt Tokens per Sec:     3991 || Lr: 0.000100
2024-02-03 04:57:29,731 [Epoch: 494 Step: 00065700] Batch Recognition Loss:   0.000493 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.030839 => Txt Tokens per Sec:     3793 || Lr: 0.000100
2024-02-03 04:57:29,827 Epoch 494: Total Training Recognition Loss 0.24  Total Training Translation Loss 7.51 
2024-02-03 04:57:29,827 EPOCH 495
2024-02-03 04:57:34,959 [Epoch: 495 Step: 00065800] Batch Recognition Loss:   0.000353 => Gls Tokens per Sec:     1528 || Batch Translation Loss:   0.065354 => Txt Tokens per Sec:     4273 || Lr: 0.000100
2024-02-03 04:57:37,337 Epoch 495: Total Training Recognition Loss 0.22  Total Training Translation Loss 7.82 
2024-02-03 04:57:37,338 EPOCH 496
2024-02-03 04:57:41,167 [Epoch: 496 Step: 00065900] Batch Recognition Loss:   0.000441 => Gls Tokens per Sec:     1358 || Batch Translation Loss:   0.018585 => Txt Tokens per Sec:     3698 || Lr: 0.000100
2024-02-03 04:57:44,982 Epoch 496: Total Training Recognition Loss 0.16  Total Training Translation Loss 7.52 
2024-02-03 04:57:44,983 EPOCH 497
2024-02-03 04:57:46,617 [Epoch: 497 Step: 00066000] Batch Recognition Loss:   0.001487 => Gls Tokens per Sec:     1567 || Batch Translation Loss:   0.022371 => Txt Tokens per Sec:     4485 || Lr: 0.000100
2024-02-03 04:57:57,403 Validation result at epoch 497, step    66000: duration: 10.7849s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.39680	Translation Loss: 88625.75781	PPL: 9946.75684
	Eval Metric: BLEU
	WER 3.75	(DEL: 0.14,	INS: 0.00,	SUB: 3.61)
	BLEU-4 0.52	(BLEU-1: 10.14,	BLEU-2: 2.72,	BLEU-3: 1.00,	BLEU-4: 0.52)
	CHRF 16.59	ROUGE 8.60
2024-02-03 04:57:57,404 Logging Recognition and Translation Outputs
2024-02-03 04:57:57,405 ========================================================================================================================
2024-02-03 04:57:57,405 Logging Sequence: 60_85.00
2024-02-03 04:57:57,405 	Gloss Reference :	A B+C+D+E
2024-02-03 04:57:57,405 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:57:57,405 	Gloss Alignment :	         
2024-02-03 04:57:57,405 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:57:57,407 	Text Reference  :	he had a  medical history of    asthma and some heart issues which is why he passed away so  quickly
2024-02-03 04:57:57,407 	Text Hypothesis :	** let me tell    you     about him    and **** ***** ****** that  is *** ** ****** how  see him    
2024-02-03 04:57:57,407 	Text Alignment  :	D  S   S  S       S       S     S          D    D     D      S        D   D  D      S    S   S      
2024-02-03 04:57:57,407 ========================================================================================================================
2024-02-03 04:57:57,407 Logging Sequence: 72_59.00
2024-02-03 04:57:57,407 	Gloss Reference :	A B+C+D+E
2024-02-03 04:57:57,408 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:57:57,408 	Gloss Alignment :	         
2024-02-03 04:57:57,408 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:57:57,409 	Text Reference  :	after that sapna and ******* *** ** **** ******** ******* shobit  started arguing and   misbehaving with the cricketer
2024-02-03 04:57:57,409 	Text Hypothesis :	***** then kohli and gambhir had an huge argument however exactly what    was     being said        is   not known    
2024-02-03 04:57:57,409 	Text Alignment  :	D     S    S         I       I   I  I    I        I       S       S       S       S     S           S    S   S        
2024-02-03 04:57:57,409 ========================================================================================================================
2024-02-03 04:57:57,409 Logging Sequence: 133_77.00
2024-02-03 04:57:57,410 	Gloss Reference :	A B+C+D+E
2024-02-03 04:57:57,410 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:57:57,410 	Gloss Alignment :	         
2024-02-03 04:57:57,410 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:57:57,411 	Text Reference  :	the group then  welcomed australian prime minister anthony albanese on his           arrival       
2024-02-03 04:57:57,411 	Text Hypothesis :	*** ***** which means    pant       would be       the     face     of uttarakhand's advertisements
2024-02-03 04:57:57,411 	Text Alignment  :	D   D     S     S        S          S     S        S       S        S  S             S             
2024-02-03 04:57:57,411 ========================================================================================================================
2024-02-03 04:57:57,411 Logging Sequence: 130_114.00
2024-02-03 04:57:57,412 	Gloss Reference :	A B+C+D+E
2024-02-03 04:57:57,412 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:57:57,412 	Gloss Alignment :	         
2024-02-03 04:57:57,412 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:57:57,412 	Text Reference  :	images of him  knitting  went viral
2024-02-03 04:57:57,413 	Text Hypothesis :	****** he then proceeded to   talk 
2024-02-03 04:57:57,413 	Text Alignment  :	D      S  S    S         S    S    
2024-02-03 04:57:57,413 ========================================================================================================================
2024-02-03 04:57:57,413 Logging Sequence: 173_107.00
2024-02-03 04:57:57,413 	Gloss Reference :	A B+C+D+E
2024-02-03 04:57:57,413 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 04:57:57,413 	Gloss Alignment :	         
2024-02-03 04:57:57,414 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 04:57:57,414 	Text Reference  :	india and england were set to play a        5-match test  series
2024-02-03 04:57:57,414 	Text Hypothesis :	***** *** i       was  not at all  stressed and     south africa
2024-02-03 04:57:57,414 	Text Alignment  :	D     D   S       S    S   S  S    S        S       S     S     
2024-02-03 04:57:57,415 ========================================================================================================================
2024-02-03 04:58:03,254 [Epoch: 497 Step: 00066100] Batch Recognition Loss:   0.000648 => Gls Tokens per Sec:     1366 || Batch Translation Loss:   0.037794 => Txt Tokens per Sec:     3759 || Lr: 0.000100
2024-02-03 04:58:03,312 Epoch 497: Total Training Recognition Loss 0.23  Total Training Translation Loss 8.72 
2024-02-03 04:58:03,312 EPOCH 498
2024-02-03 04:58:08,793 [Epoch: 498 Step: 00066200] Batch Recognition Loss:   0.001640 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.035067 => Txt Tokens per Sec:     4018 || Lr: 0.000100
2024-02-03 04:58:10,870 Epoch 498: Total Training Recognition Loss 0.27  Total Training Translation Loss 16.05 
2024-02-03 04:58:10,871 EPOCH 499
2024-02-03 04:58:14,738 [Epoch: 499 Step: 00066300] Batch Recognition Loss:   0.001039 => Gls Tokens per Sec:     1366 || Batch Translation Loss:   0.119430 => Txt Tokens per Sec:     3830 || Lr: 0.000100
2024-02-03 04:58:18,550 Epoch 499: Total Training Recognition Loss 0.41  Total Training Translation Loss 18.51 
2024-02-03 04:58:18,550 EPOCH 500
2024-02-03 04:58:20,484 [Epoch: 500 Step: 00066400] Batch Recognition Loss:   0.004188 => Gls Tokens per Sec:     1365 || Batch Translation Loss:   0.068360 => Txt Tokens per Sec:     3875 || Lr: 0.000100
2024-02-03 04:58:25,996 [Epoch: 500 Step: 00066500] Batch Recognition Loss:   0.000521 => Gls Tokens per Sec:     1450 || Batch Translation Loss:   0.045436 => Txt Tokens per Sec:     4005 || Lr: 0.000100
2024-02-03 04:58:25,996 Epoch 500: Total Training Recognition Loss 0.29  Total Training Translation Loss 17.78 
2024-02-03 04:58:25,996 EPOCH 501
2024-02-03 04:58:31,549 [Epoch: 501 Step: 00066600] Batch Recognition Loss:   0.001268 => Gls Tokens per Sec:     1441 || Batch Translation Loss:   0.176783 => Txt Tokens per Sec:     4015 || Lr: 0.000100
2024-02-03 04:58:33,452 Epoch 501: Total Training Recognition Loss 0.44  Total Training Translation Loss 20.94 
2024-02-03 04:58:33,452 EPOCH 502
2024-02-03 04:58:37,018 [Epoch: 502 Step: 00066700] Batch Recognition Loss:   0.000809 => Gls Tokens per Sec:     1504 || Batch Translation Loss:   0.032242 => Txt Tokens per Sec:     4184 || Lr: 0.000100
2024-02-03 04:58:40,818 Epoch 502: Total Training Recognition Loss 0.33  Total Training Translation Loss 13.23 
2024-02-03 04:58:40,818 EPOCH 503
2024-02-03 04:58:42,489 [Epoch: 503 Step: 00066800] Batch Recognition Loss:   0.007523 => Gls Tokens per Sec:     1629 || Batch Translation Loss:   0.056194 => Txt Tokens per Sec:     4376 || Lr: 0.000100
2024-02-03 04:58:47,888 Epoch 503: Total Training Recognition Loss 0.31  Total Training Translation Loss 9.10 
2024-02-03 04:58:47,889 EPOCH 504
2024-02-03 04:58:47,950 [Epoch: 504 Step: 00066900] Batch Recognition Loss:   0.002207 => Gls Tokens per Sec:     1333 || Batch Translation Loss:   0.025228 => Txt Tokens per Sec:     4400 || Lr: 0.000100
2024-02-03 04:58:53,848 [Epoch: 504 Step: 00067000] Batch Recognition Loss:   0.000238 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.019949 => Txt Tokens per Sec:     3788 || Lr: 0.000100
2024-02-03 04:58:55,882 Epoch 504: Total Training Recognition Loss 0.19  Total Training Translation Loss 8.92 
2024-02-03 04:58:55,882 EPOCH 505
2024-02-03 04:58:59,667 [Epoch: 505 Step: 00067100] Batch Recognition Loss:   0.000201 => Gls Tokens per Sec:     1438 || Batch Translation Loss:   0.043461 => Txt Tokens per Sec:     3948 || Lr: 0.000100
2024-02-03 04:59:03,030 Epoch 505: Total Training Recognition Loss 0.25  Total Training Translation Loss 5.75 
2024-02-03 04:59:03,030 EPOCH 506
2024-02-03 04:59:04,854 [Epoch: 506 Step: 00067200] Batch Recognition Loss:   0.000129 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   0.015612 => Txt Tokens per Sec:     4271 || Lr: 0.000100
2024-02-03 04:59:09,716 Epoch 506: Total Training Recognition Loss 0.29  Total Training Translation Loss 6.62 
2024-02-03 04:59:09,717 EPOCH 507
2024-02-03 04:59:09,824 [Epoch: 507 Step: 00067300] Batch Recognition Loss:   0.000706 => Gls Tokens per Sec:     1509 || Batch Translation Loss:   0.060793 => Txt Tokens per Sec:     5132 || Lr: 0.000100
2024-02-03 04:59:15,362 [Epoch: 507 Step: 00067400] Batch Recognition Loss:   0.343670 => Gls Tokens per Sec:     1443 || Batch Translation Loss:   0.046228 => Txt Tokens per Sec:     4017 || Lr: 0.000100
2024-02-03 04:59:17,152 Epoch 507: Total Training Recognition Loss 1.36  Total Training Translation Loss 10.13 
2024-02-03 04:59:17,152 EPOCH 508
2024-02-03 04:59:21,154 [Epoch: 508 Step: 00067500] Batch Recognition Loss:   0.000249 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.064580 => Txt Tokens per Sec:     3859 || Lr: 0.000100
2024-02-03 04:59:24,780 Epoch 508: Total Training Recognition Loss 1.05  Total Training Translation Loss 17.33 
2024-02-03 04:59:24,780 EPOCH 509
2024-02-03 04:59:26,487 [Epoch: 509 Step: 00067600] Batch Recognition Loss:   0.000497 => Gls Tokens per Sec:     1688 || Batch Translation Loss:   0.026785 => Txt Tokens per Sec:     4756 || Lr: 0.000100
2024-02-03 04:59:31,801 Epoch 509: Total Training Recognition Loss 0.67  Total Training Translation Loss 13.81 
2024-02-03 04:59:31,801 EPOCH 510
2024-02-03 04:59:31,940 [Epoch: 510 Step: 00067700] Batch Recognition Loss:   0.000144 => Gls Tokens per Sec:     1736 || Batch Translation Loss:   0.027829 => Txt Tokens per Sec:     4426 || Lr: 0.000100
2024-02-03 04:59:37,608 [Epoch: 510 Step: 00067800] Batch Recognition Loss:   0.000238 => Gls Tokens per Sec:     1412 || Batch Translation Loss:   0.057791 => Txt Tokens per Sec:     3917 || Lr: 0.000100
2024-02-03 04:59:39,402 Epoch 510: Total Training Recognition Loss 0.42  Total Training Translation Loss 13.37 
2024-02-03 04:59:39,402 EPOCH 511
2024-02-03 04:59:43,176 [Epoch: 511 Step: 00067900] Batch Recognition Loss:   0.000367 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.046129 => Txt Tokens per Sec:     4128 || Lr: 0.000100
2024-02-03 04:59:46,751 Epoch 511: Total Training Recognition Loss 0.41  Total Training Translation Loss 16.68 
2024-02-03 04:59:46,752 EPOCH 512
2024-02-03 04:59:49,034 [Epoch: 512 Step: 00068000] Batch Recognition Loss:   0.034951 => Gls Tokens per Sec:     1297 || Batch Translation Loss:   0.083110 => Txt Tokens per Sec:     3503 || Lr: 0.000100
2024-02-03 05:00:01,184 Validation result at epoch 512, step    68000: duration: 12.1491s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.48166	Translation Loss: 88305.05469	PPL: 9620.88770
	Eval Metric: BLEU
	WER 3.18	(DEL: 0.21,	INS: 0.00,	SUB: 2.97)
	BLEU-4 0.60	(BLEU-1: 10.21,	BLEU-2: 2.95,	BLEU-3: 1.20,	BLEU-4: 0.60)
	CHRF 16.65	ROUGE 8.30
2024-02-03 05:00:01,185 Logging Recognition and Translation Outputs
2024-02-03 05:00:01,185 ========================================================================================================================
2024-02-03 05:00:01,185 Logging Sequence: 180_546.00
2024-02-03 05:00:01,185 	Gloss Reference :	A B+C+D+E
2024-02-03 05:00:01,185 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:00:01,186 	Gloss Alignment :	         
2024-02-03 05:00:01,186 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:00:01,187 	Text Reference  :	they are also demanding that   the  report    of the oc    be   made public
2024-02-03 05:00:01,187 	Text Hypothesis :	**** *** **** was       packed with thousands of *** overs must go   waste 
2024-02-03 05:00:01,187 	Text Alignment  :	D    D   D    S         S      S    S            D   S     S    S    S     
2024-02-03 05:00:01,187 ========================================================================================================================
2024-02-03 05:00:01,187 Logging Sequence: 142_148.00
2024-02-03 05:00:01,187 	Gloss Reference :	A B+C+D+E
2024-02-03 05:00:01,187 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:00:01,188 	Gloss Alignment :	         
2024-02-03 05:00:01,188 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:00:01,189 	Text Reference  :	now on the 10th november 2022 india is * set to play   england in       the      semi-final
2024-02-03 05:00:01,189 	Text Hypothesis :	*** ** *** **** ******** **** there is a lot of social media   comments comments below     
2024-02-03 05:00:01,189 	Text Alignment  :	D   D  D   D    D        D    S        I S   S  S      S       S        S        S         
2024-02-03 05:00:01,189 ========================================================================================================================
2024-02-03 05:00:01,189 Logging Sequence: 118_46.00
2024-02-03 05:00:01,189 	Gloss Reference :	A B+C+D+E
2024-02-03 05:00:01,189 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:00:01,190 	Gloss Alignment :	         
2024-02-03 05:00:01,190 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:00:01,191 	Text Reference  :	since there    was  a  tie  the ******* match went    into the penalty shootout where each team gets a chance    to  score 5   times    
2024-02-03 05:00:01,192 	Text Hypothesis :	***** armbands were to show the support and   respect to   the ******* ******** ***** **** **** **** * community the ban   was incorrect
2024-02-03 05:00:01,192 	Text Alignment  :	D     S        S    S  S        I       S     S       S        D       D        D     D    D    D    D S         S   S     S   S        
2024-02-03 05:00:01,192 ========================================================================================================================
2024-02-03 05:00:01,192 Logging Sequence: 180_345.00
2024-02-03 05:00:01,192 	Gloss Reference :	A B+C+D+E
2024-02-03 05:00:01,192 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:00:01,192 	Gloss Alignment :	         
2024-02-03 05:00:01,193 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:00:01,193 	Text Reference  :	********* i  haven't done  anything
2024-02-03 05:00:01,193 	Text Hypothesis :	according to what    singh agreed  
2024-02-03 05:00:01,193 	Text Alignment  :	I         S  S       S     S       
2024-02-03 05:00:01,193 ========================================================================================================================
2024-02-03 05:00:01,193 Logging Sequence: 108_138.00
2024-02-03 05:00:01,193 	Gloss Reference :	A B+C+D+E
2024-02-03 05:00:01,194 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:00:01,194 	Gloss Alignment :	         
2024-02-03 05:00:01,194 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:00:01,195 	Text Reference  :	****** *** ****** ******* ** ***** khan  is   an uncapped player   who  has   only played domestic   cricket
2024-02-03 05:00:01,195 	Text Hypothesis :	hardik and natasa decided to renew their vows on 14th     february 2023 since it   was    valentines day    
2024-02-03 05:00:01,195 	Text Alignment  :	I      I   I      I       I  I     S     S    S  S        S        S    S     S    S      S          S      
2024-02-03 05:00:01,195 ========================================================================================================================
2024-02-03 05:00:06,786 Epoch 512: Total Training Recognition Loss 0.35  Total Training Translation Loss 10.51 
2024-02-03 05:00:06,787 EPOCH 513
2024-02-03 05:00:07,013 [Epoch: 513 Step: 00068100] Batch Recognition Loss:   0.001781 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.165212 => Txt Tokens per Sec:     4120 || Lr: 0.000100
2024-02-03 05:00:12,825 [Epoch: 513 Step: 00068200] Batch Recognition Loss:   0.002832 => Gls Tokens per Sec:     1376 || Batch Translation Loss:   0.007594 => Txt Tokens per Sec:     3830 || Lr: 0.000100
2024-02-03 05:00:14,610 Epoch 513: Total Training Recognition Loss 0.20  Total Training Translation Loss 11.16 
2024-02-03 05:00:14,610 EPOCH 514
2024-02-03 05:00:18,668 [Epoch: 514 Step: 00068300] Batch Recognition Loss:   0.001710 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.011962 => Txt Tokens per Sec:     3995 || Lr: 0.000100
2024-02-03 05:00:22,315 Epoch 514: Total Training Recognition Loss 0.24  Total Training Translation Loss 9.48 
2024-02-03 05:00:22,316 EPOCH 515
2024-02-03 05:00:24,540 [Epoch: 515 Step: 00068400] Batch Recognition Loss:   0.000660 => Gls Tokens per Sec:     1368 || Batch Translation Loss:   0.009918 => Txt Tokens per Sec:     3790 || Lr: 0.000100
2024-02-03 05:00:29,731 Epoch 515: Total Training Recognition Loss 0.21  Total Training Translation Loss 10.53 
2024-02-03 05:00:29,732 EPOCH 516
2024-02-03 05:00:29,983 [Epoch: 516 Step: 00068500] Batch Recognition Loss:   0.004521 => Gls Tokens per Sec:     1600 || Batch Translation Loss:   0.111160 => Txt Tokens per Sec:     4416 || Lr: 0.000100
2024-02-03 05:00:35,942 [Epoch: 516 Step: 00068600] Batch Recognition Loss:   0.000271 => Gls Tokens per Sec:     1343 || Batch Translation Loss:   0.175805 => Txt Tokens per Sec:     3771 || Lr: 0.000100
2024-02-03 05:00:37,678 Epoch 516: Total Training Recognition Loss 0.21  Total Training Translation Loss 6.86 
2024-02-03 05:00:37,678 EPOCH 517
2024-02-03 05:00:41,857 [Epoch: 517 Step: 00068700] Batch Recognition Loss:   0.000780 => Gls Tokens per Sec:     1379 || Batch Translation Loss:   0.021298 => Txt Tokens per Sec:     3850 || Lr: 0.000100
2024-02-03 05:00:45,245 Epoch 517: Total Training Recognition Loss 0.27  Total Training Translation Loss 11.79 
2024-02-03 05:00:45,246 EPOCH 518
2024-02-03 05:00:47,035 [Epoch: 518 Step: 00068800] Batch Recognition Loss:   0.000738 => Gls Tokens per Sec:     1744 || Batch Translation Loss:   0.048484 => Txt Tokens per Sec:     4760 || Lr: 0.000100
2024-02-03 05:00:52,535 Epoch 518: Total Training Recognition Loss 0.29  Total Training Translation Loss 19.28 
2024-02-03 05:00:52,536 EPOCH 519
2024-02-03 05:00:52,843 [Epoch: 519 Step: 00068900] Batch Recognition Loss:   0.001057 => Gls Tokens per Sec:     1573 || Batch Translation Loss:   0.272678 => Txt Tokens per Sec:     4205 || Lr: 0.000100
2024-02-03 05:00:57,949 [Epoch: 519 Step: 00069000] Batch Recognition Loss:   0.000528 => Gls Tokens per Sec:     1567 || Batch Translation Loss:   0.086659 => Txt Tokens per Sec:     4381 || Lr: 0.000100
2024-02-03 05:00:59,622 Epoch 519: Total Training Recognition Loss 0.31  Total Training Translation Loss 20.51 
2024-02-03 05:00:59,623 EPOCH 520
2024-02-03 05:01:03,739 [Epoch: 520 Step: 00069100] Batch Recognition Loss:   0.000270 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.028044 => Txt Tokens per Sec:     3969 || Lr: 0.000100
2024-02-03 05:01:06,937 Epoch 520: Total Training Recognition Loss 0.24  Total Training Translation Loss 14.90 
2024-02-03 05:01:06,937 EPOCH 521
2024-02-03 05:01:09,192 [Epoch: 521 Step: 00069200] Batch Recognition Loss:   0.012063 => Gls Tokens per Sec:     1419 || Batch Translation Loss:   0.063098 => Txt Tokens per Sec:     3972 || Lr: 0.000100
2024-02-03 05:01:14,408 Epoch 521: Total Training Recognition Loss 0.21  Total Training Translation Loss 13.19 
2024-02-03 05:01:14,408 EPOCH 522
2024-02-03 05:01:14,717 [Epoch: 522 Step: 00069300] Batch Recognition Loss:   0.000915 => Gls Tokens per Sec:     1818 || Batch Translation Loss:   0.033467 => Txt Tokens per Sec:     5140 || Lr: 0.000100
2024-02-03 05:01:20,245 [Epoch: 522 Step: 00069400] Batch Recognition Loss:   0.001902 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.207172 => Txt Tokens per Sec:     4006 || Lr: 0.000100
2024-02-03 05:01:21,760 Epoch 522: Total Training Recognition Loss 0.24  Total Training Translation Loss 15.71 
2024-02-03 05:01:21,761 EPOCH 523
2024-02-03 05:01:25,716 [Epoch: 523 Step: 00069500] Batch Recognition Loss:   0.005294 => Gls Tokens per Sec:     1497 || Batch Translation Loss:   0.033479 => Txt Tokens per Sec:     4116 || Lr: 0.000100
2024-02-03 05:01:29,413 Epoch 523: Total Training Recognition Loss 0.76  Total Training Translation Loss 13.67 
2024-02-03 05:01:29,413 EPOCH 524
2024-02-03 05:01:31,633 [Epoch: 524 Step: 00069600] Batch Recognition Loss:   0.000411 => Gls Tokens per Sec:     1479 || Batch Translation Loss:   0.038741 => Txt Tokens per Sec:     4080 || Lr: 0.000100
2024-02-03 05:01:36,648 Epoch 524: Total Training Recognition Loss 0.36  Total Training Translation Loss 8.75 
2024-02-03 05:01:36,649 EPOCH 525
2024-02-03 05:01:37,037 [Epoch: 525 Step: 00069700] Batch Recognition Loss:   0.000437 => Gls Tokens per Sec:     1654 || Batch Translation Loss:   0.046340 => Txt Tokens per Sec:     4447 || Lr: 0.000100
2024-02-03 05:01:42,736 [Epoch: 525 Step: 00069800] Batch Recognition Loss:   0.003810 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.015528 => Txt Tokens per Sec:     3921 || Lr: 0.000100
2024-02-03 05:01:44,288 Epoch 525: Total Training Recognition Loss 0.23  Total Training Translation Loss 7.20 
2024-02-03 05:01:44,289 EPOCH 526
2024-02-03 05:01:48,345 [Epoch: 526 Step: 00069900] Batch Recognition Loss:   0.000920 => Gls Tokens per Sec:     1479 || Batch Translation Loss:   0.018362 => Txt Tokens per Sec:     4012 || Lr: 0.000100
2024-02-03 05:01:51,537 Epoch 526: Total Training Recognition Loss 0.22  Total Training Translation Loss 5.01 
2024-02-03 05:01:51,537 EPOCH 527
2024-02-03 05:01:53,849 [Epoch: 527 Step: 00070000] Batch Recognition Loss:   0.000125 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.240035 => Txt Tokens per Sec:     3859 || Lr: 0.000100
2024-02-03 05:02:04,696 Validation result at epoch 527, step    70000: duration: 10.8465s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.49076	Translation Loss: 89882.75781	PPL: 11333.95020
	Eval Metric: BLEU
	WER 3.68	(DEL: 0.21,	INS: 0.00,	SUB: 3.47)
	BLEU-4 0.48	(BLEU-1: 10.03,	BLEU-2: 2.69,	BLEU-3: 0.95,	BLEU-4: 0.48)
	CHRF 16.83	ROUGE 8.34
2024-02-03 05:02:04,697 Logging Recognition and Translation Outputs
2024-02-03 05:02:04,697 ========================================================================================================================
2024-02-03 05:02:04,697 Logging Sequence: 65_115.00
2024-02-03 05:02:04,697 	Gloss Reference :	A B+C+D+E
2024-02-03 05:02:04,698 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:02:04,698 	Gloss Alignment :	         
2024-02-03 05:02:04,698 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:02:04,700 	Text Reference  :	***** *** *** the  direct flight  costing '‚¹35 crores from manchester england to    port       of spain west indies
2024-02-03 05:02:04,700 	Text Hypothesis :	india did not have a      reserve day     just  for    this super      four    match screenings in the   same day   
2024-02-03 05:02:04,700 	Text Alignment  :	I     I   I   S    S      S       S       S     S      S    S          S       S     S          S  S     S    S     
2024-02-03 05:02:04,700 ========================================================================================================================
2024-02-03 05:02:04,700 Logging Sequence: 124_134.00
2024-02-03 05:02:04,700 	Gloss Reference :	A B+C+D+E
2024-02-03 05:02:04,700 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:02:04,701 	Gloss Alignment :	         
2024-02-03 05:02:04,701 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:02:04,703 	Text Reference  :	* ***** ***** fans are    now    wondering why  he   did not      say anything about dhoni    as  he   is  very close to   dhoni
2024-02-03 05:02:04,703 	Text Hypothesis :	i can't think of   anyone better we        both grew up  together all the      best  imjadeja i'm sure you will do    your best 
2024-02-03 05:02:04,703 	Text Alignment  :	I I     I     S    S      S      S         S    S    S   S        S   S        S     S        S   S    S   S    S     S    S    
2024-02-03 05:02:04,703 ========================================================================================================================
2024-02-03 05:02:04,704 Logging Sequence: 175_64.00
2024-02-03 05:02:04,704 	Gloss Reference :	A B+C+D+E
2024-02-03 05:02:04,704 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:02:04,704 	Gloss Alignment :	         
2024-02-03 05:02:04,704 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:02:04,706 	Text Reference  :	after this championship the 6th world deaf badminton championship is   being held      from      14th july to  25th july      2023    at  the same        place
2024-02-03 05:02:04,706 	Text Hypothesis :	***** **** ************ the *** ***** **** ********* indian       team was   extremely concerned as   both are very important players for the rain-soaked asia 
2024-02-03 05:02:04,707 	Text Alignment  :	D     D    D                D   D     D    D         S            S    S     S         S         S    S    S   S    S         S       S       S           S    
2024-02-03 05:02:04,707 ========================================================================================================================
2024-02-03 05:02:04,707 Logging Sequence: 52_36.00
2024-02-03 05:02:04,707 	Gloss Reference :	A B+C+D+E
2024-02-03 05:02:04,707 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:02:04,707 	Gloss Alignment :	         
2024-02-03 05:02:04,707 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:02:04,708 	Text Reference  :	*** **** **** ***** *** *** *** **** ** ***** recently dhoni    was   travellin on   an indigo flight
2024-02-03 05:02:04,708 	Text Hypothesis :	the fans were asked him for the last 12 years and      pakistan would be        full to the    moment
2024-02-03 05:02:04,709 	Text Alignment  :	I   I    I    I     I   I   I   I    I  I     S        S        S     S         S    S  S      S     
2024-02-03 05:02:04,709 ========================================================================================================================
2024-02-03 05:02:04,709 Logging Sequence: 170_67.00
2024-02-03 05:02:04,709 	Gloss Reference :	A B+C+D+E
2024-02-03 05:02:04,709 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:02:04,709 	Gloss Alignment :	         
2024-02-03 05:02:04,709 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:02:04,711 	Text Reference  :	*** during rajasthan's innings ross  taylor came in  to bat     and was out for      a   duck
2024-02-03 05:02:04,711 	Text Hypothesis :	the third  charge      on      other is     that the 5  players and *** *** pakistan too etc 
2024-02-03 05:02:04,711 	Text Alignment  :	I   S      S           S       S     S      S    S   S  S           D   D   S        S   S   
2024-02-03 05:02:04,711 ========================================================================================================================
2024-02-03 05:02:09,748 Epoch 527: Total Training Recognition Loss 0.32  Total Training Translation Loss 8.21 
2024-02-03 05:02:09,749 EPOCH 528
2024-02-03 05:02:10,168 [Epoch: 528 Step: 00070100] Batch Recognition Loss:   0.001060 => Gls Tokens per Sec:     1717 || Batch Translation Loss:   0.029678 => Txt Tokens per Sec:     4913 || Lr: 0.000100
2024-02-03 05:02:15,905 [Epoch: 528 Step: 00070200] Batch Recognition Loss:   0.002348 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.024845 => Txt Tokens per Sec:     3860 || Lr: 0.000100
2024-02-03 05:02:17,356 Epoch 528: Total Training Recognition Loss 0.37  Total Training Translation Loss 10.12 
2024-02-03 05:02:17,356 EPOCH 529
2024-02-03 05:02:21,746 [Epoch: 529 Step: 00070300] Batch Recognition Loss:   0.000620 => Gls Tokens per Sec:     1385 || Batch Translation Loss:   0.033218 => Txt Tokens per Sec:     3857 || Lr: 0.000100
2024-02-03 05:02:24,987 Epoch 529: Total Training Recognition Loss 0.45  Total Training Translation Loss 9.98 
2024-02-03 05:02:24,988 EPOCH 530
2024-02-03 05:02:27,171 [Epoch: 530 Step: 00070400] Batch Recognition Loss:   0.000607 => Gls Tokens per Sec:     1577 || Batch Translation Loss:   0.315105 => Txt Tokens per Sec:     4525 || Lr: 0.000100
2024-02-03 05:02:32,266 Epoch 530: Total Training Recognition Loss 0.47  Total Training Translation Loss 21.68 
2024-02-03 05:02:32,266 EPOCH 531
2024-02-03 05:02:32,777 [Epoch: 531 Step: 00070500] Batch Recognition Loss:   0.000466 => Gls Tokens per Sec:     1569 || Batch Translation Loss:   0.032790 => Txt Tokens per Sec:     4143 || Lr: 0.000100
2024-02-03 05:02:38,332 [Epoch: 531 Step: 00070600] Batch Recognition Loss:   0.001697 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.172594 => Txt Tokens per Sec:     4040 || Lr: 0.000100
2024-02-03 05:02:39,788 Epoch 531: Total Training Recognition Loss 0.72  Total Training Translation Loss 29.68 
2024-02-03 05:02:39,789 EPOCH 532
2024-02-03 05:02:44,428 [Epoch: 532 Step: 00070700] Batch Recognition Loss:   0.060910 => Gls Tokens per Sec:     1328 || Batch Translation Loss:   0.023368 => Txt Tokens per Sec:     3712 || Lr: 0.000100
2024-02-03 05:02:47,870 Epoch 532: Total Training Recognition Loss 0.60  Total Training Translation Loss 13.78 
2024-02-03 05:02:47,870 EPOCH 533
2024-02-03 05:02:50,206 [Epoch: 533 Step: 00070800] Batch Recognition Loss:   0.001205 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.034150 => Txt Tokens per Sec:     4198 || Lr: 0.000100
2024-02-03 05:02:54,874 Epoch 533: Total Training Recognition Loss 0.39  Total Training Translation Loss 8.53 
2024-02-03 05:02:54,874 EPOCH 534
2024-02-03 05:02:55,420 [Epoch: 534 Step: 00070900] Batch Recognition Loss:   0.000426 => Gls Tokens per Sec:     1615 || Batch Translation Loss:   0.025995 => Txt Tokens per Sec:     4637 || Lr: 0.000100
2024-02-03 05:03:01,038 [Epoch: 534 Step: 00071000] Batch Recognition Loss:   0.000671 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.056710 => Txt Tokens per Sec:     3892 || Lr: 0.000100
2024-02-03 05:03:02,341 Epoch 534: Total Training Recognition Loss 0.30  Total Training Translation Loss 10.54 
2024-02-03 05:03:02,341 EPOCH 535
2024-02-03 05:03:06,768 [Epoch: 535 Step: 00071100] Batch Recognition Loss:   0.000527 => Gls Tokens per Sec:     1410 || Batch Translation Loss:   0.015518 => Txt Tokens per Sec:     3929 || Lr: 0.000100
2024-02-03 05:03:09,789 Epoch 535: Total Training Recognition Loss 0.26  Total Training Translation Loss 12.12 
2024-02-03 05:03:09,789 EPOCH 536
2024-02-03 05:03:11,973 [Epoch: 536 Step: 00071200] Batch Recognition Loss:   0.000706 => Gls Tokens per Sec:     1649 || Batch Translation Loss:   0.130241 => Txt Tokens per Sec:     4547 || Lr: 0.000100
2024-02-03 05:03:16,858 Epoch 536: Total Training Recognition Loss 0.18  Total Training Translation Loss 9.41 
2024-02-03 05:03:16,858 EPOCH 537
2024-02-03 05:03:17,512 [Epoch: 537 Step: 00071300] Batch Recognition Loss:   0.001038 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.036692 => Txt Tokens per Sec:     4141 || Lr: 0.000100
2024-02-03 05:03:22,847 [Epoch: 537 Step: 00071400] Batch Recognition Loss:   0.000292 => Gls Tokens per Sec:     1499 || Batch Translation Loss:   0.066145 => Txt Tokens per Sec:     4176 || Lr: 0.000100
2024-02-03 05:03:24,323 Epoch 537: Total Training Recognition Loss 0.23  Total Training Translation Loss 9.94 
2024-02-03 05:03:24,323 EPOCH 538
2024-02-03 05:03:28,881 [Epoch: 538 Step: 00071500] Batch Recognition Loss:   0.000580 => Gls Tokens per Sec:     1387 || Batch Translation Loss:   0.085936 => Txt Tokens per Sec:     3839 || Lr: 0.000100
2024-02-03 05:03:31,984 Epoch 538: Total Training Recognition Loss 0.18  Total Training Translation Loss 9.79 
2024-02-03 05:03:31,984 EPOCH 539
2024-02-03 05:03:34,502 [Epoch: 539 Step: 00071600] Batch Recognition Loss:   0.000648 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.031952 => Txt Tokens per Sec:     4213 || Lr: 0.000100
2024-02-03 05:03:39,390 Epoch 539: Total Training Recognition Loss 0.27  Total Training Translation Loss 17.07 
2024-02-03 05:03:39,391 EPOCH 540
2024-02-03 05:03:40,150 [Epoch: 540 Step: 00071700] Batch Recognition Loss:   0.003109 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.148960 => Txt Tokens per Sec:     3471 || Lr: 0.000100
2024-02-03 05:03:45,859 [Epoch: 540 Step: 00071800] Batch Recognition Loss:   0.000603 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.152645 => Txt Tokens per Sec:     3924 || Lr: 0.000100
2024-02-03 05:03:47,087 Epoch 540: Total Training Recognition Loss 0.36  Total Training Translation Loss 16.70 
2024-02-03 05:03:47,087 EPOCH 541
2024-02-03 05:03:51,766 [Epoch: 541 Step: 00071900] Batch Recognition Loss:   0.000604 => Gls Tokens per Sec:     1369 || Batch Translation Loss:   0.046003 => Txt Tokens per Sec:     3830 || Lr: 0.000100
2024-02-03 05:03:54,828 Epoch 541: Total Training Recognition Loss 0.51  Total Training Translation Loss 20.53 
2024-02-03 05:03:54,828 EPOCH 542
2024-02-03 05:03:57,249 [Epoch: 542 Step: 00072000] Batch Recognition Loss:   0.008765 => Gls Tokens per Sec:     1554 || Batch Translation Loss:   0.035579 => Txt Tokens per Sec:     4195 || Lr: 0.000100
2024-02-03 05:04:08,205 Validation result at epoch 542, step    72000: duration: 10.9564s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 9.72712	Translation Loss: 90548.04688	PPL: 12144.81250
	Eval Metric: BLEU
	WER 3.61	(DEL: 0.28,	INS: 0.00,	SUB: 3.32)
	BLEU-4 0.43	(BLEU-1: 9.45,	BLEU-2: 2.67,	BLEU-3: 0.91,	BLEU-4: 0.43)
	CHRF 16.36	ROUGE 8.20
2024-02-03 05:04:08,206 Logging Recognition and Translation Outputs
2024-02-03 05:04:08,206 ========================================================================================================================
2024-02-03 05:04:08,207 Logging Sequence: 165_124.00
2024-02-03 05:04:08,207 	Gloss Reference :	A B+C+D+E
2024-02-03 05:04:08,207 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:04:08,207 	Gloss Alignment :	         
2024-02-03 05:04:08,207 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:04:08,209 	Text Reference  :	similarly yuvraj singh'  number 12       was chosen  since his birthday falls  on  the 12    of ** *** december
2024-02-03 05:04:08,209 	Text Hypothesis :	********* that   company is     viacom18 it  managed to    bag these    groups for a   total of rs 594 crore   
2024-02-03 05:04:08,209 	Text Alignment  :	D         S      S       S      S        S   S       S     S   S        S      S   S   S        I  I   S       
2024-02-03 05:04:08,209 ========================================================================================================================
2024-02-03 05:04:08,209 Logging Sequence: 126_121.00
2024-02-03 05:04:08,210 	Gloss Reference :	A B+C+D+E
2024-02-03 05:04:08,210 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:04:08,210 	Gloss Alignment :	         
2024-02-03 05:04:08,210 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:04:08,210 	Text Reference  :	everyone was very happy by  his   victory
2024-02-03 05:04:08,211 	Text Hypothesis :	******** let me   tell  you about them   
2024-02-03 05:04:08,211 	Text Alignment  :	D        S   S    S     S   S     S      
2024-02-03 05:04:08,211 ========================================================================================================================
2024-02-03 05:04:08,211 Logging Sequence: 78_180.00
2024-02-03 05:04:08,211 	Gloss Reference :	A B+C+D+E
2024-02-03 05:04:08,211 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:04:08,211 	Gloss Alignment :	         
2024-02-03 05:04:08,211 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:04:08,212 	Text Reference  :	people have congratulated the couple on their  engagement
2024-02-03 05:04:08,212 	Text Hypothesis :	****** he   wanted        to  gift   35 people wow       
2024-02-03 05:04:08,212 	Text Alignment  :	D      S    S             S   S      S  S      S         
2024-02-03 05:04:08,212 ========================================================================================================================
2024-02-03 05:04:08,212 Logging Sequence: 73_179.00
2024-02-03 05:04:08,213 	Gloss Reference :	A B+C+D+E
2024-02-03 05:04:08,213 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:04:08,213 	Gloss Alignment :	         
2024-02-03 05:04:08,213 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:04:08,215 	Text Reference  :	** **** ******* **** ****** ********* ** ******* ******* **** he   also invested in a startup company called sahicoin which publishes news    regarding cryptocurrency
2024-02-03 05:04:08,215 	Text Hypothesis :	on 15th october 2022 indian cricketer an auction because pant will be   held     in a ******* ******* ****** video    on    his       amazing batting   skills        
2024-02-03 05:04:08,215 	Text Alignment  :	I  I    I       I    I      I         I  I       I       I    S    S    S             D       D       D      S        S     S         S       S         S             
2024-02-03 05:04:08,215 ========================================================================================================================
2024-02-03 05:04:08,215 Logging Sequence: 86_2.00
2024-02-03 05:04:08,215 	Gloss Reference :	A B+C+D+E
2024-02-03 05:04:08,215 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:04:08,216 	Gloss Alignment :	         
2024-02-03 05:04:08,216 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:04:08,216 	Text Reference  :	former indian cricketer yashpal sharma died   of heart attack on    13th    july   
2024-02-03 05:04:08,216 	Text Hypothesis :	****** ****** ********* yashpal ****** played in the   1979   match against england
2024-02-03 05:04:08,217 	Text Alignment  :	D      D      D                 D      S      S  S     S      S     S       S      
2024-02-03 05:04:08,217 ========================================================================================================================
2024-02-03 05:04:12,918 Epoch 542: Total Training Recognition Loss 0.65  Total Training Translation Loss 13.20 
2024-02-03 05:04:12,918 EPOCH 543
2024-02-03 05:04:13,678 [Epoch: 543 Step: 00072100] Batch Recognition Loss:   0.001864 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.071228 => Txt Tokens per Sec:     4300 || Lr: 0.000050
2024-02-03 05:04:19,297 [Epoch: 543 Step: 00072200] Batch Recognition Loss:   0.002008 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.012772 => Txt Tokens per Sec:     3918 || Lr: 0.000050
2024-02-03 05:04:20,383 Epoch 543: Total Training Recognition Loss 0.20  Total Training Translation Loss 4.98 
2024-02-03 05:04:20,383 EPOCH 544
2024-02-03 05:04:25,225 [Epoch: 544 Step: 00072300] Batch Recognition Loss:   0.001020 => Gls Tokens per Sec:     1339 || Batch Translation Loss:   0.019221 => Txt Tokens per Sec:     3748 || Lr: 0.000050
2024-02-03 05:04:28,353 Epoch 544: Total Training Recognition Loss 0.21  Total Training Translation Loss 3.32 
2024-02-03 05:04:28,354 EPOCH 545
2024-02-03 05:04:30,815 [Epoch: 545 Step: 00072400] Batch Recognition Loss:   0.000973 => Gls Tokens per Sec:     1562 || Batch Translation Loss:   0.027020 => Txt Tokens per Sec:     4405 || Lr: 0.000050
2024-02-03 05:04:35,601 Epoch 545: Total Training Recognition Loss 0.14  Total Training Translation Loss 2.92 
2024-02-03 05:04:35,602 EPOCH 546
2024-02-03 05:04:36,400 [Epoch: 546 Step: 00072500] Batch Recognition Loss:   0.000796 => Gls Tokens per Sec:     1506 || Batch Translation Loss:   0.014063 => Txt Tokens per Sec:     4320 || Lr: 0.000050
2024-02-03 05:04:42,299 [Epoch: 546 Step: 00072600] Batch Recognition Loss:   0.000609 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.015589 => Txt Tokens per Sec:     3733 || Lr: 0.000050
2024-02-03 05:04:43,374 Epoch 546: Total Training Recognition Loss 0.16  Total Training Translation Loss 3.36 
2024-02-03 05:04:43,374 EPOCH 547
2024-02-03 05:04:47,933 [Epoch: 547 Step: 00072700] Batch Recognition Loss:   0.000283 => Gls Tokens per Sec:     1439 || Batch Translation Loss:   0.022437 => Txt Tokens per Sec:     4006 || Lr: 0.000050
2024-02-03 05:04:50,888 Epoch 547: Total Training Recognition Loss 0.20  Total Training Translation Loss 3.70 
2024-02-03 05:04:50,888 EPOCH 548
2024-02-03 05:04:53,734 [Epoch: 548 Step: 00072800] Batch Recognition Loss:   0.000737 => Gls Tokens per Sec:     1378 || Batch Translation Loss:   0.012777 => Txt Tokens per Sec:     3859 || Lr: 0.000050
2024-02-03 05:04:58,364 Epoch 548: Total Training Recognition Loss 0.12  Total Training Translation Loss 3.38 
2024-02-03 05:04:58,364 EPOCH 549
2024-02-03 05:04:59,113 [Epoch: 549 Step: 00072900] Batch Recognition Loss:   0.000341 => Gls Tokens per Sec:     1709 || Batch Translation Loss:   0.006002 => Txt Tokens per Sec:     4553 || Lr: 0.000050
2024-02-03 05:05:04,407 [Epoch: 549 Step: 00073000] Batch Recognition Loss:   0.000234 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.013464 => Txt Tokens per Sec:     4218 || Lr: 0.000050
2024-02-03 05:05:05,344 Epoch 549: Total Training Recognition Loss 0.10  Total Training Translation Loss 2.66 
2024-02-03 05:05:05,344 EPOCH 550
2024-02-03 05:05:09,950 [Epoch: 550 Step: 00073100] Batch Recognition Loss:   0.000179 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   0.008455 => Txt Tokens per Sec:     4075 || Lr: 0.000050
2024-02-03 05:05:12,662 Epoch 550: Total Training Recognition Loss 0.11  Total Training Translation Loss 2.28 
2024-02-03 05:05:12,663 EPOCH 551
2024-02-03 05:05:15,121 [Epoch: 551 Step: 00073200] Batch Recognition Loss:   0.000140 => Gls Tokens per Sec:     1627 || Batch Translation Loss:   0.013336 => Txt Tokens per Sec:     4520 || Lr: 0.000050
2024-02-03 05:05:19,934 Epoch 551: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.19 
2024-02-03 05:05:19,935 EPOCH 552
2024-02-03 05:05:20,878 [Epoch: 552 Step: 00073300] Batch Recognition Loss:   0.000330 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.012753 => Txt Tokens per Sec:     3640 || Lr: 0.000050
2024-02-03 05:05:26,584 [Epoch: 552 Step: 00073400] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.006451 => Txt Tokens per Sec:     3925 || Lr: 0.000050
2024-02-03 05:05:27,521 Epoch 552: Total Training Recognition Loss 0.10  Total Training Translation Loss 2.44 
2024-02-03 05:05:27,521 EPOCH 553
2024-02-03 05:05:32,172 [Epoch: 553 Step: 00073500] Batch Recognition Loss:   0.000374 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.015018 => Txt Tokens per Sec:     4042 || Lr: 0.000050
2024-02-03 05:05:35,401 Epoch 553: Total Training Recognition Loss 0.11  Total Training Translation Loss 2.75 
2024-02-03 05:05:35,402 EPOCH 554
2024-02-03 05:05:38,353 [Epoch: 554 Step: 00073600] Batch Recognition Loss:   0.007672 => Gls Tokens per Sec:     1383 || Batch Translation Loss:   0.028637 => Txt Tokens per Sec:     3878 || Lr: 0.000050
2024-02-03 05:05:42,542 Epoch 554: Total Training Recognition Loss 0.18  Total Training Translation Loss 2.78 
2024-02-03 05:05:42,542 EPOCH 555
2024-02-03 05:05:43,605 [Epoch: 555 Step: 00073700] Batch Recognition Loss:   0.000357 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.011000 => Txt Tokens per Sec:     3889 || Lr: 0.000050
2024-02-03 05:05:49,336 [Epoch: 555 Step: 00073800] Batch Recognition Loss:   0.000301 => Gls Tokens per Sec:     1396 || Batch Translation Loss:   0.012576 => Txt Tokens per Sec:     3867 || Lr: 0.000050
2024-02-03 05:05:50,266 Epoch 555: Total Training Recognition Loss 0.13  Total Training Translation Loss 2.33 
2024-02-03 05:05:50,266 EPOCH 556
2024-02-03 05:05:55,077 [Epoch: 556 Step: 00073900] Batch Recognition Loss:   0.000178 => Gls Tokens per Sec:     1414 || Batch Translation Loss:   0.024548 => Txt Tokens per Sec:     3849 || Lr: 0.000050
2024-02-03 05:05:57,801 Epoch 556: Total Training Recognition Loss 0.19  Total Training Translation Loss 2.65 
2024-02-03 05:05:57,801 EPOCH 557
2024-02-03 05:06:00,425 [Epoch: 557 Step: 00074000] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1586 || Batch Translation Loss:   0.014874 => Txt Tokens per Sec:     4322 || Lr: 0.000050
2024-02-03 05:06:11,914 Validation result at epoch 557, step    74000: duration: 11.4885s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.90683	Translation Loss: 88219.51562	PPL: 9535.79102
	Eval Metric: BLEU
	WER 3.39	(DEL: 0.21,	INS: 0.00,	SUB: 3.18)
	BLEU-4 0.57	(BLEU-1: 9.59,	BLEU-2: 2.49,	BLEU-3: 1.00,	BLEU-4: 0.57)
	CHRF 16.69	ROUGE 8.05
2024-02-03 05:06:11,915 Logging Recognition and Translation Outputs
2024-02-03 05:06:11,915 ========================================================================================================================
2024-02-03 05:06:11,915 Logging Sequence: 78_43.00
2024-02-03 05:06:11,915 	Gloss Reference :	A B+C+D+E
2024-02-03 05:06:11,915 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:06:11,916 	Gloss Alignment :	         
2024-02-03 05:06:11,916 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:06:11,916 	Text Reference  :	***** *** however something happened which made    the team    very happy
2024-02-03 05:06:11,917 	Text Hypothesis :	after his 142     matches   for      india chhetri has slammed 92   goals
2024-02-03 05:06:11,917 	Text Alignment  :	I     I   S       S         S        S     S       S   S       S    S    
2024-02-03 05:06:11,917 ========================================================================================================================
2024-02-03 05:06:11,917 Logging Sequence: 94_245.00
2024-02-03 05:06:11,917 	Gloss Reference :	A B+C+D+E
2024-02-03 05:06:11,917 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:06:11,917 	Gloss Alignment :	         
2024-02-03 05:06:11,917 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:06:11,918 	Text Reference  :	bcci announced that online sale of    all tickets is expected to       start next    week  
2024-02-03 05:06:11,919 	Text Hypothesis :	**** ********* **** ****** the  teams can decide  to have     pakistan and   current season
2024-02-03 05:06:11,919 	Text Alignment  :	D    D         D    D      S    S     S   S       S  S        S        S     S       S     
2024-02-03 05:06:11,919 ========================================================================================================================
2024-02-03 05:06:11,919 Logging Sequence: 63_106.00
2024-02-03 05:06:11,919 	Gloss Reference :	A B+C+D+E
2024-02-03 05:06:11,919 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:06:11,919 	Gloss Alignment :	         
2024-02-03 05:06:11,920 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:06:11,920 	Text Reference  :	currently in the ipl   there    are  teams of cities like mumbai kolkata hyderabad etc 
2024-02-03 05:06:11,921 	Text Hypothesis :	********* it is  quite shocking that teams ** ****** have lifted the     first     time
2024-02-03 05:06:11,921 	Text Alignment  :	D         S  S   S     S        S          D  D      S    S      S       S         S   
2024-02-03 05:06:11,921 ========================================================================================================================
2024-02-03 05:06:11,921 Logging Sequence: 90_157.00
2024-02-03 05:06:11,921 	Gloss Reference :	A B+C+D+E
2024-02-03 05:06:11,921 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:06:11,921 	Gloss Alignment :	         
2024-02-03 05:06:11,922 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:06:11,922 	Text Reference  :	they chose udaipur as the location   for this
2024-02-03 05:06:11,922 	Text Hypothesis :	**** ***** ******* i  am  devastated to  this
2024-02-03 05:06:11,922 	Text Alignment  :	D    D     D       S  S   S          S       
2024-02-03 05:06:11,922 ========================================================================================================================
2024-02-03 05:06:11,922 Logging Sequence: 83_33.00
2024-02-03 05:06:11,923 	Gloss Reference :	A B+C+D+E
2024-02-03 05:06:11,923 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:06:11,923 	Gloss Alignment :	         
2024-02-03 05:06:11,923 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:06:11,924 	Text Reference  :	*** *** ** *** ***** ******** a    football match     lasts for two equal halves of       45         minutes   
2024-02-03 05:06:11,924 	Text Hypothesis :	but due to her covid pandemic they were     postponed and   are now being the    hospital undergoing treatment'
2024-02-03 05:06:11,924 	Text Alignment  :	I   I   I  I   I     I        S    S        S         S     S   S   S     S      S        S          S         
2024-02-03 05:06:11,924 ========================================================================================================================
2024-02-03 05:06:16,342 Epoch 557: Total Training Recognition Loss 0.14  Total Training Translation Loss 4.70 
2024-02-03 05:06:16,342 EPOCH 558
2024-02-03 05:06:17,318 [Epoch: 558 Step: 00074100] Batch Recognition Loss:   0.000074 => Gls Tokens per Sec:     1559 || Batch Translation Loss:   0.011032 => Txt Tokens per Sec:     4372 || Lr: 0.000050
2024-02-03 05:06:22,521 [Epoch: 558 Step: 00074200] Batch Recognition Loss:   0.000120 => Gls Tokens per Sec:     1538 || Batch Translation Loss:   0.013885 => Txt Tokens per Sec:     4271 || Lr: 0.000050
2024-02-03 05:06:23,344 Epoch 558: Total Training Recognition Loss 0.15  Total Training Translation Loss 3.86 
2024-02-03 05:06:23,344 EPOCH 559
2024-02-03 05:06:28,033 [Epoch: 559 Step: 00074300] Batch Recognition Loss:   0.000243 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.020439 => Txt Tokens per Sec:     4041 || Lr: 0.000050
2024-02-03 05:06:30,802 Epoch 559: Total Training Recognition Loss 0.11  Total Training Translation Loss 9.90 
2024-02-03 05:06:30,802 EPOCH 560
2024-02-03 05:06:33,611 [Epoch: 560 Step: 00074400] Batch Recognition Loss:   0.000328 => Gls Tokens per Sec:     1510 || Batch Translation Loss:   0.019565 => Txt Tokens per Sec:     4058 || Lr: 0.000050
2024-02-03 05:06:38,211 Epoch 560: Total Training Recognition Loss 0.12  Total Training Translation Loss 7.89 
2024-02-03 05:06:38,212 EPOCH 561
2024-02-03 05:06:39,239 [Epoch: 561 Step: 00074500] Batch Recognition Loss:   0.000922 => Gls Tokens per Sec:     1560 || Batch Translation Loss:   0.038013 => Txt Tokens per Sec:     4474 || Lr: 0.000050
2024-02-03 05:06:44,721 [Epoch: 561 Step: 00074600] Batch Recognition Loss:   0.000055 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.019975 => Txt Tokens per Sec:     4046 || Lr: 0.000050
2024-02-03 05:06:45,487 Epoch 561: Total Training Recognition Loss 0.28  Total Training Translation Loss 5.17 
2024-02-03 05:06:45,487 EPOCH 562
2024-02-03 05:06:50,282 [Epoch: 562 Step: 00074700] Batch Recognition Loss:   0.000375 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.011241 => Txt Tokens per Sec:     4068 || Lr: 0.000050
2024-02-03 05:06:53,085 Epoch 562: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.65 
2024-02-03 05:06:53,086 EPOCH 563
2024-02-03 05:06:55,953 [Epoch: 563 Step: 00074800] Batch Recognition Loss:   0.002043 => Gls Tokens per Sec:     1507 || Batch Translation Loss:   0.041068 => Txt Tokens per Sec:     4135 || Lr: 0.000050
2024-02-03 05:06:59,994 Epoch 563: Total Training Recognition Loss 0.10  Total Training Translation Loss 2.57 
2024-02-03 05:06:59,994 EPOCH 564
2024-02-03 05:07:01,097 [Epoch: 564 Step: 00074900] Batch Recognition Loss:   0.000073 => Gls Tokens per Sec:     1523 || Batch Translation Loss:   0.012164 => Txt Tokens per Sec:     3935 || Lr: 0.000050
2024-02-03 05:07:06,968 [Epoch: 564 Step: 00075000] Batch Recognition Loss:   0.000308 => Gls Tokens per Sec:     1363 || Batch Translation Loss:   0.006278 => Txt Tokens per Sec:     3867 || Lr: 0.000050
2024-02-03 05:07:07,672 Epoch 564: Total Training Recognition Loss 0.13  Total Training Translation Loss 2.52 
2024-02-03 05:07:07,672 EPOCH 565
2024-02-03 05:07:12,721 [Epoch: 565 Step: 00075100] Batch Recognition Loss:   0.000050 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.011132 => Txt Tokens per Sec:     3827 || Lr: 0.000050
2024-02-03 05:07:15,643 Epoch 565: Total Training Recognition Loss 0.11  Total Training Translation Loss 2.11 
2024-02-03 05:07:15,643 EPOCH 566
2024-02-03 05:07:18,856 [Epoch: 566 Step: 00075200] Batch Recognition Loss:   0.000132 => Gls Tokens per Sec:     1370 || Batch Translation Loss:   0.017091 => Txt Tokens per Sec:     3787 || Lr: 0.000050
2024-02-03 05:07:23,073 Epoch 566: Total Training Recognition Loss 0.08  Total Training Translation Loss 2.02 
2024-02-03 05:07:23,073 EPOCH 567
2024-02-03 05:07:24,215 [Epoch: 567 Step: 00075300] Batch Recognition Loss:   0.000381 => Gls Tokens per Sec:     1542 || Batch Translation Loss:   0.014396 => Txt Tokens per Sec:     4289 || Lr: 0.000050
2024-02-03 05:07:29,799 [Epoch: 567 Step: 00075400] Batch Recognition Loss:   0.000500 => Gls Tokens per Sec:     1431 || Batch Translation Loss:   0.024819 => Txt Tokens per Sec:     3985 || Lr: 0.000050
2024-02-03 05:07:30,482 Epoch 567: Total Training Recognition Loss 0.10  Total Training Translation Loss 6.39 
2024-02-03 05:07:30,483 EPOCH 568
2024-02-03 05:07:35,753 [Epoch: 568 Step: 00075500] Batch Recognition Loss:   0.000440 => Gls Tokens per Sec:     1352 || Batch Translation Loss:   0.332168 => Txt Tokens per Sec:     3751 || Lr: 0.000050
2024-02-03 05:07:38,194 Epoch 568: Total Training Recognition Loss 0.17  Total Training Translation Loss 9.26 
2024-02-03 05:07:38,194 EPOCH 569
2024-02-03 05:07:41,515 [Epoch: 569 Step: 00075600] Batch Recognition Loss:   0.000144 => Gls Tokens per Sec:     1350 || Batch Translation Loss:   0.018556 => Txt Tokens per Sec:     3819 || Lr: 0.000050
2024-02-03 05:07:45,804 Epoch 569: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.92 
2024-02-03 05:07:45,804 EPOCH 570
2024-02-03 05:07:46,934 [Epoch: 570 Step: 00075700] Batch Recognition Loss:   0.000237 => Gls Tokens per Sec:     1631 || Batch Translation Loss:   0.005605 => Txt Tokens per Sec:     4585 || Lr: 0.000050
2024-02-03 05:07:52,528 [Epoch: 570 Step: 00075800] Batch Recognition Loss:   0.000437 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.012748 => Txt Tokens per Sec:     3922 || Lr: 0.000050
2024-02-03 05:07:53,186 Epoch 570: Total Training Recognition Loss 0.09  Total Training Translation Loss 5.01 
2024-02-03 05:07:53,187 EPOCH 571
2024-02-03 05:07:58,467 [Epoch: 571 Step: 00075900] Batch Recognition Loss:   0.001609 => Gls Tokens per Sec:     1364 || Batch Translation Loss:   0.010164 => Txt Tokens per Sec:     3827 || Lr: 0.000050
2024-02-03 05:08:00,970 Epoch 571: Total Training Recognition Loss 0.09  Total Training Translation Loss 3.79 
2024-02-03 05:08:00,970 EPOCH 572
2024-02-03 05:08:03,890 [Epoch: 572 Step: 00076000] Batch Recognition Loss:   0.000255 => Gls Tokens per Sec:     1562 || Batch Translation Loss:   0.017362 => Txt Tokens per Sec:     4398 || Lr: 0.000050
2024-02-03 05:08:15,408 Validation result at epoch 572, step    76000: duration: 11.5181s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.70117	Translation Loss: 87169.52344	PPL: 8550.55957
	Eval Metric: BLEU
	WER 3.25	(DEL: 0.14,	INS: 0.00,	SUB: 3.11)
	BLEU-4 0.40	(BLEU-1: 9.54,	BLEU-2: 2.35,	BLEU-3: 0.83,	BLEU-4: 0.40)
	CHRF 16.79	ROUGE 8.17
2024-02-03 05:08:15,409 Logging Recognition and Translation Outputs
2024-02-03 05:08:15,410 ========================================================================================================================
2024-02-03 05:08:15,410 Logging Sequence: 138_2.00
2024-02-03 05:08:15,410 	Gloss Reference :	A B+C+D+E  
2024-02-03 05:08:15,410 	Gloss Hypothesis:	A B+C+B+E+D
2024-02-03 05:08:15,410 	Gloss Alignment :	  S        
2024-02-03 05:08:15,410 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:08:15,411 	Text Reference  :	******** ***** *** england lost to italy in    the   2020  euro   finals
2024-02-03 05:08:15,411 	Text Hypothesis :	everyone hoped she would   win  a  test  match while italy scored 2759  
2024-02-03 05:08:15,411 	Text Alignment  :	I        I     I   S       S    S  S     S     S     S     S      S     
2024-02-03 05:08:15,411 ========================================================================================================================
2024-02-03 05:08:15,412 Logging Sequence: 173_56.00
2024-02-03 05:08:15,412 	Gloss Reference :	A B+C+D+E
2024-02-03 05:08:15,412 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:08:15,412 	Gloss Alignment :	         
2024-02-03 05:08:15,412 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:08:15,413 	Text Reference  :	he has not been able to focus on practicing this      is   why   he        wants    to     step down 
2024-02-03 05:08:15,413 	Text Hypothesis :	** *** *** **** **** ** ***** ** ********** meanwhile some funny incidents happened during the  match
2024-02-03 05:08:15,413 	Text Alignment  :	D  D   D   D    D    D  D     D  D          S         S    S     S         S        S      S    S    
2024-02-03 05:08:15,414 ========================================================================================================================
2024-02-03 05:08:15,414 Logging Sequence: 139_2.00
2024-02-03 05:08:15,414 	Gloss Reference :	A B+C+D+E
2024-02-03 05:08:15,414 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:08:15,414 	Gloss Alignment :	         
2024-02-03 05:08:15,414 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:08:15,416 	Text Reference  :	***** ** *** **** ******* across the ***** ******* world people love watching cricket football    and  different types of sports 
2024-02-03 05:08:15,416 	Text Hypothesis :	prior to the team leaving for    the south african test  series new  agencies were    speculating that there     is    a  problem
2024-02-03 05:08:15,416 	Text Alignment  :	I     I  I   I    I       S          I     I       S     S      S    S        S       S           S    S         S     S  S      
2024-02-03 05:08:15,416 ========================================================================================================================
2024-02-03 05:08:15,416 Logging Sequence: 172_109.00
2024-02-03 05:08:15,416 	Gloss Reference :	A B+C+D+E
2024-02-03 05:08:15,417 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:08:15,417 	Gloss Alignment :	         
2024-02-03 05:08:15,417 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:08:15,418 	Text Reference  :	** when the   rains at 630   pm   centre was      covered  with    two layers of  protective sheets 
2024-02-03 05:08:15,418 	Text Hypothesis :	he said there is    a  doubt with the    umpire's decision players can ask    for their      support
2024-02-03 05:08:15,419 	Text Alignment  :	I  S    S     S     S  S     S    S      S        S        S       S   S      S   S          S      
2024-02-03 05:08:15,419 ========================================================================================================================
2024-02-03 05:08:15,419 Logging Sequence: 164_128.00
2024-02-03 05:08:15,419 	Gloss Reference :	A B+C+D+E        
2024-02-03 05:08:15,419 	Gloss Hypothesis:	A B+C+B+E+B+C+B+E
2024-02-03 05:08:15,419 	Gloss Alignment :	  S              
2024-02-03 05:08:15,419 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:08:15,421 	Text Reference  :	viacom18 grabbed the digital rights of  telecasting  ipl matches ** ***** for the next 5 years **** ** **** ***** for rs 20500 crore
2024-02-03 05:08:15,422 	Text Hypothesis :	******** ******* the tv      rights for broadcasting ipl matches in india for the next 5 years went to star india for rs 23575 crore
2024-02-03 05:08:15,422 	Text Alignment  :	D        D           S              S   S                        I  I                          I    I  I    I            S          
2024-02-03 05:08:15,422 ========================================================================================================================
2024-02-03 05:08:19,645 Epoch 572: Total Training Recognition Loss 0.14  Total Training Translation Loss 2.54 
2024-02-03 05:08:19,645 EPOCH 573
2024-02-03 05:08:21,061 [Epoch: 573 Step: 00076100] Batch Recognition Loss:   0.000870 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.015372 => Txt Tokens per Sec:     3584 || Lr: 0.000050
2024-02-03 05:08:26,593 [Epoch: 573 Step: 00076200] Batch Recognition Loss:   0.000401 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.008328 => Txt Tokens per Sec:     4086 || Lr: 0.000050
2024-02-03 05:08:27,195 Epoch 573: Total Training Recognition Loss 0.15  Total Training Translation Loss 3.54 
2024-02-03 05:08:27,195 EPOCH 574
2024-02-03 05:08:32,384 [Epoch: 574 Step: 00076300] Batch Recognition Loss:   0.000122 => Gls Tokens per Sec:     1403 || Batch Translation Loss:   0.012943 => Txt Tokens per Sec:     3902 || Lr: 0.000050
2024-02-03 05:08:34,764 Epoch 574: Total Training Recognition Loss 0.12  Total Training Translation Loss 3.01 
2024-02-03 05:08:34,764 EPOCH 575
2024-02-03 05:08:37,776 [Epoch: 575 Step: 00076400] Batch Recognition Loss:   0.000114 => Gls Tokens per Sec:     1541 || Batch Translation Loss:   0.007941 => Txt Tokens per Sec:     4289 || Lr: 0.000050
2024-02-03 05:08:42,006 Epoch 575: Total Training Recognition Loss 0.08  Total Training Translation Loss 2.91 
2024-02-03 05:08:42,006 EPOCH 576
2024-02-03 05:08:43,549 [Epoch: 576 Step: 00076500] Batch Recognition Loss:   0.000254 => Gls Tokens per Sec:     1297 || Batch Translation Loss:   0.021040 => Txt Tokens per Sec:     3650 || Lr: 0.000050
2024-02-03 05:08:48,962 [Epoch: 576 Step: 00076600] Batch Recognition Loss:   0.000863 => Gls Tokens per Sec:     1476 || Batch Translation Loss:   0.450450 => Txt Tokens per Sec:     4129 || Lr: 0.000050
2024-02-03 05:08:49,352 Epoch 576: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.64 
2024-02-03 05:08:49,353 EPOCH 577
2024-02-03 05:08:54,062 [Epoch: 577 Step: 00076700] Batch Recognition Loss:   0.000412 => Gls Tokens per Sec:     1563 || Batch Translation Loss:   0.015537 => Txt Tokens per Sec:     4348 || Lr: 0.000050
2024-02-03 05:08:56,102 Epoch 577: Total Training Recognition Loss 0.10  Total Training Translation Loss 6.57 
2024-02-03 05:08:56,102 EPOCH 578
2024-02-03 05:08:59,354 [Epoch: 578 Step: 00076800] Batch Recognition Loss:   0.000110 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.022048 => Txt Tokens per Sec:     3929 || Lr: 0.000050
2024-02-03 05:09:03,375 Epoch 578: Total Training Recognition Loss 0.10  Total Training Translation Loss 5.77 
2024-02-03 05:09:03,375 EPOCH 579
2024-02-03 05:09:04,952 [Epoch: 579 Step: 00076900] Batch Recognition Loss:   0.000124 => Gls Tokens per Sec:     1319 || Batch Translation Loss:   0.020400 => Txt Tokens per Sec:     3834 || Lr: 0.000050
2024-02-03 05:09:10,529 [Epoch: 579 Step: 00077000] Batch Recognition Loss:   0.000169 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.015110 => Txt Tokens per Sec:     3916 || Lr: 0.000050
2024-02-03 05:09:11,048 Epoch 579: Total Training Recognition Loss 0.17  Total Training Translation Loss 4.24 
2024-02-03 05:09:11,048 EPOCH 580
2024-02-03 05:09:16,266 [Epoch: 580 Step: 00077100] Batch Recognition Loss:   0.000717 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.017369 => Txt Tokens per Sec:     4004 || Lr: 0.000050
2024-02-03 05:09:18,610 Epoch 580: Total Training Recognition Loss 0.16  Total Training Translation Loss 2.72 
2024-02-03 05:09:18,611 EPOCH 581
2024-02-03 05:09:22,148 [Epoch: 581 Step: 00077200] Batch Recognition Loss:   0.000670 => Gls Tokens per Sec:     1358 || Batch Translation Loss:   0.022336 => Txt Tokens per Sec:     3805 || Lr: 0.000050
2024-02-03 05:09:26,232 Epoch 581: Total Training Recognition Loss 0.08  Total Training Translation Loss 2.72 
2024-02-03 05:09:26,232 EPOCH 582
2024-02-03 05:09:27,646 [Epoch: 582 Step: 00077300] Batch Recognition Loss:   0.000274 => Gls Tokens per Sec:     1529 || Batch Translation Loss:   0.017177 => Txt Tokens per Sec:     4341 || Lr: 0.000050
2024-02-03 05:09:33,376 [Epoch: 582 Step: 00077400] Batch Recognition Loss:   0.000047 => Gls Tokens per Sec:     1395 || Batch Translation Loss:   0.010295 => Txt Tokens per Sec:     3863 || Lr: 0.000050
2024-02-03 05:09:33,680 Epoch 582: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.59 
2024-02-03 05:09:33,680 EPOCH 583
2024-02-03 05:09:38,886 [Epoch: 583 Step: 00077500] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.007773 => Txt Tokens per Sec:     4043 || Lr: 0.000050
2024-02-03 05:09:41,329 Epoch 583: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.70 
2024-02-03 05:09:41,330 EPOCH 584
2024-02-03 05:09:44,510 [Epoch: 584 Step: 00077600] Batch Recognition Loss:   0.000476 => Gls Tokens per Sec:     1535 || Batch Translation Loss:   0.034961 => Txt Tokens per Sec:     4331 || Lr: 0.000050
2024-02-03 05:09:48,658 Epoch 584: Total Training Recognition Loss 0.13  Total Training Translation Loss 4.50 
2024-02-03 05:09:48,658 EPOCH 585
2024-02-03 05:09:50,243 [Epoch: 585 Step: 00077700] Batch Recognition Loss:   0.000621 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.017504 => Txt Tokens per Sec:     3954 || Lr: 0.000050
2024-02-03 05:09:55,651 [Epoch: 585 Step: 00077800] Batch Recognition Loss:   0.000330 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.017630 => Txt Tokens per Sec:     4122 || Lr: 0.000050
2024-02-03 05:09:55,910 Epoch 585: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.14 
2024-02-03 05:09:55,911 EPOCH 586
2024-02-03 05:10:01,649 [Epoch: 586 Step: 00077900] Batch Recognition Loss:   0.013749 => Gls Tokens per Sec:     1325 || Batch Translation Loss:   0.092958 => Txt Tokens per Sec:     3640 || Lr: 0.000050
2024-02-03 05:10:03,877 Epoch 586: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.45 
2024-02-03 05:10:03,877 EPOCH 587
2024-02-03 05:10:07,188 [Epoch: 587 Step: 00078000] Batch Recognition Loss:   0.000430 => Gls Tokens per Sec:     1499 || Batch Translation Loss:   0.023604 => Txt Tokens per Sec:     4127 || Lr: 0.000050
2024-02-03 05:10:18,373 Validation result at epoch 587, step    78000: duration: 11.1850s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.18652	Translation Loss: 86476.17188	PPL: 7956.44141
	Eval Metric: BLEU
	WER 3.11	(DEL: 0.14,	INS: 0.00,	SUB: 2.97)
	BLEU-4 0.38	(BLEU-1: 9.94,	BLEU-2: 2.45,	BLEU-3: 0.90,	BLEU-4: 0.38)
	CHRF 16.51	ROUGE 8.43
2024-02-03 05:10:18,374 Logging Recognition and Translation Outputs
2024-02-03 05:10:18,374 ========================================================================================================================
2024-02-03 05:10:18,375 Logging Sequence: 163_28.00
2024-02-03 05:10:18,375 	Gloss Reference :	A B+C+D+E
2024-02-03 05:10:18,375 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:10:18,375 	Gloss Alignment :	         
2024-02-03 05:10:18,375 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:10:18,376 	Text Reference  :	if an image of her face was taken it     was always blurred
2024-02-03 05:10:18,376 	Text Hypothesis :	** ** ***** ** *** **** *** ***** people are very   excited
2024-02-03 05:10:18,376 	Text Alignment  :	D  D  D     D  D   D    D   D     S      S   S      S      
2024-02-03 05:10:18,376 ========================================================================================================================
2024-02-03 05:10:18,376 Logging Sequence: 106_132.00
2024-02-03 05:10:18,376 	Gloss Reference :	A B+C+D+E
2024-02-03 05:10:18,376 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:10:18,377 	Gloss Alignment :	         
2024-02-03 05:10:18,377 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:10:18,378 	Text Reference  :	congratulatory wishes of former cricketers like yuvraj singh harbhajan singh gautam gambhir etc started pouring on social media 
2024-02-03 05:10:18,378 	Text Hypothesis :	************** ****** ** dahiya will       now  take   on    zaur      uguev of     russia  in  the     final   on 5      august
2024-02-03 05:10:18,379 	Text Alignment  :	D              D      D  S      S          S    S      S     S         S     S      S       S   S       S          S      S     
2024-02-03 05:10:18,379 ========================================================================================================================
2024-02-03 05:10:18,379 Logging Sequence: 166_57.00
2024-02-03 05:10:18,379 	Gloss Reference :	A B+C+D+E
2024-02-03 05:10:18,379 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:10:18,379 	Gloss Alignment :	         
2024-02-03 05:10:18,379 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:10:18,380 	Text Reference  :	as there was no     world cup    to ** ****** respect the   original format  
2024-02-03 05:10:18,380 	Text Hypothesis :	** for   his career he    wanted to be played between india and      pakistan
2024-02-03 05:10:18,381 	Text Alignment  :	D  S     S   S      S     S         I  I      S       S     S        S       
2024-02-03 05:10:18,381 ========================================================================================================================
2024-02-03 05:10:18,381 Logging Sequence: 137_286.00
2024-02-03 05:10:18,381 	Gloss Reference :	A B+C+D+E
2024-02-03 05:10:18,381 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:10:18,381 	Gloss Alignment :	         
2024-02-03 05:10:18,381 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:10:18,383 	Text Reference  :	also a missile strike most likely fired by      ukraine in     defence against a      russian attack had   killed two men    in         a     polish village
2024-02-03 05:10:18,384 	Text Hypothesis :	**** * ******* ****** **** ****** the   cameras caught  indian skipper rohit   sharma wiping  away   tears as     he  looked devastated after the    loss   
2024-02-03 05:10:18,384 	Text Alignment  :	D    D D       D      D    D      S     S       S       S      S       S       S      S       S      S     S      S   S      S          S     S      S      
2024-02-03 05:10:18,384 ========================================================================================================================
2024-02-03 05:10:18,384 Logging Sequence: 52_30.00
2024-02-03 05:10:18,384 	Gloss Reference :	A B+C+D+E
2024-02-03 05:10:18,384 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:10:18,384 	Gloss Alignment :	         
2024-02-03 05:10:18,385 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:10:18,386 	Text Reference  :	even though he has retired from international cricket he   still   has a      huge fan following  
2024-02-03 05:10:18,386 	Text Hypothesis :	**** ****** ** *** people  were stunned       by      your victory and called him  an  inspiration
2024-02-03 05:10:18,386 	Text Alignment  :	D    D      D  D   S       S    S             S       S    S       S   S      S    S   S          
2024-02-03 05:10:18,386 ========================================================================================================================
2024-02-03 05:10:22,663 Epoch 587: Total Training Recognition Loss 0.09  Total Training Translation Loss 6.40 
2024-02-03 05:10:22,663 EPOCH 588
2024-02-03 05:10:24,306 [Epoch: 588 Step: 00078100] Batch Recognition Loss:   0.000065 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.028261 => Txt Tokens per Sec:     3836 || Lr: 0.000050
2024-02-03 05:10:29,814 [Epoch: 588 Step: 00078200] Batch Recognition Loss:   0.000175 => Gls Tokens per Sec:     1451 || Batch Translation Loss:   0.029173 => Txt Tokens per Sec:     4060 || Lr: 0.000050
2024-02-03 05:10:30,020 Epoch 588: Total Training Recognition Loss 0.10  Total Training Translation Loss 5.33 
2024-02-03 05:10:30,020 EPOCH 589
2024-02-03 05:10:35,398 [Epoch: 589 Step: 00078300] Batch Recognition Loss:   0.000140 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.018839 => Txt Tokens per Sec:     3966 || Lr: 0.000050
2024-02-03 05:10:37,537 Epoch 589: Total Training Recognition Loss 0.13  Total Training Translation Loss 2.91 
2024-02-03 05:10:37,537 EPOCH 590
2024-02-03 05:10:40,743 [Epoch: 590 Step: 00078400] Batch Recognition Loss:   0.000054 => Gls Tokens per Sec:     1572 || Batch Translation Loss:   0.011947 => Txt Tokens per Sec:     4337 || Lr: 0.000050
2024-02-03 05:10:44,586 Epoch 590: Total Training Recognition Loss 0.06  Total Training Translation Loss 2.60 
2024-02-03 05:10:44,587 EPOCH 591
2024-02-03 05:10:46,078 [Epoch: 591 Step: 00078500] Batch Recognition Loss:   0.002202 => Gls Tokens per Sec:     1610 || Batch Translation Loss:   0.035245 => Txt Tokens per Sec:     4375 || Lr: 0.000050
2024-02-03 05:10:51,620 [Epoch: 591 Step: 00078600] Batch Recognition Loss:   0.000401 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   0.030719 => Txt Tokens per Sec:     4043 || Lr: 0.000050
2024-02-03 05:10:51,770 Epoch 591: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.57 
2024-02-03 05:10:51,770 EPOCH 592
2024-02-03 05:10:57,173 [Epoch: 592 Step: 00078700] Batch Recognition Loss:   0.000081 => Gls Tokens per Sec:     1436 || Batch Translation Loss:   0.013247 => Txt Tokens per Sec:     3990 || Lr: 0.000050
2024-02-03 05:10:59,325 Epoch 592: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.24 
2024-02-03 05:10:59,325 EPOCH 593
2024-02-03 05:11:03,120 [Epoch: 593 Step: 00078800] Batch Recognition Loss:   0.000188 => Gls Tokens per Sec:     1350 || Batch Translation Loss:   0.023406 => Txt Tokens per Sec:     3795 || Lr: 0.000050
2024-02-03 05:11:06,695 Epoch 593: Total Training Recognition Loss 0.19  Total Training Translation Loss 5.60 
2024-02-03 05:11:06,695 EPOCH 594
2024-02-03 05:11:08,368 [Epoch: 594 Step: 00078900] Batch Recognition Loss:   0.000795 => Gls Tokens per Sec:     1484 || Batch Translation Loss:   0.015822 => Txt Tokens per Sec:     3974 || Lr: 0.000050
2024-02-03 05:11:13,865 [Epoch: 594 Step: 00079000] Batch Recognition Loss:   0.000050 => Gls Tokens per Sec:     1454 || Batch Translation Loss:   0.010596 => Txt Tokens per Sec:     4084 || Lr: 0.000050
2024-02-03 05:11:13,960 Epoch 594: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.43 
2024-02-03 05:11:13,960 EPOCH 595
2024-02-03 05:11:19,482 [Epoch: 595 Step: 00079100] Batch Recognition Loss:   0.000149 => Gls Tokens per Sec:     1420 || Batch Translation Loss:   0.015584 => Txt Tokens per Sec:     3917 || Lr: 0.000050
2024-02-03 05:11:21,569 Epoch 595: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.56 
2024-02-03 05:11:21,569 EPOCH 596
2024-02-03 05:11:24,706 [Epoch: 596 Step: 00079200] Batch Recognition Loss:   0.001217 => Gls Tokens per Sec:     1658 || Batch Translation Loss:   0.015258 => Txt Tokens per Sec:     4504 || Lr: 0.000050
2024-02-03 05:11:28,763 Epoch 596: Total Training Recognition Loss 0.07  Total Training Translation Loss 4.47 
2024-02-03 05:11:28,764 EPOCH 597
2024-02-03 05:11:30,521 [Epoch: 597 Step: 00079300] Batch Recognition Loss:   0.000215 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.007086 => Txt Tokens per Sec:     3979 || Lr: 0.000050
2024-02-03 05:11:36,260 [Epoch: 597 Step: 00079400] Batch Recognition Loss:   0.000147 => Gls Tokens per Sec:     1392 || Batch Translation Loss:   0.018531 => Txt Tokens per Sec:     3890 || Lr: 0.000050
2024-02-03 05:11:36,313 Epoch 597: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.24 
2024-02-03 05:11:36,314 EPOCH 598
2024-02-03 05:11:41,912 [Epoch: 598 Step: 00079500] Batch Recognition Loss:   0.000446 => Gls Tokens per Sec:     1415 || Batch Translation Loss:   0.138516 => Txt Tokens per Sec:     3955 || Lr: 0.000050
2024-02-03 05:11:43,639 Epoch 598: Total Training Recognition Loss 0.07  Total Training Translation Loss 4.64 
2024-02-03 05:11:43,640 EPOCH 599
2024-02-03 05:11:46,884 [Epoch: 599 Step: 00079600] Batch Recognition Loss:   0.000616 => Gls Tokens per Sec:     1628 || Batch Translation Loss:   0.011572 => Txt Tokens per Sec:     4487 || Lr: 0.000050
2024-02-03 05:11:50,568 Epoch 599: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.74 
2024-02-03 05:11:50,569 EPOCH 600
2024-02-03 05:11:52,389 [Epoch: 600 Step: 00079700] Batch Recognition Loss:   0.000418 => Gls Tokens per Sec:     1451 || Batch Translation Loss:   0.049432 => Txt Tokens per Sec:     4041 || Lr: 0.000050
2024-02-03 05:11:58,295 [Epoch: 600 Step: 00079800] Batch Recognition Loss:   0.000339 => Gls Tokens per Sec:     1353 || Batch Translation Loss:   0.030777 => Txt Tokens per Sec:     3762 || Lr: 0.000050
2024-02-03 05:11:58,296 Epoch 600: Total Training Recognition Loss 0.13  Total Training Translation Loss 10.99 
2024-02-03 05:11:58,296 EPOCH 601
2024-02-03 05:12:03,725 [Epoch: 601 Step: 00079900] Batch Recognition Loss:   0.002803 => Gls Tokens per Sec:     1474 || Batch Translation Loss:   0.027940 => Txt Tokens per Sec:     4108 || Lr: 0.000050
2024-02-03 05:12:05,808 Epoch 601: Total Training Recognition Loss 0.11  Total Training Translation Loss 5.41 
2024-02-03 05:12:05,809 EPOCH 602
2024-02-03 05:12:09,505 [Epoch: 602 Step: 00080000] Batch Recognition Loss:   0.000320 => Gls Tokens per Sec:     1451 || Batch Translation Loss:   0.012464 => Txt Tokens per Sec:     3919 || Lr: 0.000050
2024-02-03 05:12:20,509 Validation result at epoch 602, step    80000: duration: 11.0020s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 11.04308	Translation Loss: 86550.29688	PPL: 8017.93457
	Eval Metric: BLEU
	WER 3.18	(DEL: 0.07,	INS: 0.00,	SUB: 3.11)
	BLEU-4 0.40	(BLEU-1: 9.85,	BLEU-2: 2.61,	BLEU-3: 0.96,	BLEU-4: 0.40)
	CHRF 16.99	ROUGE 8.28
2024-02-03 05:12:20,510 Logging Recognition and Translation Outputs
2024-02-03 05:12:20,510 ========================================================================================================================
2024-02-03 05:12:20,510 Logging Sequence: 150_47.00
2024-02-03 05:12:20,510 	Gloss Reference :	A B+C+D+E
2024-02-03 05:12:20,510 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:12:20,510 	Gloss Alignment :	         
2024-02-03 05:12:20,510 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:12:20,511 	Text Reference  :	ans     now they   have beaten    kuwait 
2024-02-03 05:12:20,511 	Text Hypothesis :	however he  showed a    heartfelt gesture
2024-02-03 05:12:20,511 	Text Alignment  :	S       S   S      S    S         S      
2024-02-03 05:12:20,511 ========================================================================================================================
2024-02-03 05:12:20,511 Logging Sequence: 178_2.00
2024-02-03 05:12:20,511 	Gloss Reference :	A B+C+D+E  
2024-02-03 05:12:20,512 	Gloss Hypothesis:	A B+E+C+D+E
2024-02-03 05:12:20,512 	Gloss Alignment :	  S        
2024-02-03 05:12:20,512 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:12:20,513 	Text Reference  :	******* ***** **** ** ***** ** on   4th     may     near   chhatrasal stadium -  which is   a  wrestling stadium ** -     
2024-02-03 05:12:20,513 	Text Hypothesis :	chennai super king is going to play against kolkata knight riders     on      27 march 2022 at wankhede  stadium in mumbai
2024-02-03 05:12:20,514 	Text Alignment  :	I       I     I    I  I     I  S    S       S       S      S          S       S  S     S    S  S                 I  S     
2024-02-03 05:12:20,514 ========================================================================================================================
2024-02-03 05:12:20,514 Logging Sequence: 72_102.00
2024-02-03 05:12:20,514 	Gloss Reference :	A B+C+D+E
2024-02-03 05:12:20,514 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:12:20,514 	Gloss Alignment :	         
2024-02-03 05:12:20,514 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:12:20,515 	Text Reference  :	sensing more      trouble shaw shifted to   another car       shaw started driving
2024-02-03 05:12:20,515 	Text Hypothesis :	******* yesterday on      23rd june    2023 raina   announced on   twitter that   
2024-02-03 05:12:20,515 	Text Alignment  :	D       S         S       S    S       S    S       S         S    S       S      
2024-02-03 05:12:20,515 ========================================================================================================================
2024-02-03 05:12:20,516 Logging Sequence: 79_198.00
2024-02-03 05:12:20,516 	Gloss Reference :	A B+C+D+E
2024-02-03 05:12:20,516 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:12:20,516 	Gloss Alignment :	         
2024-02-03 05:12:20,516 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:12:20,518 	Text Reference  :	***** ******** will try      to ** reschedule  the match before the finals now  hope     the     team   tests negative
2024-02-03 05:12:20,518 	Text Hypothesis :	delhi capitals were supposed to be quarantined for 1     days   but they   will continue playing tennis in    ipl     
2024-02-03 05:12:20,518 	Text Alignment  :	I     I        S    S           I  S           S   S     S      S   S      S    S        S       S      S     S       
2024-02-03 05:12:20,518 ========================================================================================================================
2024-02-03 05:12:20,518 Logging Sequence: 111_120.00
2024-02-03 05:12:20,518 	Gloss Reference :	A B+C+D+E
2024-02-03 05:12:20,518 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:12:20,519 	Gloss Alignment :	         
2024-02-03 05:12:20,519 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:12:20,519 	Text Reference  :	*** ** ** **** or    rs 12        lakh
2024-02-03 05:12:20,519 	Text Hypothesis :	and he is also given a  one-match ban 
2024-02-03 05:12:20,519 	Text Alignment  :	I   I  I  I    S     S  S         S   
2024-02-03 05:12:20,519 ========================================================================================================================
2024-02-03 05:12:24,144 Epoch 602: Total Training Recognition Loss 0.10  Total Training Translation Loss 5.73 
2024-02-03 05:12:24,145 EPOCH 603
2024-02-03 05:12:25,850 [Epoch: 603 Step: 00080100] Batch Recognition Loss:   0.000168 => Gls Tokens per Sec:     1596 || Batch Translation Loss:   0.027151 => Txt Tokens per Sec:     4370 || Lr: 0.000050
2024-02-03 05:12:31,556 Epoch 603: Total Training Recognition Loss 0.16  Total Training Translation Loss 3.64 
2024-02-03 05:12:31,557 EPOCH 604
2024-02-03 05:12:31,617 [Epoch: 604 Step: 00080200] Batch Recognition Loss:   0.000087 => Gls Tokens per Sec:     1356 || Batch Translation Loss:   0.013499 => Txt Tokens per Sec:     3288 || Lr: 0.000050
2024-02-03 05:12:37,454 [Epoch: 604 Step: 00080300] Batch Recognition Loss:   0.000617 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.013968 => Txt Tokens per Sec:     3813 || Lr: 0.000050
2024-02-03 05:12:39,491 Epoch 604: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.19 
2024-02-03 05:12:39,491 EPOCH 605
2024-02-03 05:12:43,335 [Epoch: 605 Step: 00080400] Batch Recognition Loss:   0.000268 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.014208 => Txt Tokens per Sec:     3978 || Lr: 0.000050
2024-02-03 05:12:47,010 Epoch 605: Total Training Recognition Loss 0.10  Total Training Translation Loss 2.67 
2024-02-03 05:12:47,011 EPOCH 606
2024-02-03 05:12:49,147 [Epoch: 606 Step: 00080500] Batch Recognition Loss:   0.002821 => Gls Tokens per Sec:     1311 || Batch Translation Loss:   0.021486 => Txt Tokens per Sec:     3824 || Lr: 0.000050
2024-02-03 05:12:54,397 Epoch 606: Total Training Recognition Loss 0.07  Total Training Translation Loss 2.23 
2024-02-03 05:12:54,398 EPOCH 607
2024-02-03 05:12:54,512 [Epoch: 607 Step: 00080600] Batch Recognition Loss:   0.000869 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.010413 => Txt Tokens per Sec:     4310 || Lr: 0.000050
2024-02-03 05:13:00,023 [Epoch: 607 Step: 00080700] Batch Recognition Loss:   0.000143 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.013084 => Txt Tokens per Sec:     4011 || Lr: 0.000050
2024-02-03 05:13:01,801 Epoch 607: Total Training Recognition Loss 0.06  Total Training Translation Loss 2.58 
2024-02-03 05:13:01,802 EPOCH 608
2024-02-03 05:13:05,552 [Epoch: 608 Step: 00080800] Batch Recognition Loss:   0.002206 => Gls Tokens per Sec:     1472 || Batch Translation Loss:   0.022604 => Txt Tokens per Sec:     4133 || Lr: 0.000050
2024-02-03 05:13:08,902 Epoch 608: Total Training Recognition Loss 0.06  Total Training Translation Loss 2.32 
2024-02-03 05:13:08,903 EPOCH 609
2024-02-03 05:13:11,142 [Epoch: 609 Step: 00080900] Batch Recognition Loss:   0.000105 => Gls Tokens per Sec:     1287 || Batch Translation Loss:   0.007275 => Txt Tokens per Sec:     3689 || Lr: 0.000050
2024-02-03 05:13:16,463 Epoch 609: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.47 
2024-02-03 05:13:16,463 EPOCH 610
2024-02-03 05:13:16,631 [Epoch: 610 Step: 00081000] Batch Recognition Loss:   0.000470 => Gls Tokens per Sec:     1437 || Batch Translation Loss:   0.012909 => Txt Tokens per Sec:     3898 || Lr: 0.000050
2024-02-03 05:13:22,466 [Epoch: 610 Step: 00081100] Batch Recognition Loss:   0.000074 => Gls Tokens per Sec:     1371 || Batch Translation Loss:   0.009102 => Txt Tokens per Sec:     3824 || Lr: 0.000050
2024-02-03 05:13:24,190 Epoch 610: Total Training Recognition Loss 0.06  Total Training Translation Loss 2.97 
2024-02-03 05:13:24,190 EPOCH 611
2024-02-03 05:13:28,377 [Epoch: 611 Step: 00081200] Batch Recognition Loss:   0.000580 => Gls Tokens per Sec:     1338 || Batch Translation Loss:   0.075492 => Txt Tokens per Sec:     3870 || Lr: 0.000050
2024-02-03 05:13:31,779 Epoch 611: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.36 
2024-02-03 05:13:31,779 EPOCH 612
2024-02-03 05:13:33,627 [Epoch: 612 Step: 00081300] Batch Recognition Loss:   0.000063 => Gls Tokens per Sec:     1602 || Batch Translation Loss:   0.020906 => Txt Tokens per Sec:     4318 || Lr: 0.000050
2024-02-03 05:13:39,304 Epoch 612: Total Training Recognition Loss 0.10  Total Training Translation Loss 7.59 
2024-02-03 05:13:39,304 EPOCH 613
2024-02-03 05:13:39,540 [Epoch: 613 Step: 00081400] Batch Recognition Loss:   0.001953 => Gls Tokens per Sec:     1362 || Batch Translation Loss:   0.009098 => Txt Tokens per Sec:     3374 || Lr: 0.000050
2024-02-03 05:13:45,284 [Epoch: 613 Step: 00081500] Batch Recognition Loss:   0.001934 => Gls Tokens per Sec:     1391 || Batch Translation Loss:   0.435659 => Txt Tokens per Sec:     3892 || Lr: 0.000050
2024-02-03 05:13:46,956 Epoch 613: Total Training Recognition Loss 0.39  Total Training Translation Loss 8.04 
2024-02-03 05:13:46,956 EPOCH 614
2024-02-03 05:13:50,977 [Epoch: 614 Step: 00081600] Batch Recognition Loss:   0.004443 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.287055 => Txt Tokens per Sec:     4002 || Lr: 0.000050
2024-02-03 05:13:54,491 Epoch 614: Total Training Recognition Loss 0.24  Total Training Translation Loss 4.59 
2024-02-03 05:13:54,492 EPOCH 615
2024-02-03 05:13:56,661 [Epoch: 615 Step: 00081700] Batch Recognition Loss:   0.001888 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.012321 => Txt Tokens per Sec:     4016 || Lr: 0.000050
2024-02-03 05:14:01,569 Epoch 615: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.67 
2024-02-03 05:14:01,569 EPOCH 616
2024-02-03 05:14:01,795 [Epoch: 616 Step: 00081800] Batch Recognition Loss:   0.000128 => Gls Tokens per Sec:     1778 || Batch Translation Loss:   0.040407 => Txt Tokens per Sec:     4929 || Lr: 0.000050
2024-02-03 05:14:07,688 [Epoch: 616 Step: 00081900] Batch Recognition Loss:   0.000483 => Gls Tokens per Sec:     1358 || Batch Translation Loss:   0.039330 => Txt Tokens per Sec:     3779 || Lr: 0.000050
2024-02-03 05:14:09,296 Epoch 616: Total Training Recognition Loss 0.13  Total Training Translation Loss 7.09 
2024-02-03 05:14:09,296 EPOCH 617
2024-02-03 05:14:13,076 [Epoch: 617 Step: 00082000] Batch Recognition Loss:   0.001527 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.021170 => Txt Tokens per Sec:     4197 || Lr: 0.000050
2024-02-03 05:14:24,415 Validation result at epoch 617, step    82000: duration: 11.3388s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.63254	Translation Loss: 85817.82812	PPL: 7430.58301
	Eval Metric: BLEU
	WER 2.90	(DEL: 0.21,	INS: 0.00,	SUB: 2.69)
	BLEU-4 0.41	(BLEU-1: 9.87,	BLEU-2: 2.68,	BLEU-3: 0.98,	BLEU-4: 0.41)
	CHRF 16.85	ROUGE 8.10
2024-02-03 05:14:24,416 Logging Recognition and Translation Outputs
2024-02-03 05:14:24,416 ========================================================================================================================
2024-02-03 05:14:24,416 Logging Sequence: 60_195.00
2024-02-03 05:14:24,416 	Gloss Reference :	A B+C+D+E
2024-02-03 05:14:24,416 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:14:24,416 	Gloss Alignment :	         
2024-02-03 05:14:24,417 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:14:24,418 	Text Reference  :	**** ** *** **** **** ******** people loved    to  watch his aggressive expressions and his  bowling   
2024-02-03 05:14:24,418 	Text Hypothesis :	plus do you know that everyone loves  watching ipl which is  why        i           am  very protective
2024-02-03 05:14:24,418 	Text Alignment  :	I    I  I   I    I    I        S      S        S   S     S   S          S           S   S    S         
2024-02-03 05:14:24,418 ========================================================================================================================
2024-02-03 05:14:24,418 Logging Sequence: 105_160.00
2024-02-03 05:14:24,418 	Gloss Reference :	A B+C+D+E
2024-02-03 05:14:24,419 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:14:24,419 	Gloss Alignment :	         
2024-02-03 05:14:24,419 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:14:24,420 	Text Reference  :	** ************* *** *** **** ** *** * **** *** many people tweeted congratulatory messages for   praggnanandhaa
2024-02-03 05:14:24,420 	Text Hypothesis :	he congratualted him and said it was a good day and  that   it      was            a        proud moment        
2024-02-03 05:14:24,420 	Text Alignment  :	I  I             I   I   I    I  I   I I    I   S    S      S       S              S        S     S             
2024-02-03 05:14:24,420 ========================================================================================================================
2024-02-03 05:14:24,420 Logging Sequence: 161_200.00
2024-02-03 05:14:24,421 	Gloss Reference :	A B+C+D+E
2024-02-03 05:14:24,421 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:14:24,421 	Gloss Alignment :	         
2024-02-03 05:14:24,421 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:14:24,423 	Text Reference  :	********* congratulations i   am   proud    of  your hardwork and determination as   a    captain for  all these years  
2024-02-03 05:14:24,423 	Text Hypothesis :	according to              the many netizens who is   held     in  2021          from 10th july    2023 to  3     matches
2024-02-03 05:14:24,423 	Text Alignment  :	I         S               S   S    S        S   S    S        S   S             S    S    S       S    S   S     S      
2024-02-03 05:14:24,423 ========================================================================================================================
2024-02-03 05:14:24,423 Logging Sequence: 132_69.00
2024-02-03 05:14:24,423 	Gloss Reference :	A B+C+D+E
2024-02-03 05:14:24,423 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:14:24,424 	Gloss Alignment :	         
2024-02-03 05:14:24,424 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:14:24,425 	Text Reference  :	the team was      presented the    tiny ashes trophy the team cheered and posed for cameras on  the  dias
2024-02-03 05:14:24,425 	Text Hypothesis :	*** **** reliance has       turned out  to    be     the **** ******* *** ***** t20 world   cup many team
2024-02-03 05:14:24,425 	Text Alignment  :	D   D    S        S         S      S    S     S          D    D       D   D     S   S       S   S    S   
2024-02-03 05:14:24,425 ========================================================================================================================
2024-02-03 05:14:24,426 Logging Sequence: 111_120.00
2024-02-03 05:14:24,426 	Gloss Reference :	A B+C+D+E
2024-02-03 05:14:24,426 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:14:24,426 	Gloss Alignment :	         
2024-02-03 05:14:24,426 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:14:24,427 	Text Reference  :	*** ** ** * or   rs 12        lakh
2024-02-03 05:14:24,427 	Text Hypothesis :	and he is a such a  one-match ban 
2024-02-03 05:14:24,427 	Text Alignment  :	I   I  I  I S    S  S         S   
2024-02-03 05:14:24,427 ========================================================================================================================
2024-02-03 05:14:28,110 Epoch 617: Total Training Recognition Loss 0.09  Total Training Translation Loss 6.24 
2024-02-03 05:14:28,110 EPOCH 618
2024-02-03 05:14:30,223 [Epoch: 618 Step: 00082100] Batch Recognition Loss:   0.000295 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.051812 => Txt Tokens per Sec:     4188 || Lr: 0.000050
2024-02-03 05:14:35,431 Epoch 618: Total Training Recognition Loss 0.16  Total Training Translation Loss 8.23 
2024-02-03 05:14:35,431 EPOCH 619
2024-02-03 05:14:35,802 [Epoch: 619 Step: 00082200] Batch Recognition Loss:   0.000915 => Gls Tokens per Sec:     1301 || Batch Translation Loss:   0.050624 => Txt Tokens per Sec:     3585 || Lr: 0.000050
2024-02-03 05:14:41,184 [Epoch: 619 Step: 00082300] Batch Recognition Loss:   0.000383 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.017638 => Txt Tokens per Sec:     4115 || Lr: 0.000050
2024-02-03 05:14:42,743 Epoch 619: Total Training Recognition Loss 0.08  Total Training Translation Loss 6.97 
2024-02-03 05:14:42,743 EPOCH 620
2024-02-03 05:14:46,515 [Epoch: 620 Step: 00082400] Batch Recognition Loss:   0.000876 => Gls Tokens per Sec:     1550 || Batch Translation Loss:   0.008728 => Txt Tokens per Sec:     4296 || Lr: 0.000050
2024-02-03 05:14:50,097 Epoch 620: Total Training Recognition Loss 0.10  Total Training Translation Loss 5.33 
2024-02-03 05:14:50,098 EPOCH 621
2024-02-03 05:14:52,321 [Epoch: 621 Step: 00082500] Batch Recognition Loss:   0.000054 => Gls Tokens per Sec:     1440 || Batch Translation Loss:   0.024525 => Txt Tokens per Sec:     4011 || Lr: 0.000050
2024-02-03 05:14:57,528 Epoch 621: Total Training Recognition Loss 0.08  Total Training Translation Loss 4.62 
2024-02-03 05:14:57,528 EPOCH 622
2024-02-03 05:14:57,890 [Epoch: 622 Step: 00082600] Batch Recognition Loss:   0.000243 => Gls Tokens per Sec:     1551 || Batch Translation Loss:   0.012665 => Txt Tokens per Sec:     4449 || Lr: 0.000050
2024-02-03 05:15:03,741 [Epoch: 622 Step: 00082700] Batch Recognition Loss:   0.000294 => Gls Tokens per Sec:     1367 || Batch Translation Loss:   0.021415 => Txt Tokens per Sec:     3803 || Lr: 0.000050
2024-02-03 05:15:05,313 Epoch 622: Total Training Recognition Loss 0.07  Total Training Translation Loss 4.35 
2024-02-03 05:15:05,313 EPOCH 623
2024-02-03 05:15:09,349 [Epoch: 623 Step: 00082800] Batch Recognition Loss:   0.000338 => Gls Tokens per Sec:     1467 || Batch Translation Loss:   0.018108 => Txt Tokens per Sec:     4073 || Lr: 0.000050
2024-02-03 05:15:12,815 Epoch 623: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.74 
2024-02-03 05:15:12,816 EPOCH 624
2024-02-03 05:15:15,127 [Epoch: 624 Step: 00082900] Batch Recognition Loss:   0.000803 => Gls Tokens per Sec:     1420 || Batch Translation Loss:   0.010841 => Txt Tokens per Sec:     3955 || Lr: 0.000050
2024-02-03 05:15:19,850 Epoch 624: Total Training Recognition Loss 0.08  Total Training Translation Loss 3.00 
2024-02-03 05:15:19,851 EPOCH 625
2024-02-03 05:15:20,416 [Epoch: 625 Step: 00083000] Batch Recognition Loss:   0.000278 => Gls Tokens per Sec:     1134 || Batch Translation Loss:   0.082636 => Txt Tokens per Sec:     3069 || Lr: 0.000050
2024-02-03 05:15:26,087 [Epoch: 625 Step: 00083100] Batch Recognition Loss:   0.000173 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.024853 => Txt Tokens per Sec:     3942 || Lr: 0.000050
2024-02-03 05:15:27,404 Epoch 625: Total Training Recognition Loss 0.06  Total Training Translation Loss 3.86 
2024-02-03 05:15:27,404 EPOCH 626
2024-02-03 05:15:31,993 [Epoch: 626 Step: 00083200] Batch Recognition Loss:   0.000376 => Gls Tokens per Sec:     1308 || Batch Translation Loss:   0.021401 => Txt Tokens per Sec:     3718 || Lr: 0.000050
2024-02-03 05:15:34,904 Epoch 626: Total Training Recognition Loss 0.09  Total Training Translation Loss 3.58 
2024-02-03 05:15:34,905 EPOCH 627
2024-02-03 05:15:36,908 [Epoch: 627 Step: 00083300] Batch Recognition Loss:   0.000075 => Gls Tokens per Sec:     1678 || Batch Translation Loss:   0.020055 => Txt Tokens per Sec:     4690 || Lr: 0.000050
2024-02-03 05:15:42,056 Epoch 627: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.04 
2024-02-03 05:15:42,056 EPOCH 628
2024-02-03 05:15:42,483 [Epoch: 628 Step: 00083400] Batch Recognition Loss:   0.001106 => Gls Tokens per Sec:     1694 || Batch Translation Loss:   0.009835 => Txt Tokens per Sec:     4733 || Lr: 0.000050
2024-02-03 05:15:48,384 [Epoch: 628 Step: 00083500] Batch Recognition Loss:   0.000751 => Gls Tokens per Sec:     1354 || Batch Translation Loss:   0.163271 => Txt Tokens per Sec:     3726 || Lr: 0.000050
2024-02-03 05:15:49,727 Epoch 628: Total Training Recognition Loss 0.09  Total Training Translation Loss 5.96 
2024-02-03 05:15:49,728 EPOCH 629
2024-02-03 05:15:53,703 [Epoch: 629 Step: 00083600] Batch Recognition Loss:   0.000211 => Gls Tokens per Sec:     1530 || Batch Translation Loss:   0.513012 => Txt Tokens per Sec:     4269 || Lr: 0.000050
2024-02-03 05:15:56,931 Epoch 629: Total Training Recognition Loss 0.10  Total Training Translation Loss 6.23 
2024-02-03 05:15:56,932 EPOCH 630
2024-02-03 05:15:59,261 [Epoch: 630 Step: 00083700] Batch Recognition Loss:   0.000166 => Gls Tokens per Sec:     1477 || Batch Translation Loss:   0.048093 => Txt Tokens per Sec:     4002 || Lr: 0.000050
2024-02-03 05:16:04,244 Epoch 630: Total Training Recognition Loss 0.13  Total Training Translation Loss 5.86 
2024-02-03 05:16:04,244 EPOCH 631
2024-02-03 05:16:04,906 [Epoch: 631 Step: 00083800] Batch Recognition Loss:   0.000847 => Gls Tokens per Sec:     1210 || Batch Translation Loss:   0.016201 => Txt Tokens per Sec:     3192 || Lr: 0.000050
2024-02-03 05:16:10,595 [Epoch: 631 Step: 00083900] Batch Recognition Loss:   0.002652 => Gls Tokens per Sec:     1407 || Batch Translation Loss:   0.015855 => Txt Tokens per Sec:     3980 || Lr: 0.000050
2024-02-03 05:16:11,966 Epoch 631: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.51 
2024-02-03 05:16:11,966 EPOCH 632
2024-02-03 05:16:16,366 [Epoch: 632 Step: 00084000] Batch Recognition Loss:   0.003055 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.019805 => Txt Tokens per Sec:     3852 || Lr: 0.000050
2024-02-03 05:16:27,552 Validation result at epoch 632, step    84000: duration: 11.1848s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 10.31115	Translation Loss: 87499.47656	PPL: 8848.66797
	Eval Metric: BLEU
	WER 3.25	(DEL: 0.14,	INS: 0.00,	SUB: 3.11)
	BLEU-4 0.43	(BLEU-1: 9.81,	BLEU-2: 2.32,	BLEU-3: 0.83,	BLEU-4: 0.43)
	CHRF 16.40	ROUGE 8.12
2024-02-03 05:16:27,553 Logging Recognition and Translation Outputs
2024-02-03 05:16:27,553 ========================================================================================================================
2024-02-03 05:16:27,553 Logging Sequence: 96_199.00
2024-02-03 05:16:27,553 	Gloss Reference :	A B+C+D+E
2024-02-03 05:16:27,554 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:16:27,554 	Gloss Alignment :	         
2024-02-03 05:16:27,554 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:16:27,554 	Text Reference  :	with india's win people felt relaxed
2024-02-03 05:16:27,554 	Text Hypothesis :	**** ******* he  is     very excited
2024-02-03 05:16:27,554 	Text Alignment  :	D    D       S   S      S    S      
2024-02-03 05:16:27,555 ========================================================================================================================
2024-02-03 05:16:27,555 Logging Sequence: 67_129.00
2024-02-03 05:16:27,555 	Gloss Reference :	A B+C+D+E
2024-02-03 05:16:27,555 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:16:27,555 	Gloss Alignment :	         
2024-02-03 05:16:27,555 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:16:27,556 	Text Reference  :	**** ** *** * ******* ** lee stressed on  3        points  
2024-02-03 05:16:27,556 	Text Hypothesis :	this is why i decided to not retire   and continue playing'
2024-02-03 05:16:27,556 	Text Alignment  :	I    I  I   I I       I  S   S        S   S        S       
2024-02-03 05:16:27,556 ========================================================================================================================
2024-02-03 05:16:27,557 Logging Sequence: 149_96.00
2024-02-03 05:16:27,557 	Gloss Reference :	A B+C+D+E
2024-02-03 05:16:27,557 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:16:27,557 	Gloss Alignment :	         
2024-02-03 05:16:27,557 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:16:27,558 	Text Reference  :	** *** *** *** ***** **** australian police  filed the *** **** ** *** complaint and arrested him 
2024-02-03 05:16:27,558 	Text Hypothesis :	it was not the first time that       earlier in    the era when he was paid      rs  1        lakh
2024-02-03 05:16:27,558 	Text Alignment  :	I  I   I   I   I     I    S          S       S         I   I    I  I   S         S   S        S   
2024-02-03 05:16:27,558 ========================================================================================================================
2024-02-03 05:16:27,559 Logging Sequence: 101_30.00
2024-02-03 05:16:27,559 	Gloss Reference :	A B+C+D+E
2024-02-03 05:16:27,559 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:16:27,559 	Gloss Alignment :	         
2024-02-03 05:16:27,559 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:16:27,560 	Text Reference  :	the national under-19 teams of countries like australia england india   etc contested in    the tournament
2024-02-03 05:16:27,560 	Text Hypothesis :	*** ******** ******** ***** ** ********* **** people    were    shocked to  see       these -   time      
2024-02-03 05:16:27,560 	Text Alignment  :	D   D        D        D     D  D         D    S         S       S       S   S         S     S   S         
2024-02-03 05:16:27,560 ========================================================================================================================
2024-02-03 05:16:27,561 Logging Sequence: 111_120.00
2024-02-03 05:16:27,561 	Gloss Reference :	A B+C+D+E
2024-02-03 05:16:27,561 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:16:27,561 	Gloss Alignment :	         
2024-02-03 05:16:27,561 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:16:27,562 	Text Reference  :	*** *** ***** ******* **** ******** **** *** ******* **** **** or  rs  12   lakh    
2024-02-03 05:16:27,562 	Text Hypothesis :	and the match referee then confirms that the minimum over rate has not been achieved
2024-02-03 05:16:27,562 	Text Alignment  :	I   I   I     I       I    I        I    I   I       I    I    S   S   S    S       
2024-02-03 05:16:27,562 ========================================================================================================================
2024-02-03 05:16:31,037 Epoch 632: Total Training Recognition Loss 0.09  Total Training Translation Loss 5.83 
2024-02-03 05:16:31,038 EPOCH 633
2024-02-03 05:16:33,511 [Epoch: 633 Step: 00084100] Batch Recognition Loss:   0.000103 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.013302 => Txt Tokens per Sec:     3974 || Lr: 0.000050
2024-02-03 05:16:38,735 Epoch 633: Total Training Recognition Loss 0.16  Total Training Translation Loss 6.02 
2024-02-03 05:16:38,736 EPOCH 634
2024-02-03 05:16:39,244 [Epoch: 634 Step: 00084200] Batch Recognition Loss:   0.000243 => Gls Tokens per Sec:     1736 || Batch Translation Loss:   0.054138 => Txt Tokens per Sec:     4639 || Lr: 0.000050
2024-02-03 05:16:45,094 [Epoch: 634 Step: 00084300] Batch Recognition Loss:   0.002375 => Gls Tokens per Sec:     1368 || Batch Translation Loss:   0.008699 => Txt Tokens per Sec:     3838 || Lr: 0.000050
2024-02-03 05:16:46,403 Epoch 634: Total Training Recognition Loss 0.14  Total Training Translation Loss 5.22 
2024-02-03 05:16:46,403 EPOCH 635
2024-02-03 05:16:50,507 [Epoch: 635 Step: 00084400] Batch Recognition Loss:   0.000243 => Gls Tokens per Sec:     1521 || Batch Translation Loss:   0.030557 => Txt Tokens per Sec:     4239 || Lr: 0.000050
2024-02-03 05:16:53,648 Epoch 635: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.91 
2024-02-03 05:16:53,649 EPOCH 636
2024-02-03 05:16:56,184 [Epoch: 636 Step: 00084500] Batch Recognition Loss:   0.000062 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.013442 => Txt Tokens per Sec:     4023 || Lr: 0.000050
2024-02-03 05:17:01,283 Epoch 636: Total Training Recognition Loss 0.12  Total Training Translation Loss 5.81 
2024-02-03 05:17:01,284 EPOCH 637
2024-02-03 05:17:01,933 [Epoch: 637 Step: 00084600] Batch Recognition Loss:   0.000253 => Gls Tokens per Sec:     1480 || Batch Translation Loss:   0.022933 => Txt Tokens per Sec:     3944 || Lr: 0.000050
2024-02-03 05:17:07,457 [Epoch: 637 Step: 00084700] Batch Recognition Loss:   0.000364 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.020008 => Txt Tokens per Sec:     4014 || Lr: 0.000050
2024-02-03 05:17:08,634 Epoch 637: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.01 
2024-02-03 05:17:08,635 EPOCH 638
2024-02-03 05:17:13,233 [Epoch: 638 Step: 00084800] Batch Recognition Loss:   0.000840 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.005111 => Txt Tokens per Sec:     3872 || Lr: 0.000050
2024-02-03 05:17:15,999 Epoch 638: Total Training Recognition Loss 0.11  Total Training Translation Loss 4.74 
2024-02-03 05:17:15,999 EPOCH 639
2024-02-03 05:17:18,418 [Epoch: 639 Step: 00084900] Batch Recognition Loss:   0.000195 => Gls Tokens per Sec:     1522 || Batch Translation Loss:   0.015336 => Txt Tokens per Sec:     4203 || Lr: 0.000050
2024-02-03 05:17:23,289 Epoch 639: Total Training Recognition Loss 0.14  Total Training Translation Loss 4.63 
2024-02-03 05:17:23,289 EPOCH 640
2024-02-03 05:17:24,001 [Epoch: 640 Step: 00085000] Batch Recognition Loss:   0.000174 => Gls Tokens per Sec:     1463 || Batch Translation Loss:   0.012989 => Txt Tokens per Sec:     4079 || Lr: 0.000050
2024-02-03 05:17:29,709 [Epoch: 640 Step: 00085100] Batch Recognition Loss:   0.000142 => Gls Tokens per Sec:     1400 || Batch Translation Loss:   0.014225 => Txt Tokens per Sec:     3929 || Lr: 0.000050
2024-02-03 05:17:30,751 Epoch 640: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.90 
2024-02-03 05:17:30,752 EPOCH 641
2024-02-03 05:17:35,216 [Epoch: 641 Step: 00085200] Batch Recognition Loss:   0.002435 => Gls Tokens per Sec:     1434 || Batch Translation Loss:   0.010862 => Txt Tokens per Sec:     3984 || Lr: 0.000050
2024-02-03 05:17:38,270 Epoch 641: Total Training Recognition Loss 0.08  Total Training Translation Loss 5.54 
2024-02-03 05:17:38,271 EPOCH 642
2024-02-03 05:17:40,760 [Epoch: 642 Step: 00085300] Batch Recognition Loss:   0.000095 => Gls Tokens per Sec:     1511 || Batch Translation Loss:   0.019591 => Txt Tokens per Sec:     4259 || Lr: 0.000050
2024-02-03 05:17:45,397 Epoch 642: Total Training Recognition Loss 0.09  Total Training Translation Loss 3.98 
2024-02-03 05:17:45,397 EPOCH 643
2024-02-03 05:17:46,269 [Epoch: 643 Step: 00085400] Batch Recognition Loss:   0.000206 => Gls Tokens per Sec:     1288 || Batch Translation Loss:   0.092268 => Txt Tokens per Sec:     3563 || Lr: 0.000050
2024-02-03 05:17:51,939 [Epoch: 643 Step: 00085500] Batch Recognition Loss:   0.000117 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.016760 => Txt Tokens per Sec:     3943 || Lr: 0.000050
2024-02-03 05:17:53,111 Epoch 643: Total Training Recognition Loss 0.17  Total Training Translation Loss 4.12 
2024-02-03 05:17:53,111 EPOCH 644
2024-02-03 05:17:57,761 [Epoch: 644 Step: 00085600] Batch Recognition Loss:   0.000228 => Gls Tokens per Sec:     1394 || Batch Translation Loss:   0.019155 => Txt Tokens per Sec:     3904 || Lr: 0.000050
2024-02-03 05:18:00,563 Epoch 644: Total Training Recognition Loss 0.13  Total Training Translation Loss 3.96 
2024-02-03 05:18:00,563 EPOCH 645
2024-02-03 05:18:03,282 [Epoch: 645 Step: 00085700] Batch Recognition Loss:   0.024309 => Gls Tokens per Sec:     1413 || Batch Translation Loss:   0.030781 => Txt Tokens per Sec:     3974 || Lr: 0.000050
2024-02-03 05:18:07,939 Epoch 645: Total Training Recognition Loss 0.10  Total Training Translation Loss 5.87 
2024-02-03 05:18:07,939 EPOCH 646
2024-02-03 05:18:08,867 [Epoch: 646 Step: 00085800] Batch Recognition Loss:   0.000337 => Gls Tokens per Sec:     1295 || Batch Translation Loss:   0.051281 => Txt Tokens per Sec:     3775 || Lr: 0.000050
2024-02-03 05:18:14,472 [Epoch: 646 Step: 00085900] Batch Recognition Loss:   0.000368 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.028808 => Txt Tokens per Sec:     3956 || Lr: 0.000050
2024-02-03 05:18:15,380 Epoch 646: Total Training Recognition Loss 0.12  Total Training Translation Loss 6.85 
2024-02-03 05:18:15,380 EPOCH 647
2024-02-03 05:18:19,657 [Epoch: 647 Step: 00086000] Batch Recognition Loss:   0.000308 => Gls Tokens per Sec:     1534 || Batch Translation Loss:   0.029354 => Txt Tokens per Sec:     4275 || Lr: 0.000050
2024-02-03 05:18:31,442 Validation result at epoch 647, step    86000: duration: 11.7853s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.98977	Translation Loss: 86471.85938	PPL: 7952.88330
	Eval Metric: BLEU
	WER 2.97	(DEL: 0.07,	INS: 0.00,	SUB: 2.90)
	BLEU-4 0.61	(BLEU-1: 10.00,	BLEU-2: 2.89,	BLEU-3: 1.10,	BLEU-4: 0.61)
	CHRF 16.74	ROUGE 8.27
2024-02-03 05:18:31,443 Logging Recognition and Translation Outputs
2024-02-03 05:18:31,443 ========================================================================================================================
2024-02-03 05:18:31,443 Logging Sequence: 136_107.00
2024-02-03 05:18:31,443 	Gloss Reference :	A B+C+D+E
2024-02-03 05:18:31,443 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:18:31,444 	Gloss Alignment :	         
2024-02-03 05:18:31,444 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:18:31,445 	Text Reference  :	***** *** *** *** ***** ** sindhu replied that she had   stop  eating icecream because of her training
2024-02-03 05:18:31,445 	Text Hypothesis :	india had won the total of 58     runs    off  31  balls laced with   a        target  of 139 runs    
2024-02-03 05:18:31,445 	Text Alignment  :	I     I   I   I   I     I  S      S       S    S   S     S     S      S        S          S   S       
2024-02-03 05:18:31,446 ========================================================================================================================
2024-02-03 05:18:31,446 Logging Sequence: 53_111.00
2024-02-03 05:18:31,446 	Gloss Reference :	A B+C+D+E
2024-02-03 05:18:31,446 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:18:31,446 	Gloss Alignment :	         
2024-02-03 05:18:31,446 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:18:31,447 	Text Reference  :	he tweeted and said i request all the strong world     leaders to  help afghanistan 
2024-02-03 05:18:31,447 	Text Hypothesis :	** ******* *** **** * ******* *** *** people applauded biles   for her  achievements
2024-02-03 05:18:31,447 	Text Alignment  :	D  D       D   D    D D       D   D   S      S         S       S   S    S           
2024-02-03 05:18:31,447 ========================================================================================================================
2024-02-03 05:18:31,447 Logging Sequence: 180_409.00
2024-02-03 05:18:31,448 	Gloss Reference :	A B+C+D+E
2024-02-03 05:18:31,448 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:18:31,448 	Gloss Alignment :	         
2024-02-03 05:18:31,448 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:18:31,449 	Text Reference  :	******* ******* **** ******** cricketer kapil dev       etc     have **** also shown support to the wrestlers through their tweets 
2024-02-03 05:18:31,449 	Text Hypothesis :	several leaders from congress and       other political parties have come out  in    support of the ********* ******* 2     matches
2024-02-03 05:18:31,450 	Text Alignment  :	I       I       I    I        S         S     S         S            I    S    S             S      D         D       S     S      
2024-02-03 05:18:31,450 ========================================================================================================================
2024-02-03 05:18:31,450 Logging Sequence: 149_96.00
2024-02-03 05:18:31,450 	Gloss Reference :	A B+C+D+E
2024-02-03 05:18:31,450 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:18:31,450 	Gloss Alignment :	         
2024-02-03 05:18:31,450 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:18:31,451 	Text Reference  :	** *** australian police filed the *** *** complaint and arrested him 
2024-02-03 05:18:31,451 	Text Hypothesis :	it was a          small  fine  the boy was fined     rs  65       lakh
2024-02-03 05:18:31,451 	Text Alignment  :	I  I   S          S      S         I   I   S         S   S        S   
2024-02-03 05:18:31,452 ========================================================================================================================
2024-02-03 05:18:31,452 Logging Sequence: 80_65.00
2024-02-03 05:18:31,452 	Gloss Reference :	A B+C+D+E
2024-02-03 05:18:31,452 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:18:31,452 	Gloss Alignment :	         
2024-02-03 05:18:31,452 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:18:31,453 	Text Reference  :	people began speculating a rift   in       their marriage such     rumors were        on the   sign
2024-02-03 05:18:31,453 	Text Hypothesis :	****** ***** *********** * senior citizens with  weak     immunity are    susceptible to camel flu 
2024-02-03 05:18:31,453 	Text Alignment  :	D      D     D           D S      S        S     S        S        S      S           S  S     S   
2024-02-03 05:18:31,454 ========================================================================================================================
2024-02-03 05:18:34,179 Epoch 647: Total Training Recognition Loss 0.13  Total Training Translation Loss 4.75 
2024-02-03 05:18:34,179 EPOCH 648
2024-02-03 05:18:36,616 [Epoch: 648 Step: 00086100] Batch Recognition Loss:   0.000632 => Gls Tokens per Sec:     1609 || Batch Translation Loss:   0.017156 => Txt Tokens per Sec:     4422 || Lr: 0.000050
2024-02-03 05:18:41,601 Epoch 648: Total Training Recognition Loss 0.23  Total Training Translation Loss 6.54 
2024-02-03 05:18:41,602 EPOCH 649
2024-02-03 05:18:42,482 [Epoch: 649 Step: 00086200] Batch Recognition Loss:   0.000241 => Gls Tokens per Sec:     1458 || Batch Translation Loss:   0.020571 => Txt Tokens per Sec:     4050 || Lr: 0.000050
2024-02-03 05:18:47,973 [Epoch: 649 Step: 00086300] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.025620 => Txt Tokens per Sec:     4013 || Lr: 0.000050
2024-02-03 05:18:49,015 Epoch 649: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.74 
2024-02-03 05:18:49,015 EPOCH 650
2024-02-03 05:18:53,682 [Epoch: 650 Step: 00086400] Batch Recognition Loss:   0.000096 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.127205 => Txt Tokens per Sec:     3976 || Lr: 0.000050
2024-02-03 05:18:56,622 Epoch 650: Total Training Recognition Loss 0.13  Total Training Translation Loss 4.56 
2024-02-03 05:18:56,623 EPOCH 651
2024-02-03 05:18:59,336 [Epoch: 651 Step: 00086500] Batch Recognition Loss:   0.000631 => Gls Tokens per Sec:     1475 || Batch Translation Loss:   0.017462 => Txt Tokens per Sec:     4055 || Lr: 0.000050
2024-02-03 05:19:03,838 Epoch 651: Total Training Recognition Loss 0.18  Total Training Translation Loss 3.94 
2024-02-03 05:19:03,838 EPOCH 652
2024-02-03 05:19:04,644 [Epoch: 652 Step: 00086600] Batch Recognition Loss:   0.000840 => Gls Tokens per Sec:     1689 || Batch Translation Loss:   0.016642 => Txt Tokens per Sec:     4573 || Lr: 0.000050
2024-02-03 05:19:10,594 [Epoch: 652 Step: 00086700] Batch Recognition Loss:   0.000244 => Gls Tokens per Sec:     1343 || Batch Translation Loss:   0.016161 => Txt Tokens per Sec:     3771 || Lr: 0.000050
2024-02-03 05:19:11,505 Epoch 652: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.25 
2024-02-03 05:19:11,505 EPOCH 653
2024-02-03 05:19:16,310 [Epoch: 653 Step: 00086800] Batch Recognition Loss:   0.000877 => Gls Tokens per Sec:     1399 || Batch Translation Loss:   0.026867 => Txt Tokens per Sec:     3942 || Lr: 0.000050
2024-02-03 05:19:18,971 Epoch 653: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.74 
2024-02-03 05:19:18,971 EPOCH 654
2024-02-03 05:19:21,916 [Epoch: 654 Step: 00086900] Batch Recognition Loss:   0.000076 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.011522 => Txt Tokens per Sec:     3883 || Lr: 0.000050
2024-02-03 05:19:26,279 Epoch 654: Total Training Recognition Loss 0.08  Total Training Translation Loss 3.36 
2024-02-03 05:19:26,280 EPOCH 655
2024-02-03 05:19:27,135 [Epoch: 655 Step: 00087000] Batch Recognition Loss:   0.000373 => Gls Tokens per Sec:     1684 || Batch Translation Loss:   0.016959 => Txt Tokens per Sec:     4851 || Lr: 0.000050
2024-02-03 05:19:32,870 [Epoch: 655 Step: 00087100] Batch Recognition Loss:   0.000484 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.035469 => Txt Tokens per Sec:     3836 || Lr: 0.000050
2024-02-03 05:19:33,740 Epoch 655: Total Training Recognition Loss 0.08  Total Training Translation Loss 2.96 
2024-02-03 05:19:33,740 EPOCH 656
2024-02-03 05:19:38,370 [Epoch: 656 Step: 00087200] Batch Recognition Loss:   0.000720 => Gls Tokens per Sec:     1470 || Batch Translation Loss:   0.015756 => Txt Tokens per Sec:     3965 || Lr: 0.000050
2024-02-03 05:19:41,238 Epoch 656: Total Training Recognition Loss 0.08  Total Training Translation Loss 3.27 
2024-02-03 05:19:41,238 EPOCH 657
2024-02-03 05:19:44,047 [Epoch: 657 Step: 00087300] Batch Recognition Loss:   0.000478 => Gls Tokens per Sec:     1482 || Batch Translation Loss:   0.016714 => Txt Tokens per Sec:     4171 || Lr: 0.000050
2024-02-03 05:19:48,356 Epoch 657: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.36 
2024-02-03 05:19:48,356 EPOCH 658
2024-02-03 05:19:49,568 [Epoch: 658 Step: 00087400] Batch Recognition Loss:   0.000198 => Gls Tokens per Sec:     1255 || Batch Translation Loss:   0.017486 => Txt Tokens per Sec:     3566 || Lr: 0.000050
2024-02-03 05:19:55,456 [Epoch: 658 Step: 00087500] Batch Recognition Loss:   0.000226 => Gls Tokens per Sec:     1358 || Batch Translation Loss:   0.014199 => Txt Tokens per Sec:     3750 || Lr: 0.000050
2024-02-03 05:19:56,360 Epoch 658: Total Training Recognition Loss 0.25  Total Training Translation Loss 6.01 
2024-02-03 05:19:56,361 EPOCH 659
2024-02-03 05:20:01,240 [Epoch: 659 Step: 00087600] Batch Recognition Loss:   0.004677 => Gls Tokens per Sec:     1411 || Batch Translation Loss:   0.034544 => Txt Tokens per Sec:     3895 || Lr: 0.000050
2024-02-03 05:20:03,847 Epoch 659: Total Training Recognition Loss 0.12  Total Training Translation Loss 5.89 
2024-02-03 05:20:03,847 EPOCH 660
2024-02-03 05:20:06,631 [Epoch: 660 Step: 00087700] Batch Recognition Loss:   0.000111 => Gls Tokens per Sec:     1524 || Batch Translation Loss:   0.021350 => Txt Tokens per Sec:     4298 || Lr: 0.000050
2024-02-03 05:20:10,936 Epoch 660: Total Training Recognition Loss 0.10  Total Training Translation Loss 6.06 
2024-02-03 05:20:10,936 EPOCH 661
2024-02-03 05:20:12,040 [Epoch: 661 Step: 00087800] Batch Recognition Loss:   0.000221 => Gls Tokens per Sec:     1451 || Batch Translation Loss:   0.025580 => Txt Tokens per Sec:     4013 || Lr: 0.000050
2024-02-03 05:20:17,574 [Epoch: 661 Step: 00087900] Batch Recognition Loss:   0.000361 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.023745 => Txt Tokens per Sec:     4003 || Lr: 0.000050
2024-02-03 05:20:18,381 Epoch 661: Total Training Recognition Loss 0.14  Total Training Translation Loss 4.73 
2024-02-03 05:20:18,381 EPOCH 662
2024-02-03 05:20:22,787 [Epoch: 662 Step: 00088000] Batch Recognition Loss:   0.000178 => Gls Tokens per Sec:     1580 || Batch Translation Loss:   0.014440 => Txt Tokens per Sec:     4351 || Lr: 0.000050
2024-02-03 05:20:34,359 Validation result at epoch 662, step    88000: duration: 11.5721s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.44511	Translation Loss: 86258.10156	PPL: 7778.26318
	Eval Metric: BLEU
	WER 2.90	(DEL: 0.07,	INS: 0.00,	SUB: 2.83)
	BLEU-4 0.48	(BLEU-1: 10.25,	BLEU-2: 2.65,	BLEU-3: 0.97,	BLEU-4: 0.48)
	CHRF 16.71	ROUGE 8.73
2024-02-03 05:20:34,361 Logging Recognition and Translation Outputs
2024-02-03 05:20:34,361 ========================================================================================================================
2024-02-03 05:20:34,361 Logging Sequence: 61_84.00
2024-02-03 05:20:34,362 	Gloss Reference :	A B+C+D+E
2024-02-03 05:20:34,362 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:20:34,362 	Gloss Alignment :	         
2024-02-03 05:20:34,362 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:20:34,363 	Text Reference  :	** let me   tell you  about it  
2024-02-03 05:20:34,363 	Text Hypothesis :	it has been the  same since long
2024-02-03 05:20:34,363 	Text Alignment  :	I  S   S    S    S    S     S   
2024-02-03 05:20:34,363 ========================================================================================================================
2024-02-03 05:20:34,363 Logging Sequence: 122_164.00
2024-02-03 05:20:34,363 	Gloss Reference :	A B+C+D+E
2024-02-03 05:20:34,364 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:20:34,364 	Gloss Alignment :	         
2024-02-03 05:20:34,364 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:20:34,365 	Text Reference  :	you no longer have to be a ticket checking inspector in       the  railways
2024-02-03 05:20:34,365 	Text Hypothesis :	*** ** ****** **** ** ** a video  of       the       incident went viral   
2024-02-03 05:20:34,365 	Text Alignment  :	D   D  D      D    D  D    S      S        S         S        S    S       
2024-02-03 05:20:34,365 ========================================================================================================================
2024-02-03 05:20:34,365 Logging Sequence: 112_130.00
2024-02-03 05:20:34,365 	Gloss Reference :	A B+C+D+E
2024-02-03 05:20:34,365 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:20:34,366 	Gloss Alignment :	         
2024-02-03 05:20:34,366 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:20:34,368 	Text Reference  :	* **** **** ****** they will now     have lucknow's staudium named after late     atal bihari vajpayee stadium as     their home base 
2024-02-03 05:20:34,368 	Text Hypothesis :	a user said azam's face is   visible and  someone's hand     with  nails although the  gender of       the     person was   not  clear
2024-02-03 05:20:34,368 	Text Alignment  :	I I    I    I      S    S    S       S    S         S        S     S     S        S    S      S        S       S      S     S    S    
2024-02-03 05:20:34,368 ========================================================================================================================
2024-02-03 05:20:34,368 Logging Sequence: 122_28.00
2024-02-03 05:20:34,369 	Gloss Reference :	A B+C+D+E
2024-02-03 05:20:34,369 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:20:34,369 	Gloss Alignment :	         
2024-02-03 05:20:34,369 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:20:34,370 	Text Reference  :	now at     the ***** ******* age of  26  chanu took  part   in the   tokyo olympics in      japan  
2024-02-03 05:20:34,371 	Text Hypothesis :	*** during the match between rcb and lsg was   being played in start from  the      bidding process
2024-02-03 05:20:34,371 	Text Alignment  :	D   S          I     I       S   S   S   S     S     S         S     S     S        S       S      
2024-02-03 05:20:34,371 ========================================================================================================================
2024-02-03 05:20:34,371 Logging Sequence: 132_69.00
2024-02-03 05:20:34,371 	Gloss Reference :	A B+C+D+E
2024-02-03 05:20:34,371 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:20:34,372 	Gloss Alignment :	         
2024-02-03 05:20:34,372 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:20:34,374 	Text Reference  :	***** *** *** the *** team was presented the     tiny  ashes trophy the team cheered and posed for cameras on      the dias
2024-02-03 05:20:34,374 	Text Hypothesis :	thank you for the ipl team *** ********* chennai super kings after  the **** game    was held  at  the     stadium in  2021
2024-02-03 05:20:34,374 	Text Alignment  :	I     I   I       I        D   D         S       S     S     S          D    S       S   S     S   S       S       S   S   
2024-02-03 05:20:34,374 ========================================================================================================================
2024-02-03 05:20:37,159 Epoch 662: Total Training Recognition Loss 0.13  Total Training Translation Loss 4.60 
2024-02-03 05:20:37,159 EPOCH 663
2024-02-03 05:20:40,048 [Epoch: 663 Step: 00088100] Batch Recognition Loss:   0.001354 => Gls Tokens per Sec:     1496 || Batch Translation Loss:   0.016967 => Txt Tokens per Sec:     4389 || Lr: 0.000050
2024-02-03 05:20:44,299 Epoch 663: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.49 
2024-02-03 05:20:44,299 EPOCH 664
2024-02-03 05:20:45,675 [Epoch: 664 Step: 00088200] Batch Recognition Loss:   0.000490 => Gls Tokens per Sec:     1222 || Batch Translation Loss:   0.018332 => Txt Tokens per Sec:     3502 || Lr: 0.000050
2024-02-03 05:20:50,884 [Epoch: 664 Step: 00088300] Batch Recognition Loss:   0.000150 => Gls Tokens per Sec:     1536 || Batch Translation Loss:   0.126196 => Txt Tokens per Sec:     4240 || Lr: 0.000050
2024-02-03 05:20:51,705 Epoch 664: Total Training Recognition Loss 0.12  Total Training Translation Loss 4.46 
2024-02-03 05:20:51,705 EPOCH 665
2024-02-03 05:20:56,581 [Epoch: 665 Step: 00088400] Batch Recognition Loss:   0.000719 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.015063 => Txt Tokens per Sec:     4001 || Lr: 0.000050
2024-02-03 05:20:59,410 Epoch 665: Total Training Recognition Loss 0.15  Total Training Translation Loss 7.47 
2024-02-03 05:20:59,411 EPOCH 666
2024-02-03 05:21:02,543 [Epoch: 666 Step: 00088500] Batch Recognition Loss:   0.000703 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.027655 => Txt Tokens per Sec:     3927 || Lr: 0.000050
2024-02-03 05:21:06,801 Epoch 666: Total Training Recognition Loss 0.22  Total Training Translation Loss 16.46 
2024-02-03 05:21:06,801 EPOCH 667
2024-02-03 05:21:08,142 [Epoch: 667 Step: 00088600] Batch Recognition Loss:   0.000156 => Gls Tokens per Sec:     1314 || Batch Translation Loss:   0.018537 => Txt Tokens per Sec:     3640 || Lr: 0.000050
2024-02-03 05:21:14,125 [Epoch: 667 Step: 00088700] Batch Recognition Loss:   0.000803 => Gls Tokens per Sec:     1336 || Batch Translation Loss:   0.020780 => Txt Tokens per Sec:     3724 || Lr: 0.000050
2024-02-03 05:21:14,812 Epoch 667: Total Training Recognition Loss 0.14  Total Training Translation Loss 4.68 
2024-02-03 05:21:14,812 EPOCH 668
2024-02-03 05:21:19,937 [Epoch: 668 Step: 00088800] Batch Recognition Loss:   0.000484 => Gls Tokens per Sec:     1390 || Batch Translation Loss:   0.030195 => Txt Tokens per Sec:     3851 || Lr: 0.000050
2024-02-03 05:21:22,194 Epoch 668: Total Training Recognition Loss 0.14  Total Training Translation Loss 7.27 
2024-02-03 05:21:22,195 EPOCH 669
2024-02-03 05:21:25,393 [Epoch: 669 Step: 00088900] Batch Recognition Loss:   0.000275 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.020826 => Txt Tokens per Sec:     3970 || Lr: 0.000050
2024-02-03 05:21:29,805 Epoch 669: Total Training Recognition Loss 0.14  Total Training Translation Loss 4.08 
2024-02-03 05:21:29,805 EPOCH 670
2024-02-03 05:21:30,956 [Epoch: 670 Step: 00089000] Batch Recognition Loss:   0.000270 => Gls Tokens per Sec:     1600 || Batch Translation Loss:   0.017299 => Txt Tokens per Sec:     4364 || Lr: 0.000050
2024-02-03 05:21:36,904 [Epoch: 670 Step: 00089100] Batch Recognition Loss:   0.000291 => Gls Tokens per Sec:     1343 || Batch Translation Loss:   0.018309 => Txt Tokens per Sec:     3771 || Lr: 0.000050
2024-02-03 05:21:37,453 Epoch 670: Total Training Recognition Loss 0.12  Total Training Translation Loss 3.28 
2024-02-03 05:21:37,453 EPOCH 671
2024-02-03 05:21:42,697 [Epoch: 671 Step: 00089200] Batch Recognition Loss:   0.001698 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.016233 => Txt Tokens per Sec:     3832 || Lr: 0.000050
2024-02-03 05:21:45,192 Epoch 671: Total Training Recognition Loss 0.09  Total Training Translation Loss 3.86 
2024-02-03 05:21:45,192 EPOCH 672
2024-02-03 05:21:48,227 [Epoch: 672 Step: 00089300] Batch Recognition Loss:   0.000218 => Gls Tokens per Sec:     1503 || Batch Translation Loss:   0.015311 => Txt Tokens per Sec:     4240 || Lr: 0.000050
2024-02-03 05:21:52,426 Epoch 672: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.39 
2024-02-03 05:21:52,426 EPOCH 673
2024-02-03 05:21:53,814 [Epoch: 673 Step: 00089400] Batch Recognition Loss:   0.002294 => Gls Tokens per Sec:     1386 || Batch Translation Loss:   0.004690 => Txt Tokens per Sec:     3670 || Lr: 0.000050
2024-02-03 05:21:59,615 [Epoch: 673 Step: 00089500] Batch Recognition Loss:   0.000229 => Gls Tokens per Sec:     1377 || Batch Translation Loss:   0.012849 => Txt Tokens per Sec:     3902 || Lr: 0.000050
2024-02-03 05:22:00,090 Epoch 673: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.76 
2024-02-03 05:22:00,090 EPOCH 674
2024-02-03 05:22:05,061 [Epoch: 674 Step: 00089600] Batch Recognition Loss:   0.000487 => Gls Tokens per Sec:     1465 || Batch Translation Loss:   0.028578 => Txt Tokens per Sec:     4152 || Lr: 0.000050
2024-02-03 05:22:07,319 Epoch 674: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.12 
2024-02-03 05:22:07,320 EPOCH 675
2024-02-03 05:22:10,641 [Epoch: 675 Step: 00089700] Batch Recognition Loss:   0.000374 => Gls Tokens per Sec:     1398 || Batch Translation Loss:   0.030812 => Txt Tokens per Sec:     3757 || Lr: 0.000050
2024-02-03 05:22:14,766 Epoch 675: Total Training Recognition Loss 0.09  Total Training Translation Loss 3.97 
2024-02-03 05:22:14,767 EPOCH 676
2024-02-03 05:22:16,097 [Epoch: 676 Step: 00089800] Batch Recognition Loss:   0.000196 => Gls Tokens per Sec:     1504 || Batch Translation Loss:   0.018461 => Txt Tokens per Sec:     4179 || Lr: 0.000050
2024-02-03 05:22:22,058 [Epoch: 676 Step: 00089900] Batch Recognition Loss:   0.001574 => Gls Tokens per Sec:     1341 || Batch Translation Loss:   0.034297 => Txt Tokens per Sec:     3747 || Lr: 0.000050
2024-02-03 05:22:22,538 Epoch 676: Total Training Recognition Loss 0.09  Total Training Translation Loss 7.67 
2024-02-03 05:22:22,538 EPOCH 677
2024-02-03 05:22:27,703 [Epoch: 677 Step: 00090000] Batch Recognition Loss:   0.000131 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.036878 => Txt Tokens per Sec:     3939 || Lr: 0.000050
2024-02-03 05:22:38,838 Validation result at epoch 677, step    90000: duration: 11.1348s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.42019	Translation Loss: 87785.77344	PPL: 9115.73926
	Eval Metric: BLEU
	WER 2.83	(DEL: 0.07,	INS: 0.00,	SUB: 2.76)
	BLEU-4 0.40	(BLEU-1: 9.32,	BLEU-2: 2.29,	BLEU-3: 0.83,	BLEU-4: 0.40)
	CHRF 16.07	ROUGE 8.05
2024-02-03 05:22:38,840 Logging Recognition and Translation Outputs
2024-02-03 05:22:38,840 ========================================================================================================================
2024-02-03 05:22:38,840 Logging Sequence: 161_210.00
2024-02-03 05:22:38,840 	Gloss Reference :	A B+C+D+E
2024-02-03 05:22:38,840 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:22:38,840 	Gloss Alignment :	         
2024-02-03 05:22:38,840 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:22:38,841 	Text Reference  :	***** *** ***** **** we  hope he   continues playing   for india 
2024-02-03 05:22:38,841 	Text Hypothesis :	after the match they won the  toss and       captioned it  saying
2024-02-03 05:22:38,841 	Text Alignment  :	I     I   I     I    S   S    S    S         S         S   S     
2024-02-03 05:22:38,842 ========================================================================================================================
2024-02-03 05:22:38,842 Logging Sequence: 111_83.00
2024-02-03 05:22:38,842 	Gloss Reference :	A B+C+D+E
2024-02-03 05:22:38,842 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:22:38,842 	Gloss Alignment :	         
2024-02-03 05:22:38,842 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:22:38,844 	Text Reference  :	and the other 10 team members are fined 25 of   the     match fee      or           rs  6   lakh       
2024-02-03 05:22:38,844 	Text Hypothesis :	*** *** ***** ** **** ******* *** now   on 27th october 2022  football championship was not comfortable
2024-02-03 05:22:38,844 	Text Alignment  :	D   D   D     D  D    D       D   S     S  S    S       S     S        S            S   S   S          
2024-02-03 05:22:38,844 ========================================================================================================================
2024-02-03 05:22:38,844 Logging Sequence: 157_72.00
2024-02-03 05:22:38,844 	Gloss Reference :	A B+C+D+E
2024-02-03 05:22:38,845 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:22:38,845 	Gloss Alignment :	         
2024-02-03 05:22:38,845 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:22:38,847 	Text Reference  :	the cost of each sandwich was rs 150 however due to  the heavy rains the ******** cost   of the sandwich was increased to *** rs   250
2024-02-03 05:22:38,847 	Text Hypothesis :	*** **** ** **** ******** *** ** *** ******* as  per the ***** rules the original target of *** 215      was truncated to 171 runs in 
2024-02-03 05:22:38,847 	Text Alignment  :	D   D    D  D    D        D   D  D   D       S   S       D     S         I        S         D   S            S            I   S    S  
2024-02-03 05:22:38,847 ========================================================================================================================
2024-02-03 05:22:38,847 Logging Sequence: 129_25.00
2024-02-03 05:22:38,848 	Gloss Reference :	A B+C+D+E
2024-02-03 05:22:38,848 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:22:38,848 	Gloss Alignment :	         
2024-02-03 05:22:38,848 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:22:38,849 	Text Reference  :	japan prime minister yoshihde suga recently met     with top ministers of       his   government
2024-02-03 05:22:38,849 	Text Hypothesis :	he    has   learnt   the      art  of       chasing from the great     mahendra singh dhoni     
2024-02-03 05:22:38,849 	Text Alignment  :	S     S     S        S        S    S        S       S    S   S         S        S     S         
2024-02-03 05:22:38,849 ========================================================================================================================
2024-02-03 05:22:38,850 Logging Sequence: 82_81.00
2024-02-03 05:22:38,850 	Gloss Reference :	A B+C+D+E
2024-02-03 05:22:38,850 	Gloss Hypothesis:	A B+C+B  
2024-02-03 05:22:38,850 	Gloss Alignment :	  S      
2024-02-03 05:22:38,850 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:22:38,852 	Text Reference  :	since    the ******* *** couple were residents of   mumbai the mumbai police cyber cell began  investigating the  matter
2024-02-03 05:22:38,852 	Text Hypothesis :	remember the picture was an     old  and       team ahead  of  its    upto   you   and  others to            join sports
2024-02-03 05:22:38,852 	Text Alignment  :	S            I       I   S      S    S         S    S      S   S      S      S     S    S      S             S    S     
2024-02-03 05:22:38,852 ========================================================================================================================
2024-02-03 05:22:41,220 Epoch 677: Total Training Recognition Loss 0.08  Total Training Translation Loss 6.83 
2024-02-03 05:22:41,220 EPOCH 678
2024-02-03 05:22:44,258 [Epoch: 678 Step: 00090100] Batch Recognition Loss:   0.000369 => Gls Tokens per Sec:     1554 || Batch Translation Loss:   0.062259 => Txt Tokens per Sec:     4301 || Lr: 0.000050
2024-02-03 05:22:48,245 Epoch 678: Total Training Recognition Loss 0.15  Total Training Translation Loss 5.13 
2024-02-03 05:22:48,246 EPOCH 679
2024-02-03 05:22:49,731 [Epoch: 679 Step: 00090200] Batch Recognition Loss:   0.000935 => Gls Tokens per Sec:     1402 || Batch Translation Loss:   0.027996 => Txt Tokens per Sec:     3966 || Lr: 0.000050
2024-02-03 05:22:55,420 [Epoch: 679 Step: 00090300] Batch Recognition Loss:   0.000273 => Gls Tokens per Sec:     1405 || Batch Translation Loss:   0.072258 => Txt Tokens per Sec:     3894 || Lr: 0.000050
2024-02-03 05:22:55,777 Epoch 679: Total Training Recognition Loss 0.07  Total Training Translation Loss 4.88 
2024-02-03 05:22:55,777 EPOCH 680
2024-02-03 05:23:00,990 [Epoch: 680 Step: 00090400] Batch Recognition Loss:   0.001361 => Gls Tokens per Sec:     1428 || Batch Translation Loss:   0.357507 => Txt Tokens per Sec:     3951 || Lr: 0.000050
2024-02-03 05:23:03,144 Epoch 680: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.65 
2024-02-03 05:23:03,144 EPOCH 681
2024-02-03 05:23:06,460 [Epoch: 681 Step: 00090500] Batch Recognition Loss:   0.000289 => Gls Tokens per Sec:     1448 || Batch Translation Loss:   0.037109 => Txt Tokens per Sec:     4021 || Lr: 0.000050
2024-02-03 05:23:10,681 Epoch 681: Total Training Recognition Loss 0.08  Total Training Translation Loss 7.12 
2024-02-03 05:23:10,682 EPOCH 682
2024-02-03 05:23:11,923 [Epoch: 682 Step: 00090600] Batch Recognition Loss:   0.000785 => Gls Tokens per Sec:     1741 || Batch Translation Loss:   0.023603 => Txt Tokens per Sec:     4790 || Lr: 0.000050
2024-02-03 05:23:17,642 [Epoch: 682 Step: 00090700] Batch Recognition Loss:   0.000202 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.143217 => Txt Tokens per Sec:     3922 || Lr: 0.000050
2024-02-03 05:23:17,948 Epoch 682: Total Training Recognition Loss 0.08  Total Training Translation Loss 5.41 
2024-02-03 05:23:17,948 EPOCH 683
2024-02-03 05:23:23,130 [Epoch: 683 Step: 00090800] Batch Recognition Loss:   0.001134 => Gls Tokens per Sec:     1452 || Batch Translation Loss:   0.010096 => Txt Tokens per Sec:     4020 || Lr: 0.000050
2024-02-03 05:23:25,468 Epoch 683: Total Training Recognition Loss 0.09  Total Training Translation Loss 12.05 
2024-02-03 05:23:25,469 EPOCH 684
2024-02-03 05:23:28,655 [Epoch: 684 Step: 00090900] Batch Recognition Loss:   0.002023 => Gls Tokens per Sec:     1532 || Batch Translation Loss:   0.042641 => Txt Tokens per Sec:     4229 || Lr: 0.000050
2024-02-03 05:23:32,338 Epoch 684: Total Training Recognition Loss 0.16  Total Training Translation Loss 8.22 
2024-02-03 05:23:32,338 EPOCH 685
2024-02-03 05:23:34,041 [Epoch: 685 Step: 00091000] Batch Recognition Loss:   0.003790 => Gls Tokens per Sec:     1317 || Batch Translation Loss:   0.020953 => Txt Tokens per Sec:     3734 || Lr: 0.000050
2024-02-03 05:23:39,790 [Epoch: 685 Step: 00091100] Batch Recognition Loss:   0.000439 => Gls Tokens per Sec:     1392 || Batch Translation Loss:   0.026396 => Txt Tokens per Sec:     3834 || Lr: 0.000050
2024-02-03 05:23:40,144 Epoch 685: Total Training Recognition Loss 0.16  Total Training Translation Loss 3.73 
2024-02-03 05:23:40,145 EPOCH 686
2024-02-03 05:23:45,483 [Epoch: 686 Step: 00091200] Batch Recognition Loss:   0.019989 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.022115 => Txt Tokens per Sec:     3956 || Lr: 0.000050
2024-02-03 05:23:47,641 Epoch 686: Total Training Recognition Loss 0.13  Total Training Translation Loss 3.12 
2024-02-03 05:23:47,641 EPOCH 687
2024-02-03 05:23:50,822 [Epoch: 687 Step: 00091300] Batch Recognition Loss:   0.000524 => Gls Tokens per Sec:     1560 || Batch Translation Loss:   0.017313 => Txt Tokens per Sec:     4280 || Lr: 0.000050
2024-02-03 05:23:54,945 Epoch 687: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.98 
2024-02-03 05:23:54,945 EPOCH 688
2024-02-03 05:23:56,425 [Epoch: 688 Step: 00091400] Batch Recognition Loss:   0.000636 => Gls Tokens per Sec:     1568 || Batch Translation Loss:   0.034861 => Txt Tokens per Sec:     4359 || Lr: 0.000050
2024-02-03 05:24:02,323 [Epoch: 688 Step: 00091500] Batch Recognition Loss:   0.000269 => Gls Tokens per Sec:     1357 || Batch Translation Loss:   0.721081 => Txt Tokens per Sec:     3754 || Lr: 0.000050
2024-02-03 05:24:02,632 Epoch 688: Total Training Recognition Loss 0.08  Total Training Translation Loss 5.12 
2024-02-03 05:24:02,633 EPOCH 689
2024-02-03 05:24:08,116 [Epoch: 689 Step: 00091600] Batch Recognition Loss:   0.000138 => Gls Tokens per Sec:     1401 || Batch Translation Loss:   0.019481 => Txt Tokens per Sec:     3920 || Lr: 0.000050
2024-02-03 05:24:10,251 Epoch 689: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.52 
2024-02-03 05:24:10,251 EPOCH 690
2024-02-03 05:24:14,065 [Epoch: 690 Step: 00091700] Batch Recognition Loss:   0.000366 => Gls Tokens per Sec:     1322 || Batch Translation Loss:   0.042644 => Txt Tokens per Sec:     3717 || Lr: 0.000050
2024-02-03 05:24:17,986 Epoch 690: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.65 
2024-02-03 05:24:17,986 EPOCH 691
2024-02-03 05:24:19,770 [Epoch: 691 Step: 00091800] Batch Recognition Loss:   0.000244 => Gls Tokens per Sec:     1346 || Batch Translation Loss:   0.013954 => Txt Tokens per Sec:     3594 || Lr: 0.000050
2024-02-03 05:24:25,593 [Epoch: 691 Step: 00091900] Batch Recognition Loss:   0.001521 => Gls Tokens per Sec:     1372 || Batch Translation Loss:   0.026266 => Txt Tokens per Sec:     3875 || Lr: 0.000050
2024-02-03 05:24:25,741 Epoch 691: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.28 
2024-02-03 05:24:25,742 EPOCH 692
2024-02-03 05:24:31,533 [Epoch: 692 Step: 00092000] Batch Recognition Loss:   0.000134 => Gls Tokens per Sec:     1340 || Batch Translation Loss:   0.017230 => Txt Tokens per Sec:     3761 || Lr: 0.000050
2024-02-03 05:24:42,643 Validation result at epoch 692, step    92000: duration: 11.1103s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.47784	Translation Loss: 86893.59375	PPL: 8308.97949
	Eval Metric: BLEU
	WER 2.90	(DEL: 0.14,	INS: 0.00,	SUB: 2.76)
	BLEU-4 0.44	(BLEU-1: 10.16,	BLEU-2: 2.61,	BLEU-3: 0.93,	BLEU-4: 0.44)
	CHRF 16.54	ROUGE 8.41
2024-02-03 05:24:42,644 Logging Recognition and Translation Outputs
2024-02-03 05:24:42,644 ========================================================================================================================
2024-02-03 05:24:42,644 Logging Sequence: 101_70.00
2024-02-03 05:24:42,645 	Gloss Reference :	A B+C+D+E
2024-02-03 05:24:42,645 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:24:42,645 	Gloss Alignment :	         
2024-02-03 05:24:42,645 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:24:42,647 	Text Reference  :	when england started batting india bowled very well       and england lost 7   wickets  for     just  91  runs   
2024-02-03 05:24:42,647 	Text Hypothesis :	**** ******* the     final   of    the    u-19 tournament was held    on   5th february between india and england
2024-02-03 05:24:42,647 	Text Alignment  :	D    D       S       S       S     S      S    S          S   S       S    S   S        S       S     S   S      
2024-02-03 05:24:42,647 ========================================================================================================================
2024-02-03 05:24:42,647 Logging Sequence: 157_72.00
2024-02-03 05:24:42,647 	Gloss Reference :	A B+C+D+E
2024-02-03 05:24:42,647 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:24:42,648 	Gloss Alignment :	         
2024-02-03 05:24:42,648 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:24:42,650 	Text Reference  :	the cost of each sandwich was rs 150 however due to  the heavy rains the ******** cost   of the sandwich was increased to *** rs   250
2024-02-03 05:24:42,650 	Text Hypothesis :	*** **** ** **** ******** *** ** *** ******* as  per the ***** rules the original target of *** 215      was truncated to 171 runs in 
2024-02-03 05:24:42,650 	Text Alignment  :	D   D    D  D    D        D   D  D   D       S   S       D     S         I        S         D   S            S            I   S    S  
2024-02-03 05:24:42,650 ========================================================================================================================
2024-02-03 05:24:42,650 Logging Sequence: 127_165.00
2024-02-03 05:24:42,651 	Gloss Reference :	A B+C+D+E
2024-02-03 05:24:42,651 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:24:42,651 	Gloss Alignment :	         
2024-02-03 05:24:42,651 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:24:42,652 	Text Reference  :	neeraj's father satish kumar   expressed immense pride  in  his son's       achievement 
2024-02-03 05:24:42,652 	Text Hypothesis :	******** ****** ****** however a         single  person has an  interesting superstition
2024-02-03 05:24:42,652 	Text Alignment  :	D        D      D      S       S         S       S      S   S   S           S           
2024-02-03 05:24:42,652 ========================================================================================================================
2024-02-03 05:24:42,652 Logging Sequence: 88_13.00
2024-02-03 05:24:42,652 	Gloss Reference :	A B+C+D+E
2024-02-03 05:24:42,652 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:24:42,652 	Gloss Alignment :	         
2024-02-03 05:24:42,653 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:24:42,654 	Text Reference  :	while his fans were elated by the victory there were some  who are jealous and     want  to   kill  messi    
2024-02-03 05:24:42,654 	Text Hypothesis :	***** *** **** **** ****** ** *** ******* ***** **** messi is  one of      idesign gold' most loyal customers
2024-02-03 05:24:42,654 	Text Alignment  :	D     D   D    D    D      D  D   D       D     D    S     S   S   S       S       S     S    S     S        
2024-02-03 05:24:42,654 ========================================================================================================================
2024-02-03 05:24:42,654 Logging Sequence: 139_2.00
2024-02-03 05:24:42,654 	Gloss Reference :	A B+C+D+E
2024-02-03 05:24:42,655 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:24:42,655 	Gloss Alignment :	         
2024-02-03 05:24:42,655 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:24:42,656 	Text Reference  :	across the  world  people love    watching cricket football and   different types of  sports
2024-02-03 05:24:42,656 	Text Hypothesis :	****** they played for    another 30       minutes but      still the       score was 1-1   
2024-02-03 05:24:42,656 	Text Alignment  :	D      S    S      S      S       S        S       S        S     S         S     S   S     
2024-02-03 05:24:42,656 ========================================================================================================================
2024-02-03 05:24:44,578 Epoch 692: Total Training Recognition Loss 0.11  Total Training Translation Loss 2.87 
2024-02-03 05:24:44,579 EPOCH 693
2024-02-03 05:24:48,179 [Epoch: 693 Step: 00092100] Batch Recognition Loss:   0.000290 => Gls Tokens per Sec:     1423 || Batch Translation Loss:   0.012443 => Txt Tokens per Sec:     3941 || Lr: 0.000050
2024-02-03 05:24:52,123 Epoch 693: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.06 
2024-02-03 05:24:52,123 EPOCH 694
2024-02-03 05:24:53,734 [Epoch: 694 Step: 00092200] Batch Recognition Loss:   0.000240 => Gls Tokens per Sec:     1540 || Batch Translation Loss:   0.021262 => Txt Tokens per Sec:     4120 || Lr: 0.000050
2024-02-03 05:24:59,428 [Epoch: 694 Step: 00092300] Batch Recognition Loss:   0.000139 => Gls Tokens per Sec:     1403 || Batch Translation Loss:   0.015563 => Txt Tokens per Sec:     3962 || Lr: 0.000050
2024-02-03 05:24:59,535 Epoch 694: Total Training Recognition Loss 0.08  Total Training Translation Loss 5.21 
2024-02-03 05:24:59,536 EPOCH 695
2024-02-03 05:25:05,060 [Epoch: 695 Step: 00092400] Batch Recognition Loss:   0.000330 => Gls Tokens per Sec:     1420 || Batch Translation Loss:   0.028248 => Txt Tokens per Sec:     3964 || Lr: 0.000050
2024-02-03 05:25:07,128 Epoch 695: Total Training Recognition Loss 0.11  Total Training Translation Loss 5.60 
2024-02-03 05:25:07,129 EPOCH 696
2024-02-03 05:25:10,474 [Epoch: 696 Step: 00092500] Batch Recognition Loss:   0.004109 => Gls Tokens per Sec:     1556 || Batch Translation Loss:   0.029550 => Txt Tokens per Sec:     4217 || Lr: 0.000050
2024-02-03 05:25:14,368 Epoch 696: Total Training Recognition Loss 0.15  Total Training Translation Loss 6.70 
2024-02-03 05:25:14,368 EPOCH 697
2024-02-03 05:25:16,290 [Epoch: 697 Step: 00092600] Batch Recognition Loss:   0.002295 => Gls Tokens per Sec:     1333 || Batch Translation Loss:   0.008361 => Txt Tokens per Sec:     3696 || Lr: 0.000050
2024-02-03 05:25:21,779 [Epoch: 697 Step: 00092700] Batch Recognition Loss:   0.000080 => Gls Tokens per Sec:     1456 || Batch Translation Loss:   0.030667 => Txt Tokens per Sec:     4042 || Lr: 0.000050
2024-02-03 05:25:21,845 Epoch 697: Total Training Recognition Loss 0.14  Total Training Translation Loss 6.95 
2024-02-03 05:25:21,846 EPOCH 698
2024-02-03 05:25:27,312 [Epoch: 698 Step: 00092800] Batch Recognition Loss:   0.000166 => Gls Tokens per Sec:     1449 || Batch Translation Loss:   0.028567 => Txt Tokens per Sec:     4019 || Lr: 0.000050
2024-02-03 05:25:29,233 Epoch 698: Total Training Recognition Loss 0.10  Total Training Translation Loss 5.17 
2024-02-03 05:25:29,233 EPOCH 699
2024-02-03 05:25:33,107 [Epoch: 699 Step: 00092900] Batch Recognition Loss:   0.000658 => Gls Tokens per Sec:     1363 || Batch Translation Loss:   0.038400 => Txt Tokens per Sec:     3827 || Lr: 0.000050
2024-02-03 05:25:36,730 Epoch 699: Total Training Recognition Loss 0.15  Total Training Translation Loss 6.36 
2024-02-03 05:25:36,731 EPOCH 700
2024-02-03 05:25:38,491 [Epoch: 700 Step: 00093000] Batch Recognition Loss:   0.000366 => Gls Tokens per Sec:     1502 || Batch Translation Loss:   0.016519 => Txt Tokens per Sec:     4229 || Lr: 0.000050
2024-02-03 05:25:44,275 [Epoch: 700 Step: 00093100] Batch Recognition Loss:   0.004682 => Gls Tokens per Sec:     1381 || Batch Translation Loss:   0.030343 => Txt Tokens per Sec:     3825 || Lr: 0.000050
2024-02-03 05:25:44,275 Epoch 700: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.84 
2024-02-03 05:25:44,276 EPOCH 701
2024-02-03 05:25:50,149 [Epoch: 701 Step: 00093200] Batch Recognition Loss:   0.000195 => Gls Tokens per Sec:     1362 || Batch Translation Loss:   0.021470 => Txt Tokens per Sec:     3742 || Lr: 0.000050
2024-02-03 05:25:52,103 Epoch 701: Total Training Recognition Loss 0.13  Total Training Translation Loss 3.53 
2024-02-03 05:25:52,103 EPOCH 702
2024-02-03 05:25:55,863 [Epoch: 702 Step: 00093300] Batch Recognition Loss:   0.000112 => Gls Tokens per Sec:     1426 || Batch Translation Loss:   0.014744 => Txt Tokens per Sec:     3944 || Lr: 0.000050
2024-02-03 05:25:59,595 Epoch 702: Total Training Recognition Loss 0.10  Total Training Translation Loss 3.22 
2024-02-03 05:25:59,595 EPOCH 703
2024-02-03 05:26:01,477 [Epoch: 703 Step: 00093400] Batch Recognition Loss:   0.000144 => Gls Tokens per Sec:     1446 || Batch Translation Loss:   0.168641 => Txt Tokens per Sec:     3905 || Lr: 0.000050
2024-02-03 05:26:07,120 Epoch 703: Total Training Recognition Loss 0.08  Total Training Translation Loss 2.72 
2024-02-03 05:26:07,121 EPOCH 704
2024-02-03 05:26:07,186 [Epoch: 704 Step: 00093500] Batch Recognition Loss:   0.000505 => Gls Tokens per Sec:     1250 || Batch Translation Loss:   0.028789 => Txt Tokens per Sec:     4078 || Lr: 0.000050
2024-02-03 05:26:12,714 [Epoch: 704 Step: 00093600] Batch Recognition Loss:   0.000445 => Gls Tokens per Sec:     1447 || Batch Translation Loss:   0.014521 => Txt Tokens per Sec:     4025 || Lr: 0.000050
2024-02-03 05:26:14,491 Epoch 704: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.41 
2024-02-03 05:26:14,491 EPOCH 705
2024-02-03 05:26:17,781 [Epoch: 705 Step: 00093700] Batch Recognition Loss:   0.000228 => Gls Tokens per Sec:     1654 || Batch Translation Loss:   0.012747 => Txt Tokens per Sec:     4511 || Lr: 0.000050
2024-02-03 05:26:21,650 Epoch 705: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.50 
2024-02-03 05:26:21,650 EPOCH 706
2024-02-03 05:26:23,690 [Epoch: 706 Step: 00093800] Batch Recognition Loss:   0.000352 => Gls Tokens per Sec:     1374 || Batch Translation Loss:   0.018675 => Txt Tokens per Sec:     3918 || Lr: 0.000050
2024-02-03 05:26:29,196 Epoch 706: Total Training Recognition Loss 0.15  Total Training Translation Loss 8.16 
2024-02-03 05:26:29,197 EPOCH 707
2024-02-03 05:26:29,352 [Epoch: 707 Step: 00093900] Batch Recognition Loss:   0.000292 => Gls Tokens per Sec:     1039 || Batch Translation Loss:   0.028835 => Txt Tokens per Sec:     3552 || Lr: 0.000050
2024-02-03 05:26:34,850 [Epoch: 707 Step: 00094000] Batch Recognition Loss:   0.000109 => Gls Tokens per Sec:     1455 || Batch Translation Loss:   0.016998 => Txt Tokens per Sec:     4015 || Lr: 0.000050
2024-02-03 05:26:45,907 Validation result at epoch 707, step    94000: duration: 11.0560s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.17091	Translation Loss: 87938.17969	PPL: 9261.18164
	Eval Metric: BLEU
	WER 3.11	(DEL: 0.14,	INS: 0.00,	SUB: 2.97)
	BLEU-4 0.45	(BLEU-1: 9.37,	BLEU-2: 2.37,	BLEU-3: 0.88,	BLEU-4: 0.45)
	CHRF 16.31	ROUGE 7.78
2024-02-03 05:26:45,908 Logging Recognition and Translation Outputs
2024-02-03 05:26:45,908 ========================================================================================================================
2024-02-03 05:26:45,908 Logging Sequence: 100_119.00
2024-02-03 05:26:45,908 	Gloss Reference :	A B+C+D+E
2024-02-03 05:26:45,908 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:26:45,908 	Gloss Alignment :	         
2024-02-03 05:26:45,909 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:26:45,909 	Text Reference  :	** an  indian team   was sent to the   cwg  in kuala lumpur malayasia
2024-02-03 05:26:45,909 	Text Hypothesis :	as his entire family was **** ** still back in ***** all    matches  
2024-02-03 05:26:45,910 	Text Alignment  :	I  S   S      S          D    D  S     S       D     S      S        
2024-02-03 05:26:45,910 ========================================================================================================================
2024-02-03 05:26:45,910 Logging Sequence: 104_78.00
2024-02-03 05:26:45,910 	Gloss Reference :	A B+C+D+E
2024-02-03 05:26:45,910 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:26:45,910 	Gloss Alignment :	         
2024-02-03 05:26:45,910 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:26:45,911 	Text Reference  :	with is amazing moves carlsen won      the   first          tie-breaker
2024-02-03 05:26:45,911 	Text Hypothesis :	**** ** ******* and   that    everyone hoped praggnanandhaa proud      
2024-02-03 05:26:45,911 	Text Alignment  :	D    D  D       S     S       S        S     S              S          
2024-02-03 05:26:45,911 ========================================================================================================================
2024-02-03 05:26:45,911 Logging Sequence: 59_101.00
2024-02-03 05:26:45,912 	Gloss Reference :	A B+C+D+E
2024-02-03 05:26:45,912 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:26:45,912 	Gloss Alignment :	         
2024-02-03 05:26:45,912 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:26:45,914 	Text Reference  :	did you see the video fox said she won   her medals   because of a   condom and       is very happy
2024-02-03 05:26:45,914 	Text Hypothesis :	*** as  per the ***** *** **** *** rules the original target  of 215 was    truncated to buy  him  
2024-02-03 05:26:45,914 	Text Alignment  :	D   S   S       D     D   D    D   S     S   S        S          S   S      S         S  S    S    
2024-02-03 05:26:45,914 ========================================================================================================================
2024-02-03 05:26:45,914 Logging Sequence: 169_229.00
2024-02-03 05:26:45,914 	Gloss Reference :	A B+C+D+E
2024-02-03 05:26:45,914 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:26:45,914 	Gloss Alignment :	         
2024-02-03 05:26:45,915 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:26:45,917 	Text Reference  :	the drop was  a mistake when  we          take    a    step  that leads  to a   mistake   the next step is towards learning
2024-02-03 05:26:45,917 	Text Hypothesis :	*** he   owns a bike    named confederate hellcat x132 which was  bought by the cricketer in  2018 for  rs 27      lakh    
2024-02-03 05:26:45,917 	Text Alignment  :	D   S    S      S       S     S           S       S    S     S    S      S  S   S         S   S    S    S  S       S       
2024-02-03 05:26:45,917 ========================================================================================================================
2024-02-03 05:26:45,917 Logging Sequence: 173_91.00
2024-02-03 05:26:45,918 	Gloss Reference :	A B+C+D+E
2024-02-03 05:26:45,918 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:26:45,918 	Gloss Alignment :	         
2024-02-03 05:26:45,918 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:26:45,919 	Text Reference  :	'œthe news reports about virat stepping down as    captain is   absolute rubbish    
2024-02-03 05:26:45,919 	Text Hypothesis :	***** **** ******* kohli will  continue to   train and     have been     quarantined
2024-02-03 05:26:45,919 	Text Alignment  :	D     D    D       S     S     S        S    S     S       S    S        S          
2024-02-03 05:26:45,919 ========================================================================================================================
2024-02-03 05:26:47,755 Epoch 707: Total Training Recognition Loss 0.11  Total Training Translation Loss 8.55 
2024-02-03 05:26:47,756 EPOCH 708
2024-02-03 05:26:51,621 [Epoch: 708 Step: 00094100] Batch Recognition Loss:   0.000703 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.844552 => Txt Tokens per Sec:     4000 || Lr: 0.000050
2024-02-03 05:26:55,060 Epoch 708: Total Training Recognition Loss 0.17  Total Training Translation Loss 14.48 
2024-02-03 05:26:55,060 EPOCH 709
2024-02-03 05:26:56,848 [Epoch: 709 Step: 00094200] Batch Recognition Loss:   0.005610 => Gls Tokens per Sec:     1611 || Batch Translation Loss:   0.029895 => Txt Tokens per Sec:     4453 || Lr: 0.000050
2024-02-03 05:27:02,661 Epoch 709: Total Training Recognition Loss 0.20  Total Training Translation Loss 5.45 
2024-02-03 05:27:02,661 EPOCH 710
2024-02-03 05:27:02,833 [Epoch: 710 Step: 00094300] Batch Recognition Loss:   0.000349 => Gls Tokens per Sec:     1404 || Batch Translation Loss:   0.032411 => Txt Tokens per Sec:     3731 || Lr: 0.000050
2024-02-03 05:27:08,407 [Epoch: 710 Step: 00094400] Batch Recognition Loss:   0.000690 => Gls Tokens per Sec:     1435 || Batch Translation Loss:   0.031488 => Txt Tokens per Sec:     3992 || Lr: 0.000050
2024-02-03 05:27:10,211 Epoch 710: Total Training Recognition Loss 0.15  Total Training Translation Loss 4.63 
2024-02-03 05:27:10,211 EPOCH 711
2024-02-03 05:27:14,153 [Epoch: 711 Step: 00094500] Batch Recognition Loss:   0.003814 => Gls Tokens per Sec:     1421 || Batch Translation Loss:   0.026343 => Txt Tokens per Sec:     3920 || Lr: 0.000050
2024-02-03 05:27:17,411 Epoch 711: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.54 
2024-02-03 05:27:17,412 EPOCH 712
2024-02-03 05:27:19,611 [Epoch: 712 Step: 00094600] Batch Recognition Loss:   0.000320 => Gls Tokens per Sec:     1347 || Batch Translation Loss:   0.008255 => Txt Tokens per Sec:     3680 || Lr: 0.000050
2024-02-03 05:27:25,016 Epoch 712: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.74 
2024-02-03 05:27:25,017 EPOCH 713
2024-02-03 05:27:25,224 [Epoch: 713 Step: 00094700] Batch Recognition Loss:   0.001529 => Gls Tokens per Sec:     1553 || Batch Translation Loss:   0.033299 => Txt Tokens per Sec:     4461 || Lr: 0.000050
2024-02-03 05:27:30,826 [Epoch: 713 Step: 00094800] Batch Recognition Loss:   0.000269 => Gls Tokens per Sec:     1429 || Batch Translation Loss:   0.023126 => Txt Tokens per Sec:     3993 || Lr: 0.000050
2024-02-03 05:27:32,419 Epoch 713: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.46 
2024-02-03 05:27:32,419 EPOCH 714
2024-02-03 05:27:36,405 [Epoch: 714 Step: 00094900] Batch Recognition Loss:   0.010025 => Gls Tokens per Sec:     1425 || Batch Translation Loss:   0.029763 => Txt Tokens per Sec:     3887 || Lr: 0.000050
2024-02-03 05:27:39,872 Epoch 714: Total Training Recognition Loss 0.09  Total Training Translation Loss 4.53 
2024-02-03 05:27:39,872 EPOCH 715
2024-02-03 05:27:41,957 [Epoch: 715 Step: 00095000] Batch Recognition Loss:   0.000182 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.013982 => Txt Tokens per Sec:     3961 || Lr: 0.000050
2024-02-03 05:27:47,190 Epoch 715: Total Training Recognition Loss 0.08  Total Training Translation Loss 3.40 
2024-02-03 05:27:47,191 EPOCH 716
2024-02-03 05:27:47,409 [Epoch: 716 Step: 00095100] Batch Recognition Loss:   0.000728 => Gls Tokens per Sec:     1835 || Batch Translation Loss:   0.033741 => Txt Tokens per Sec:     4716 || Lr: 0.000050
2024-02-03 05:27:52,940 [Epoch: 716 Step: 00095200] Batch Recognition Loss:   0.001096 => Gls Tokens per Sec:     1445 || Batch Translation Loss:   0.216843 => Txt Tokens per Sec:     4043 || Lr: 0.000050
2024-02-03 05:27:54,436 Epoch 716: Total Training Recognition Loss 0.11  Total Training Translation Loss 3.95 
2024-02-03 05:27:54,436 EPOCH 717
2024-02-03 05:27:58,161 [Epoch: 717 Step: 00095300] Batch Recognition Loss:   0.000167 => Gls Tokens per Sec:     1547 || Batch Translation Loss:   0.017780 => Txt Tokens per Sec:     4299 || Lr: 0.000050
2024-02-03 05:28:01,626 Epoch 717: Total Training Recognition Loss 0.17  Total Training Translation Loss 4.79 
2024-02-03 05:28:01,626 EPOCH 718
2024-02-03 05:28:03,707 [Epoch: 718 Step: 00095400] Batch Recognition Loss:   0.001475 => Gls Tokens per Sec:     1501 || Batch Translation Loss:   0.105550 => Txt Tokens per Sec:     4197 || Lr: 0.000050
2024-02-03 05:28:09,335 Epoch 718: Total Training Recognition Loss 0.10  Total Training Translation Loss 4.22 
2024-02-03 05:28:09,336 EPOCH 719
2024-02-03 05:28:09,785 [Epoch: 719 Step: 00095500] Batch Recognition Loss:   0.000392 => Gls Tokens per Sec:     1074 || Batch Translation Loss:   0.027614 => Txt Tokens per Sec:     3338 || Lr: 0.000050
2024-02-03 05:28:15,434 [Epoch: 719 Step: 00095600] Batch Recognition Loss:   0.000622 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.025160 => Txt Tokens per Sec:     3887 || Lr: 0.000050
2024-02-03 05:28:17,047 Epoch 719: Total Training Recognition Loss 0.10  Total Training Translation Loss 6.61 
2024-02-03 05:28:17,048 EPOCH 720
2024-02-03 05:28:20,899 [Epoch: 720 Step: 00095700] Batch Recognition Loss:   0.000264 => Gls Tokens per Sec:     1516 || Batch Translation Loss:   0.424572 => Txt Tokens per Sec:     4151 || Lr: 0.000050
2024-02-03 05:28:24,353 Epoch 720: Total Training Recognition Loss 0.10  Total Training Translation Loss 8.43 
2024-02-03 05:28:24,354 EPOCH 721
2024-02-03 05:28:26,449 [Epoch: 721 Step: 00095800] Batch Recognition Loss:   0.000359 => Gls Tokens per Sec:     1527 || Batch Translation Loss:   0.013520 => Txt Tokens per Sec:     4196 || Lr: 0.000050
2024-02-03 05:28:31,946 Epoch 721: Total Training Recognition Loss 0.14  Total Training Translation Loss 5.64 
2024-02-03 05:28:31,946 EPOCH 722
2024-02-03 05:28:32,295 [Epoch: 722 Step: 00095900] Batch Recognition Loss:   0.000360 => Gls Tokens per Sec:     1614 || Batch Translation Loss:   0.051906 => Txt Tokens per Sec:     4389 || Lr: 0.000050
2024-02-03 05:28:37,841 [Epoch: 722 Step: 00096000] Batch Recognition Loss:   0.001208 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   0.039803 => Txt Tokens per Sec:     4063 || Lr: 0.000050
2024-02-03 05:28:48,924 Validation result at epoch 722, step    96000: duration: 11.0814s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 7.96825	Translation Loss: 86932.46094	PPL: 8342.58984
	Eval Metric: BLEU
	WER 3.11	(DEL: 0.14,	INS: 0.00,	SUB: 2.97)
	BLEU-4 0.55	(BLEU-1: 10.61,	BLEU-2: 2.81,	BLEU-3: 1.08,	BLEU-4: 0.55)
	CHRF 16.75	ROUGE 8.90
2024-02-03 05:28:48,925 Logging Recognition and Translation Outputs
2024-02-03 05:28:48,925 ========================================================================================================================
2024-02-03 05:28:48,926 Logging Sequence: 60_40.00
2024-02-03 05:28:48,926 	Gloss Reference :	A B+C+D+E
2024-02-03 05:28:48,926 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:28:48,926 	Gloss Alignment :	         
2024-02-03 05:28:48,926 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:28:48,927 	Text Reference  :	a     little while later    he         became unconscious
2024-02-03 05:28:48,927 	Text Hypothesis :	dhoni has    a     stunning collection of     vehicles   
2024-02-03 05:28:48,927 	Text Alignment  :	S     S      S     S        S          S      S          
2024-02-03 05:28:48,927 ========================================================================================================================
2024-02-03 05:28:48,927 Logging Sequence: 51_163.00
2024-02-03 05:28:48,927 	Gloss Reference :	A B+C+D+E
2024-02-03 05:28:48,927 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:28:48,928 	Gloss Alignment :	         
2024-02-03 05:28:48,928 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:28:48,928 	Text Reference  :	it is not only done to    celebrate victories and special occassions
2024-02-03 05:28:48,929 	Text Hypothesis :	** or up  to   a    small wedding   because   the turned  out       
2024-02-03 05:28:48,929 	Text Alignment  :	D  S  S   S    S    S     S         S         S   S       S         
2024-02-03 05:28:48,929 ========================================================================================================================
2024-02-03 05:28:48,929 Logging Sequence: 138_211.00
2024-02-03 05:28:48,929 	Gloss Reference :	A B+C+D+E
2024-02-03 05:28:48,929 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:28:48,929 	Gloss Alignment :	         
2024-02-03 05:28:48,929 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:28:48,930 	Text Reference  :	*** ***** **** ** ** immediately after this     people who     support rashford
2024-02-03 05:28:48,930 	Text Hypothesis :	the match went to be played      at    narendra modi   stadium in      dubai   
2024-02-03 05:28:48,930 	Text Alignment  :	I   I     I    I  I  S           S     S        S      S       S       S       
2024-02-03 05:28:48,930 ========================================================================================================================
2024-02-03 05:28:48,931 Logging Sequence: 127_165.00
2024-02-03 05:28:48,931 	Gloss Reference :	A B+C+D+E
2024-02-03 05:28:48,931 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:28:48,931 	Gloss Alignment :	         
2024-02-03 05:28:48,931 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:28:48,932 	Text Reference  :	neeraj's father satish  kumar expressed immense pride in   his   son's achievement
2024-02-03 05:28:48,932 	Text Hypothesis :	******** ****** members of    the       support staff head coach rahul dravid     
2024-02-03 05:28:48,932 	Text Alignment  :	D        D      S       S     S         S       S     S    S     S     S          
2024-02-03 05:28:48,932 ========================================================================================================================
2024-02-03 05:28:48,933 Logging Sequence: 67_129.00
2024-02-03 05:28:48,933 	Gloss Reference :	A B+C+D+E
2024-02-03 05:28:48,933 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:28:48,933 	Gloss Alignment :	         
2024-02-03 05:28:48,933 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:28:48,934 	Text Reference  :	*** *** **** *** lee    stressed on 3  points
2024-02-03 05:28:48,934 	Text Hypothesis :	but why they are always want     to be sent  
2024-02-03 05:28:48,934 	Text Alignment  :	I   I   I    I   S      S        S  S  S     
2024-02-03 05:28:48,934 ========================================================================================================================
2024-02-03 05:28:50,391 Epoch 722: Total Training Recognition Loss 0.14  Total Training Translation Loss 14.74 
2024-02-03 05:28:50,391 EPOCH 723
2024-02-03 05:28:54,492 [Epoch: 723 Step: 00096100] Batch Recognition Loss:   0.000758 => Gls Tokens per Sec:     1444 || Batch Translation Loss:   0.202898 => Txt Tokens per Sec:     4070 || Lr: 0.000050
2024-02-03 05:28:57,886 Epoch 723: Total Training Recognition Loss 0.24  Total Training Translation Loss 9.38 
2024-02-03 05:28:57,887 EPOCH 724
2024-02-03 05:28:59,967 [Epoch: 724 Step: 00096200] Batch Recognition Loss:   0.001151 => Gls Tokens per Sec:     1578 || Batch Translation Loss:   0.014656 => Txt Tokens per Sec:     4387 || Lr: 0.000050
2024-02-03 05:29:05,083 Epoch 724: Total Training Recognition Loss 0.19  Total Training Translation Loss 4.18 
2024-02-03 05:29:05,083 EPOCH 725
2024-02-03 05:29:05,549 [Epoch: 725 Step: 00096300] Batch Recognition Loss:   0.000634 => Gls Tokens per Sec:     1375 || Batch Translation Loss:   0.042092 => Txt Tokens per Sec:     3886 || Lr: 0.000050
2024-02-03 05:29:11,176 [Epoch: 725 Step: 00096400] Batch Recognition Loss:   0.000391 => Gls Tokens per Sec:     1422 || Batch Translation Loss:   0.020578 => Txt Tokens per Sec:     3995 || Lr: 0.000050
2024-02-03 05:29:12,600 Epoch 725: Total Training Recognition Loss 0.12  Total Training Translation Loss 2.96 
2024-02-03 05:29:12,600 EPOCH 726
2024-02-03 05:29:16,675 [Epoch: 726 Step: 00096500] Batch Recognition Loss:   0.001241 => Gls Tokens per Sec:     1473 || Batch Translation Loss:   0.017663 => Txt Tokens per Sec:     4072 || Lr: 0.000050
2024-02-03 05:29:20,144 Epoch 726: Total Training Recognition Loss 0.10  Total Training Translation Loss 2.77 
2024-02-03 05:29:20,144 EPOCH 727
2024-02-03 05:29:22,448 [Epoch: 727 Step: 00096600] Batch Recognition Loss:   0.000999 => Gls Tokens per Sec:     1459 || Batch Translation Loss:   0.010847 => Txt Tokens per Sec:     4083 || Lr: 0.000050
2024-02-03 05:29:27,599 Epoch 727: Total Training Recognition Loss 0.09  Total Training Translation Loss 2.96 
2024-02-03 05:29:27,599 EPOCH 728
2024-02-03 05:29:28,154 [Epoch: 728 Step: 00096700] Batch Recognition Loss:   0.000275 => Gls Tokens per Sec:     1306 || Batch Translation Loss:   0.023488 => Txt Tokens per Sec:     3811 || Lr: 0.000050
2024-02-03 05:29:33,981 [Epoch: 728 Step: 00096800] Batch Recognition Loss:   0.000581 => Gls Tokens per Sec:     1373 || Batch Translation Loss:   0.010898 => Txt Tokens per Sec:     3837 || Lr: 0.000050
2024-02-03 05:29:35,240 Epoch 728: Total Training Recognition Loss 0.08  Total Training Translation Loss 2.77 
2024-02-03 05:29:35,241 EPOCH 729
2024-02-03 05:29:39,330 [Epoch: 729 Step: 00096900] Batch Recognition Loss:   0.000226 => Gls Tokens per Sec:     1487 || Batch Translation Loss:   0.007495 => Txt Tokens per Sec:     4166 || Lr: 0.000050
2024-02-03 05:29:42,686 Epoch 729: Total Training Recognition Loss 0.09  Total Training Translation Loss 3.73 
2024-02-03 05:29:42,687 EPOCH 730
2024-02-03 05:29:45,103 [Epoch: 730 Step: 00097000] Batch Recognition Loss:   0.000188 => Gls Tokens per Sec:     1424 || Batch Translation Loss:   0.017229 => Txt Tokens per Sec:     3958 || Lr: 0.000050
2024-02-03 05:29:50,205 Epoch 730: Total Training Recognition Loss 0.07  Total Training Translation Loss 3.86 
2024-02-03 05:29:50,205 EPOCH 731
2024-02-03 05:29:50,712 [Epoch: 731 Step: 00097100] Batch Recognition Loss:   0.000351 => Gls Tokens per Sec:     1581 || Batch Translation Loss:   0.135079 => Txt Tokens per Sec:     4690 || Lr: 0.000050
2024-02-03 05:29:56,440 [Epoch: 731 Step: 00097200] Batch Recognition Loss:   0.000253 => Gls Tokens per Sec:     1397 || Batch Translation Loss:   0.039430 => Txt Tokens per Sec:     3891 || Lr: 0.000050
2024-02-03 05:29:57,851 Epoch 731: Total Training Recognition Loss 0.13  Total Training Translation Loss 6.64 
2024-02-03 05:29:57,852 EPOCH 732
2024-02-03 05:30:02,124 [Epoch: 732 Step: 00097300] Batch Recognition Loss:   0.000133 => Gls Tokens per Sec:     1442 || Batch Translation Loss:   0.016694 => Txt Tokens per Sec:     4086 || Lr: 0.000050
2024-02-03 05:30:05,141 Epoch 732: Total Training Recognition Loss 0.19  Total Training Translation Loss 7.01 
2024-02-03 05:30:05,142 EPOCH 733
2024-02-03 05:30:07,560 [Epoch: 733 Step: 00097400] Batch Recognition Loss:   0.000205 => Gls Tokens per Sec:     1457 || Batch Translation Loss:   0.036336 => Txt Tokens per Sec:     3986 || Lr: 0.000050
2024-02-03 05:30:12,842 Epoch 733: Total Training Recognition Loss 0.13  Total Training Translation Loss 9.25 
2024-02-03 05:30:12,843 EPOCH 734
2024-02-03 05:30:13,437 [Epoch: 734 Step: 00097500] Batch Recognition Loss:   0.001159 => Gls Tokens per Sec:     1481 || Batch Translation Loss:   0.016251 => Txt Tokens per Sec:     3761 || Lr: 0.000050
2024-02-03 05:30:19,079 [Epoch: 734 Step: 00097600] Batch Recognition Loss:   0.001161 => Gls Tokens per Sec:     1416 || Batch Translation Loss:   0.036176 => Txt Tokens per Sec:     3944 || Lr: 0.000050
2024-02-03 05:30:20,288 Epoch 734: Total Training Recognition Loss 0.12  Total Training Translation Loss 6.54 
2024-02-03 05:30:20,288 EPOCH 735
2024-02-03 05:30:24,415 [Epoch: 735 Step: 00097700] Batch Recognition Loss:   0.001388 => Gls Tokens per Sec:     1512 || Batch Translation Loss:   0.018375 => Txt Tokens per Sec:     4221 || Lr: 0.000050
2024-02-03 05:30:27,458 Epoch 735: Total Training Recognition Loss 0.15  Total Training Translation Loss 4.97 
2024-02-03 05:30:27,459 EPOCH 736
2024-02-03 05:30:29,857 [Epoch: 736 Step: 00097800] Batch Recognition Loss:   0.000141 => Gls Tokens per Sec:     1501 || Batch Translation Loss:   0.021190 => Txt Tokens per Sec:     4147 || Lr: 0.000050
2024-02-03 05:30:34,634 Epoch 736: Total Training Recognition Loss 0.11  Total Training Translation Loss 6.03 
2024-02-03 05:30:34,634 EPOCH 737
2024-02-03 05:30:35,160 [Epoch: 737 Step: 00097900] Batch Recognition Loss:   0.000253 => Gls Tokens per Sec:     1829 || Batch Translation Loss:   0.031360 => Txt Tokens per Sec:     4688 || Lr: 0.000050
2024-02-03 05:30:40,903 [Epoch: 737 Step: 00098000] Batch Recognition Loss:   0.000439 => Gls Tokens per Sec:     1393 || Batch Translation Loss:   0.044469 => Txt Tokens per Sec:     3911 || Lr: 0.000050
2024-02-03 05:30:52,100 Validation result at epoch 737, step    98000: duration: 11.1972s
	Recognition Beam Size: 1	Translation Beam Size: 1	Translation Beam Alpha: -1
	Recognition Loss: 8.17295	Translation Loss: 86712.15625	PPL: 8153.86670
	Eval Metric: BLEU
	WER 2.76	(DEL: 0.07,	INS: 0.00,	SUB: 2.69)
	BLEU-4 0.00	(BLEU-1: 9.20,	BLEU-2: 2.09,	BLEU-3: 0.66,	BLEU-4: 0.00)
	CHRF 16.40	ROUGE 7.79
2024-02-03 05:30:52,102 Logging Recognition and Translation Outputs
2024-02-03 05:30:52,102 ========================================================================================================================
2024-02-03 05:30:52,102 Logging Sequence: 116_133.00
2024-02-03 05:30:52,102 	Gloss Reference :	A B+C+D+E
2024-02-03 05:30:52,102 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:30:52,103 	Gloss Alignment :	         
2024-02-03 05:30:52,103 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:30:52,103 	Text Reference  :	he expressed his   sadness  in   the ****** *** *** caption    
2024-02-03 05:30:52,103 	Text Hypothesis :	it is        being reported that the reason was not comfortable
2024-02-03 05:30:52,104 	Text Alignment  :	S  S         S     S        S        I      I   I   S          
2024-02-03 05:30:52,104 ========================================================================================================================
2024-02-03 05:30:52,104 Logging Sequence: 144_45.00
2024-02-03 05:30:52,104 	Gloss Reference :	A B+C+D+E
2024-02-03 05:30:52,104 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:30:52,104 	Gloss Alignment :	         
2024-02-03 05:30:52,104 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:30:52,105 	Text Reference  :	****** *** ********* ******* legendary cricketer sachin tendulkar tweeted the ***** ******** ** viral video 
2024-02-03 05:30:52,105 	Text Hypothesis :	people are predicted current skipped   babar     azam   to        become  the prime minister in the   future
2024-02-03 05:30:52,105 	Text Alignment  :	I      I   I         I       S         S         S      S         S           I     I        I  S     S     
2024-02-03 05:30:52,106 ========================================================================================================================
2024-02-03 05:30:52,106 Logging Sequence: 174_174.00
2024-02-03 05:30:52,106 	Gloss Reference :	A B+C+D+E
2024-02-03 05:30:52,106 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:30:52,106 	Gloss Alignment :	         
2024-02-03 05:30:52,106 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:30:52,107 	Text Reference  :	england all-rounder natalie sciver-brunt was   roped   in  by  mumbai indians for   rs   32      crore
2024-02-03 05:30:52,107 	Text Hypothesis :	******* *********** later   reporters    asked cummins why did he     call    usman back cummins said 
2024-02-03 05:30:52,108 	Text Alignment  :	D       D           S       S            S     S       S   S   S      S       S     S    S       S    
2024-02-03 05:30:52,108 ========================================================================================================================
2024-02-03 05:30:52,108 Logging Sequence: 162_55.00
2024-02-03 05:30:52,108 	Gloss Reference :	A B+C+D+E
2024-02-03 05:30:52,108 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:30:52,108 	Gloss Alignment :	         
2024-02-03 05:30:52,108 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:30:52,110 	Text Reference  :	people do  not   understand that the ****** * **** team practices very hard unfortunately they    lost this time   
2024-02-03 05:30:52,110 	Text Hypothesis :	for    the third offence    in   the season a fine of   rs        30   lakh is            imposed on   the  captain
2024-02-03 05:30:52,110 	Text Alignment  :	S      S   S     S          S        I      I I    S    S         S    S    S             S       S    S    S      
2024-02-03 05:30:52,111 ========================================================================================================================
2024-02-03 05:30:52,111 Logging Sequence: 138_182.00
2024-02-03 05:30:52,111 	Gloss Reference :	A B+C+D+E
2024-02-03 05:30:52,111 	Gloss Hypothesis:	A B+C+D+E
2024-02-03 05:30:52,111 	Gloss Alignment :	         
2024-02-03 05:30:52,111 	--------------------------------------------------------------------------------------------------------------------
2024-02-03 05:30:52,112 	Text Reference  :	there is a  mural of   marcus rashford's face in   machester
2024-02-03 05:30:52,112 	Text Hypothesis :	***** ** in one   over bumrah scored     35   runs wow      
2024-02-03 05:30:52,112 	Text Alignment  :	D     D  S  S     S    S      S          S    S    S        
2024-02-03 05:30:52,112 ========================================================================================================================
2024-02-03 05:30:52,116 Training ended since there were no improvements inthe last learning rate step: 0.000050
2024-02-03 05:30:52,117 Best validation result at step    46000:   0.95 eval_metric.
2024-02-03 05:31:16,859 ------------------------------------------------------------
2024-02-03 05:31:16,859 [DEV] partition [RECOGNITION] experiment [BW]: 1
2024-02-03 05:31:28,403 finished in 11.5440s 
2024-02-03 05:31:28,404 ************************************************************
2024-02-03 05:31:28,404 [DEV] partition [RECOGNITION] results:
	New Best CTC Decode Beam Size: 1
	WER 3.47	(DEL: 0.21,	INS: 0.00,	SUB: 3.25)
2024-02-03 05:31:28,404 ************************************************************
2024-02-03 05:31:28,404 ------------------------------------------------------------
2024-02-03 05:31:28,404 [DEV] partition [RECOGNITION] experiment [BW]: 2
2024-02-03 05:31:39,215 finished in 10.8108s 
2024-02-03 05:31:39,216 ------------------------------------------------------------
2024-02-03 05:31:39,216 [DEV] partition [RECOGNITION] experiment [BW]: 3
2024-02-03 05:31:49,857 finished in 10.6417s 
2024-02-03 05:31:49,857 ------------------------------------------------------------
2024-02-03 05:31:49,858 [DEV] partition [RECOGNITION] experiment [BW]: 4
2024-02-03 05:32:00,507 finished in 10.6488s 
2024-02-03 05:32:00,508 ------------------------------------------------------------
2024-02-03 05:32:00,508 [DEV] partition [RECOGNITION] experiment [BW]: 5
2024-02-03 05:32:11,134 finished in 10.6256s 
2024-02-03 05:32:11,134 ------------------------------------------------------------
2024-02-03 05:32:11,134 [DEV] partition [RECOGNITION] experiment [BW]: 6
2024-02-03 05:32:22,044 finished in 10.9100s 
2024-02-03 05:32:22,044 ------------------------------------------------------------
2024-02-03 05:32:22,044 [DEV] partition [RECOGNITION] experiment [BW]: 7
2024-02-03 05:32:32,701 finished in 10.6576s 
2024-02-03 05:32:32,702 ------------------------------------------------------------
2024-02-03 05:32:32,702 [DEV] partition [RECOGNITION] experiment [BW]: 8
2024-02-03 05:32:43,608 finished in 10.9057s 
2024-02-03 05:32:43,609 ------------------------------------------------------------
2024-02-03 05:32:43,609 [DEV] partition [RECOGNITION] experiment [BW]: 9
2024-02-03 05:32:54,239 finished in 10.6304s 
2024-02-03 05:32:54,240 ------------------------------------------------------------
2024-02-03 05:32:54,240 [DEV] partition [RECOGNITION] experiment [BW]: 10
2024-02-03 05:33:05,520 finished in 11.2801s 
2024-02-03 05:33:05,521 ============================================================
2024-02-03 05:33:16,196 [DEV] partition [Translation] results:
	New Best Translation Beam Size: 1 and Alpha: -1
	BLEU-4 0.95	(BLEU-1: 10.88,	BLEU-2: 3.50,	BLEU-3: 1.62,	BLEU-4: 0.95)
	CHRF 17.09	ROUGE 9.16
2024-02-03 05:33:16,196 ------------------------------------------------------------
2024-02-03 05:51:21,214 ************************************************************
2024-02-03 05:51:21,215 [DEV] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 1
	Best Translation Beam Size: 1 and Alpha: -1
	WER 3.47	(DEL: 0.21,	INS: 0.00,	SUB: 3.25)
	BLEU-4 0.95	(BLEU-1: 10.88,	BLEU-2: 3.50,	BLEU-3: 1.62,	BLEU-4: 0.95)
	CHRF 17.09	ROUGE 9.16
2024-02-03 05:51:21,215 ************************************************************
2024-02-03 05:51:31,872 [TEST] partition [Recognition & Translation] results:
	Best CTC Decode Beam Size: 1
	Best Translation Beam Size: 1 and Alpha: -1
	WER 3.81	(DEL: 0.14,	INS: 0.00,	SUB: 3.67)
	BLEU-4 0.54	(BLEU-1: 9.84,	BLEU-2: 2.71,	BLEU-3: 1.07,	BLEU-4: 0.54)
	CHRF 16.87	ROUGE 8.22
2024-02-03 05:51:31,873 ************************************************************
