{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d162ada",
   "metadata": {},
   "source": [
    "# **Import all required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa8d849-bde6-4b5b-9511-583d502d89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "# import tensorflow_addons as tfa\n",
    "# import keras_tuner\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7, EfficientNetB0 \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras import mixed_precision\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import platform\n",
    "from progress.bar import Bar\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28758cca-200b-402f-8cf4-86dfe4c08f78",
   "metadata": {},
   "source": [
    "# **Enable fp16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f46b74-6982-4840-836f-19f54fe695b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "tf.keras.backend.clear_session()\n",
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17e323-06f2-4938-8f8b-6d9dbc7cddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25995e90",
   "metadata": {},
   "source": [
    "# **Mention the destination of the files to access:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162b72d-11ab-4035-bb54-c58a390b0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# validation\n",
    "vw_dest = \"Dataset/excels/ISH_News_Sports final VAL.xlsx\"\n",
    "vo_dest = \"Dataset/Pickles/excel_dataVal.pickle\"\n",
    "vf_dest = \"Dataset/Final folder for frames\"\n",
    "\n",
    "# test\n",
    "tw_dest = \"Dataset/excels/ISH_News_Sports final TEST.xlsx\"\n",
    "to_dest = \"Dataset/Pickles/excel_dataTest.pickle\"\n",
    "tf_dest = \"Dataset/Final folder for frames\"\n",
    "\n",
    "# train\n",
    "w_dest = \"Dataset/excels/ISH_News_Sports final TRAIN.xlsx\"\n",
    "o_dest = \"Dataset/Pickles/excel_data.pickle\"\n",
    "f_dest = \"Dataset/Final folder for frames\"\n",
    "\n",
    "# Batch Size\n",
    "batch_size_user = 64\n",
    "# batch_size_user = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535875b-3733-4340-ace8-19029d5857fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls():\n",
    "    system = platform.system()\n",
    "    if system == 'Windows':\n",
    "        os.system('cls')\n",
    "    elif system == 'Linux':\n",
    "        os.system('clear')\n",
    "    elif system == 'MacOS':\n",
    "        os.system('clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eafff1",
   "metadata": {},
   "source": [
    "# **Initialise the CNN model here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc80e6-90f3-4254-9a40-67042ebca1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB7(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe5458",
   "metadata": {},
   "source": [
    "# **Function for extraction of features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96856f6-6a00-4a01-a7a3-a7b9ba39693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_batch(filenames, destination):\n",
    "    features_listofList = []\n",
    "    for filename in filenames:\n",
    "        input_string = filename\n",
    "        pattern = r'\\d+'\n",
    "        match = re.search(pattern, input_string)\n",
    "        if match:\n",
    "            first_match = match.group()\n",
    "            input_folder = os.path.join(os.getcwd(), destination, first_match, input_string)\n",
    "            file_paths_frames = [os.path.join(input_folder, file) for file in sorted(os.listdir(input_folder)) if file.endswith(\".jpg\")]\n",
    "\n",
    "            batch_images = []\n",
    "            for frame_file in file_paths_frames:\n",
    "                image = cv2.imread(frame_file)\n",
    "                x1, y1 = 535, 0\n",
    "                x2, y2 = 1385, 1080\n",
    "                image = image[y1:y2, x1:x2]\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "                image = preprocess_input(image)\n",
    "                image = np.expand_dims(image, axis=0)\n",
    "                batch_images.append(image)\n",
    "\n",
    "            batch_images = np.concatenate(batch_images, axis=0)\n",
    "            spatial_embeddings_batch = feature_extractor.predict(batch_images)\n",
    "\n",
    "            for spatial_embedding in spatial_embeddings_batch:\n",
    "                features_listofList.append(spatial_embedding)\n",
    "        else:\n",
    "            print(\"No match found.\")\n",
    "            return None\n",
    "\n",
    "    return torch.tensor(np.array(features_listofList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa41352",
   "metadata": {},
   "source": [
    "# **Function to create the pickle file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e172c15-2d77-48c7-b475-8894b471d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pickle_batch(workbook_dest, output_dest, frame_dest):\n",
    "    # load the excel file\n",
    "    workbook = load_workbook(workbook_dest)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    excel_data = []\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        excel_data.append(row)\n",
    "\n",
    "    # Get the features in batches\n",
    "    list_of_inputs = []\n",
    "    batch_size = batch_size_user  # Adjust as needed\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for i in tqdm(range(0, len(excel_data), batch_size), desc=\"Processing Batches\", unit=\"batch\"):\n",
    "            batch_filenames = [str(tmp[0]) for tmp in excel_data[i:i+batch_size]]\n",
    "            features = get_features_batch(batch_filenames, frame_dest)\n",
    "\n",
    "            for tmp, feature in zip(excel_data[i:i+batch_size], features):\n",
    "                if feature is not None:\n",
    "                    data_dict = {\n",
    "                        'name': tmp[0],\n",
    "                        'signer': tmp[1],\n",
    "                        'gloss': tmp[2],\n",
    "                        'text': tmp[3],\n",
    "                        'sign': feature + 1e-8\n",
    "                    }\n",
    "                    list_of_inputs.append(data_dict)\n",
    "\n",
    "    with gzip.open(os.path.join(os.getcwd(), output_dest), 'wb') as f:\n",
    "        pickle.dump(list_of_inputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418f4d2",
   "metadata": {},
   "source": [
    "# **Call for training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a3a0d-abd5-455a-a485-58ac1b90fd4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing pickle\n",
    "create_pickle_batch(tw_dest, to_dest, tf_dest)\n",
    "\n",
    "print(\"Testing pickle Creation Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882db06-bc47-4343-a1e3-47da154df499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation pickle\n",
    "create_pickle_batch(vw_dest, vo_dest, vf_dest)\n",
    "\n",
    "print(\"Validation/dev pickle Creation Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30d5b2-98a0-4b51-8aaf-cfd3bb0f4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training pickle\n",
    "create_pickle_batch(w_dest, o_dest, f_dest)\n",
    "\n",
    "print(\"Training pickle Creation Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc94e7-e87a-4f1a-9a85-bea2eb7944a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
